2019-09-29 12:16:00,763 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:00,840 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:00,925 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:00,928 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:00,946 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @951ms
2019-09-29 12:16:01,047 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-29 12:16:01,047 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-29 12:16:01,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-29 12:16:01,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-29 12:16:01,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-29 12:16:01,049 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-29 12:16:01,061 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:01,062 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:01,063 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:01,407 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@815b41f
2019-09-29 12:16:01,408 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-29 12:16:01,485 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-29 12:16:01,486 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-29 12:16:01,488 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-29 12:16:01,621 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-29 12:16:01,638 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:01,756 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(137)) - No pipeline exists in current db
2019-09-29 12:16:01,759 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:01,929 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-29 12:16:02,322 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:02,491 [Socket Reader #1 for port 44621] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44621
2019-09-29 12:16:02,527 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:02,528 [Socket Reader #1 for port 38953] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38953
2019-09-29 12:16:02,538 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:02,539 [Socket Reader #1 for port 38150] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38150
2019-09-29 12:16:02,564 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-29 12:16:02,701 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:02,715 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:02,725 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:02,727 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-29 12:16:02,727 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:02,727 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:02,753 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:38150
2019-09-29 12:16:02,801 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-29 12:16:02,812 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-29 12:16:02,813 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-29 12:16:03,018 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:38150
2019-09-29 12:16:03,018 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:03,018 [IPC Server listener on 38150] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38150: starting
2019-09-29 12:16:03,021 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38953
2019-09-29 12:16:03,023 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:38953
2019-09-29 12:16:03,023 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:03,023 [IPC Server listener on 38953] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38953: starting
2019-09-29 12:16:03,025 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:44621
2019-09-29 12:16:03,026 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:44621
2019-09-29 12:16:03,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:03,026 [IPC Server listener on 44621] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44621: starting
2019-09-29 12:16:03,030 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38318
2019-09-29 12:16:03,031 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:03,064 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bf1ec20{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:03,064 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e858e0a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:03,133 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5bd73d1a{/,file:///tmp/jetty-0.0.0.0-38318-scm-_-any-8551185977336039390.dir/webapp/,AVAILABLE}{/scm}
2019-09-29 12:16:03,138 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42a9a63e{HTTP/1.1,[http/1.1]}{0.0.0.0:38318}
2019-09-29 12:16:03,138 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3144ms
2019-09-29 12:16:03,141 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-29 12:16:03,141 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-29 12:16:03,142 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:38318
2019-09-29 12:16:03,148 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@596df867] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-29 12:16:03,149 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:03,276 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:03,276 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:03,279 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-1: 127.0.0.1:12870
2019-09-29 12:16:03,279 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-1: 127.0.0.1:12871
2019-09-29 12:16:03,280 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-1, RPC Address: localhost:12868 and Ratis port: 12872
2019-09-29 12:16:04,017 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:04,027 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-29 12:16:04,027 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-29 12:16:04,027 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-29 12:16:04,028 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-29 12:16:04,028 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-29 12:16:04,028 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-29 12:16:04,028 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-29 12:16:04,029 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-29 12:16:04,029 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-29 12:16:04,029 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-29 12:16:04,029 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-29 12:16:04,030 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-29 12:16:04,030 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-29 12:16:04,030 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-29 12:16:04,030 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-29 12:16:04,031 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-29 12:16:04,031 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-29 12:16:04,031 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-29 12:16:04,031 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-29 12:16:04,032 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-29 12:16:04,032 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-29 12:16:04,032 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-29 12:16:04,032 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:04,033 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:04,033 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:04,753 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3430)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-29 12:16:04,790 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:04,988 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:12872, localhost:12878, localhost:12884
2019-09-29 12:16:05,040 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:05,123 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:05,128 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 12872 (custom)
2019-09-29 12:16:05,129 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-29 12:16:05,130 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:05,131 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:05,132 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:05,363 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis] (custom)
2019-09-29 12:16:05,370 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-1: addNew group-523986131536:[omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878] returns group-523986131536:java.util.concurrent.CompletableFuture@148c7c4b[Not completed]
2019-09-29 12:16:05,372 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1389)) - OzoneManager Ratis server initialized at port 12872
2019-09-29 12:16:05,375 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:05,376 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:05,379 [main] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-09-29 12:16:05,391 [pool-22-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - omNode-1: new RaftServerImpl for group-523986131536:[omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878] with OzoneManagerStateMachine:uninitialized
2019-09-29 12:16:05,394 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-29 12:16:05,395 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-29 12:16:05,395 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-09-29 12:16:05,396 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:05,397 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:05,404 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:05,406 [Socket Reader #1 for port 12868] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 12868
2019-09-29 12:16:05,409 [pool-22-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-1@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:05,409 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis] (custom)
2019-09-29 12:16:05,424 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-09-29 12:16:05,445 [main] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:12868
2019-09-29 12:16:05,445 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-29 12:16:05,446 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer omNode-1 at port 12872
2019-09-29 12:16:05,453 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:05,490 [pool-22-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-09-29 12:16:05,500 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-09-29 12:16:05,507 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:05,515 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:05,516 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:05,519 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:05,525 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:05,532 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new omNode-1@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-09-29 12:16:05,533 [pool-22-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-29 12:16:05,539 [pool-22-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-29 12:16:05,571 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-29 12:16:05,572 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-29 12:16:05,575 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:05,575 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:05,576 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-29 12:16:05,576 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:05,578 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:05,578 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:05,578 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:05,588 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-29 12:16:05,593 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:05,598 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:05,598 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-29 12:16:05,599 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-29 12:16:05,599 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:05,627 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - omNode-1@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null
2019-09-29 12:16:05,631 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-1@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:05,633 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start FollowerState
2019-09-29 12:16:05,636 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-09-29 12:16:05,637 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-1: start RPC server
2019-09-29 12:16:05,773 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-1: GrpcService started, listening on 0.0.0.0/0.0.0.0:12872
2019-09-29 12:16:05,786 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:05,786 [IPC Server listener on 12868] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 12868: starting
2019-09-29 12:16:05,792 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:12870
2019-09-29 12:16:05,795 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:05,796 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:05,798 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:05,799 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-29 12:16:05,800 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:05,800 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:05,802 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 12870
2019-09-29 12:16:05,802 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:05,804 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a2909ae{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:05,805 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3f702946{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:05,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f668f29{/,file:///tmp/jetty-0.0.0.0-12870-ozoneManager-_-any-3621843178112774808.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-29 12:16:05,853 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@716e431d{HTTP/1.1,[http/1.1]}{0.0.0.0:12870}
2019-09-29 12:16:05,854 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5860ms
2019-09-29 12:16:05,855 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:05,857 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:12870
2019-09-29 12:16:05,859 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:12868
2019-09-29 12:16:05,860 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:05,885 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:05,886 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:05,888 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-2: 127.0.0.1:12876
2019-09-29 12:16:05,888 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-2: 127.0.0.1:12877
2019-09-29 12:16:05,889 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-2, RPC Address: localhost:12874 and Ratis port: 12878
2019-09-29 12:16:05,896 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:05,897 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-29 12:16:05,897 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-29 12:16:05,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-29 12:16:05,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-29 12:16:05,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-29 12:16:05,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-29 12:16:05,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-29 12:16:05,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-29 12:16:05,900 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-29 12:16:05,900 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-29 12:16:05,900 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-29 12:16:05,900 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-29 12:16:05,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-29 12:16:05,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-29 12:16:05,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-29 12:16:05,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-29 12:16:05,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-29 12:16:05,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-29 12:16:05,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-29 12:16:05,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-29 12:16:05,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-29 12:16:05,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-29 12:16:05,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:05,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:05,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:06,664 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:06,666 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3430)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-29 12:16:06,666 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:12878, localhost:12872, localhost:12884
2019-09-29 12:16:06,670 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:06,670 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:06,670 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 12878 (custom)
2019-09-29 12:16:06,671 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-29 12:16:06,671 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:06,671 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:06,672 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:06,673 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis] (custom)
2019-09-29 12:16:06,673 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-2: addNew group-523986131536:[omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878] returns group-523986131536:java.util.concurrent.CompletableFuture@2412a42b[Not completed]
2019-09-29 12:16:06,674 [pool-40-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - omNode-2: new RaftServerImpl for group-523986131536:[omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878] with OzoneManagerStateMachine:uninitialized
2019-09-29 12:16:06,674 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1389)) - OzoneManager Ratis server initialized at port 12878
2019-09-29 12:16:06,675 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-29 12:16:06,675 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:06,675 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-29 12:16:06,675 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:06,676 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-09-29 12:16:06,676 [main] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-09-29 12:16:06,676 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:06,676 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:06,677 [pool-40-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-2@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:06,677 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis] (custom)
2019-09-29 12:16:06,678 [pool-40-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-09-29 12:16:06,680 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:06,681 [Socket Reader #1 for port 12874] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 12874
2019-09-29 12:16:06,701 [pool-40-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:06,708 [main] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:12874
2019-09-29 12:16:06,708 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-29 12:16:06,708 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer omNode-2 at port 12878
2019-09-29 12:16:06,732 [pool-40-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-09-29 12:16:06,733 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-09-29 12:16:06,733 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:06,734 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:06,734 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:06,734 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:06,735 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:06,735 [pool-40-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new omNode-2@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-09-29 12:16:06,746 [Thread-95] INFO  impl.FollowerState (FollowerState.java:run(106)) - omNode-1:group-523986131536 changes to CANDIDATE, lastRpcTime:1112, electionTimeout:1110ms
2019-09-29 12:16:06,756 [Thread-95] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-1: shutdown FollowerState
2019-09-29 12:16:06,757 [Thread-95] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-1@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-29 12:16:06,761 [Thread-95] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderElection
2019-09-29 12:16:06,762 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-29 12:16:06,763 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-29 12:16:06,764 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:06,764 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:06,764 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-29 12:16:06,764 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:06,764 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:06,765 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:06,765 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:06,765 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-29 12:16:06,766 [pool-40-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:06,766 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:06,767 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-29 12:16:06,767 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-29 12:16:06,767 [pool-40-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:06,773 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - omNode-2@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null
2019-09-29 12:16:06,774 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-2@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:06,774 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-09-29 12:16:06,775 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-09-29 12:16:06,776 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-2: start RPC server
2019-09-29 12:16:06,779 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-2: GrpcService started, listening on 0.0.0.0/0.0.0.0:12878
2019-09-29 12:16:06,782 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:06,782 [IPC Server listener on 12874] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 12874: starting
2019-09-29 12:16:06,787 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - omNode-1@group-523986131536:LeaderElection1: begin an election at term 1 for -1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null
2019-09-29 12:16:06,787 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:12876
2019-09-29 12:16:06,790 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:06,790 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:06,793 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:06,795 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-29 12:16:06,796 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:06,796 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:06,797 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 12876
2019-09-29 12:16:06,798 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:06,800 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a2ef072{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:06,801 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f00f851{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:06,865 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68880c21{/,file:///tmp/jetty-0.0.0.0-12876-ozoneManager-_-any-8711465049165327386.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-29 12:16:06,866 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2dd2e270{HTTP/1.1,[http/1.1]}{0.0.0.0:12876}
2019-09-29 12:16:06,867 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6872ms
2019-09-29 12:16:06,868 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:06,868 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:12876
2019-09-29 12:16:06,869 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:12874
2019-09-29 12:16:06,870 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:06,905 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:06,905 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:06,907 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-3: 127.0.0.1:12882
2019-09-29 12:16:06,907 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-3: 127.0.0.1:12883
2019-09-29 12:16:06,907 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-3, RPC Address: localhost:12880 and Ratis port: 12884
2019-09-29 12:16:06,912 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:06,913 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-29 12:16:06,913 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-29 12:16:06,913 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-29 12:16:06,913 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-29 12:16:06,914 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-29 12:16:06,914 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-29 12:16:06,914 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-29 12:16:06,914 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-29 12:16:06,914 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-29 12:16:06,915 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-29 12:16:06,915 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-29 12:16:06,915 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-29 12:16:06,915 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-29 12:16:06,915 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-29 12:16:06,916 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-29 12:16:06,916 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-29 12:16:06,916 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-29 12:16:06,916 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-29 12:16:06,916 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-29 12:16:06,917 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-29 12:16:06,917 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-29 12:16:06,917 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-29 12:16:06,918 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:06,918 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:06,918 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:07,192 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-1@group-523986131536:LeaderElection1 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:12884
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-29 12:16:07,338 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-2@group-523986131536: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:omNode-1
2019-09-29 12:16:07,338 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-09-29 12:16:07,338 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-09-29 12:16:07,338 [Thread-134] INFO  impl.FollowerState (FollowerState.java:run(115)) - omNode-2: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-29 12:16:07,391 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-1@group-523986131536:LeaderElection1: Election PASSED; received 1 response(s) [omNode-1<-omNode-2#0:OK-t1] and 1 exception(s); omNode-1@group-523986131536:t1, leader=null, voted=omNode-1, raftlog=omNode-1@group-523986131536-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null
2019-09-29 12:16:07,392 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:12884
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-29 12:16:07,395 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-1: shutdown LeaderElection
2019-09-29 12:16:07,396 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-1@group-523986131536: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-29 12:16:07,396 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - omNode-1@group-523986131536: change Leader from null to omNode-1 at term 1 for becomeLeader, leader elected after 1896ms
2019-09-29 12:16:07,405 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-29 12:16:07,406 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-29 12:16:07,410 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-29 12:16:07,416 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-29 12:16:07,416 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-29 12:16:07,417 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-29 12:16:07,451 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-29 12:16:07,451 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:07,452 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-09-29 12:16:07,456 [omNode-1@group-523986131536:LeaderElection1] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-29 12:16:07,456 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:07,457 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:07,458 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-29 12:16:07,458 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:07,458 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-09-29 12:16:07,459 [omNode-1@group-523986131536:LeaderElection1] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-29 12:16:07,459 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:07,459 [omNode-1@group-523986131536:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:07,463 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderState
2019-09-29 12:16:07,486 [omNode-1@group-523986131536:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:07,496 [omNode-1@group-523986131536:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - omNode-1@group-523986131536: set configuration 0: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null at 0
2019-09-29 12:16:07,524 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-29 12:16:07,534 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 0 -> 0
2019-09-29 12:16:07,539 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - omNode-2@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 805ms
2019-09-29 12:16:07,564 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - omNode-2@group-523986131536: set configuration 0: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null at 0
2019-09-29 12:16:07,565 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:07,638 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:07,640 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3430)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-29 12:16:07,640 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:12884, localhost:12872, localhost:12878
2019-09-29 12:16:07,643 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:07,643 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:07,644 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 12884 (custom)
2019-09-29 12:16:07,644 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-29 12:16:07,644 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:07,645 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:07,645 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:07,646 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis] (custom)
2019-09-29 12:16:07,647 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-3: addNew group-523986131536:[omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878] returns group-523986131536:java.util.concurrent.CompletableFuture@7a04fea7[Not completed]
2019-09-29 12:16:07,647 [pool-56-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - omNode-3: new RaftServerImpl for group-523986131536:[omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878] with OzoneManagerStateMachine:uninitialized
2019-09-29 12:16:07,647 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1389)) - OzoneManager Ratis server initialized at port 12884
2019-09-29 12:16:07,648 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-29 12:16:07,648 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:07,649 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-29 12:16:07,649 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:07,649 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-09-29 12:16:07,649 [main] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-09-29 12:16:07,649 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:07,650 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:07,650 [pool-56-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-3@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:07,651 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis] (custom)
2019-09-29 12:16:07,651 [pool-56-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-09-29 12:16:07,653 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:07,654 [Socket Reader #1 for port 12880] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 12880
2019-09-29 12:16:07,675 [pool-56-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:07,684 [main] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:12880
2019-09-29 12:16:07,684 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-29 12:16:07,684 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer omNode-3 at port 12884
2019-09-29 12:16:07,698 [pool-56-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-09-29 12:16:07,699 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-09-29 12:16:07,699 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:07,700 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:07,700 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:07,700 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:07,700 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:07,701 [pool-56-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new omNode-3@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-09-29 12:16:07,705 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-29 12:16:07,706 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-29 12:16:07,706 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:07,706 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:07,706 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-29 12:16:07,707 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:07,707 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:07,707 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:07,707 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:07,708 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-29 12:16:07,708 [pool-56-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:07,708 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:07,709 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-29 12:16:07,709 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-29 12:16:07,709 [pool-56-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:07,715 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - omNode-3@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null
2019-09-29 12:16:07,715 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-3@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:07,716 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-09-29 12:16:07,717 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-09-29 12:16:07,718 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-3: start RPC server
2019-09-29 12:16:07,720 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-3: GrpcService started, listening on 0.0.0.0/0.0.0.0:12884
2019-09-29 12:16:07,721 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:07,721 [IPC Server listener on 12880] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 12880: starting
2019-09-29 12:16:07,724 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-09-29 12:16:07,724 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-09-29 12:16:07,728 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:12882
2019-09-29 12:16:07,731 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:07,732 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:07,735 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:07,736 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-29 12:16:07,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:07,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:07,738 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 12882
2019-09-29 12:16:07,739 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:07,748 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14ef2482{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:07,750 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75483843{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:07,798 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - omNode-3@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 99ms
2019-09-29 12:16:07,799 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - omNode-3@group-523986131536: set configuration 0: [omNode-3:localhost:12884, omNode-1:localhost:12872, omNode-2:localhost:12878], old=null at 0
2019-09-29 12:16:07,799 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:07,821 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1ac4ccad{/,file:///tmp/jetty-0.0.0.0-12882-ozoneManager-_-any-1931886398320059609.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-29 12:16:07,822 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@fd9ebde{HTTP/1.1,[http/1.1]}{0.0.0.0:12882}
2019-09-29 12:16:07,823 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7828ms
2019-09-29 12:16:07,823 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:07,824 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-09-29 12:16:07,824 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:12882
2019-09-29 12:16:07,825 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:12880
2019-09-29 12:16:07,993 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-29 12:16:08,044 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-lsfh5-224679870 ip:192.168.30.19
2019-09-29 12:16:08,078 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-29 12:16:08,080 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/containers/hdds to VolumeSet
2019-09-29 12:16:08,083 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4cb2918c
2019-09-29 12:16:08,100 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4cb2918c
2019-09-29 12:16:08,157 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:08,158 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:08,158 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-29 12:16:08,158 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-29 12:16:08,158 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:08,158 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:08,159 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:08,159 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis] (custom)
2019-09-29 12:16:08,217 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-29 12:16:08,219 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:08,219 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:08,221 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:08,222 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-29 12:16:08,222 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:08,222 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:08,223 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46505
2019-09-29 12:16:08,223 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:08,225 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b112b13{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:08,225 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ac3f6f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:08,255 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5922d3e9{/,file:///tmp/jetty-0.0.0.0-46505-hddsDatanode-_-any-8076604429393990848.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-29 12:16:08,256 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7d57dbb5{HTTP/1.1,[http/1.1]}{0.0.0.0:46505}
2019-09-29 12:16:08,257 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8262ms
2019-09-29 12:16:08,257 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:08,257 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46505
2019-09-29 12:16:08,260 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:08,265 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@eee1c48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-29 12:16:08,400 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/meta/datanode.id
2019-09-29 12:16:09,261 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:10,262 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:10,340 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-29 12:16:10,343 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-29 12:16:10,344 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb at port 0
2019-09-29 12:16:10,353 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: start RPC server
2019-09-29 12:16:10,357 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: GrpcService started, listening on 0.0.0.0/0.0.0.0:45442
2019-09-29 12:16:10,358 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb is started using port 45442
2019-09-29 12:16:10,361 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb is started using port 40187
2019-09-29 12:16:11,262 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:12,263 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:12,313 [IPC Server handler 0 on 44621] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/5aa9d67d-39e4-4a0b-aa40-855d18bee3fb
2019-09-29 12:16:12,314 [IPC Server handler 0 on 44621] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb{ip: 192.168.30.19, host: pr-hdds-1569-lsfh5-224679870, networkLocation: /default-rack, certSerialId: null}
2019-09-29 12:16:12,320 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-29 12:16:12,321 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-29 12:16:12,321 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-29 12:16:12,404 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: addNew group-DD945D3100DF:[5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:192.168.30.19:45442] returns group-DD945D3100DF:java.util.concurrent.CompletableFuture@2cee6170[Not completed]
2019-09-29 12:16:12,415 [pool-64-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: new RaftServerImpl for group-DD945D3100DF:[5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:192.168.30.19:45442] with ContainerStateMachine:uninitialized
2019-09-29 12:16:12,416 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-29 12:16:12,417 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-29 12:16:12,417 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-29 12:16:12,417 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:12,417 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:12,417 [pool-64-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: ConfigurationManager, init=-1: [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:192.168.30.19:45442], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:12,418 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis] (custom)
2019-09-29 12:16:12,418 [pool-64-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis/02b51e20-6d7f-4000-82ea-dd945d3100df does not exist. Creating ...
2019-09-29 12:16:12,442 [pool-64-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis/02b51e20-6d7f-4000-82ea-dd945d3100df/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:12,466 [pool-64-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis/02b51e20-6d7f-4000-82ea-dd945d3100df has been successfully formatted.
2019-09-29 12:16:12,466 [pool-64-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DD945D3100DF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-29 12:16:12,467 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-29 12:16:12,467 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:12,467 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:12,467 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:12,468 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-29 12:16:12,468 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:12,468 [pool-64-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis/02b51e20-6d7f-4000-82ea-dd945d3100df
2019-09-29 12:16:12,475 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-29 12:16:12,475 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-29 12:16:12,476 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-29 12:16:12,476 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:12,476 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-29 12:16:12,477 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:12,477 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:12,477 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:12,477 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:12,478 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-29 12:16:12,478 [pool-64-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:12,479 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:12,479 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-29 12:16:12,479 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-29 12:16:12,479 [pool-64-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:12,485 [pool-64-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: start as a follower, conf=-1: [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:192.168.30.19:45442], old=null
2019-09-29 12:16:12,485 [pool-64-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:12,485 [pool-64-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: start FollowerState
2019-09-29 12:16:12,486 [pool-64-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD945D3100DF,id=5aa9d67d-39e4-4a0b-aa40-855d18bee3fb
2019-09-29 12:16:12,531 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 02b51e20-6d7f-4000-82ea-dd945d3100df, Nodes: 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb{ip: 192.168.30.19, host: pr-hdds-1569-lsfh5-224679870, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-29 12:16:12,534 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Cannot create pipeline of factor 1 using 0 nodes.
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.pickNodesNeverUsed(RatisPipelineProvider.java:113)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:125)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:12,534 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(143)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-29 12:16:12,535 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:144)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:128)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:12,535 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Cannot create pipeline of factor 1 using 0 nodes.
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.pickNodesNeverUsed(RatisPipelineProvider.java:113)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:125)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:12,536 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(143)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-29 12:16:12,536 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:144)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:128)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:13,264 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-09-29 12:16:14,189 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume68967, with jenkins1000 as owner.
2019-09-29 12:16:14,341 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume68967 for user:jenkins1000
2019-09-29 12:16:14,341 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume68967 for user:jenkins1000
2019-09-29 12:16:14,341 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume68967 for user:jenkins1000
2019-09-29 12:16:14,361 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume68967/bucket30412, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-29 12:16:14,590 [main] INFO  ozone.TestOzoneFsHAURLs (TestOzoneFsHAURLs.java:getLeaderOMNodeAddr(169)) - Found leader OM: nodeId=omNode-1, ozone.om.address.om-service-test1.omNode-1=127.0.0.1:12868
Found 2 items
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 /dir1
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 /dir2
Found 2 items
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs:///dir1
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs:///dir2
-ls: Service ID or host name must not be omitted when ozone.om.service.ids is defined.
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
	[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-v] [-x] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
	[-head <file>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]
Found 2 items
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs://bucket30412.volume68967.127.0.0.1/dir1
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs://bucket30412.volume68967.127.0.0.1/dir2
Found 2 items
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs://bucket30412.volume68967.127.0.0.1:12868/dir1
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs://bucket30412.volume68967.127.0.0.1:12868/dir2
Found 2 items
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs://bucket30412.volume68967.om-service-test1/dir1
drwxrwxrwx   - jenkins1000 jenkins1000          0 2019-09-29 12:16 o3fs://bucket30412.volume68967.om-service-test1/dir2
-ls: Port 12868 specified in URI but host 'om-service-test1' is a logical (HA) OzoneManager and does not use port information.
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
	[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-v] [-x] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
	[-head <file>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]
2019-09-29 12:16:14,779 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-29 12:16:14,779 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-3
2019-09-29 12:16:14,779 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 12880
2019-09-29 12:16:14,788 [IPC Server listener on 12880] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 12880
2019-09-29 12:16:14,789 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:14,794 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-3: close
2019-09-29 12:16:14,801 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - omNode-3@group-523986131536: shutdown
2019-09-29 12:16:14,801 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-09-29 12:16:14,801 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-09-29 12:16:14,802 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - omNode-3@group-523986131536-StateMachineUpdater: set stopIndex = 7
2019-09-29 12:16:14,802 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:14,802 [Thread-181] INFO  impl.FollowerState (FollowerState.java:run(115)) - omNode-3: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-29 12:16:14,808 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:14,809 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-3@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:14,810 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-3@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-29 12:16:14,818 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - omNode-3@group-523986131536: closes. applyIndex: 7
2019-09-29 12:16:14,820 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - omNode-3@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:14,823 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - omNode-3@group-523986131536-SegmentedRaftLogWorker close()
2019-09-29 12:16:14,828 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-3: shutdown server with port 12884 now
2019-09-29 12:16:14,836 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-3: shutdown server with port 12884 successfully
2019-09-29 12:16:14,836 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-29 12:16:14,837 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - omNode-3: installSnapshot onError, lastRequest: omNode-1->omNode-3#21-t1, previous=(t:1, i:7), leaderCommit=7, initializing? false, entries: size=1, first=(t:1, i:8), METADATAENTRY(c7): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-29 12:16:14,837 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-29 12:16:14,839 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-29 12:16:14,843 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 9 -> 8
2019-09-29 12:16:14,844 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
Sep 29, 2019 12:16:14 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@1efb9a2e
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-29 12:16:14,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1ac4ccad{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-29 12:16:14,852 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@fd9ebde{HTTP/1.1,[http/1.1]}{0.0.0.0:12882}
2019-09-29 12:16:14,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75483843{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:14,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14ef2482{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:14,867 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-1
2019-09-29 12:16:14,867 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 12868
2019-09-29 12:16:14,870 [IPC Server listener on 12868] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 12868
2019-09-29 12:16:14,870 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:14,870 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-1: close
2019-09-29 12:16:14,871 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - omNode-1@group-523986131536: shutdown
2019-09-29 12:16:14,872 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-09-29 12:16:14,872 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - omNode-1: shutdown LeaderState
2019-09-29 12:16:14,874 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$230/1060248834@10d9152] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - omNode-1@group-523986131536->omNode-3-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-29 12:16:14,874 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$230/1060248834@6070347b] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - omNode-1@group-523986131536->omNode-2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-29 12:16:14,874 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - omNode-1-PendingRequests: sendNotLeaderResponses
2019-09-29 12:16:14,877 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - omNode-2: Completed APPEND_ENTRIES, lastRequest: omNode-1->omNode-2#21-t1, previous=(t:1, i:7), leaderCommit=7, initializing? false, entries: size=1, first=(t:1, i:8), METADATAENTRY(c7)
2019-09-29 12:16:14,879 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - omNode-1@group-523986131536-StateMachineUpdater: set stopIndex = 8
2019-09-29 12:16:14,879 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:14,884 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - omNode-1@group-523986131536->omNode-2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-29 12:16:14,885 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-2: nextIndex: updateUnconditionally 9 -> 8
2019-09-29 12:16:14,885 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:14,887 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:14,887 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-29 12:16:14,888 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:14,889 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:14,889 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:14,889 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly 7 -> 7
2019-09-29 12:16:14,889 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - omNode-1@group-523986131536: closes. applyIndex: 8
2019-09-29 12:16:14,890 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - omNode-1@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:14,891 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - omNode-1@group-523986131536-SegmentedRaftLogWorker close()
2019-09-29 12:16:14,892 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-1: shutdown server with port 12872 now
2019-09-29 12:16:14,893 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-1: shutdown server with port 12872 successfully
2019-09-29 12:16:14,893 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-29 12:16:14,893 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-29 12:16:14,893 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-29 12:16:14,895 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f668f29{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-29 12:16:14,895 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@716e431d{HTTP/1.1,[http/1.1]}{0.0.0.0:12870}
2019-09-29 12:16:14,896 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3f702946{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:14,896 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a2909ae{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:14,909 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-2
2019-09-29 12:16:14,909 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 12874
2019-09-29 12:16:14,911 [IPC Server listener on 12874] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 12874
2019-09-29 12:16:14,911 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:14,911 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-2: close
2019-09-29 12:16:14,913 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - omNode-2@group-523986131536: shutdown
2019-09-29 12:16:14,913 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-09-29 12:16:14,913 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-09-29 12:16:14,913 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - omNode-2@group-523986131536-StateMachineUpdater: set stopIndex = 7
2019-09-29 12:16:14,914 [Thread-166] INFO  impl.FollowerState (FollowerState.java:run(115)) - omNode-2: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-29 12:16:14,913 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:14,915 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:14,915 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-2@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:14,915 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-2@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-29 12:16:14,916 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - omNode-2@group-523986131536: closes. applyIndex: 7
2019-09-29 12:16:14,916 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - omNode-2@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:14,917 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - omNode-2@group-523986131536-SegmentedRaftLogWorker close()
2019-09-29 12:16:14,918 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-2: shutdown server with port 12878 now
2019-09-29 12:16:14,919 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-2: shutdown server with port 12878 successfully
2019-09-29 12:16:14,920 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-29 12:16:14,920 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-29 12:16:14,920 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-29 12:16:14,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@68880c21{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-29 12:16:14,922 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2dd2e270{HTTP/1.1,[http/1.1]}{0.0.0.0:12876}
2019-09-29 12:16:14,922 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f00f851{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:14,922 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a2ef072{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:14,935 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-29 12:16:14,935 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-29 12:16:15,265 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-29 12:16:15,327 [Thread-256] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-29 12:16:15,330 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-29 12:16:17,500 [Thread-259] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:group-DD945D3100DF changes to CANDIDATE, lastRpcTime:5014, electionTimeout:5014ms
2019-09-29 12:16:17,501 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: shutdown FollowerState
2019-09-29 12:16:17,501 [Thread-259] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-29 12:16:17,501 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: start LeaderElection
2019-09-29 12:16:17,540 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2: begin an election at term 1 for -1: [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:192.168.30.19:45442], old=null
2019-09-29 12:16:17,543 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: shutdown LeaderElection
2019-09-29 12:16:17,543 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-29 12:16:17,543 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: change Leader from null to 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb at term 1 for becomeLeader, leader elected after 5076ms
2019-09-29 12:16:17,543 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-29 12:16:17,544 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-29 12:16:17,544 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-29 12:16:17,544 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-29 12:16:17,545 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-29 12:16:17,545 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-29 12:16:17,552 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: start LeaderState
2019-09-29 12:16:17,553 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:17,553 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: set configuration 0: [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb:192.168.30.19:45442], old=null at 0
2019-09-29 12:16:17,608 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/ratis/02b51e20-6d7f-4000-82ea-dd945d3100df/current/log_inprogress_0
2019-09-29 12:16:19,937 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-29 12:16:19,938 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: close
2019-09-29 12:16:19,938 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: shutdown
2019-09-29 12:16:19,939 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD945D3100DF,id=5aa9d67d-39e4-4a0b-aa40-855d18bee3fb
2019-09-29 12:16:19,939 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: shutdown LeaderState
2019-09-29 12:16:19,940 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb-PendingRequests: sendNotLeaderResponses
2019-09-29 12:16:19,941 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-StateMachineUpdater: set stopIndex = 0
2019-09-29 12:16:19,942 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF: closes. applyIndex: 0
2019-09-29 12:16:19,943 [5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:19,944 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb@group-DD945D3100DF-SegmentedRaftLogWorker close()
2019-09-29 12:16:19,946 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: shutdown server with port 45442 now
2019-09-29 12:16:19,948 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 5aa9d67d-39e4-4a0b-aa40-855d18bee3fb: shutdown server with port 45442 successfully
2019-09-29 12:16:19,952 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-a5fe0885-f3fd-455f-9407-03684cd4d9d2/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-29 12:16:19,983 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-29 12:16:19,986 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-29 12:16:19,987 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5922d3e9{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-29 12:16:19,988 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7d57dbb5{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-29 12:16:19,988 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ac3f6f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:19,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b112b13{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:19,992 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-29 12:16:19,992 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-29 12:16:19,992 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(204)) - Stopping Replication Monitor Thread.
2019-09-29 12:16:19,993 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-29 12:16:19,993 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-29 12:16:19,993 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-29 12:16:19,993 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44621
2019-09-29 12:16:19,995 [IPC Server listener on 44621] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44621
2019-09-29 12:16:19,995 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:20,021 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-29 12:16:20,021 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-29 12:16:20,022 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-29 12:16:20,022 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38953
2019-09-29 12:16:20,023 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-29 12:16:20,023 [IPC Server listener on 38953] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38953
2019-09-29 12:16:20,023 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-29 12:16:20,024 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38150
2019-09-29 12:16:20,024 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:20,025 [IPC Server listener on 38150] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38150
2019-09-29 12:16:20,025 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-29 12:16:20,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:20,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5bd73d1a{/,null,UNAVAILABLE}{/scm}
2019-09-29 12:16:20,028 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42a9a63e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-29 12:16:20,029 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e858e0a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:20,029 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bf1ec20{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:20,031 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-29 12:16:20,031 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-29 12:16:20,032 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-29 12:16:20,033 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-29 12:16:20,039 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-09-29 12:16:20,044 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-29 12:16:20,044 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-09-29 12:16:20,086 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,112 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,136 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,136 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-29 12:16:20,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-29 12:16:20,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-29 12:16:20,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-29 12:16:20,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-29 12:16:20,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-29 12:16:20,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:20,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:20,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:20,384 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@566f1852
2019-09-29 12:16:20,385 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-29 12:16:20,389 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-29 12:16:20,390 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-29 12:16:20,390 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-29 12:16:20,391 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-29 12:16:20,391 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,493 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(137)) - No pipeline exists in current db
2019-09-29 12:16:20,493 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,596 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-29 12:16:20,598 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:20,599 [Socket Reader #1 for port 38092] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38092
2019-09-29 12:16:20,605 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:20,606 [Socket Reader #1 for port 40452] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40452
2019-09-29 12:16:20,608 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:20,609 [Socket Reader #1 for port 36678] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36678
2019-09-29 12:16:20,611 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-29 12:16:20,614 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:20,616 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:20,619 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:20,620 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-29 12:16:20,620 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:20,620 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:20,623 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36678
2019-09-29 12:16:20,625 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-29 12:16:20,626 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-29 12:16:20,627 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-29 12:16:20,654 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:20,662 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:36678
2019-09-29 12:16:20,662 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:20,662 [IPC Server listener on 36678] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36678: starting
2019-09-29 12:16:20,667 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:40452
2019-09-29 12:16:20,668 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:40452
2019-09-29 12:16:20,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:20,669 [IPC Server listener on 40452] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40452: starting
2019-09-29 12:16:20,673 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:38092
2019-09-29 12:16:20,673 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:38092
2019-09-29 12:16:20,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:20,673 [IPC Server listener on 38092] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38092: starting
2019-09-29 12:16:20,680 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42527
2019-09-29 12:16:20,681 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:20,683 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51f95f0d{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:20,683 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@706ddbc8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:20,726 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@16c1519e{/,file:///tmp/jetty-0.0.0.0-42527-scm-_-any-8454706087260787214.dir/webapp/,AVAILABLE}{/scm}
2019-09-29 12:16:20,727 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a02e34b{HTTP/1.1,[http/1.1]}{0.0.0.0:42527}
2019-09-29 12:16:20,727 [main] INFO  server.Server (Server.java:doStart(419)) - Started @20733ms
2019-09-29 12:16:20,728 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:20,728 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:42527
2019-09-29 12:16:20,729 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b000fe6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-29 12:16:20,730 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,754 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,754 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,755 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-1: 127.0.0.1:12866
2019-09-29 12:16:20,755 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-1: 127.0.0.1:12867
2019-09-29 12:16:20,755 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-1, RPC Address: localhost:12864 and Ratis port: 12868
2019-09-29 12:16:20,761 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:20,761 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-29 12:16:20,761 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-29 12:16:20,762 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-29 12:16:20,762 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-29 12:16:20,762 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-29 12:16:20,762 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-29 12:16:20,762 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-29 12:16:20,763 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-29 12:16:20,763 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-29 12:16:20,763 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-29 12:16:20,763 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-29 12:16:20,763 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-29 12:16:20,763 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-29 12:16:20,764 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-29 12:16:20,764 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-29 12:16:20,764 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-29 12:16:20,764 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-29 12:16:20,764 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-29 12:16:20,765 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-29 12:16:20,765 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-29 12:16:20,765 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-29 12:16:20,765 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-29 12:16:20,765 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:20,765 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:20,766 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:21,531 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:21,532 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3430)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-29 12:16:21,533 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:12868, localhost:12874, localhost:12880
2019-09-29 12:16:21,535 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:21,535 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:21,535 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 12868 (custom)
2019-09-29 12:16:21,536 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-29 12:16:21,536 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:21,536 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:21,536 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:21,537 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis] (custom)
2019-09-29 12:16:21,537 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-1: addNew group-523986131536:[omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874] returns group-523986131536:java.util.concurrent.CompletableFuture@40709f9[Not completed]
2019-09-29 12:16:21,538 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - omNode-1: new RaftServerImpl for group-523986131536:[omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874] with OzoneManagerStateMachine:uninitialized
2019-09-29 12:16:21,538 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1389)) - OzoneManager Ratis server initialized at port 12868
2019-09-29 12:16:21,539 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-29 12:16:21,539 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:21,539 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-29 12:16:21,539 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:21,539 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-09-29 12:16:21,539 [main] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-09-29 12:16:21,539 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:21,540 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:21,540 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-1@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:21,540 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis] (custom)
2019-09-29 12:16:21,541 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-09-29 12:16:21,542 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:21,542 [Socket Reader #1 for port 12864] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 12864
2019-09-29 12:16:21,563 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:21,565 [main] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:12864
2019-09-29 12:16:21,565 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-29 12:16:21,565 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer omNode-1 at port 12868
2019-09-29 12:16:21,588 [pool-89-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-09-29 12:16:21,588 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-09-29 12:16:21,588 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:21,588 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:21,589 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:21,589 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:21,589 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:21,589 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new omNode-1@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-09-29 12:16:21,590 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-29 12:16:21,590 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-29 12:16:21,590 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:21,590 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:21,590 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-29 12:16:21,591 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:21,591 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:21,591 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:21,591 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:21,591 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-29 12:16:21,592 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:21,592 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:21,592 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-29 12:16:21,593 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-29 12:16:21,593 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:21,594 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - omNode-1@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null
2019-09-29 12:16:21,594 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-1@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:21,594 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start FollowerState
2019-09-29 12:16:21,595 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-09-29 12:16:21,596 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-1: start RPC server
2019-09-29 12:16:21,599 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-1: GrpcService started, listening on 0.0.0.0/0.0.0.0:12868
2019-09-29 12:16:21,600 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:21,601 [IPC Server listener on 12864] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 12864: starting
2019-09-29 12:16:21,605 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:12866
2019-09-29 12:16:21,608 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:21,609 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:21,612 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:21,614 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-29 12:16:21,614 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:21,614 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:21,615 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 12866
2019-09-29 12:16:21,616 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:21,619 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@709f0202{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:21,620 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14168e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:21,687 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a90265a{/,file:///tmp/jetty-0.0.0.0-12866-ozoneManager-_-any-6962909069119222373.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-29 12:16:21,687 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a32191e{HTTP/1.1,[http/1.1]}{0.0.0.0:12866}
2019-09-29 12:16:21,688 [main] INFO  server.Server (Server.java:doStart(419)) - Started @21694ms
2019-09-29 12:16:21,688 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:21,689 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:12866
2019-09-29 12:16:21,689 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:12864
2019-09-29 12:16:21,690 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:21,714 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:21,714 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:21,716 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-2: 127.0.0.1:12872
2019-09-29 12:16:21,716 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-2: 127.0.0.1:12873
2019-09-29 12:16:21,716 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-2, RPC Address: localhost:12870 and Ratis port: 12874
2019-09-29 12:16:21,723 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:21,724 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-29 12:16:21,724 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-29 12:16:21,724 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-29 12:16:21,725 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-29 12:16:21,725 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-29 12:16:21,725 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-29 12:16:21,726 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-29 12:16:21,726 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-29 12:16:21,726 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-29 12:16:21,726 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-29 12:16:21,727 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-29 12:16:21,727 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-29 12:16:21,727 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-29 12:16:21,727 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-29 12:16:21,728 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-29 12:16:21,728 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-29 12:16:21,728 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-29 12:16:21,728 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-29 12:16:21,729 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-29 12:16:21,729 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-29 12:16:21,729 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-29 12:16:21,730 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-29 12:16:21,730 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:21,730 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:21,730 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:22,521 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:22,522 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3430)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-29 12:16:22,523 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:12874, localhost:12868, localhost:12880
2019-09-29 12:16:22,525 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:22,526 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:22,526 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 12874 (custom)
2019-09-29 12:16:22,526 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-29 12:16:22,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:22,527 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:22,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:22,528 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis] (custom)
2019-09-29 12:16:22,529 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-2: addNew group-523986131536:[omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874] returns group-523986131536:java.util.concurrent.CompletableFuture@7fedb795[Not completed]
2019-09-29 12:16:22,529 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - omNode-2: new RaftServerImpl for group-523986131536:[omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874] with OzoneManagerStateMachine:uninitialized
2019-09-29 12:16:22,529 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1389)) - OzoneManager Ratis server initialized at port 12874
2019-09-29 12:16:22,530 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-29 12:16:22,530 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:22,531 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-29 12:16:22,531 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:22,531 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-09-29 12:16:22,531 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:22,531 [main] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-09-29 12:16:22,532 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:22,532 [pool-106-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-2@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:22,532 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis] (custom)
2019-09-29 12:16:22,533 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-09-29 12:16:22,535 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:22,536 [Socket Reader #1 for port 12870] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 12870
2019-09-29 12:16:22,564 [main] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:12870
2019-09-29 12:16:22,564 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-29 12:16:22,564 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer omNode-2 at port 12874
2019-09-29 12:16:22,585 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:22,610 [pool-106-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-09-29 12:16:22,610 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-09-29 12:16:22,610 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:22,611 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:22,611 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:22,611 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:22,611 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:22,611 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new omNode-2@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-09-29 12:16:22,612 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-29 12:16:22,612 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-29 12:16:22,612 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:22,612 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:22,613 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-29 12:16:22,613 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:22,613 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:22,613 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:22,613 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:22,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-29 12:16:22,614 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:22,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:22,615 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-29 12:16:22,615 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-29 12:16:22,615 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:22,616 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - omNode-2@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null
2019-09-29 12:16:22,616 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-2@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:22,617 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-09-29 12:16:22,618 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-09-29 12:16:22,619 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-2: start RPC server
2019-09-29 12:16:22,621 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-2: GrpcService started, listening on 0.0.0.0/0.0.0.0:12874
2019-09-29 12:16:22,622 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:22,623 [IPC Server listener on 12870] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 12870: starting
2019-09-29 12:16:22,628 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:12872
2019-09-29 12:16:22,631 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:22,632 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:22,635 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:22,637 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-29 12:16:22,637 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:22,638 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:22,639 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 12872
2019-09-29 12:16:22,639 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:22,642 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d7fd41{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:22,642 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@19fd43da{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:22,716 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7e64c1a9{/,file:///tmp/jetty-0.0.0.0-12872-ozoneManager-_-any-4617238808280811025.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-29 12:16:22,716 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fda2001{HTTP/1.1,[http/1.1]}{0.0.0.0:12872}
2019-09-29 12:16:22,717 [main] INFO  server.Server (Server.java:doStart(419)) - Started @22723ms
2019-09-29 12:16:22,717 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:22,718 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:12872
2019-09-29 12:16:22,718 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:12870
2019-09-29 12:16:22,720 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:22,744 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:22,745 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:22,746 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-3: 127.0.0.1:12878
2019-09-29 12:16:22,746 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeSpecificConfigs(698)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-3: 127.0.0.1:12879
2019-09-29 12:16:22,747 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-3, RPC Address: localhost:12876 and Ratis port: 12880
2019-09-29 12:16:22,753 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-29 12:16:22,753 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-29 12:16:22,754 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-29 12:16:22,754 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-29 12:16:22,754 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-29 12:16:22,754 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-29 12:16:22,755 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-29 12:16:22,755 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-29 12:16:22,755 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-29 12:16:22,756 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-29 12:16:22,756 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-29 12:16:22,756 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-29 12:16:22,756 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-29 12:16:22,757 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-29 12:16:22,757 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-29 12:16:22,757 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-29 12:16:22,758 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-29 12:16:22,758 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-29 12:16:22,758 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-29 12:16:22,758 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-29 12:16:22,759 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-29 12:16:22,759 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-29 12:16:22,759 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-29 12:16:22,759 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-29 12:16:22,760 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-29 12:16:22,760 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-29 12:16:22,795 [Thread-384] INFO  impl.FollowerState (FollowerState.java:run(106)) - omNode-1:group-523986131536 changes to CANDIDATE, lastRpcTime:1200, electionTimeout:1200ms
2019-09-29 12:16:22,795 [Thread-384] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-1: shutdown FollowerState
2019-09-29 12:16:22,795 [Thread-384] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-1@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-29 12:16:22,796 [Thread-384] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderElection
2019-09-29 12:16:22,818 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - omNode-1@group-523986131536:LeaderElection3: begin an election at term 1 for -1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null
2019-09-29 12:16:22,828 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-1@group-523986131536:LeaderElection3 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:12880
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-29 12:16:22,840 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-2@group-523986131536: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:omNode-1
2019-09-29 12:16:22,841 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-09-29 12:16:22,841 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-09-29 12:16:22,841 [Thread-422] INFO  impl.FollowerState (FollowerState.java:run(115)) - omNode-2: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-29 12:16:22,864 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-1@group-523986131536:LeaderElection3: Election PASSED; received 1 response(s) [omNode-1<-omNode-2#0:OK-t1] and 1 exception(s); omNode-1@group-523986131536:t1, leader=null, voted=omNode-1, raftlog=omNode-1@group-523986131536-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null
2019-09-29 12:16:22,864 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:12880
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-29 12:16:22,865 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-1: shutdown LeaderElection
2019-09-29 12:16:22,866 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-1@group-523986131536: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-29 12:16:22,866 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - omNode-1@group-523986131536: change Leader from null to omNode-1 at term 1 for becomeLeader, leader elected after 1278ms
2019-09-29 12:16:22,866 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-29 12:16:22,866 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-29 12:16:22,867 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-29 12:16:22,867 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-29 12:16:22,867 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-29 12:16:22,867 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-29 12:16:22,868 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-29 12:16:22,868 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:22,868 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-09-29 12:16:22,868 [omNode-1@group-523986131536:LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-29 12:16:22,869 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:22,869 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:22,869 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-29 12:16:22,869 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:22,869 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-09-29 12:16:22,870 [omNode-1@group-523986131536:LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-29 12:16:22,870 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:22,870 [omNode-1@group-523986131536:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:22,870 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderState
2019-09-29 12:16:22,871 [omNode-1@group-523986131536:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:22,872 [omNode-1@group-523986131536:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - omNode-1@group-523986131536: set configuration 0: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null at 0
2019-09-29 12:16:22,873 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-29 12:16:22,875 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 0 -> 0
2019-09-29 12:16:22,877 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - omNode-2@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 266ms
2019-09-29 12:16:22,882 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - omNode-2@group-523986131536: set configuration 0: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null at 0
2019-09-29 12:16:22,882 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:22,909 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-09-29 12:16:22,909 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-09-29 12:16:22,926 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-29 12:16:22,928 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 1 -> 0
2019-09-29 12:16:23,428 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-29 12:16:23,431 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 0 -> 0
2019-09-29 12:16:23,566 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:23,570 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3430)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-29 12:16:23,572 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:12880, localhost:12868, localhost:12874
2019-09-29 12:16:23,574 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:23,574 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:23,574 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 12880 (custom)
2019-09-29 12:16:23,575 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-29 12:16:23,575 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:23,575 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:23,575 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:23,577 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis] (custom)
2019-09-29 12:16:23,577 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-3: addNew group-523986131536:[omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874] returns group-523986131536:java.util.concurrent.CompletableFuture@60cb1ed6[Not completed]
2019-09-29 12:16:23,577 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - omNode-3: new RaftServerImpl for group-523986131536:[omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874] with OzoneManagerStateMachine:uninitialized
2019-09-29 12:16:23,578 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1389)) - OzoneManager Ratis server initialized at port 12880
2019-09-29 12:16:23,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-29 12:16:23,579 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:23,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-29 12:16:23,580 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-29 12:16:23,580 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-09-29 12:16:23,580 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:23,580 [main] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-09-29 12:16:23,580 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:23,580 [pool-122-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-3@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:23,581 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis] (custom)
2019-09-29 12:16:23,581 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-09-29 12:16:23,583 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-29 12:16:23,584 [Socket Reader #1 for port 12876] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 12876
2019-09-29 12:16:23,605 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:23,615 [main] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:12876
2019-09-29 12:16:23,615 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-29 12:16:23,615 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer omNode-3 at port 12880
2019-09-29 12:16:23,629 [pool-122-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-09-29 12:16:23,629 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-09-29 12:16:23,629 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:23,629 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:23,630 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:23,630 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:23,630 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:23,630 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new omNode-3@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-09-29 12:16:23,630 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-29 12:16:23,630 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:23,631 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-29 12:16:23,632 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:23,632 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:23,632 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-29 12:16:23,632 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-29 12:16:23,633 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:23,634 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - omNode-3@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null
2019-09-29 12:16:23,634 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - omNode-3@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:23,634 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-09-29 12:16:23,635 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-09-29 12:16:23,636 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-3: start RPC server
2019-09-29 12:16:23,643 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-3: GrpcService started, listening on 0.0.0.0/0.0.0.0:12880
2019-09-29 12:16:23,644 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-29 12:16:23,644 [IPC Server listener on 12876] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 12876: starting
2019-09-29 12:16:23,651 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:12878
2019-09-29 12:16:23,656 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:23,657 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:23,660 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:23,661 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-29 12:16:23,662 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:23,662 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:23,663 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 12878
2019-09-29 12:16:23,663 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:23,666 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b791a81{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:23,667 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47b269c4{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:23,729 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5af5d76f{/,file:///tmp/jetty-0.0.0.0-12878-ozoneManager-_-any-3251972216387892912.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-29 12:16:23,731 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a8cea24{HTTP/1.1,[http/1.1]}{0.0.0.0:12878}
2019-09-29 12:16:23,731 [main] INFO  server.Server (Server.java:doStart(419)) - Started @23737ms
2019-09-29 12:16:23,731 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:23,732 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:12878
2019-09-29 12:16:23,732 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:12876
2019-09-29 12:16:23,736 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-29 12:16:23,739 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-lsfh5-224679870 ip:192.168.30.19
2019-09-29 12:16:23,749 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-29 12:16:23,749 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/containers/hdds to VolumeSet
2019-09-29 12:16:23,749 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fde8f7c
2019-09-29 12:16:23,750 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fde8f7c
2019-09-29 12:16:23,770 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-29 12:16:23,770 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-29 12:16:23,770 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-29 12:16:23,771 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-29 12:16:23,771 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:23,771 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-29 12:16:23,771 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-29 12:16:23,772 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis] (custom)
2019-09-29 12:16:23,773 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-29 12:16:23,774 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-29 12:16:23,775 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-29 12:16:23,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 12:16:23,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-29 12:16:23,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 12:16:23,778 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 12:16:23,778 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43915
2019-09-29 12:16:23,778 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-29 12:16:23,780 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78da899f{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-29 12:16:23,781 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51da32e5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-29 12:16:23,808 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@125d47c4{/,file:///tmp/jetty-0.0.0.0-43915-hddsDatanode-_-any-5148002292907520201.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-29 12:16:23,808 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@193bb809{HTTP/1.1,[http/1.1]}{0.0.0.0:43915}
2019-09-29 12:16:23,809 [main] INFO  server.Server (Server.java:doStart(419)) - Started @23815ms
2019-09-29 12:16:23,810 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-29 12:16:23,810 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43915
2019-09-29 12:16:23,811 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:23,814 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e8d7c7a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-29 12:16:23,822 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/meta/datanode.id
2019-09-29 12:16:23,963 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - omNode-3@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 334ms
2019-09-29 12:16:23,970 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - omNode-3@group-523986131536: set configuration 0: [omNode-3:localhost:12880, omNode-1:localhost:12868, omNode-2:localhost:12874], old=null at 0
2019-09-29 12:16:23,971 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:24,001 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-09-29 12:16:24,813 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:25,814 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:25,846 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-29 12:16:25,849 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-29 12:16:25,849 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 695832ea-4764-4d50-a88f-98a8994435c3 at port 0
2019-09-29 12:16:25,859 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 695832ea-4764-4d50-a88f-98a8994435c3: start RPC server
2019-09-29 12:16:25,861 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 695832ea-4764-4d50-a88f-98a8994435c3: GrpcService started, listening on 0.0.0.0/0.0.0.0:38239
2019-09-29 12:16:25,861 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 695832ea-4764-4d50-a88f-98a8994435c3 is started using port 38239
2019-09-29 12:16:25,863 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 695832ea-4764-4d50-a88f-98a8994435c3 is started using port 39113
2019-09-29 12:16:26,814 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:27,815 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-29 12:16:27,818 [IPC Server handler 0 on 38092] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/695832ea-4764-4d50-a88f-98a8994435c3
2019-09-29 12:16:27,819 [IPC Server handler 0 on 38092] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 695832ea-4764-4d50-a88f-98a8994435c3{ip: 192.168.30.19, host: pr-hdds-1569-lsfh5-224679870, networkLocation: /default-rack, certSerialId: null}
2019-09-29 12:16:27,822 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-29 12:16:27,823 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-29 12:16:27,823 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-29 12:16:27,842 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 695832ea-4764-4d50-a88f-98a8994435c3: addNew group-C93A80EEA1CB:[695832ea-4764-4d50-a88f-98a8994435c3:192.168.30.19:38239] returns group-C93A80EEA1CB:java.util.concurrent.CompletableFuture@3e29e63a[Not completed]
2019-09-29 12:16:27,855 [pool-130-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 695832ea-4764-4d50-a88f-98a8994435c3: new RaftServerImpl for group-C93A80EEA1CB:[695832ea-4764-4d50-a88f-98a8994435c3:192.168.30.19:38239] with ContainerStateMachine:uninitialized
2019-09-29 12:16:27,858 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-29 12:16:27,858 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-29 12:16:27,858 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-29 12:16:27,859 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-29 12:16:27,859 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-29 12:16:27,859 [pool-130-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: ConfigurationManager, init=-1: [695832ea-4764-4d50-a88f-98a8994435c3:192.168.30.19:38239], old=null, confs=<EMPTY_MAP>
2019-09-29 12:16:27,859 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis] (custom)
2019-09-29 12:16:27,860 [pool-130-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis/c3425112-dda6-4128-9a6b-c93a80eea1cb does not exist. Creating ...
2019-09-29 12:16:27,883 [pool-130-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis/c3425112-dda6-4128-9a6b-c93a80eea1cb/in_use.lock acquired by nodename 30814@pr-hdds-1569-lsfh5-224679870
2019-09-29 12:16:27,907 [pool-130-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis/c3425112-dda6-4128-9a6b-c93a80eea1cb has been successfully formatted.
2019-09-29 12:16:27,908 [pool-130-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C93A80EEA1CB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-29 12:16:27,908 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-29 12:16:27,908 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-29 12:16:27,909 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-29 12:16:27,909 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-29 12:16:27,909 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-29 12:16:27,909 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-29 12:16:27,910 [pool-130-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis/c3425112-dda6-4128-9a6b-c93a80eea1cb
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-29 12:16:27,915 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-29 12:16:27,916 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-29 12:16:27,916 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-29 12:16:27,916 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-29 12:16:27,917 [pool-130-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-29 12:16:27,917 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-29 12:16:27,917 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-29 12:16:27,918 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-29 12:16:27,918 [pool-130-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-29 12:16:27,923 [pool-130-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: start as a follower, conf=-1: [695832ea-4764-4d50-a88f-98a8994435c3:192.168.30.19:38239], old=null
2019-09-29 12:16:27,923 [pool-130-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-29 12:16:27,923 [pool-130-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 695832ea-4764-4d50-a88f-98a8994435c3: start FollowerState
2019-09-29 12:16:27,923 [pool-130-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C93A80EEA1CB,id=695832ea-4764-4d50-a88f-98a8994435c3
2019-09-29 12:16:27,935 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c3425112-dda6-4128-9a6b-c93a80eea1cb, Nodes: 695832ea-4764-4d50-a88f-98a8994435c3{ip: 192.168.30.19, host: pr-hdds-1569-lsfh5-224679870, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-29 12:16:27,936 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Cannot create pipeline of factor 1 using 0 nodes.
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.pickNodesNeverUsed(RatisPipelineProvider.java:113)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:125)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:27,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(143)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-29 12:16:27,936 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:144)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:128)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:27,937 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Cannot create pipeline of factor 1 using 0 nodes.
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.pickNodesNeverUsed(RatisPipelineProvider.java:113)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:125)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:27,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(143)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-29 12:16:27,937 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(188)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:144)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:128)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:179)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-29 12:16:28,815 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-09-29 12:16:28,846 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume35809, with jenkins1000 as owner.
2019-09-29 12:16:28,868 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume35809 for user:jenkins1000
2019-09-29 12:16:28,876 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume35809/bucket13566, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-29 12:16:28,878 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume35809 for user:jenkins1000
2019-09-29 12:16:28,878 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume35809 for user:jenkins1000
-ls: Ozone file system URL should be one of the following formats: o3fs://bucket.volume/key  OR o3fs://bucket.volume.om-host.example.com/key  OR o3fs://bucket.volume.om-host.example.com:5678/key
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
	[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-v] [-x] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
	[-head <file>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]
-ls: Ozone file system URL should be one of the following formats: o3fs://bucket.volume/key  OR o3fs://bucket.volume.om-host.example.com/key  OR o3fs://bucket.volume.om-host.example.com:5678/key
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
	[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-v] [-x] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
	[-head <file>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]
-ls: Ozone file system URL should be one of the following formats: o3fs://bucket.volume/key  OR o3fs://bucket.volume.om-host.example.com/key  OR o3fs://bucket.volume.om-host.example.com:5678/key
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
	[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-v] [-x] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
	[-head <file>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]
-ls: Service ID or host name must not be omitted when ozone.om.service.ids is defined.
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
	[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-v] [-x] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
	[-head <file>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]
2019-09-29 12:16:28,960 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-29 12:16:28,961 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-3
2019-09-29 12:16:28,961 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 12876
2019-09-29 12:16:28,967 [IPC Server listener on 12876] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 12876
2019-09-29 12:16:28,968 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:28,970 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-3: close
2019-09-29 12:16:28,974 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - omNode-3@group-523986131536: shutdown
2019-09-29 12:16:28,979 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-09-29 12:16:28,979 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-09-29 12:16:28,979 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - omNode-3@group-523986131536-StateMachineUpdater: set stopIndex = 7
2019-09-29 12:16:28,980 [Thread-472] INFO  impl.FollowerState (FollowerState.java:run(115)) - omNode-3: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-29 12:16:28,980 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:28,982 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:28,982 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-3@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:28,982 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-3@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-29 12:16:28,983 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - omNode-3@group-523986131536: closes. applyIndex: 7
2019-09-29 12:16:28,983 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - omNode-3@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:28,984 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - omNode-3@group-523986131536-SegmentedRaftLogWorker close()
2019-09-29 12:16:28,985 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-3: shutdown server with port 12880 now
2019-09-29 12:16:28,987 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - omNode-3: installSnapshot onError, lastRequest: omNode-1->omNode-3#21-t1, previous=(t:1, i:7), leaderCommit=7, initializing? false, entries: size=1, first=(t:1, i:8), METADATAENTRY(c7): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-29 12:16:28,987 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-3: shutdown server with port 12880 successfully
2019-09-29 12:16:28,989 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-29 12:16:28,989 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-29 12:16:28,989 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
Sep 29, 2019 12:16:28 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@25dcdc47
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-29 12:16:28,990 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 9 -> 8
2019-09-29 12:16:28,992 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-29 12:16:28,993 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5af5d76f{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-29 12:16:28,994 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a8cea24{HTTP/1.1,[http/1.1]}{0.0.0.0:12878}
2019-09-29 12:16:28,994 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47b269c4{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:28,994 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b791a81{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:29,007 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-1
2019-09-29 12:16:29,007 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 12864
2019-09-29 12:16:29,009 [IPC Server listener on 12864] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 12864
2019-09-29 12:16:29,009 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:29,009 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-1: close
2019-09-29 12:16:29,011 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - omNode-1@group-523986131536: shutdown
2019-09-29 12:16:29,011 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-09-29 12:16:29,011 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - omNode-1: shutdown LeaderState
2019-09-29 12:16:29,013 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - omNode-1-PendingRequests: sendNotLeaderResponses
2019-09-29 12:16:29,013 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$230/1060248834@30ec04b4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - omNode-1@group-523986131536->omNode-3-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-29 12:16:29,013 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$230/1060248834@118fab1f] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - omNode-1@group-523986131536->omNode-2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-29 12:16:29,016 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - omNode-1@group-523986131536-StateMachineUpdater: set stopIndex = 8
2019-09-29 12:16:29,016 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - omNode-2: Completed APPEND_ENTRIES, lastRequest: omNode-1->omNode-2#20-t1, previous=(t:1, i:7), leaderCommit=7, initializing? false, entries: size=1, first=(t:1, i:8), METADATAENTRY(c7)
2019-09-29 12:16:29,016 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:29,019 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - omNode-1@group-523986131536->omNode-2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-29 12:16:29,020 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-2: nextIndex: updateUnconditionally 9 -> 8
2019-09-29 12:16:29,020 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:29,020 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:29,020 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-29 12:16:29,021 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:29,021 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:29,021 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:29,021 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly 7 -> 7
2019-09-29 12:16:29,022 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - omNode-1@group-523986131536: closes. applyIndex: 8
2019-09-29 12:16:29,022 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - omNode-1@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:29,023 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - omNode-1@group-523986131536-SegmentedRaftLogWorker close()
2019-09-29 12:16:29,024 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-1: shutdown server with port 12868 now
2019-09-29 12:16:29,024 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-1: shutdown server with port 12868 successfully
2019-09-29 12:16:29,025 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-29 12:16:29,025 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-29 12:16:29,025 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-29 12:16:29,026 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a90265a{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-29 12:16:29,027 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a32191e{HTTP/1.1,[http/1.1]}{0.0.0.0:12866}
2019-09-29 12:16:29,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14168e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:29,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@709f0202{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:29,029 [main] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-2
2019-09-29 12:16:29,029 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 12870
2019-09-29 12:16:29,031 [IPC Server listener on 12870] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 12870
2019-09-29 12:16:29,031 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:29,031 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-2: close
2019-09-29 12:16:29,032 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - omNode-2@group-523986131536: shutdown
2019-09-29 12:16:29,033 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-09-29 12:16:29,033 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-09-29 12:16:29,033 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - omNode-2@group-523986131536-StateMachineUpdater: set stopIndex = 7
2019-09-29 12:16:29,033 [Thread-455] INFO  impl.FollowerState (FollowerState.java:run(115)) - omNode-2: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-29 12:16:29,033 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-29 12:16:29,035 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 7
2019-09-29 12:16:29,035 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(258)) - omNode-2@group-523986131536-StateMachineUpdater: Took a snapshot at index 7
2019-09-29 12:16:29,035 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(83)) - omNode-2@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-29 12:16:29,035 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - omNode-2@group-523986131536: closes. applyIndex: 7
2019-09-29 12:16:29,036 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - omNode-2@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:29,037 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - omNode-2@group-523986131536-SegmentedRaftLogWorker close()
2019-09-29 12:16:29,038 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-2: shutdown server with port 12874 now
2019-09-29 12:16:29,039 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-2: shutdown server with port 12874 successfully
2019-09-29 12:16:29,039 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-29 12:16:29,039 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-29 12:16:29,039 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-29 12:16:29,040 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7e64c1a9{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-29 12:16:29,040 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fda2001{HTTP/1.1,[http/1.1]}{0.0.0.0:12872}
2019-09-29 12:16:29,041 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@19fd43da{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:29,041 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d7fd41{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:29,053 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-29 12:16:29,054 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-29 12:16:29,814 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-29 12:16:30,825 [Thread-542] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-29 12:16:30,827 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-29 12:16:33,072 [Thread-544] INFO  impl.FollowerState (FollowerState.java:run(106)) - 695832ea-4764-4d50-a88f-98a8994435c3:group-C93A80EEA1CB changes to CANDIDATE, lastRpcTime:5149, electionTimeout:5149ms
2019-09-29 12:16:33,073 [Thread-544] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 695832ea-4764-4d50-a88f-98a8994435c3: shutdown FollowerState
2019-09-29 12:16:33,073 [Thread-544] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-29 12:16:33,074 [Thread-544] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 695832ea-4764-4d50-a88f-98a8994435c3: start LeaderElection
2019-09-29 12:16:33,111 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4: begin an election at term 1 for -1: [695832ea-4764-4d50-a88f-98a8994435c3:192.168.30.19:38239], old=null
2019-09-29 12:16:33,111 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 695832ea-4764-4d50-a88f-98a8994435c3: shutdown LeaderElection
2019-09-29 12:16:33,111 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-29 12:16:33,111 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: change Leader from null to 695832ea-4764-4d50-a88f-98a8994435c3 at term 1 for becomeLeader, leader elected after 5203ms
2019-09-29 12:16:33,112 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-29 12:16:33,113 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-29 12:16:33,113 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-29 12:16:33,113 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-29 12:16:33,113 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-29 12:16:33,113 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-29 12:16:33,117 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 695832ea-4764-4d50-a88f-98a8994435c3: start LeaderState
2019-09-29 12:16:33,118 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-29 12:16:33,118 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: set configuration 0: [695832ea-4764-4d50-a88f-98a8994435c3:192.168.30.19:38239], old=null at 0
2019-09-29 12:16:33,175 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/ratis/c3425112-dda6-4128-9a6b-c93a80eea1cb/current/log_inprogress_0
2019-09-29 12:16:34,054 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-29 12:16:34,055 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 695832ea-4764-4d50-a88f-98a8994435c3: close
2019-09-29 12:16:34,055 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: shutdown
2019-09-29 12:16:34,056 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C93A80EEA1CB,id=695832ea-4764-4d50-a88f-98a8994435c3
2019-09-29 12:16:34,056 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 695832ea-4764-4d50-a88f-98a8994435c3: shutdown LeaderState
2019-09-29 12:16:34,057 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 695832ea-4764-4d50-a88f-98a8994435c3-PendingRequests: sendNotLeaderResponses
2019-09-29 12:16:34,057 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-StateMachineUpdater: set stopIndex = 0
2019-09-29 12:16:34,062 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB: closes. applyIndex: 0
2019-09-29 12:16:34,062 [695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-29 12:16:34,063 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 695832ea-4764-4d50-a88f-98a8994435c3@group-C93A80EEA1CB-SegmentedRaftLogWorker close()
2019-09-29 12:16:34,065 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 695832ea-4764-4d50-a88f-98a8994435c3: shutdown server with port 38239 now
2019-09-29 12:16:34,066 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 695832ea-4764-4d50-a88f-98a8994435c3: shutdown server with port 38239 successfully
2019-09-29 12:16:34,073 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-577fadda-5248-4187-af98-e3e8b28fd015/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-29 12:16:34,110 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-29 12:16:34,112 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-29 12:16:34,113 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@125d47c4{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-29 12:16:34,114 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@193bb809{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-29 12:16:34,114 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51da32e5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:34,115 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78da899f{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:34,115 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-29 12:16:34,116 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-29 12:16:34,116 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(204)) - Stopping Replication Monitor Thread.
2019-09-29 12:16:34,116 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-29 12:16:34,116 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-29 12:16:34,116 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-29 12:16:34,116 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38092
2019-09-29 12:16:34,118 [IPC Server listener on 38092] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38092
2019-09-29 12:16:34,120 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:34,215 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-29 12:16:34,215 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-29 12:16:34,216 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-29 12:16:34,216 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40452
2019-09-29 12:16:34,217 [IPC Server listener on 40452] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40452
2019-09-29 12:16:34,218 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-29 12:16:34,219 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:34,219 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-29 12:16:34,220 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36678
2019-09-29 12:16:34,222 [IPC Server listener on 36678] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36678
2019-09-29 12:16:34,222 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-29 12:16:34,223 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-29 12:16:34,225 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@16c1519e{/,null,UNAVAILABLE}{/scm}
2019-09-29 12:16:34,226 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a02e34b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-29 12:16:34,227 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@706ddbc8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-29 12:16:34,227 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51f95f0d{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-29 12:16:34,229 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-29 12:16:34,229 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-29 12:16:34,230 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-29 12:16:34,231 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-29 12:16:34,235 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-09-29 12:16:34,241 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
