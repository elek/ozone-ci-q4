[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Detecting the operating system and CPU architecture
[INFO] ------------------------------------------------------------------------
[INFO] os.detected.name: linux
[INFO] os.detected.arch: x86_64
[INFO] os.detected.version: 3.10
[INFO] os.detected.version.major: 3
[INFO] os.detected.version.minor: 10
[INFO] os.detected.release: centos
[INFO] os.detected.release.version: 7
[INFO] os.detected.release.like.centos: true
[INFO] os.detected.release.like.rhel: true
[INFO] os.detected.release.like.fedora: true
[INFO] os.detected.classifier: linux-x86_64
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Apache Hadoop Ozone Main                                           [pom]
[INFO] Apache Hadoop HDDS                                                 [pom]
[INFO] Apache Hadoop HDDS Config                                          [jar]
[INFO] Apache Hadoop HDDS Common                                          [jar]
[INFO] Apache Hadoop HDDS Client                                          [jar]
[INFO] Apache Hadoop HDDS Server Framework                                [jar]
[INFO] Apache Hadoop HDDS Container Service                               [jar]
[INFO] Apache Hadoop HDDS/Ozone Documentation                             [jar]
[INFO] Apache Hadoop HDDS SCM Server                                      [jar]
[INFO] Apache Hadoop HDDS Tools                                           [jar]
[INFO] Apache Hadoop Ozone                                                [pom]
[INFO] Apache Hadoop Ozone Common                                         [jar]
[INFO] Apache Hadoop Ozone Client                                         [jar]
[INFO] Apache Hadoop Ozone Manager Server                                 [jar]
[INFO] Apache Hadoop Ozone S3 Gateway                                     [jar]
[INFO] Apache Hadoop Ozone CSI service                                    [jar]
[INFO] Apache Hadoop Ozone Recon CodeGen                                  [jar]
[INFO] Apache Hadoop Ozone Recon                                          [jar]
[INFO] Apache Hadoop Ozone FileSystem Single Jar Library                  [jar]
[INFO] Apache Hadoop Ozone FileSystem Legacy Jar Library                  [jar]
[INFO] Apache Hadoop Ozone Datanode                                       [jar]
[INFO] Apache Hadoop Ozone In-Place Upgrade                               [jar]
[INFO] Apache Hadoop Ozone Insight Tool                                   [jar]
[INFO] Apache Hadoop Ozone Distribution                                   [pom]
[INFO] Apache Hadoop Ozone Fault Injection Tests                          [pom]
[INFO] Apache Hadoop Ozone Network Tests                                  [jar]
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-main-ozone >-----------------
[INFO] Building Apache Hadoop Ozone Main 0.5.0-SNAPSHOT                  [1/26]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-main-ozone ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-main-ozone ---
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-hdds >--------------------
[INFO] Building Apache Hadoop HDDS 0.5.0-SNAPSHOT                        [2/26]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds ---
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdds-config >----------------
[INFO] Building Apache Hadoop HDDS Config 0.5.0-SNAPSHOT                 [3/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-config ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-config ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-config ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/config/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-config ---
[INFO] Compiling 8 source files to /workdir/hadoop-hdds/config/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-config ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-config ---
[INFO] Compiling 3 source files to /workdir/hadoop-hdds/config/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-config ---
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/surefire-junit4/3.0.0-M1/surefire-junit4-3.0.0-M1.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/3.0.0-M1/surefire-junit4-3.0.0-M1.jar
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/3.0.0-M1/surefire-junit4-3.0.0-M1.jar (17 kB at 155 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/surefire-junit4/3.0.0-M1/surefire-junit4-3.0.0-M1.pom
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/3.0.0-M1/surefire-junit4-3.0.0-M1.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/3.0.0-M1/surefire-junit4-3.0.0-M1.pom (1.7 kB at 73 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/surefire-providers/3.0.0-M1/surefire-providers-3.0.0-M1.pom
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/3.0.0-M1/surefire-providers-3.0.0-M1.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/3.0.0-M1/surefire-providers-3.0.0-M1.pom (2.5 kB at 110 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/common-junit4/3.0.0-M1/common-junit4-3.0.0-M1.pom
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/3.0.0-M1/common-junit4-3.0.0-M1.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/3.0.0-M1/common-junit4-3.0.0-M1.pom (2.1 kB at 74 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/common-junit3/3.0.0-M1/common-junit3-3.0.0-M1.pom
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/3.0.0-M1/common-junit3-3.0.0-M1.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/3.0.0-M1/common-junit3-3.0.0-M1.pom (1.6 kB at 63 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/common-java5/3.0.0-M1/common-java5-3.0.0-M1.pom
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/3.0.0-M1/common-java5-3.0.0-M1.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/3.0.0-M1/common-java5-3.0.0-M1.pom (3.1 kB at 96 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/common-java5/3.0.0-M1/common-java5-3.0.0-M1.jar
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/common-junit4/3.0.0-M1/common-junit4-3.0.0-M1.jar
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/maven/surefire/common-junit3/3.0.0-M1/common-junit3-3.0.0-M1.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/3.0.0-M1/common-junit3-3.0.0-M1.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/3.0.0-M1/common-junit4-3.0.0-M1.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/3.0.0-M1/common-java5-3.0.0-M1.jar
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/3.0.0-M1/common-java5-3.0.0-M1.jar (32 kB at 892 kB/s)
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/3.0.0-M1/common-junit3-3.0.0-M1.jar (12 kB at 224 kB/s)
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/3.0.0-M1/common-junit4-3.0.0-M1.jar (28 kB at 520 kB/s)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdds.conf.TestConfigFileAppender
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 s - in org.apache.hadoop.hdds.conf.TestConfigFileAppender
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdds-common >----------------
[INFO] Building Apache Hadoop HDDS Common 0.5.0-SNAPSHOT                 [4/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-server/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-server/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (614 B at 1.0 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-proto/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-proto/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-proto/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.2 kB at 2.0 kB/s)
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-proto/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.2 kB at 2.0 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-common/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-common/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-common/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloaded from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-common/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.6 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-client/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-client/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-client/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloaded from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-client/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-metrics/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-metrics/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-metrics/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloaded from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis-metrics/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-netty/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-netty/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-grpc/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/ratis/ratis-grpc/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (1.0 kB at 1.7 kB/s)
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-common ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- protobuf-maven-plugin:0.5.1:compile (compile-protoc) @ hadoop-hdds-common ---
[INFO] Compiling 1 proto file(s) to /workdir/hadoop-hdds/common/target/generated-sources/java
[INFO] 
[INFO] --- protobuf-maven-plugin:0.5.1:compile-custom (compile-protoc) @ hadoop-hdds-common ---
[INFO] Compiling 1 proto file(s) to /workdir/hadoop-hdds/common/target/generated-sources/java
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (default) @ hadoop-hdds-common ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:protoc (compile-protoc) @ hadoop-hdds-common ---
[INFO] Wrote protoc checksums to file /workdir/hadoop-hdds/common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-common ---
[INFO] Downloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml
[INFO] Downloaded from apache.snapshots: https://repository.apache.org/snapshots/org/apache/ratis/ratis/0.5.0-201fc85-SNAPSHOT/maven-metadata.xml (614 B at 1.0 kB/s)
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:version-info (version-info) @ hadoop-hdds-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: f6d33c472d8e683c54c6fbf6ab62068
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 5 resources
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-common ---
[INFO] Compiling 241 source files to /workdir/hadoop-hdds/common/target/classes
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/DBProfile.java: Some input files use or override a deprecated API.
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/DBProfile.java: Recompile with -Xlint:deprecation for details.
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/CodecRegistry.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/CodecRegistry.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- protobuf-maven-plugin:0.5.1:test-compile (compile-protoc) @ hadoop-hdds-common ---
[INFO] /workdir/hadoop-hdds/common/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf-maven-plugin:0.5.1:test-compile-custom (compile-protoc) @ hadoop-hdds-common ---
[INFO] /workdir/hadoop-hdds/common/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 20 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-common ---
[INFO] Compiling 56 source files to /workdir/hadoop-hdds/common/target/test-classes
[WARNING] /workdir/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.ozone.lease.TestLeaseManager
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.148 s - in org.apache.hadoop.ozone.lease.TestLeaseManager
[INFO] Running org.apache.hadoop.ozone.lock.TestLockManager
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.91 s - in org.apache.hadoop.ozone.lock.TestLockManager
[INFO] Running org.apache.hadoop.ozone.common.TestChecksumByteBuffer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.566 s - in org.apache.hadoop.ozone.common.TestChecksumByteBuffer
[INFO] Running org.apache.hadoop.ozone.common.TestStateMachine
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.ozone.common.TestStateMachine
[INFO] Running org.apache.hadoop.ozone.common.TestChecksum
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.148 s - in org.apache.hadoop.ozone.common.TestChecksum
[INFO] Running org.apache.hadoop.ozone.audit.TestOzoneAuditLogger
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.728 s - in org.apache.hadoop.ozone.audit.TestOzoneAuditLogger
[INFO] Running org.apache.hadoop.hdds.utils.db.cache.TestTableCacheImpl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.123 s - in org.apache.hadoop.hdds.utils.db.cache.TestTableCacheImpl
[INFO] Running org.apache.hadoop.hdds.utils.db.TestDBStoreBuilder
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.73 s - in org.apache.hadoop.hdds.utils.db.TestDBStoreBuilder
[INFO] Running org.apache.hadoop.hdds.utils.db.TestTypedRDBTableStore
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.05 s - in org.apache.hadoop.hdds.utils.db.TestTypedRDBTableStore
[INFO] Running org.apache.hadoop.hdds.utils.db.TestRDBStore
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.919 s - in org.apache.hadoop.hdds.utils.db.TestRDBStore
[INFO] Running org.apache.hadoop.hdds.utils.db.TestDBConfigFromFile
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.382 s - in org.apache.hadoop.hdds.utils.db.TestDBConfigFromFile
[INFO] Running org.apache.hadoop.hdds.utils.db.TestRDBTableStore
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.734 s - in org.apache.hadoop.hdds.utils.db.TestRDBTableStore
[INFO] Running org.apache.hadoop.hdds.utils.TestRocksDBStoreMBean
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.937 s - in org.apache.hadoop.hdds.utils.TestRocksDBStoreMBean
[INFO] Running org.apache.hadoop.hdds.utils.TestHddsIdFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.1 s - in org.apache.hadoop.hdds.utils.TestHddsIdFactory
[INFO] Running org.apache.hadoop.hdds.utils.TestRetriableTask
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.183 s - in org.apache.hadoop.hdds.utils.TestRetriableTask
[INFO] Running org.apache.hadoop.hdds.utils.TestMetadataStore
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.87 s - in org.apache.hadoop.hdds.utils.TestMetadataStore
[INFO] Running org.apache.hadoop.hdds.ratis.TestContainerCommandRequestMessage
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.321 s - in org.apache.hadoop.hdds.ratis.TestContainerCommandRequestMessage
[INFO] Running org.apache.hadoop.hdds.scm.net.TestNetworkTopologyImpl
[WARNING] Tests run: 75, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 3.781 s - in org.apache.hadoop.hdds.scm.net.TestNetworkTopologyImpl
[INFO] Running org.apache.hadoop.hdds.scm.net.TestYamlSchemaLoader
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.274 s - in org.apache.hadoop.hdds.scm.net.TestYamlSchemaLoader
[INFO] Running org.apache.hadoop.hdds.scm.net.TestNodeSchemaManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.309 s - in org.apache.hadoop.hdds.scm.net.TestNodeSchemaManager
[INFO] Running org.apache.hadoop.hdds.scm.net.TestNodeSchemaLoader
[INFO] Tests run: 28, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.299 s - in org.apache.hadoop.hdds.scm.net.TestNodeSchemaLoader
[INFO] Running org.apache.hadoop.hdds.scm.exceptions.TestSCMExceptionResultCodes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.066 s - in org.apache.hadoop.hdds.scm.exceptions.TestSCMExceptionResultCodes
[INFO] Running org.apache.hadoop.hdds.TestHddsUtils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.106 s - in org.apache.hadoop.hdds.TestHddsUtils
[INFO] Running org.apache.hadoop.hdds.security.x509.certificates.TestCertificateSignRequest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.465 s - in org.apache.hadoop.hdds.security.x509.certificates.TestCertificateSignRequest
[INFO] Running org.apache.hadoop.hdds.security.x509.certificates.TestRootCertificate
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.264 s - in org.apache.hadoop.hdds.security.x509.certificates.TestRootCertificate
[INFO] Running org.apache.hadoop.hdds.security.x509.keys.TestKeyCodec
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.357 s - in org.apache.hadoop.hdds.security.x509.keys.TestKeyCodec
[INFO] Running org.apache.hadoop.hdds.security.x509.keys.TestHDDSKeyGenerator
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.601 s - in org.apache.hadoop.hdds.security.x509.keys.TestHDDSKeyGenerator
[INFO] Running org.apache.hadoop.hdds.security.x509.certificate.utils.TestCertificateCodec
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.085 s - in org.apache.hadoop.hdds.security.x509.certificate.utils.TestCertificateCodec
[INFO] Running org.apache.hadoop.hdds.security.x509.certificate.authority.TestDefaultProfile
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.668 s - in org.apache.hadoop.hdds.security.x509.certificate.authority.TestDefaultProfile
[INFO] Running org.apache.hadoop.hdds.security.x509.certificate.authority.TestDefaultCAServer
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.091 s - in org.apache.hadoop.hdds.security.x509.certificate.authority.TestDefaultCAServer
[INFO] Running org.apache.hadoop.hdds.security.x509.certificate.client.TestDefaultCertificateClient
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.643 s - in org.apache.hadoop.hdds.security.x509.certificate.client.TestDefaultCertificateClient
[INFO] Running org.apache.hadoop.hdds.security.x509.certificate.client.TestCertificateClientInit
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.614 s - in org.apache.hadoop.hdds.security.x509.certificate.client.TestCertificateClientInit
[INFO] Running org.apache.hadoop.hdds.security.token.TestOzoneBlockTokenIdentifier
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.827 s - in org.apache.hadoop.hdds.security.token.TestOzoneBlockTokenIdentifier
[INFO] Running org.apache.hadoop.hdds.conf.TestOzoneConfiguration
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.484 s - in org.apache.hadoop.hdds.conf.TestOzoneConfiguration
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 285, Failures: 0, Errors: 0, Skipped: 1
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdds-client >----------------
[INFO] Building Apache Hadoop HDDS Client 0.5.0-SNAPSHOT                 [5/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-client ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-client ---
[INFO] Compiling 15 source files to /workdir/hadoop-hdds/client/target/classes
[WARNING] /workdir/hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/XceiverClientGrpc.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/XceiverClientGrpc.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/client/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-client ---
[INFO] Compiling 3 source files to /workdir/hadoop-hdds/client/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-client ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdds.scm.storage.TestChunkInputStream
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.21 s - in org.apache.hadoop.hdds.scm.storage.TestChunkInputStream
[INFO] Running org.apache.hadoop.hdds.scm.storage.TestBlockInputStream
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.18 s - in org.apache.hadoop.hdds.scm.storage.TestBlockInputStream
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------< org.apache.hadoop:hadoop-hdds-server-framework >-----------
[INFO] Building Apache Hadoop HDDS Server Framework 0.5.0-SNAPSHOT       [6/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-server-framework ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-server-framework ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-server-framework ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 35 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-server-framework ---
[INFO] Compiling 21 source files to /workdir/hadoop-hdds/framework/target/classes
[WARNING] /workdir/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/server/events/EventQueue.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/server/events/EventQueue.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-server-framework ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-server-framework ---
[INFO] Compiling 9 source files to /workdir/hadoop-hdds/framework/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-server-framework ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdds.server.events.TestEventQueue
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.59 s - in org.apache.hadoop.hdds.server.events.TestEventQueue
[INFO] Running org.apache.hadoop.hdds.server.events.TestEventQueueChain
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.238 s - in org.apache.hadoop.hdds.server.events.TestEventQueueChain
[INFO] Running org.apache.hadoop.hdds.server.events.TestEventWatcher
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.649 s - in org.apache.hadoop.hdds.server.events.TestEventWatcher
[INFO] Running org.apache.hadoop.hdds.server.TestProfileServlet
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.131 s - in org.apache.hadoop.hdds.server.TestProfileServlet
[INFO] Running org.apache.hadoop.hdds.server.TestServerUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.52 s - in org.apache.hadoop.hdds.server.TestServerUtils
[INFO] Running org.apache.hadoop.hdds.server.TestPrometheusMetricsSink
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.531 s - in org.apache.hadoop.hdds.server.TestPrometheusMetricsSink
[INFO] Running org.apache.hadoop.hdds.server.TestBaseHttpServer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.337 s - in org.apache.hadoop.hdds.server.TestBaseHttpServer
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------< org.apache.hadoop:hadoop-hdds-container-service >-----------
[INFO] Building Apache Hadoop HDDS Container Service 0.5.0-SNAPSHOT      [7/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-container-service ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:protoc (compile-protoc) @ hadoop-hdds-container-service ---
[INFO] Wrote protoc checksums to file /workdir/hadoop-hdds/container-service/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-container-service ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-container-service ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-container-service ---
[INFO] Compiling 159 source files to /workdir/hadoop-hdds/container-service/target/classes
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1051,26] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1059,15] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1061,26] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1066,57] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1068,36] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1069,37] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java:[1069,58] sun.misc.Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/impl/ContainerDataYaml.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/impl/ContainerDataYaml.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-container-service ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-container-service ---
[INFO] Compiling 48 source files to /workdir/hadoop-hdds/container-service/target/test-classes
[WARNING] /workdir/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/volume/TestHddsVolumeChecker.java: /workdir/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/volume/TestHddsVolumeChecker.java uses or overrides a deprecated API.
[WARNING] /workdir/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/volume/TestHddsVolumeChecker.java: Recompile with -Xlint:deprecation for details.
[WARNING] /workdir/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/ScmTestMock.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/ScmTestMock.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-container-service ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.ozone.container.replication.TestReplicationSupervisor
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.336 s - in org.apache.hadoop.ozone.container.replication.TestReplicationSupervisor
[INFO] Running org.apache.hadoop.ozone.container.common.report.TestReportManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.103 s - in org.apache.hadoop.ozone.container.common.report.TestReportManager
[INFO] Running org.apache.hadoop.ozone.container.common.report.TestReportPublisher
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.689 s - in org.apache.hadoop.ozone.container.common.report.TestReportPublisher
[INFO] Running org.apache.hadoop.ozone.container.common.report.TestReportPublisherFactory
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.328 s - in org.apache.hadoop.ozone.container.common.report.TestReportPublisherFactory
[INFO] Running org.apache.hadoop.ozone.container.common.TestDatanodeLayOutVersion
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.081 s - in org.apache.hadoop.ozone.container.common.TestDatanodeLayOutVersion
[INFO] Running org.apache.hadoop.ozone.container.common.TestChunkLayOutVersion
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.092 s - in org.apache.hadoop.ozone.container.common.TestChunkLayOutVersion
[INFO] Running org.apache.hadoop.ozone.container.common.TestContainerCache
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.295 s - in org.apache.hadoop.ozone.container.common.TestContainerCache
[INFO] Running org.apache.hadoop.ozone.container.common.TestDatanodeStateMachine
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.017 s - in org.apache.hadoop.ozone.container.common.TestDatanodeStateMachine
[INFO] Running org.apache.hadoop.ozone.container.common.states.endpoint.TestHeartbeatEndpointTask
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.452 s - in org.apache.hadoop.ozone.container.common.states.endpoint.TestHeartbeatEndpointTask
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerCommandHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.339 s - in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.interfaces.TestHandler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.955 s - in org.apache.hadoop.ozone.container.common.interfaces.TestHandler
[INFO] Running org.apache.hadoop.ozone.container.common.TestKeyValueContainerData
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.14 s - in org.apache.hadoop.ozone.container.common.TestKeyValueContainerData
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestHddsVolume
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.08 s - in org.apache.hadoop.ozone.container.common.volume.TestHddsVolume
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestHddsVolumeChecker
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.315 s - in org.apache.hadoop.ozone.container.common.volume.TestHddsVolumeChecker
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestVolumeSet
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.052 s - in org.apache.hadoop.ozone.container.common.volume.TestVolumeSet
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestRoundRobinVolumeChoosingPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.174 s - in org.apache.hadoop.ozone.container.common.volume.TestRoundRobinVolumeChoosingPolicy
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestVolumeSetDiskChecks
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.796 s - in org.apache.hadoop.ozone.container.common.volume.TestVolumeSetDiskChecks
[INFO] Running org.apache.hadoop.ozone.container.common.helpers.TestDatanodeVersionFile
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.312 s - in org.apache.hadoop.ozone.container.common.helpers.TestDatanodeVersionFile
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestContainerSet
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.072 s - in org.apache.hadoop.ozone.container.common.impl.TestContainerSet
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestHddsDispatcher
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.731 s - in org.apache.hadoop.ozone.container.common.impl.TestHddsDispatcher
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestContainerDataYaml
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.451 s - in org.apache.hadoop.ozone.container.common.impl.TestContainerDataYaml
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestContainerScrubberMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.754 s - in org.apache.hadoop.ozone.container.ozoneimpl.TestContainerScrubberMetrics
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.004 s - in org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueBlockIterator
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.958 s - in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueBlockIterator
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerCheck
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.417 s - in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerCheck
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandlerWithUnhealthyContainer
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.884 s - in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandlerWithUnhealthyContainer
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestTarContainerPacker
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.425 s - in org.apache.hadoop.ozone.container.keyvalue.TestTarContainerPacker
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.896 s - in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandler
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestBlockManagerImpl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.58 s - in org.apache.hadoop.ozone.container.keyvalue.TestBlockManagerImpl
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy
[ERROR] Tests run: 5, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 1.356 s <<< FAILURE! - in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy
[ERROR] testMarkClosedContainerAsUnhealthy(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy)  Time elapsed: 0.03 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:985)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:87)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy.setUp(TestKeyValueContainerMarkUnhealthy.java:83)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testMarkQuasiClosedContainerAsUnhealthy(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy)  Time elapsed: 0 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.junit.internal.runners.statements.FailOnTimeout.evaluateStatement(FailOnTimeout.java:25)
	at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:17)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testMarkClosingContainerAsUnhealthy(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy)  Time elapsed: 0 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.junit.internal.runners.statements.FailOnTimeout.evaluateStatement(FailOnTimeout.java:25)
	at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:17)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestChunkManagerImpl
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.071 s - in org.apache.hadoop.ozone.container.keyvalue.TestChunkManagerImpl
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer
[ERROR] Tests run: 10, Failures: 0, Errors: 10, Skipped: 0, Time elapsed: 0.668 s <<< FAILURE! - in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer
[ERROR] testCreateContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.319 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)
	at java.lang.UNIXProcess.initStreams(UNIXProcess.java:288)
	at java.lang.UNIXProcess.lambda$new$2(UNIXProcess.java:258)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:257)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:87)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testCloseContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.034 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testDiskFullExceptionCreateContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.025 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testDuplicateContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.024 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testReportOfUnhealthyContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.03 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testDeleteContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.026 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testUpdateContainer(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.034 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testUpdateContainerUnsupportedRequest(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.017 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testContainerImportExport(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.023 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testBlockIterator(org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer)  Time elapsed: 0.019 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.fs.CachingGetSpaceUsed.init(CachingGetSpaceUsed.java:94)
	at org.apache.hadoop.fs.GetSpaceUsed$Builder.build(GetSpaceUsed.java:166)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.startScmUsageThread(VolumeUsage.java:75)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.<init>(VolumeUsage.java:66)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:96)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.<init>(VolumeInfo.java:34)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo$Builder.build(VolumeInfo.java:74)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:173)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.<init>(HddsVolume.java:72)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156)
	at org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer.setUp(TestKeyValueContainer.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainer.setUp:92 ? OutOfMemory unable to create new native threa...
[ERROR]   TestKeyValueContainerMarkUnhealthy.setUp:83 ? OutOfMemory unable to create new...
[ERROR]   TestKeyValueContainerMarkUnhealthy.testMarkClosingContainerAsUnhealthy ? OutOfMemory
[ERROR]   TestKeyValueContainerMarkUnhealthy.testMarkQuasiClosedContainerAsUnhealthy ? OutOfMemory
[INFO] 
[ERROR] Tests run: 127, Failures: 0, Errors: 13, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-hdds-docs >-----------------
[INFO] Building Apache Hadoop HDDS/Ozone Documentation 0.5.0-SNAPSHOT    [8/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-docs ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-docs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-docs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/docs/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-docs ---
[INFO] No sources to compile
[INFO] 
[INFO] --- exec-maven-plugin:1.6.0:exec (default) @ hadoop-hdds-docs ---
Hugo is not yet installed. Doc generation is skipped.
which: no hugo in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/findbugs/bin:/opt/maven/bin:/opt/ant/bin:/opt/blockade/bin)
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-docs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/docs/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-docs ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-docs ---
[INFO] 
[INFO] --------------< org.apache.hadoop:hadoop-hdds-server-scm >--------------
[INFO] Building Apache Hadoop HDDS SCM Server 0.5.0-SNAPSHOT             [9/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-server-scm ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-server-scm ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-server-scm ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-server-scm ---
[INFO] Compiling 137 source files to /workdir/hadoop-hdds/server-scm/target/classes
[WARNING] /workdir/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ReplicationManager.java: /workdir/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ReplicationManager.java uses or overrides a deprecated API.
[WARNING] /workdir/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ReplicationManager.java: Recompile with -Xlint:deprecation for details.
[WARNING] /workdir/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/safemode/SCMSafeModeManager.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/safemode/SCMSafeModeManager.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-server-scm ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 6 resources
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-server-scm ---
[INFO] Compiling 58 source files to /workdir/hadoop-hdds/server-scm/target/test-classes
[WARNING] /workdir/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/MockNodeManager.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/MockNodeManager.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-server-scm ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.ozone.container.common.TestEndPoint
[ERROR] Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 1.115 s <<< FAILURE! - in org.apache.hadoop.ozone.container.common.TestEndPoint
[ERROR] org.apache.hadoop.ozone.container.common.TestEndPoint  Time elapsed: 1.113 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Server.start(Server.java:3076)
	at org.apache.hadoop.ozone.container.common.SCMTestUtils.startScmRpcServer(SCMTestUtils.java:102)
	at org.apache.hadoop.ozone.container.common.TestEndPoint.setUp(TestEndPoint.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] org.apache.hadoop.ozone.container.common.TestEndPoint  Time elapsed: 1.115 s  <<< ERROR!
java.lang.NullPointerException
	at org.apache.hadoop.fs.FileUtil.fullyDeleteContents(FileUtil.java:266)
	at org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:182)
	at org.apache.hadoop.fs.FileUtil.fullyDelete(FileUtil.java:153)
	at org.apache.hadoop.ozone.container.common.TestEndPoint.tearDown(TestEndPoint.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[INFO] Running org.apache.hadoop.ozone.container.placement.TestDatanodeMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 s - in org.apache.hadoop.ozone.container.placement.TestDatanodeMetrics
[INFO] Running org.apache.hadoop.ozone.container.placement.TestContainerPlacement
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.271 s - in org.apache.hadoop.ozone.container.placement.TestContainerPlacement
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerStateManager
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.047 s - in org.apache.hadoop.hdds.scm.container.TestContainerStateManager
[INFO] Running org.apache.hadoop.hdds.scm.container.TestReplicationManager
[ERROR] Tests run: 13, Failures: 0, Errors: 4, Skipped: 0, Time elapsed: 4.211 s <<< FAILURE! - in org.apache.hadoop.hdds.scm.container.TestReplicationManager
[ERROR] testReplicationManagerRestart(org.apache.hadoop.hdds.scm.container.TestReplicationManager)  Time elapsed: 0.626 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.start(ReplicationManager.java:167)
	at org.apache.hadoop.hdds.scm.container.TestReplicationManager.testReplicationManagerRestart(TestReplicationManager.java:131)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testOpenContainer(org.apache.hadoop.hdds.scm.container.TestReplicationManager)  Time elapsed: 0.018 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.start(ReplicationManager.java:167)
	at org.apache.hadoop.hdds.scm.container.TestReplicationManager.setup(TestReplicationManager.java:115)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testOverReplicatedQuasiClosedContainer(org.apache.hadoop.hdds.scm.container.TestReplicationManager)  Time elapsed: 0.016 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.start(ReplicationManager.java:167)
	at org.apache.hadoop.hdds.scm.container.TestReplicationManager.setup(TestReplicationManager.java:115)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[ERROR] testUnderReplicatedQuasiClosedContainer(org.apache.hadoop.hdds.scm.container.TestReplicationManager)  Time elapsed: 0.017 s  <<< ERROR!
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.start(ReplicationManager.java:167)
	at org.apache.hadoop.hdds.scm.container.TestReplicationManager.setup(TestReplicationManager.java:115)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /workdir/hadoop-hdds/server-scm/target/surefire-reports/2019-10-17T10-46-27_282-jvmRun1.dumpstream
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   TestReplicationManager.setup:115 ? OutOfMemory unable to create new native thr...
[ERROR]   TestReplicationManager.setup:115 ? OutOfMemory unable to create new native thr...
[ERROR]   TestReplicationManager.testReplicationManagerRestart:131 ? OutOfMemory unable ...
[ERROR]   TestReplicationManager.setup:115 ? OutOfMemory unable to create new native thr...
[ERROR] org.apache.hadoop.ozone.container.common.TestEndPoint.org.apache.hadoop.ozone.container.common.TestEndPoint
[ERROR]   Run 1: TestEndPoint.setUp:118 ? OutOfMemory unable to create new native thread
[ERROR]   Run 2: TestEndPoint.tearDown:111 ? NullPointer
[INFO] 
[INFO] 
[ERROR] Tests run: 18, Failures: 0, Errors: 5, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdds-tools >-----------------
[INFO] Building Apache Hadoop HDDS Tools 0.5.0-SNAPSHOT                 [10/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-tools ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-tools ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-tools ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/tools/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-tools ---
[INFO] Compiling 23 source files to /workdir/hadoop-hdds/tools/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-tools ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/tools/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-tools ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-tools ---
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-ozone >-------------------
[INFO] Building Apache Hadoop Ozone 0.5.0-SNAPSHOT                      [11/26]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-ozone ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-ozone ---
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-ozone-common >----------------
[INFO] Building Apache Hadoop Ozone Common 0.5.0-SNAPSHOT               [12/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-ozone-common ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:protoc (compile-protoc) @ hadoop-ozone-common ---
[INFO] Wrote protoc checksums to file /workdir/hadoop-ozone/common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-ozone-common ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:version-info (version-info) @ hadoop-ozone-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: e1d5461d99418ce6f29af87158167
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-ozone-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 0 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-ozone-common ---
[INFO] Compiling 107 source files to /workdir/hadoop-ozone/common/target/classes
[WARNING] /workdir/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/S3SecretManagerImpl.java: /workdir/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/S3SecretManagerImpl.java uses or overrides a deprecated API.
[WARNING] /workdir/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/S3SecretManagerImpl.java: Recompile with -Xlint:deprecation for details.
[WARNING] /workdir/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/ha/OMFailoverProxyProvider.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/ha/OMFailoverProxyProvider.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-ozone-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-ozone/common/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-ozone-common ---
[INFO] Compiling 20 source files to /workdir/hadoop-ozone/common/target/test-classes
[WARNING] /workdir/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/lock/TestOzoneManagerLock.java: /workdir/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/lock/TestOzoneManagerLock.java uses or overrides a deprecated API.
[WARNING] /workdir/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/lock/TestOzoneManagerLock.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-ozone-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /workdir/hadoop-ozone/common/target/surefire-reports/2019-10-17T10-51-45_620-jvmRun1.dumpstream
[INFO] Running org.apache.hadoop.ozone.om.codec.TestOmPrefixInfoCodec
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.146 s - in org.apache.hadoop.ozone.om.codec.TestOmPrefixInfoCodec
[INFO] Running org.apache.hadoop.ozone.om.helpers.TestOmBucketInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.145 s - in org.apache.hadoop.ozone.om.helpers.TestOmBucketInfo
[INFO] Running org.apache.hadoop.ozone.om.helpers.TestOmMultipartUpload
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.062 s - in org.apache.hadoop.ozone.om.helpers.TestOmMultipartUpload
[INFO] Running org.apache.hadoop.ozone.om.helpers.TestOzoneAclUtil
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.523 s - in org.apache.hadoop.ozone.om.helpers.TestOzoneAclUtil
[INFO] Running org.apache.hadoop.ozone.om.helpers.TestOmKeyInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.107 s - in org.apache.hadoop.ozone.om.helpers.TestOmKeyInfo
[INFO] Running org.apache.hadoop.ozone.om.exceptions.TestResultCodes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.084 s - in org.apache.hadoop.ozone.om.exceptions.TestResultCodes
[INFO] Running org.apache.hadoop.ozone.TestOzoneAcls
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.ozone.TestOzoneAcls
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-ozone-client >----------------
[INFO] Building Apache Hadoop Ozone Client 0.5.0-SNAPSHOT               [13/26]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-ozone-client ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-ozone-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-ozone-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-ozone/client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-ozone-client ---
[INFO] Compiling 29 source files to /workdir/hadoop-ozone/client/target/classes
[WARNING] /workdir/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/rpc/RpcClient.java: /workdir/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/rpc/RpcClient.java uses unchecked or unsafe operations.
[WARNING] /workdir/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/rpc/RpcClient.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-ozone-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-ozone/client/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-ozone-client ---
[INFO] Compiling 3 source files to /workdir/hadoop-ozone/client/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-ozone-client ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Apache Hadoop Ozone Main 0.5.0-SNAPSHOT:
[INFO] 
[INFO] Apache Hadoop Ozone Main ........................... SUCCESS [  0.992 s]
[INFO] Apache Hadoop HDDS ................................. SUCCESS [  2.942 s]
[INFO] Apache Hadoop HDDS Config .......................... SUCCESS [  7.852 s]
[INFO] Apache Hadoop HDDS Common .......................... SUCCESS [02:45 min]
[INFO] Apache Hadoop HDDS Client .......................... SUCCESS [  3.809 s]
[INFO] Apache Hadoop HDDS Server Framework ................ SUCCESS [ 20.491 s]
[INFO] Apache Hadoop HDDS Container Service ............... FAILURE [01:34 min]
[INFO] Apache Hadoop HDDS/Ozone Documentation ............. SUCCESS [  0.726 s]
[INFO] Apache Hadoop HDDS SCM Server ...................... FAILURE [ 18.316 s]
[INFO] Apache Hadoop HDDS Tools ........................... SUCCESS [  1.022 s]
[INFO] Apache Hadoop Ozone ................................ SUCCESS [  0.018 s]
[INFO] Apache Hadoop Ozone Common ......................... FAILURE [ 18.832 s]
[INFO] Apache Hadoop Ozone Client ......................... FAILURE [  1.240 s]
[INFO] Apache Hadoop Ozone Manager Server ................. SKIPPED
[INFO] Apache Hadoop Ozone S3 Gateway ..................... SKIPPED
[INFO] Apache Hadoop Ozone CSI service .................... SKIPPED
[INFO] Apache Hadoop Ozone Recon CodeGen .................. SKIPPED
[INFO] Apache Hadoop Ozone Recon .......................... SKIPPED
[INFO] Apache Hadoop Ozone FileSystem Single Jar Library .. SKIPPED
[INFO] Apache Hadoop Ozone FileSystem Legacy Jar Library .. SKIPPED
[INFO] Apache Hadoop Ozone Datanode ....................... SKIPPED
[INFO] Apache Hadoop Ozone In-Place Upgrade ............... SKIPPED
[INFO] Apache Hadoop Ozone Insight Tool ................... SKIPPED
[INFO] Apache Hadoop Ozone Distribution ................... SKIPPED
[INFO] Apache Hadoop Ozone Fault Injection Tests .......... SKIPPED
[INFO] Apache Hadoop Ozone Network Tests .................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  05:37 min
[INFO] Finished at: 2019-10-17T10:51:57Z
[INFO] ------------------------------------------------------------------------
[ERROR] unable to create new native thread -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/OutOfMemoryError
[INFO] Build failures were ignored.
/workdir/hadoop-ozone/dev-support/checks/_mvn_unit_report.sh: fork: Cannot allocate memory
xargs: grep: terminated by signal 13
