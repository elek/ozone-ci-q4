2019-10-13 08:57:02,941 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1065ms
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-10-13 08:57:03,565 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:03,583 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:03,586 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2019-10-13 08:57:03,587 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:03,588 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:03,637 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42705
2019-10-13 08:57:03,641 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:03,723 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49c90a9c{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:03,724 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f36c2f0{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:03,927 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(88)) - -------------------------------------------------------------
2019-10-13 08:57:03,927 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(89)) -   Java runtime version : 1.8.0_212-b04
2019-10-13 08:57:03,927 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(91)) -   User: jenkins1000
2019-10-13 08:57:03,931 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(92)) -   KMS Hadoop Version: 3.2.0
2019-10-13 08:57:03,931 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(93)) - -------------------------------------------------------------
2019-10-13 08:57:03,946 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'CREATE' ACL '*'
2019-10-13 08:57:03,948 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'DELETE' ACL '*'
2019-10-13 08:57:03,948 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'ROLLOVER' ACL '*'
2019-10-13 08:57:03,949 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GET' ACL '*'
2019-10-13 08:57:03,949 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GET_KEYS' ACL '*'
2019-10-13 08:57:03,949 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GET_METADATA' ACL '*'
2019-10-13 08:57:03,949 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'SET_KEY_MATERIAL' ACL '*'
2019-10-13 08:57:03,949 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GENERATE_EEK' ACL '*'
2019-10-13 08:57:03,950 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'DECRYPT_EEK' ACL '*'
2019-10-13 08:57:03,951 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2019-10-13 08:57:03,951 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2019-10-13 08:57:03,951 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2019-10-13 08:57:03,951 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2019-10-13 08:57:04,096 [main] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2019-10-13 08:57:04,291 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(143)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/workdir/hadoop-ozone/integration-test/target/test-dir/TestSecureOzoneRpcClient/54438f06-e315-423d-bdb6-a68010aa3a67/kms.keystore
2019-10-13 08:57:04,301 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(157)) - Initialized KeyProviderCryptoExtension EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/workdir/hadoop-ozone/integration-test/target/test-dir/TestSecureOzoneRpcClient/54438f06-e315-423d-bdb6-a68010aa3a67/kms.keystore
2019-10-13 08:57:04,301 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(162)) - Default key bitlength is 128
2019-10-13 08:57:04,301 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - KMS Started
2019-10-13 08:57:04,343 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
2019-10-13 08:57:04,346 [Thread[Thread-12,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(675)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2019-10-13 08:57:04,346 [Thread[Thread-12,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
Oct 13, 2019 8:57:04 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
Oct 13, 2019 8:57:04 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
Oct 13, 2019 8:57:04 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
Oct 13, 2019 8:57:04 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-10-13 08:57:05,917 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@245a060f{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/kms}
2019-10-13 08:57:05,928 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a50ae65{HTTP/1.1,[http/1.1]}{localhost:42705}
2019-10-13 08:57:05,929 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4056ms
2019-10-13 08:57:06,006 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-kms.properties,hadoop-metrics2.properties
2019-10-13 08:57:06,033 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-13 08:57:06,033 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2019-10-13 08:57:06,045 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23e44287] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:07,543 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:07,608 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:07,612 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:07,716 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-10-13 08:57:07,716 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-10-13 08:57:07,717 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-10-13 08:57:07,717 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-10-13 08:57:07,717 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-10-13 08:57:07,717 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-10-13 08:57:07,729 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:57:07,729 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:57:07,730 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:57:07,939 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3a175162
2019-10-13 08:57:07,941 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-10-13 08:57:07,972 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:57:07,972 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:57:07,974 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-10-13 08:57:07,985 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-10-13 08:57:08,000 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:08,060 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-10-13 08:57:08,062 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:08,162 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-10-13 08:57:08,207 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:57:08,227 [Socket Reader #1 for port 41134] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41134
2019-10-13 08:57:08,264 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:57:08,265 [Socket Reader #1 for port 44350] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44350
2019-10-13 08:57:08,274 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:57:08,275 [Socket Reader #1 for port 34068] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34068
2019-10-13 08:57:08,295 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-10-13 08:57:08,297 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:08,298 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:08,300 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:08,301 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-10-13 08:57:08,301 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:08,301 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:08,314 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:34068
2019-10-13 08:57:08,315 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2019-10-13 08:57:08,318 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:34068
2019-10-13 08:57:08,319 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:57:08,319 [IPC Server listener on 34068] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34068: starting
2019-10-13 08:57:08,322 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:44350
2019-10-13 08:57:08,323 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:44350
2019-10-13 08:57:08,323 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:57:08,323 [IPC Server listener on 44350] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44350: starting
2019-10-13 08:57:08,325 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41134
2019-10-13 08:57:08,326 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:41134
2019-10-13 08:57:08,326 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:57:08,326 [IPC Server listener on 41134] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41134: starting
2019-10-13 08:57:08,329 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43443
2019-10-13 08:57:08,329 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:08,331 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58fef7f7{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:08,332 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12eedfee{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:57:08,336 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a08efdc{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-10-13 08:57:08,337 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@57272109{HTTP/1.1,[http/1.1]}{0.0.0.0:43443}
2019-10-13 08:57:08,337 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6465ms
2019-10-13 08:57:08,339 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-10-13 08:57:08,340 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-10-13 08:57:08,341 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:43443
2019-10-13 08:57:08,342 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d6bbd35] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:08,347 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:08,365 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-10-13 08:57:08,366 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-10-13 08:57:08,367 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:08,368 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:08,476 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:57:08,486 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: userTable
2019-10-13 08:57:08,486 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-10-13 08:57:08,487 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: volumeTable
2019-10-13 08:57:08,487 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-10-13 08:57:08,487 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: bucketTable
2019-10-13 08:57:08,488 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-10-13 08:57:08,488 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: keyTable
2019-10-13 08:57:08,488 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-10-13 08:57:08,488 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedTable
2019-10-13 08:57:08,489 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-10-13 08:57:08,489 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: openKeyTable
2019-10-13 08:57:08,489 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-10-13 08:57:08,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3Table
2019-10-13 08:57:08,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-10-13 08:57:08,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: multipartInfoTable
2019-10-13 08:57:08,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-10-13 08:57:08,491 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: dTokenTable
2019-10-13 08:57:08,491 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-10-13 08:57:08,491 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3SecretTable
2019-10-13 08:57:08,492 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-10-13 08:57:08,492 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: prefixTable
2019-10-13 08:57:08,492 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-10-13 08:57:08,492 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:57:08,493 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:57:08,493 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:57:09,044 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:57:09,045 [Socket Reader #1 for port 33761] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33761
2019-10-13 08:57:09,062 [main] INFO  om.OzoneManager (OzoneManager.java:start(1071)) - OzoneManager RPC server is listening at localhost/127.0.0.1:33761
2019-10-13 08:57:09,062 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-10-13 08:57:09,082 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:57:09,082 [IPC Server listener on 33761] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33761: starting
2019-10-13 08:57:09,089 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-10-13 08:57:09,090 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:09,091 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:09,094 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:09,094 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-10-13 08:57:09,094 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:09,095 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:09,097 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42419
2019-10-13 08:57:09,097 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:09,100 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15d42ccb{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:09,101 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@46383a78{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:57:09,106 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68ee3b6d{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-10-13 08:57:09,107 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@e76b097{HTTP/1.1,[http/1.1]}{0.0.0.0:42419}
2019-10-13 08:57:09,107 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7235ms
2019-10-13 08:57:09,108 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:09,108 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:42419
2019-10-13 08:57:09,238 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:09,314 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:09,355 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:09,358 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-0/data/containers/hdds to VolumeSet
2019-10-13 08:57:09,363 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3138953b
2019-10-13 08:57:09,390 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3138953b
2019-10-13 08:57:09,553 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:09,643 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:09,648 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:09,649 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:09,650 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:09,651 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:09,652 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:09,829 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-0/data/ratis] (custom)
2019-10-13 08:57:09,879 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:09,882 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:09,882 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:09,885 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:09,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:09,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:09,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:09,887 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35065
2019-10-13 08:57:09,888 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:09,891 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5efeb117{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:09,892 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@149b4d20{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:09,935 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@322204dc{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:09,938 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@656a3d6b{HTTP/1.1,[http/1.1]}{0.0.0.0:35065}
2019-10-13 08:57:09,939 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8067ms
2019-10-13 08:57:09,939 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:09,941 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35065
2019-10-13 08:57:09,942 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:09,959 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:09,974 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:09,975 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-1/data/containers/hdds to VolumeSet
2019-10-13 08:57:09,975 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@16f0ec18
2019-10-13 08:57:09,976 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@16f0ec18
2019-10-13 08:57:09,986 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1855ee32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,020 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,021 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,021 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,021 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,022 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,022 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,022 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,023 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-1/data/ratis] (custom)
2019-10-13 08:57:10,024 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,026 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,027 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,028 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,029 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,029 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,029 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,031 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36193
2019-10-13 08:57:10,032 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,033 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b57c345{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@902fdbe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,074 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e900e1a{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,076 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@196624bf{HTTP/1.1,[http/1.1]}{0.0.0.0:36193}
2019-10-13 08:57:10,076 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8204ms
2019-10-13 08:57:10,077 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,078 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36193
2019-10-13 08:57:10,079 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,081 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2cf47299] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,083 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,089 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,089 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-2/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,089 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7fdd43cd
2019-10-13 08:57:10,090 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7fdd43cd
2019-10-13 08:57:10,112 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,113 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,113 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,114 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,114 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,119 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,120 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-2/data/ratis] (custom)
2019-10-13 08:57:10,127 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,129 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,130 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,133 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,136 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45873
2019-10-13 08:57:10,136 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,140 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b80e5a9{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,141 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a50b32d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,161 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-0/meta/datanode.id
2019-10-13 08:57:10,165 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-1/meta/datanode.id
2019-10-13 08:57:10,181 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fe07361{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,182 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@741ac284{HTTP/1.1,[http/1.1]}{0.0.0.0:45873}
2019-10-13 08:57:10,183 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8310ms
2019-10-13 08:57:10,183 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,184 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45873
2019-10-13 08:57:10,184 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,187 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@391119df] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,187 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,189 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-2/meta/datanode.id
2019-10-13 08:57:10,195 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,195 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-3/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,195 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@bd3eff4
2019-10-13 08:57:10,196 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@bd3eff4
2019-10-13 08:57:10,213 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,213 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,213 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,214 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,214 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,214 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,214 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,215 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-3/data/ratis] (custom)
2019-10-13 08:57:10,217 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,218 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,219 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,221 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,221 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,221 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,222 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,222 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35109
2019-10-13 08:57:10,222 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,224 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e140497{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,225 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b6c7012{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,258 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@f2d890c{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,258 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a2e0d57{HTTP/1.1,[http/1.1]}{0.0.0.0:35109}
2019-10-13 08:57:10,259 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8387ms
2019-10-13 08:57:10,259 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,260 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35109
2019-10-13 08:57:10,261 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,264 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4039aa6b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,264 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,265 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-3/meta/datanode.id
2019-10-13 08:57:10,270 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,271 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-4/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,271 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@415d88de
2019-10-13 08:57:10,271 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@415d88de
2019-10-13 08:57:10,288 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,288 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,289 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,289 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,289 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,289 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,289 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,290 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-4/data/ratis] (custom)
2019-10-13 08:57:10,292 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,293 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,293 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,295 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,295 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,296 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,296 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,297 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43370
2019-10-13 08:57:10,297 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,299 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11d4d979{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,299 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c25cfe1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,331 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a54acec{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,332 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19da993b{HTTP/1.1,[http/1.1]}{0.0.0.0:43370}
2019-10-13 08:57:10,333 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8460ms
2019-10-13 08:57:10,333 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,334 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43370
2019-10-13 08:57:10,334 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,339 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fc23c26] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,339 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,340 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-4/meta/datanode.id
2019-10-13 08:57:10,348 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-5/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,349 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-5/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,349 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@647b9364
2019-10-13 08:57:10,350 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@647b9364
2019-10-13 08:57:10,371 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,372 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,372 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,372 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,373 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,373 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,373 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,374 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-5/data/ratis] (custom)
2019-10-13 08:57:10,376 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,378 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,378 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,380 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,382 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37129
2019-10-13 08:57:10,382 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,384 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e7abaf7{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,385 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63bfdbcb{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,414 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6c33da7a{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,415 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@69aabcb0{HTTP/1.1,[http/1.1]}{0.0.0.0:37129}
2019-10-13 08:57:10,416 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8544ms
2019-10-13 08:57:10,416 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,417 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37129
2019-10-13 08:57:10,417 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,421 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@11849ded] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,422 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,423 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-5/meta/datanode.id
2019-10-13 08:57:10,429 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-6/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,430 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-6/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,430 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@73e776b7
2019-10-13 08:57:10,431 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@73e776b7
2019-10-13 08:57:10,451 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,451 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,451 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,452 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,452 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,452 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,452 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,453 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-6/data/ratis] (custom)
2019-10-13 08:57:10,454 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,456 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,456 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,458 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,460 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38197
2019-10-13 08:57:10,460 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,462 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42ef042a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,463 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e0c4f21{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,507 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5729b410{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,510 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@768bd5ab{HTTP/1.1,[http/1.1]}{0.0.0.0:38197}
2019-10-13 08:57:10,510 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8638ms
2019-10-13 08:57:10,510 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,511 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38197
2019-10-13 08:57:10,513 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,520 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@217d87f4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,598 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,617 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-6/meta/datanode.id
2019-10-13 08:57:10,632 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-7/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,633 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-7/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,633 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3cdff901
2019-10-13 08:57:10,659 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3cdff901
2019-10-13 08:57:10,673 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,674 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,674 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,674 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,674 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,675 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,675 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,676 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-7/data/ratis] (custom)
2019-10-13 08:57:10,679 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,681 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,682 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,683 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,684 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,684 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,684 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,685 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43257
2019-10-13 08:57:10,685 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,688 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@421d54b3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,689 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4dad8ec0{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,734 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@373afd6c{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,737 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@521441d5{HTTP/1.1,[http/1.1]}{0.0.0.0:43257}
2019-10-13 08:57:10,737 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8865ms
2019-10-13 08:57:10,738 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,739 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43257
2019-10-13 08:57:10,739 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,744 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c923df6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,744 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,746 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-7/meta/datanode.id
2019-10-13 08:57:10,767 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-8/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,768 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-8/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,768 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2f995afc
2019-10-13 08:57:10,777 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2f995afc
2019-10-13 08:57:10,800 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:57:10,800 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:57:10,801 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:57:10,801 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:57:10,801 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:57:10,801 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:57:10,801 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:57:10,802 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-8/data/ratis] (custom)
2019-10-13 08:57:10,804 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:57:10,853 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:57:10,854 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:57:10,856 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:57:10,856 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:57:10,857 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:57:10,857 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:57:10,858 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36907
2019-10-13 08:57:10,858 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:57:10,860 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35787726{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:57:10,861 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27976390{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:57:10,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@412ebe64{/,file:///workdir/hadoop-ozone/integration-test/target/tmp/kms/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:57:10,890 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6f731759{HTTP/1.1,[http/1.1]}{0.0.0.0:36907}
2019-10-13 08:57:10,890 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9018ms
2019-10-13 08:57:10,891 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:57:10,892 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36907
2019-10-13 08:57:10,892 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:57:10,896 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7977fce9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:57:10,897 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:57:10,898 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-8/meta/datanode.id
2019-10-13 08:57:10,902 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-9/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:57:10,903 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-9/data/containers/hdds to VolumeSet
2019-10-13 08:57:10,903 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@22ead351
2019-10-13 08:57:10,903 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@22ead351
2019-10-13 08:57:10,915 [Thread[Thread-12,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(696)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2019-10-13 08:57:10,926 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(191)) - KMS Stopped
2019-10-13 08:57:10,927 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@245a060f{/,null,UNAVAILABLE}{/kms}
2019-10-13 08:57:10,933 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a50ae65{HTTP/1.1,[http/1.1]}{localhost:0}
2019-10-13 08:57:10,933 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f36c2f0{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar!/webapps/static,UNAVAILABLE}
2019-10-13 08:57:10,934 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49c90a9c{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:57:10,972 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-7/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,972 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,973 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-6/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,973 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,974 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,974 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-9/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,974 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,974 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,974 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-8/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:57:10,975 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-703c8cda-f017-4c7e-a91b-5cbe0c7379d0/datanode-5/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
