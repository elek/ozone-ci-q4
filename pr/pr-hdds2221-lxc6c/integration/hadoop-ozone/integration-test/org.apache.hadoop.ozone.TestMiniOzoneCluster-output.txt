2019-10-13 08:52:50,338 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:50,443 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:50,447 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:50,473 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @953ms
2019-10-13 08:52:50,570 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-10-13 08:52:50,571 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-10-13 08:52:50,571 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-10-13 08:52:50,571 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-10-13 08:52:50,572 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-10-13 08:52:50,572 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-10-13 08:52:50,584 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:52:50,584 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:52:50,585 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:52:50,833 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@62dad3e5
2019-10-13 08:52:50,835 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-10-13 08:52:50,909 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:52:50,911 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:52:50,915 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-10-13 08:52:50,987 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-10-13 08:52:51,006 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:51,102 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-10-13 08:52:51,104 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:51,200 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-10-13 08:52:51,668 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:52:51,698 [Socket Reader #1 for port 43654] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43654
2019-10-13 08:52:51,820 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:52:51,821 [Socket Reader #1 for port 37979] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37979
2019-10-13 08:52:51,829 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:52:51,829 [Socket Reader #1 for port 39229] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39229
2019-10-13 08:52:51,849 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-10-13 08:52:52,032 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:52:52,041 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:52:52,050 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:52:52,053 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-10-13 08:52:52,053 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:52:52,053 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:52:52,085 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39229
2019-10-13 08:52:52,161 [Thread-0] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-10-13 08:52:52,174 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-13 08:52:52,174 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-10-13 08:52:52,474 [Thread-0] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:39229
2019-10-13 08:52:52,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:52:52,475 [IPC Server listener on 39229] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39229: starting
2019-10-13 08:52:52,478 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37979
2019-10-13 08:52:52,480 [Thread-0] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:37979
2019-10-13 08:52:52,480 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:52:52,480 [IPC Server listener on 37979] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37979: starting
2019-10-13 08:52:52,482 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:43654
2019-10-13 08:52:52,482 [Thread-0] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:43654
2019-10-13 08:52:52,484 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:52:52,484 [IPC Server listener on 43654] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43654: starting
2019-10-13 08:52:52,488 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41038
2019-10-13 08:52:52,491 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:52:52,540 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@514e9d25{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:52:52,542 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@da96dc0{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:52:54,139 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a11253a{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-10-13 08:52:54,145 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b809{HTTP/1.1,[http/1.1]}{0.0.0.0:41038}
2019-10-13 08:52:54,145 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @4624ms
2019-10-13 08:52:54,147 [Thread-0] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-10-13 08:52:54,147 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-10-13 08:52:54,149 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:41038
2019-10-13 08:52:54,153 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5aaed1b4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:52:54,157 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:54,454 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-10-13 08:52:54,455 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-10-13 08:52:54,456 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:54,457 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:55,195 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:52:55,205 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: userTable
2019-10-13 08:52:55,205 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-10-13 08:52:55,206 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: volumeTable
2019-10-13 08:52:55,206 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-10-13 08:52:55,206 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: bucketTable
2019-10-13 08:52:55,206 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-10-13 08:52:55,207 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: keyTable
2019-10-13 08:52:55,207 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-10-13 08:52:55,207 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedTable
2019-10-13 08:52:55,207 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-10-13 08:52:55,208 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: openKeyTable
2019-10-13 08:52:55,208 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-10-13 08:52:55,208 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3Table
2019-10-13 08:52:55,208 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-10-13 08:52:55,208 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: multipartInfoTable
2019-10-13 08:52:55,209 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-10-13 08:52:55,209 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: dTokenTable
2019-10-13 08:52:55,209 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-10-13 08:52:55,209 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3SecretTable
2019-10-13 08:52:55,210 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-10-13 08:52:55,210 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: prefixTable
2019-10-13 08:52:55,210 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-10-13 08:52:55,210 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:52:55,211 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:52:55,211 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:52:55,736 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:52:55,737 [Socket Reader #1 for port 43649] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43649
2019-10-13 08:52:55,758 [Thread-0] INFO  om.OzoneManager (OzoneManager.java:start(1071)) - OzoneManager RPC server is listening at localhost/127.0.0.1:43649
2019-10-13 08:52:55,758 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-10-13 08:52:55,767 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:52:55,767 [IPC Server listener on 43649] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43649: starting
2019-10-13 08:52:55,772 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-10-13 08:52:55,773 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:52:55,773 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:52:55,775 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:52:55,776 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-10-13 08:52:55,776 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:52:55,776 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:52:55,778 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37268
2019-10-13 08:52:55,778 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:52:55,780 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c971693{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:52:55,780 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72121ce4{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:52:55,785 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28375284{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-10-13 08:52:55,786 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7c80edf3{HTTP/1.1,[http/1.1]}{0.0.0.0:37268}
2019-10-13 08:52:55,787 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @6266ms
2019-10-13 08:52:55,787 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:52:55,788 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:37268
2019-10-13 08:52:56,068 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:52:56,118 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:52:56,149 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:52:56,151 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-0/data/containers/hdds to VolumeSet
2019-10-13 08:52:56,154 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ed4ba21
2019-10-13 08:52:56,172 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ed4ba21
2019-10-13 08:52:56,303 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:52:56,371 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:52:56,376 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:52:56,377 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:52:56,379 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:52:56,379 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:52:56,380 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:52:56,546 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-0/data/ratis] (custom)
2019-10-13 08:52:56,598 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:52:56,600 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:52:56,600 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:52:56,602 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:52:56,603 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:52:56,603 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:52:56,603 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:52:56,604 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34715
2019-10-13 08:52:56,604 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:52:56,607 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1182e7f{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:52:56,607 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a8a165d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:52:56,647 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f4b0243{/,file:///tmp/jetty-0.0.0.0-34715-hddsDatanode-_-any-241558463803142969.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:52:56,649 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c86696{HTTP/1.1,[http/1.1]}{0.0.0.0:34715}
2019-10-13 08:52:56,655 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @7134ms
2019-10-13 08:52:56,655 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:52:56,656 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34715
2019-10-13 08:52:56,658 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:52:56,663 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:52:56,668 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18caa33a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:52:56,671 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:52:56,672 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-1/data/containers/hdds to VolumeSet
2019-10-13 08:52:56,672 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@176e13be
2019-10-13 08:52:56,675 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@176e13be
2019-10-13 08:52:56,696 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:52:56,696 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:52:56,697 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:52:56,697 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:52:56,697 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:52:56,698 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:52:56,698 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:52:56,700 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-1/data/ratis] (custom)
2019-10-13 08:52:56,703 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:52:56,705 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:52:56,706 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:52:56,708 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:52:56,708 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:52:56,709 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:52:56,709 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:52:56,711 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42913
2019-10-13 08:52:56,711 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:52:56,716 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32715fa1{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:52:56,716 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4cb53dc5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:52:56,750 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2dc64361{/,file:///tmp/jetty-0.0.0.0-42913-hddsDatanode-_-any-7057895440437532890.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:52:56,752 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b2f8187{HTTP/1.1,[http/1.1]}{0.0.0.0:42913}
2019-10-13 08:52:56,753 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @7232ms
2019-10-13 08:52:56,753 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:52:56,754 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42913
2019-10-13 08:52:56,755 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:52:56,758 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@55b5badb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:52:56,759 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:52:56,766 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:52:56,767 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/containers/hdds to VolumeSet
2019-10-13 08:52:56,767 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4c479fee
2019-10-13 08:52:56,768 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4c479fee
2019-10-13 08:52:56,787 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:52:56,787 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:52:56,788 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:52:56,788 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:52:56,789 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:52:56,789 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:52:56,789 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:52:56,790 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis] (custom)
2019-10-13 08:52:56,793 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:52:56,795 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:52:56,796 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:52:56,798 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:52:56,799 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:52:56,799 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:52:56,799 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:52:56,800 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43413
2019-10-13 08:52:56,800 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:52:56,802 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ced072b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:52:56,803 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a4bfb65{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:52:56,820 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-0/meta/datanode.id
2019-10-13 08:52:56,823 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-1/meta/datanode.id
2019-10-13 08:52:57,768 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5250220e{/,file:///tmp/jetty-0.0.0.0-43413-hddsDatanode-_-any-4984152235438024322.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:52:57,770 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e4dac37{HTTP/1.1,[http/1.1]}{0.0.0.0:43413}
2019-10-13 08:52:57,770 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @8250ms
2019-10-13 08:52:57,771 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:52:57,771 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43413
2019-10-13 08:52:57,773 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:52:57,774 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47006953] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:52:57,776 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/meta/datanode.id
2019-10-13 08:52:58,767 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:52:58,769 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:52:58,773 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:52:58,773 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:52:58,774 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:52:58,774 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis d9f74945-47a6-4b02-a24a-d4d9c3c70f89 at port 0
2019-10-13 08:52:58,774 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd at port 0
2019-10-13 08:52:58,784 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:52:58,784 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:52:59,775 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:52:59,790 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:52:59,792 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:52:59,792 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:52:59,792 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:00,671 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:00,671 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:00,671 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd at port 0
2019-10-13 08:53:00,672 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:00,761 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:00,761 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:00,761 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis d9f74945-47a6-4b02-a24a-d4d9c3c70f89 at port 0
2019-10-13 08:53:00,762 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:00,776 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:53:01,778 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:53:01,781 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:01,781 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:01,781 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:01,782 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:02,671 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:02,671 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:02,671 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd at port 0
2019-10-13 08:53:02,672 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:02,762 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:02,762 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:02,762 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis d9f74945-47a6-4b02-a24a-d4d9c3c70f89 at port 0
2019-10-13 08:53:02,762 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:02,778 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:53:03,778 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:03,779 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:53:03,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:03,779 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:03,781 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:04,671 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:04,672 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:04,672 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd at port 0
2019-10-13 08:53:04,687 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd: start RPC server
2019-10-13 08:53:04,761 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:04,762 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:04,762 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis d9f74945-47a6-4b02-a24a-d4d9c3c70f89 at port 0
2019-10-13 08:53:04,764 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d9f74945-47a6-4b02-a24a-d4d9c3c70f89: start RPC server
2019-10-13 08:53:04,781 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:53:04,813 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd: GrpcService started, listening on 0.0.0.0/0.0.0.0:36131
2019-10-13 08:53:04,815 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd is started using port 36131
2019-10-13 08:53:04,813 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d9f74945-47a6-4b02-a24a-d4d9c3c70f89: GrpcService started, listening on 0.0.0.0/0.0.0.0:42007
2019-10-13 08:53:04,817 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis d9f74945-47a6-4b02-a24a-d4d9c3c70f89 is started using port 42007
2019-10-13 08:53:04,818 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd is started using port 45877
2019-10-13 08:53:04,820 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc d9f74945-47a6-4b02-a24a-d4d9c3c70f89 is started using port 37991
2019-10-13 08:53:05,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:05,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:05,780 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:05,781 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-13 08:53:05,782 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:06,701 [IPC Server handler 1 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 43654, call Call#13 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.node.NodeStateManager.addNode(NodeStateManager.java:275)
	at org.apache.hadoop.hdds.scm.node.SCMNodeManager.register(SCMNodeManager.java:263)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:216)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:06,704 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:43654 for past 0 seconds.
org.apache.hadoop.ipc.RemoteException(java.lang.OutOfMemoryError): unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.node.NodeStateManager.addNode(NodeStateManager.java:275)
	at org.apache.hadoop.hdds.scm.node.SCMNodeManager.register(SCMNodeManager.java:263)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:216)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy34.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.register(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:173)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:120)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:47)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-10-13 08:53:06,762 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#14 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.node.NodeStateManager.addNode(NodeStateManager.java:275)
	at org.apache.hadoop.hdds.scm.node.SCMNodeManager.register(SCMNodeManager.java:263)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:216)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:06,763 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:43654 for past 0 seconds.
org.apache.hadoop.ipc.RemoteException(java.lang.OutOfMemoryError): unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.node.NodeStateManager.addNode(NodeStateManager.java:275)
	at org.apache.hadoop.hdds.scm.node.SCMNodeManager.register(SCMNodeManager.java:263)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:216)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy34.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.register(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:173)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:120)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:47)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-10-13 08:53:06,782 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:07,781 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:07,781 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:07,782 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:07,782 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:07,782 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:08,674 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-10-13 08:53:08,674 [IPC Server handler 0 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 43654, call Call#16 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:08,762 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#17 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:08,782 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:09,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:09,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:09,780 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:09,780 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:09,783 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:10,678 [IPC Server handler 1 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 43654, call Call#19 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:10,763 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#20 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:10,783 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:11,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:11,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:11,780 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:11,782 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:11,783 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:12,671 [IPC Server handler 0 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 43654, call Call#22 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:12,763 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#23 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:12,784 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:13,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:13,782 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:13,782 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:13,783 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:13,784 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:14,672 [IPC Server handler 0 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 43654, call Call#25 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:14,763 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#26 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:14,784 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:15,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:15,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:15,780 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:15,780 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:15,785 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:16,671 [IPC Server handler 0 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 43654, call Call#28 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:16,763 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#29 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:16,785 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:17,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:17,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:17,780 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:17,780 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:17,785 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:18,671 [IPC Server handler 0 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 43654, call Call#31 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:18,763 [IPC Server handler 2 on 43654] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 43654, call Call#32 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 192.168.30.5:58796
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.onMessage(SingleThreadExecutor.java:83)
	at org.apache.hadoop.hdds.server.events.EventQueue.fireEvent(EventQueue.java:177)
	at org.apache.hadoop.hdds.scm.server.SCMDatanodeProtocolServer.register(SCMDatanodeProtocolServer.java:222)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.register(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:69)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.processMessage(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolServerSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolServerSideTranslatorPB.java:77)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos$StorageContainerDatanodeProtocolService$2.callBlockingMethod(StorageContainerDatanodeProtocolProtos.java:31247)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-10-13 08:53:18,785 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:19,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:19,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:19,779 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:19,780 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(153)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: unable to create new native thread
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:148)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:185)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:46)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:376)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:186)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.prestartAllCoreThreads(ThreadPoolExecutor.java:1617)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:420)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2019-10-13 08:53:19,786 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-13 08:53:20,286 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-10-13 08:53:20,287 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-10-13 08:53:20,287 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-10-13 08:53:20,288 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43649
2019-10-13 08:53:20,293 [IPC Server listener on 43649] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43649
2019-10-13 08:53:20,297 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(250)) - Stopping OMDoubleBuffer flush thread
2019-10-13 08:53:20,297 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:53:20,298 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(193)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-10-13 08:53:20,300 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-10-13 08:53:20,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28375284{/,null,UNAVAILABLE}{/ozoneManager}
2019-10-13 08:53:20,310 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7c80edf3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:53:20,311 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72121ce4{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-13 08:53:20,312 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c971693{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:53:20,319 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-10-13 08:53:20,668 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-13 08:53:20,760 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-13 08:53:21,779 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:21,780 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:21,780 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 at port 0
2019-10-13 08:53:21,783 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: start RPC server
2019-10-13 08:53:21,787 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: GrpcService started, listening on 0.0.0.0/0.0.0.0:39086
2019-10-13 08:53:21,787 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 8dcf0e33-6b70-4639-92c4-bd13bd852442 is started using port 39086
2019-10-13 08:53:21,790 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 8dcf0e33-6b70-4639-92c4-bd13bd852442 is started using port 42607
2019-10-13 08:53:23,780 [IPC Server handler 3 on 43654] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/8dcf0e33-6b70-4639-92c4-bd13bd852442
2019-10-13 08:53:23,780 [IPC Server handler 3 on 43654] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 8dcf0e33-6b70-4639-92c4-bd13bd852442{ip: 192.168.30.5, host: pr-hdds2221-lxc6c-2460884185, networkLocation: /default-rack, certSerialId: null}
2019-10-13 08:53:23,781 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-10-13 08:53:23,781 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-10-13 08:53:24,207 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: addNew group-6AC53996743D:[8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086] returns group-6AC53996743D:java.util.concurrent.CompletableFuture@faebd09[Not completed]
2019-10-13 08:53:24,216 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: new RaftServerImpl for group-6AC53996743D:[8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086] with ContainerStateMachine:uninitialized
2019-10-13 08:53:24,217 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-13 08:53:24,218 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-13 08:53:24,218 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-13 08:53:24,219 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-13 08:53:24,219 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-13 08:53:24,226 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D: ConfigurationManager, init=-1: [8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086], old=null, confs=<EMPTY_MAP>
2019-10-13 08:53:24,226 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis] (custom)
2019-10-13 08:53:24,231 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-13 08:53:24,232 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/4e65f8f6-592c-4bc0-935c-6ac53996743d does not exist. Creating ...
2019-10-13 08:53:25,322 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:53:25,326 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:53:25,327 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d9f74945-47a6-4b02-a24a-d4d9c3c70f89: close
2019-10-13 08:53:25,327 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd: close
2019-10-13 08:53:25,330 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd: shutdown server with port 36131 now
2019-10-13 08:53:25,330 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d9f74945-47a6-4b02-a24a-d4d9c3c70f89: shutdown server with port 42007 now
2019-10-13 08:53:25,333 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd: shutdown server with port 36131 successfully
2019-10-13 08:53:25,334 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d9f74945-47a6-4b02-a24a-d4d9c3c70f89: shutdown server with port 42007 successfully
2019-10-13 08:53:26,277 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:53:26,277 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:53:26,293 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:53:26,293 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:53:26,296 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-13 08:53:26,296 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-13 08:53:26,298 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2dc64361{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-13 08:53:26,298 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3f4b0243{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-13 08:53:26,299 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b2f8187{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:53:26,299 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c86696{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:53:26,300 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4cb53dc5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-13 08:53:26,300 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a8a165d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-13 08:53:26,301 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32715fa1{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:53:26,301 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1182e7f{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:53:26,777 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-13 08:53:26,786 [Thread-193] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-10-13 08:53:26,787 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-10-13 08:53:26,929 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@69f37f22 for 8dcf0e33-6b70-4639-92c4-bd13bd852442
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2961111478ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:227)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2961111478ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-10-13 08:53:26,949 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: addNew group-DB9108498581:[d9f74945-47a6-4b02-a24a-d4d9c3c70f89:192.168.30.5:42007, 8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086, 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd:192.168.30.5:36131] returns group-DB9108498581:java.util.concurrent.CompletableFuture@48fee775[Not completed]
2019-10-13 08:53:26,951 [RATISCREATEPIPELINE3] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@bba017d for d9f74945-47a6-4b02-a24a-d4d9c3c70f89
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:76)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.30.5:42007
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-13 08:53:26,952 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@bba017d for 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:76)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:227)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.30.5:36131
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-13 08:53:27,027 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/4e65f8f6-592c-4bc0-935c-6ac53996743d/in_use.lock acquired by nodename 3491@pr-hdds2221-lxc6c-2460884185
2019-10-13 08:53:27,432 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/4e65f8f6-592c-4bc0-935c-6ac53996743d has been successfully formatted.
2019-10-13 08:53:27,434 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-6AC53996743D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-13 08:53:27,435 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-13 08:53:27,437 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-13 08:53:27,442 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-13 08:53:27,442 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:53:27,444 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:27,446 [pool-47-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-10-13 08:53:27,449 [pool-47-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-10-13 08:53:27,493 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-13 08:53:27,499 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/4e65f8f6-592c-4bc0-935c-6ac53996743d
2019-10-13 08:53:27,499 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-13 08:53:27,499 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-13 08:53:27,501 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:27,502 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-13 08:53:27,502 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-13 08:53:27,503 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-13 08:53:27,504 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-13 08:53:27,504 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-13 08:53:27,504 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-13 08:53:27,516 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-13 08:53:27,520 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-13 08:53:27,524 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-13 08:53:27,525 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-13 08:53:27,526 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-13 08:53:27,526 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-13 08:53:27,555 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: new RaftServerImpl for group-DB9108498581:[d9f74945-47a6-4b02-a24a-d4d9c3c70f89:192.168.30.5:42007, 8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086, 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd:192.168.30.5:36131] with ContainerStateMachine:uninitialized
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-DB9108498581: ConfigurationManager, init=-1: [d9f74945-47a6-4b02-a24a-d4d9c3c70f89:192.168.30.5:42007, 8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086, 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd:192.168.30.5:36131], old=null, confs=<EMPTY_MAP>
2019-10-13 08:53:27,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis] (custom)
2019-10-13 08:53:27,557 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-13 08:53:27,557 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/bfd05294-bb4d-4e98-b6a0-db9108498581 does not exist. Creating ...
2019-10-13 08:53:29,917 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/bfd05294-bb4d-4e98-b6a0-db9108498581/in_use.lock acquired by nodename 3491@pr-hdds2221-lxc6c-2460884185
2019-10-13 08:53:29,941 [RATISCREATEPIPELINE2] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@bba017d for 8dcf0e33-6b70-4639-92c4-bd13bd852442
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998755628ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998755628ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-10-13 08:53:29,952 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: addNew group-A9AA8481579F:[8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086] returns group-A9AA8481579F:java.util.concurrent.CompletableFuture@7513736f[Not completed]
2019-10-13 08:53:31,302 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:53:32,078 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/bfd05294-bb4d-4e98-b6a0-db9108498581 has been successfully formatted.
2019-10-13 08:53:32,079 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-DB9108498581: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-13 08:53:32,079 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-13 08:53:32,079 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-13 08:53:32,079 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-13 08:53:32,080 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:53:32,080 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:32,080 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-13 08:53:32,080 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-DB9108498581-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/bfd05294-bb4d-4e98-b6a0-db9108498581
2019-10-13 08:53:32,080 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-13 08:53:32,081 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-13 08:53:32,081 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:32,081 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-13 08:53:32,081 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-13 08:53:32,081 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-13 08:53:32,081 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-13 08:53:32,082 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-13 08:53:32,082 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-13 08:53:32,082 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-13 08:53:32,083 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-DB9108498581-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-13 08:53:32,083 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-13 08:53:32,083 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-13 08:53:32,083 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-13 08:53:32,084 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-13 08:53:32,091 [pool-47-thread-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: remove      null 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-DB9108498581:t0, leader=null, voted=null, raftlog=8dcf0e33-6b70-4639-92c4-bd13bd852442@group-DB9108498581-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d9f74945-47a6-4b02-a24a-d4d9c3c70f89:192.168.30.5:42007, 8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086, 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd:192.168.30.5:36131], old=null NEW
2019-10-13 08:53:32,092 [pool-47-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: Failed groupAdd* GroupManagementRequest:client-6093138E1DC4->8dcf0e33-6b70-4639-92c4-bd13bd852442@group-DB9108498581, cid=2, seq=0, RW, null, Add:group-DB9108498581:[d9f74945-47a6-4b02-a24a-d4d9c3c70f89:192.168.30.5:42007, 8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086, 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd:192.168.30.5:36131]
java.util.concurrent.CompletionException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@5185f77e rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 2, completed tasks = 1]
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@5185f77e rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 2, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)
	at java.util.concurrent.CompletableFuture$UniCompletion.claim(CompletableFuture.java:529)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:599)
	... 6 more
2019-10-13 08:53:32,093 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D: start as a follower, conf=-1: [8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086], old=null
2019-10-13 08:53:32,095 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-13 08:53:32,096 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: start FollowerState
2019-10-13 08:53:32,099 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AC53996743D,id=8dcf0e33-6b70-4639-92c4-bd13bd852442
2019-10-13 08:53:32,117 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: new RaftServerImpl for group-A9AA8481579F:[8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086] with ContainerStateMachine:uninitialized
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-A9AA8481579F: ConfigurationManager, init=-1: [8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086], old=null, confs=<EMPTY_MAP>
2019-10-13 08:53:32,118 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis] (custom)
2019-10-13 08:53:32,119 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-13 08:53:32,119 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/37d643f5-c340-4906-a843-a9aa8481579f does not exist. Creating ...
2019-10-13 08:53:32,947 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@1fa19515 for 8dcf0e33-6b70-4639-92c4-bd13bd852442
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999762346ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:227)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999762346ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-10-13 08:53:32,959 [RATISCREATEPIPELINE2] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@22a7d2fc for d9f74945-47a6-4b02-a24a-d4d9c3c70f89
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:76)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.30.5:42007
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-13 08:53:32,960 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@22a7d2fc for 28c8fa72-68d9-4bf3-8c6f-13d81e1d26cd
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:76)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:227)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.30.5:36131
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-13 08:53:32,987 [RATISCREATEPIPELINE3] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$186/1452151876@22a7d2fc for 8dcf0e33-6b70-4639-92c4-bd13bd852442
java.io.IOException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$AsyncSupply@3a42132 rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 3]
	at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54)
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:106)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$AsyncSupply@3a42132 rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 3]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.ratis.util.ReflectionUtils.instantiateException(ReflectionUtils.java:222)
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:104)
	... 17 more
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: Task java.util.concurrent.CompletableFuture$AsyncSupply@3a42132 rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 3]
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
	Suppressed: java.lang.IllegalStateException: Failed to cast the object to class java.io.IOException
		at org.apache.ratis.util.IOUtils.readObject(IOUtils.java:204)
		at org.apache.ratis.util.IOUtils.bytes2Object(IOUtils.java:195)
		at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
		at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
		at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
		... 15 more
	Caused by: java.lang.ClassCastException: Cannot cast java.util.concurrent.RejectedExecutionException to java.io.IOException
		at java.lang.Class.cast(Class.java:3369)
		at org.apache.ratis.util.IOUtils.readObject(IOUtils.java:200)
		... 19 more
2019-10-13 08:53:34,812 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/37d643f5-c340-4906-a843-a9aa8481579f/in_use.lock acquired by nodename 3491@pr-hdds2221-lxc6c-2460884185
2019-10-13 08:53:37,220 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/37d643f5-c340-4906-a843-a9aa8481579f has been successfully formatted.
2019-10-13 08:53:37,221 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-A9AA8481579F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-13 08:53:37,221 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-13 08:53:37,221 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-13 08:53:37,221 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-13 08:53:37,221 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-A9AA8481579F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/ratis/37d643f5-c340-4906-a843-a9aa8481579f
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:37,222 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-13 08:53:37,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-13 08:53:37,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-13 08:53:37,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-13 08:53:37,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-13 08:53:37,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-13 08:53:37,223 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-13 08:53:37,224 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-A9AA8481579F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-13 08:53:37,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-13 08:53:37,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-13 08:53:37,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-13 08:53:37,225 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-13 08:53:37,229 [pool-47-thread-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: remove      null 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-A9AA8481579F:t0, leader=null, voted=null, raftlog=8dcf0e33-6b70-4639-92c4-bd13bd852442@group-A9AA8481579F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086], old=null NEW
2019-10-13 08:53:37,229 [pool-47-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: Failed groupAdd* GroupManagementRequest:client-B3FBF259FE2F->8dcf0e33-6b70-4639-92c4-bd13bd852442@group-A9AA8481579F, cid=4, seq=0, RW, null, Add:group-A9AA8481579F:[8dcf0e33-6b70-4639-92c4-bd13bd852442:192.168.30.5:39086]
java.util.concurrent.CompletionException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@7b76e1ae rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 3]
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@7b76e1ae rejected from java.util.concurrent.ThreadPoolExecutor@5d2661cb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 3]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)
	at java.util.concurrent.CompletableFuture$UniCompletion.claim(CompletableFuture.java:529)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:599)
	... 6 more
2019-10-13 08:53:37,229 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: close
2019-10-13 08:53:37,231 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(247)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D: shutdown
2019-10-13 08:53:37,233 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AC53996743D,id=8dcf0e33-6b70-4639-92c4-bd13bd852442
2019-10-13 08:53:37,233 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: shutdown FollowerState
2019-10-13 08:53:37,234 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(117)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-13 08:53:37,234 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-StateMachineUpdater: set stopIndex = -1
2019-10-13 08:53:37,236 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D: closes. applyIndex: -1
2019-10-13 08:53:37,240 [8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-13 08:53:37,240 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442@group-6AC53996743D-SegmentedRaftLogWorker close()
2019-10-13 08:53:37,242 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: shutdown server with port 39086 now
2019-10-13 08:53:37,244 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 8dcf0e33-6b70-4639-92c4-bd13bd852442: shutdown server with port 39086 successfully
2019-10-13 08:53:37,250 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-4cd0a264-3a6f-4b53-8070-a938b70d8709/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:53:37,269 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:53:37,271 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-13 08:53:37,273 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5250220e{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-13 08:53:37,274 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e4dac37{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:53:37,275 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a4bfb65{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-13 08:53:37,277 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ced072b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:53:37,278 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-10-13 08:53:37,278 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(810)) - Stopping Replication Manager Service.
2019-10-13 08:53:37,278 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-10-13 08:53:37,278 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(817)) - Stopping Lease Manager of the command watchers
2019-10-13 08:53:37,279 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping datanode service RPC server
2019-10-13 08:53:37,279 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-10-13 08:53:37,279 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43654
2019-10-13 08:53:37,280 [IPC Server listener on 43654] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43654
2019-10-13 08:53:37,281 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:53:37,319 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-10-13 08:53:37,320 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(832)) - Stopping block service RPC server
2019-10-13 08:53:37,320 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-10-13 08:53:37,320 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37979
2019-10-13 08:53:37,321 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(839)) - Stopping the StorageContainerLocationProtocol RPC server
2019-10-13 08:53:37,322 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:53:37,322 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-10-13 08:53:37,322 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39229
2019-10-13 08:53:37,322 [IPC Server listener on 37979] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37979
2019-10-13 08:53:37,323 [IPC Server listener on 39229] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39229
2019-10-13 08:53:37,323 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping Storage Container Manager HTTP server.
2019-10-13 08:53:37,324 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:53:37,324 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a11253a{/,null,UNAVAILABLE}{/scm}
2019-10-13 08:53:37,325 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b809{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:53:37,325 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@da96dc0{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-13 08:53:37,326 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@514e9d25{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:53:37,327 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(857)) - Stopping Block Manager Service.
2019-10-13 08:53:37,327 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:53:37,327 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:53:37,328 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(879)) - Stopping SCM Event Queue.
2019-10-13 08:53:37,333 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-10-13 08:53:37,337 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-10-13 08:53:37,337 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
2019-10-13 08:53:37,369 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:41,423 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:41,424 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:41,424 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-10-13 08:53:41,424 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-10-13 08:53:41,424 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-10-13 08:53:41,425 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-10-13 08:53:41,425 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-10-13 08:53:41,425 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-10-13 08:53:41,425 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:53:41,425 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:53:41,426 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:53:53,974 [Thread-202] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@2e349217
2019-10-13 08:53:53,975 [Thread-202] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-10-13 08:53:53,981 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:53:53,981 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:53:53,981 [Thread-202] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-10-13 08:53:53,982 [Thread-202] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-10-13 08:53:53,982 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:54,043 [Thread-202] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-10-13 08:53:54,043 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:54,103 [Thread-202] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-10-13 08:53:54,104 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:53:54,105 [Socket Reader #1 for port 42237] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42237
2019-10-13 08:53:54,107 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:53:54,108 [Socket Reader #1 for port 39432] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39432
2019-10-13 08:53:54,109 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:53:54,110 [Socket Reader #1 for port 44014] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44014
2019-10-13 08:53:54,112 [Thread-202] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-10-13 08:53:54,114 [Thread-202] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:53:54,115 [Thread-202] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:53:54,117 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:53:54,118 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-10-13 08:53:54,119 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:53:54,119 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:53:54,122 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:44014
2019-10-13 08:53:54,124 [Thread-202] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-10-13 08:53:54,125 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-13 08:53:54,126 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-10-13 08:53:54,143 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:53:54,152 [Thread-202] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:44014
2019-10-13 08:53:54,153 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:53:54,153 [IPC Server listener on 44014] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44014: starting
2019-10-13 08:53:54,158 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39432
2019-10-13 08:53:54,159 [Thread-202] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:39432
2019-10-13 08:53:54,159 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:53:54,160 [IPC Server listener on 39432] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39432: starting
2019-10-13 08:53:54,162 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:42237
2019-10-13 08:53:54,162 [Thread-202] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:42237
2019-10-13 08:53:54,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:53:54,165 [IPC Server listener on 42237] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42237: starting
2019-10-13 08:53:54,167 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41432
2019-10-13 08:53:54,168 [Thread-202] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:53:54,169 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66230183{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:53:54,170 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@151df571{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:53:54,687 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@79f83f4a{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-10-13 08:53:54,688 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a32a0ff{HTTP/1.1,[http/1.1]}{0.0.0.0:41432}
2019-10-13 08:53:54,689 [Thread-202] INFO  server.Server (Server.java:doStart(419)) - Started @65168ms
2019-10-13 08:53:54,689 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:53:54,690 [Thread-202] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:41432
2019-10-13 08:53:54,690 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:54,690 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d99f207] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:53:54,705 [Thread-202] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-10-13 08:53:54,705 [Thread-202] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-10-13 08:53:54,705 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:54,706 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:54,715 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:53:54,716 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: userTable
2019-10-13 08:53:54,716 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-10-13 08:53:54,716 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: volumeTable
2019-10-13 08:53:54,716 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-10-13 08:53:54,717 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: bucketTable
2019-10-13 08:53:54,717 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-10-13 08:53:54,717 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: keyTable
2019-10-13 08:53:54,717 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-10-13 08:53:54,717 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedTable
2019-10-13 08:53:54,717 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-10-13 08:53:54,718 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: openKeyTable
2019-10-13 08:53:54,718 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-10-13 08:53:54,718 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3Table
2019-10-13 08:53:54,718 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-10-13 08:53:54,718 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: multipartInfoTable
2019-10-13 08:53:54,718 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-10-13 08:53:54,719 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: dTokenTable
2019-10-13 08:53:54,719 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-10-13 08:53:54,719 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3SecretTable
2019-10-13 08:53:54,719 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-10-13 08:53:54,719 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: prefixTable
2019-10-13 08:53:54,719 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-10-13 08:53:54,720 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:53:54,720 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:53:54,720 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:53:55,200 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:53:55,201 [Socket Reader #1 for port 34804] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34804
2019-10-13 08:53:55,216 [Thread-202] INFO  om.OzoneManager (OzoneManager.java:start(1071)) - OzoneManager RPC server is listening at localhost/127.0.0.1:34804
2019-10-13 08:53:55,216 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-10-13 08:53:55,218 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:53:55,218 [IPC Server listener on 34804] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34804: starting
2019-10-13 08:53:55,222 [Thread-202] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-10-13 08:53:55,224 [Thread-202] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:53:55,224 [Thread-202] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:53:55,226 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:53:55,227 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-10-13 08:53:55,227 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:53:55,227 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:53:55,227 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36061
2019-10-13 08:53:55,227 [Thread-202] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:53:55,230 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@eacd7d2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:53:55,231 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3affa986{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:53:55,235 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24f0ee1f{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-10-13 08:53:55,236 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f4bfa04{HTTP/1.1,[http/1.1]}{0.0.0.0:36061}
2019-10-13 08:53:55,236 [Thread-202] INFO  server.Server (Server.java:doStart(419)) - Started @65715ms
2019-10-13 08:53:55,236 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:53:55,236 [Thread-202] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:36061
2019-10-13 08:53:55,241 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-13 08:53:55,243 [Thread-202] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:53:55,249 [Thread-202] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:53:55,249 [Thread-202] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers/hdds to VolumeSet
2019-10-13 08:53:55,250 [Thread-202] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@36e92d94
2019-10-13 08:53:55,251 [Thread-202] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@36e92d94
2019-10-13 08:53:55,266 [Thread-202] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:53:55,266 [Thread-202] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:53:55,266 [Thread-202] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:53:55,267 [Thread-202] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:53:55,267 [Thread-202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:53:55,267 [Thread-202] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:53:55,267 [Thread-202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:53:55,268 [Thread-202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis] (custom)
2019-10-13 08:53:55,270 [Thread-202] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-13 08:53:55,271 [Thread-202] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:53:55,272 [Thread-202] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:53:55,274 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:53:55,275 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:53:55,275 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:53:55,276 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:53:55,277 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36915
2019-10-13 08:53:55,277 [Thread-202] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:53:55,279 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67456f60{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:53:55,279 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44316498{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:53:55,318 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f7a83ff{/,file:///tmp/jetty-0.0.0.0-36915-hddsDatanode-_-any-7788024542407065156.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:53:55,320 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1ccbfdc8{HTTP/1.1,[http/1.1]}{0.0.0.0:36915}
2019-10-13 08:53:55,320 [Thread-202] INFO  server.Server (Server.java:doStart(419)) - Started @65799ms
2019-10-13 08:53:55,320 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:53:55,321 [Thread-202] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36915
2019-10-13 08:53:55,322 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-10-13 08:53:55,324 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a1d3636] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:53:55,326 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/meta/datanode.id
2019-10-13 08:53:56,323 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-10-13 08:53:57,324 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-10-13 08:53:57,356 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:53:57,357 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:53:57,357 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis cbaa6e77-b72c-4a39-9946-d8ab9c7c0400 at port 0
2019-10-13 08:53:57,362 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start RPC server
2019-10-13 08:53:57,365 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: GrpcService started, listening on 0.0.0.0/0.0.0.0:45277
2019-10-13 08:53:57,366 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis cbaa6e77-b72c-4a39-9946-d8ab9c7c0400 is started using port 45277
2019-10-13 08:53:57,368 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc cbaa6e77-b72c-4a39-9946-d8ab9c7c0400 is started using port 42782
2019-10-13 08:53:58,324 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-10-13 08:53:59,325 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-10-13 08:53:59,328 [IPC Server handler 0 on 42237] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cbaa6e77-b72c-4a39-9946-d8ab9c7c0400
2019-10-13 08:53:59,329 [IPC Server handler 0 on 42237] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : cbaa6e77-b72c-4a39-9946-d8ab9c7c0400{ip: 192.168.30.5, host: pr-hdds2221-lxc6c-2460884185, networkLocation: /default-rack, certSerialId: null}
2019-10-13 08:53:59,329 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-10-13 08:53:59,330 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-10-13 08:53:59,330 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-10-13 08:53:59,355 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: addNew group-6D9EAFCE15BB:[cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277] returns group-6D9EAFCE15BB:java.util.concurrent.CompletableFuture@7f3c07ff[Not completed]
2019-10-13 08:53:59,357 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: new RaftServerImpl for group-6D9EAFCE15BB:[cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277] with ContainerStateMachine:uninitialized
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: ConfigurationManager, init=-1: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null, confs=<EMPTY_MAP>
2019-10-13 08:53:59,359 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis] (custom)
2019-10-13 08:53:59,360 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-13 08:53:59,360 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb does not exist. Creating ...
2019-10-13 08:53:59,373 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/in_use.lock acquired by nodename 3491@pr-hdds2221-lxc6c-2460884185
2019-10-13 08:53:59,386 [pool-77-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb has been successfully formatted.
2019-10-13 08:53:59,387 [pool-77-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-6D9EAFCE15BB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-13 08:53:59,387 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-13 08:53:59,387 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-13 08:53:59,387 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-13 08:53:59,387 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:53:59,387 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:59,391 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-13 08:53:59,391 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb
2019-10-13 08:53:59,391 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-13 08:53:59,391 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-13 08:53:59,391 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:53:59,391 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-13 08:53:59,392 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-13 08:53:59,392 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-13 08:53:59,392 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-13 08:53:59,392 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-13 08:53:59,392 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-13 08:53:59,393 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-13 08:53:59,393 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-13 08:53:59,393 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-13 08:53:59,393 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-13 08:53:59,393 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-13 08:53:59,394 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-13 08:53:59,397 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: start as a follower, conf=-1: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null
2019-10-13 08:53:59,397 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-13 08:53:59,397 [pool-77-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start FollowerState
2019-10-13 08:53:59,397 [pool-77-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D9EAFCE15BB,id=cbaa6e77-b72c-4a39-9946-d8ab9c7c0400
2019-10-13 08:53:59,441 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 46799535-95f7-42a4-9e61-6d9eafce15bb, Nodes: cbaa6e77-b72c-4a39-9946-d8ab9c7c0400{ip: 192.168.30.5, host: pr-hdds2221-lxc6c-2460884185, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-13 08:54:00,325 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-10-13 08:54:00,325 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(810)) - Stopping Replication Manager Service.
2019-10-13 08:54:00,326 [Thread-202] INFO  container.ReplicationManager (ReplicationManager.java:stop(209)) - Replication Monitor Thread is not running.
2019-10-13 08:54:00,326 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(817)) - Stopping Lease Manager of the command watchers
2019-10-13 08:54:00,326 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping datanode service RPC server
2019-10-13 08:54:00,326 [Thread-202] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-10-13 08:54:00,326 [Thread-202] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42237
2019-10-13 08:54:00,331 [IPC Server listener on 42237] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42237
2019-10-13 08:54:00,332 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:00,391 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-10-13 08:54:00,391 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(832)) - Stopping block service RPC server
2019-10-13 08:54:00,391 [Thread-202] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-10-13 08:54:00,391 [Thread-202] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39432
2019-10-13 08:54:00,393 [IPC Server listener on 39432] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39432
2019-10-13 08:54:00,393 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:00,393 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(839)) - Stopping the StorageContainerLocationProtocol RPC server
2019-10-13 08:54:00,394 [Thread-202] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-10-13 08:54:00,394 [Thread-202] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44014
2019-10-13 08:54:00,396 [IPC Server listener on 44014] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44014
2019-10-13 08:54:00,396 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping Storage Container Manager HTTP server.
2019-10-13 08:54:00,396 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:00,397 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@79f83f4a{/,null,UNAVAILABLE}{/scm}
2019-10-13 08:54:00,398 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a32a0ff{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:54:00,398 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@151df571{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-13 08:54:00,398 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66230183{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:54:00,399 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(857)) - Stopping Block Manager Service.
2019-10-13 08:54:00,399 [Thread-202] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:54:00,399 [Thread-202] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:54:00,400 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(879)) - Stopping SCM Event Queue.
2019-10-13 08:54:00,404 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-10-13 08:54:00,407 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-10-13 08:54:01,324 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-13 08:54:02,332 [Thread-344] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-10-13 08:54:02,333 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-10-13 08:54:04,544 [Thread-346] INFO  impl.FollowerState (FollowerState.java:run(108)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-FollowerState: change to CANDIDATE, lastRpcTime:5146ms, electionTimeout:5146ms
2019-10-13 08:54:04,545 [Thread-346] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown FollowerState
2019-10-13 08:54:04,545 [Thread-346] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-13 08:54:04,549 [Thread-346] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start LeaderElection
2019-10-13 08:54:04,573 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1: begin an election at term 1 for -1: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null
2019-10-13 08:54:04,575 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown LeaderElection
2019-10-13 08:54:04,575 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-13 08:54:04,576 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: change Leader from null to cbaa6e77-b72c-4a39-9946-d8ab9c7c0400 at term 1 for becomeLeader, leader elected after 5188ms
2019-10-13 08:54:04,582 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-13 08:54:04,582 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-13 08:54:04,585 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-13 08:54:04,588 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-13 08:54:04,588 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-13 08:54:04,588 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-13 08:54:04,610 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start LeaderState
2019-10-13 08:54:04,627 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-13 08:54:04,636 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: set configuration 0: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null at 0
2019-10-13 08:54:04,788 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(574)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/current/log_inprogress_0
2019-10-13 08:54:05,407 [Thread-202] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:05,408 [Thread-202] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: close
2019-10-13 08:54:05,408 [Thread-202] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(247)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: shutdown
2019-10-13 08:54:05,409 [Thread-202] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D9EAFCE15BB,id=cbaa6e77-b72c-4a39-9946-d8ab9c7c0400
2019-10-13 08:54:05,409 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown LeaderState
2019-10-13 08:54:05,410 [Thread-202] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-PendingRequests: sendNotLeaderResponses
2019-10-13 08:54:05,412 [Thread-202] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-StateMachineUpdater: set stopIndex = 0
2019-10-13 08:54:05,413 [Thread-202] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: closes. applyIndex: 0
2019-10-13 08:54:05,413 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-13 08:54:05,414 [Thread-202] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker close()
2019-10-13 08:54:05,418 [Thread-202] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown server with port 45277 now
2019-10-13 08:54:05,420 [Thread-202] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown server with port 45277 successfully
2019-10-13 08:54:05,426 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:05,438 [Thread-202] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:05,439 [Thread-202] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-13 08:54:05,440 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f7a83ff{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-13 08:54:05,440 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1ccbfdc8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:54:05,441 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44316498{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-13 08:54:05,441 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67456f60{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:54:05,445 [Thread-202] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-hddsdatanode.properties,hadoop-metrics2.properties
2019-10-13 08:54:05,446 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-13 08:54:05,446 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - HddsDatanode metrics system started
2019-10-13 08:54:05,463 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:54:05,506 [Thread-202] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2221-lxc6c-2460884185 ip:192.168.30.5
2019-10-13 08:54:05,508 [Thread-202] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers : 4096 
2019-10-13 08:54:05,509 [Thread-202] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:05,509 [Thread-202] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers/hdds to VolumeSet
2019-10-13 08:54:05,509 [Thread-202] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5562f3bf
2019-10-13 08:54:05,510 [Thread-202] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5562f3bf
2019-10-13 08:54:05,526 [Thread-202] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:05,526 [Thread-202] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:05,526 [Thread-202] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 45277 (custom)
2019-10-13 08:54:05,526 [Thread-202] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:05,526 [Thread-202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:05,527 [Thread-202] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:05,527 [Thread-202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:05,527 [Thread-202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis] (custom)
2019-10-13 08:54:05,528 [Thread-202] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb
2019-10-13 08:54:05,529 [Thread-202] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: addNew group-6D9EAFCE15BB:[] returns group-6D9EAFCE15BB:java.util.concurrent.CompletableFuture@47327902[Not completed]
2019-10-13 08:54:05,531 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: new RaftServerImpl for group-6D9EAFCE15BB:[] with ContainerStateMachine:uninitialized
2019-10-13 08:54:05,532 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-13 08:54:05,532 [Thread-202] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:36915
2019-10-13 08:54:05,532 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-13 08:54:05,532 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-13 08:54:05,532 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-13 08:54:05,532 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-13 08:54:05,533 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-10-13 08:54:05,533 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis] (custom)
2019-10-13 08:54:05,533 [Thread-202] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:54:05,533 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-13 08:54:05,534 [Thread-202] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:54:05,535 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:54:05,536 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-13 08:54:05,536 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:54:05,536 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:54:05,537 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36915
2019-10-13 08:54:05,537 [Thread-202] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:54:05,539 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d41313b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:54:05,539 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d651a39{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-13 08:54:05,569 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a40cfc8{/,file:///tmp/jetty-0.0.0.0-36915-hddsDatanode-_-any-1882646865817315090.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-13 08:54:05,570 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7df51992{HTTP/1.1,[http/1.1]}{0.0.0.0:36915}
2019-10-13 08:54:05,570 [Thread-202] INFO  server.Server (Server.java:doStart(419)) - Started @76050ms
2019-10-13 08:54:05,570 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:54:05,571 [Thread-202] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36915
2019-10-13 08:54:05,572 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7516470e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:54:05,575 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/in_use.lock acquired by nodename 3491@pr-hdds2221-lxc6c-2460884185
2019-10-13 08:54:05,576 [pool-89-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-6D9EAFCE15BB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-13 08:54:05,577 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-13 08:54:05,577 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-13 08:54:05,577 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-13 08:54:05,577 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:05,577 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-13 08:54:05,578 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-13 08:54:05,579 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-13 08:54:05,579 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-13 08:54:05,579 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-13 08:54:05,585 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: set configuration 0: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null at 0
2019-10-13 08:54:05,585 [pool-89-thread-1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(140)) - Successfully read 1 entries from segment file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/current/log_inprogress_0
2019-10-13 08:54:05,585 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
2019-10-13 08:54:05,614 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-13 08:54:05,614 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-13 08:54:05,614 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-13 08:54:05,615 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-13 08:54:07,574 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:42237 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "pr-hdds2221-lxc6c-2460884185/192.168.30.5"; destination host is: "0.0.0.0":42237; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy34.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-10-13 08:54:10,575 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:11,576 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:12,577 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:13,578 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:14,579 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:15,580 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:16,581 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:17,582 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:18,583 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:19,584 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:20,585 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:21,586 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:22,587 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:23,588 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:24,588 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:25,574 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(810)) - Stopping Replication Manager Service.
2019-10-13 08:54:25,575 [Thread-202] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-10-13 08:54:25,575 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(817)) - Stopping Lease Manager of the command watchers
2019-10-13 08:54:25,575 [Thread-202] ERROR server.StorageContainerManager (StorageContainerManager.java:stop(820)) - Lease Manager of the command watchers stop failed
2019-10-13 08:54:25,575 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping datanode service RPC server
2019-10-13 08:54:25,576 [Thread-202] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-10-13 08:54:25,576 [Thread-202] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42237
2019-10-13 08:54:25,576 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(832)) - Stopping block service RPC server
2019-10-13 08:54:25,576 [Thread-202] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-10-13 08:54:25,577 [Thread-202] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39432
2019-10-13 08:54:25,577 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(839)) - Stopping the StorageContainerLocationProtocol RPC server
2019-10-13 08:54:25,577 [Thread-202] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-10-13 08:54:25,577 [Thread-202] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44014
2019-10-13 08:54:25,577 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping Storage Container Manager HTTP server.
2019-10-13 08:54:25,577 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(857)) - Stopping Block Manager Service.
2019-10-13 08:54:25,578 [Thread-202] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:54:25,578 [Thread-202] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:54:25,578 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(879)) - Stopping SCM Event Queue.
2019-10-13 08:54:25,579 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-10-13 08:54:25,582 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-10-13 08:54:25,583 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:54:25,583 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:54:25,584 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-10-13 08:54:25,584 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-10-13 08:54:25,584 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-10-13 08:54:25,585 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-10-13 08:54:25,585 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-10-13 08:54:25,585 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-10-13 08:54:25,585 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-13 08:54:25,586 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-13 08:54:25,586 [Thread-202] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-13 08:54:25,589 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:25,645 [Thread-202] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@4d4c5a7
2019-10-13 08:54:25,645 [Thread-202] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-10-13 08:54:25,649 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:54:25,649 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-13 08:54:25,649 [Thread-202] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-10-13 08:54:25,650 [Thread-202] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-10-13 08:54:25,650 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:54:25,698 [Thread-202] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-13 08:54:25,715 [Thread-202] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-10-13 08:54:25,716 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:54:25,716 [Socket Reader #1 for port 42237] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42237
2019-10-13 08:54:25,718 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:54:25,719 [Socket Reader #1 for port 39432] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39432
2019-10-13 08:54:25,720 [Thread-202] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-13 08:54:25,720 [Socket Reader #1 for port 44014] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44014
2019-10-13 08:54:25,722 [Thread-202] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:41432
2019-10-13 08:54:25,723 [Thread-202] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-13 08:54:25,723 [Thread-202] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-13 08:54:25,725 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 08:54:25,725 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-10-13 08:54:25,726 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 08:54:25,726 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 08:54:25,728 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:44014
2019-10-13 08:54:25,729 [Thread-202] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-10-13 08:54:25,730 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-13 08:54:25,730 [Thread-202] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-10-13 08:54:25,743 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:54:25,842 [Thread-202] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:44014
2019-10-13 08:54:25,842 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:54:25,843 [IPC Server listener on 44014] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44014: starting
2019-10-13 08:54:25,846 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39432
2019-10-13 08:54:25,846 [Thread-202] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:39432
2019-10-13 08:54:25,847 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:54:25,847 [IPC Server listener on 39432] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39432: starting
2019-10-13 08:54:25,854 [Thread-202] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:42237
2019-10-13 08:54:25,855 [Thread-202] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:42237
2019-10-13 08:54:25,858 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-13 08:54:25,862 [IPC Server listener on 42237] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42237: starting
2019-10-13 08:54:25,865 [Thread-202] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41432
2019-10-13 08:54:25,865 [Thread-202] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-13 08:54:25,867 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5877f5c4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-13 08:54:25,868 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3793aeb5{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-13 08:54:26,590 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42237. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-10-13 08:54:26,596 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-13 08:54:26,596 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-13 08:54:26,597 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis cbaa6e77-b72c-4a39-9946-d8ab9c7c0400 at port 45277
2019-10-13 08:54:26,604 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: start as a follower, conf=0: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null
2019-10-13 08:54:26,604 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: changes role from      null to FOLLOWER at term 1 for startAsFollower
2019-10-13 08:54:26,604 [Datanode State Machine Thread - 0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start FollowerState
2019-10-13 08:54:26,605 [Datanode State Machine Thread - 0] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D9EAFCE15BB,id=cbaa6e77-b72c-4a39-9946-d8ab9c7c0400
2019-10-13 08:54:26,606 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start RPC server
2019-10-13 08:54:26,610 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: GrpcService started, listening on 0.0.0.0/0.0.0.0:45277
2019-10-13 08:54:27,582 [IPC Server handler 0 on 42237] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cbaa6e77-b72c-4a39-9946-d8ab9c7c0400
2019-10-13 08:54:27,583 [IPC Server handler 0 on 42237] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : cbaa6e77-b72c-4a39-9946-d8ab9c7c0400{ip: 192.168.30.5, host: pr-hdds2221-lxc6c-2460884185, networkLocation: /default-rack, certSerialId: null}
2019-10-13 08:54:27,584 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-10-13 08:54:27,585 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(108)) - Pipeline PipelineID=46799535-95f7-42a4-9e61-6d9eafce15bb reported by cbaa6e77-b72c-4a39-9946-d8ab9c7c0400{ip: 192.168.30.5, host: pr-hdds2221-lxc6c-2460884185, networkLocation: /default-rack, certSerialId: null}
2019-10-13 08:54:27,585 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-10-13 08:54:27,585 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-10-13 08:54:27,586 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(136)) - Pipeline Pipeline[ Id: 46799535-95f7-42a4-9e61-6d9eafce15bb, Nodes: cbaa6e77-b72c-4a39-9946-d8ab9c7c0400{ip: 192.168.30.5, host: pr-hdds2221-lxc6c-2460884185, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] moved to OPEN state
2019-10-13 08:54:29,829 [Thread-202] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9fd30a4{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-10-13 08:54:29,830 [Thread-202] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@20e48472{HTTP/1.1,[http/1.1]}{0.0.0.0:41432}
2019-10-13 08:54:29,830 [Thread-202] INFO  server.Server (Server.java:doStart(419)) - Started @100310ms
2019-10-13 08:54:29,830 [Thread-202] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-13 08:54:29,831 [Thread-202] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:41432
2019-10-13 08:54:29,831 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-10-13 08:54:29,832 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@428d4efb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-13 08:54:29,832 [Thread-202] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-10-13 08:54:29,832 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-10-13 08:54:29,832 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-10-13 08:54:29,832 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-10-13 08:54:29,833 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34804
2019-10-13 08:54:29,835 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(250)) - Stopping OMDoubleBuffer flush thread
2019-10-13 08:54:29,835 [IPC Server listener on 34804] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34804
2019-10-13 08:54:29,835 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:29,836 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(193)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-10-13 08:54:29,837 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-10-13 08:54:29,841 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@24f0ee1f{/,null,UNAVAILABLE}{/ozoneManager}
2019-10-13 08:54:29,841 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4f4bfa04{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-13 08:54:29,842 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3affa986{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-13 08:54:29,843 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@eacd7d2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:54:29,846 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-10-13 08:54:30,576 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-13 08:54:30,586 [Thread-455] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-10-13 08:54:30,587 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-10-13 08:54:31,656 [Thread-445] INFO  impl.FollowerState (FollowerState.java:run(108)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-FollowerState: change to CANDIDATE, lastRpcTime:5051ms, electionTimeout:5051ms
2019-10-13 08:54:31,657 [Thread-445] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown FollowerState
2019-10-13 08:54:31,657 [Thread-445] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-10-13 08:54:31,657 [Thread-445] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start LeaderElection
2019-10-13 08:54:31,671 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2: begin an election at term 2 for 0: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null
2019-10-13 08:54:31,672 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown LeaderElection
2019-10-13 08:54:31,673 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-10-13 08:54:31,673 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: change Leader from null to cbaa6e77-b72c-4a39-9946-d8ab9c7c0400 at term 2 for becomeLeader, leader elected after 26095ms
2019-10-13 08:54:31,673 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-13 08:54:31,673 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-13 08:54:31,673 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-13 08:54:31,674 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-13 08:54:31,674 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-13 08:54:31,674 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-13 08:54:31,674 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: start LeaderState
2019-10-13 08:54:31,675 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(390)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2019-10-13 08:54:31,677 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(531)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/current/log_0-0
2019-10-13 08:54:31,680 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: set configuration 1: [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400:192.168.30.5:45277], old=null at 1
2019-10-13 08:54:31,713 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(574)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/ratis/46799535-95f7-42a4-9e61-6d9eafce15bb/current/log_inprogress_1
2019-10-13 08:54:34,847 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:34,848 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: close
2019-10-13 08:54:34,848 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(247)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: shutdown
2019-10-13 08:54:34,849 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D9EAFCE15BB,id=cbaa6e77-b72c-4a39-9946-d8ab9c7c0400
2019-10-13 08:54:34,849 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown LeaderState
2019-10-13 08:54:34,849 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-PendingRequests: sendNotLeaderResponses
2019-10-13 08:54:34,853 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-StateMachineUpdater: set stopIndex = 2
2019-10-13 08:54:34,853 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB: closes. applyIndex: 2
2019-10-13 08:54:34,854 [cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-13 08:54:34,855 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400@group-6D9EAFCE15BB-SegmentedRaftLogWorker close()
2019-10-13 08:54:34,856 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown server with port 45277 now
2019-10-13 08:54:34,857 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - cbaa6e77-b72c-4a39-9946-d8ab9c7c0400: shutdown server with port 45277 successfully
2019-10-13 08:54:34,860 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-282b4ad0-4abf-4c52-a30d-40644c8199e3/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:34,874 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:34,876 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-13 08:54:34,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a40cfc8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-13 08:54:34,878 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7df51992{HTTP/1.1,[http/1.1]}{0.0.0.0:36915}
2019-10-13 08:54:34,879 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d651a39{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-13 08:54:34,879 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d41313b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:54:34,880 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-10-13 08:54:34,880 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(810)) - Stopping Replication Manager Service.
2019-10-13 08:54:34,880 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-10-13 08:54:34,880 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(817)) - Stopping Lease Manager of the command watchers
2019-10-13 08:54:34,880 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping datanode service RPC server
2019-10-13 08:54:34,881 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-10-13 08:54:34,881 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42237
2019-10-13 08:54:34,883 [IPC Server listener on 42237] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42237
2019-10-13 08:54:34,883 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:34,962 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-10-13 08:54:34,963 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(832)) - Stopping block service RPC server
2019-10-13 08:54:34,963 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-10-13 08:54:34,964 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39432
2019-10-13 08:54:34,965 [IPC Server listener on 39432] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39432
2019-10-13 08:54:34,965 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:34,965 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(839)) - Stopping the StorageContainerLocationProtocol RPC server
2019-10-13 08:54:34,966 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-10-13 08:54:34,966 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44014
2019-10-13 08:54:34,967 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping Storage Container Manager HTTP server.
2019-10-13 08:54:34,967 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-13 08:54:34,967 [IPC Server listener on 44014] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44014
2019-10-13 08:54:34,969 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9fd30a4{/,null,UNAVAILABLE}{/scm}
2019-10-13 08:54:34,969 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@20e48472{HTTP/1.1,[http/1.1]}{0.0.0.0:41432}
2019-10-13 08:54:34,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3793aeb5{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-13 08:54:34,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5877f5c4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-13 08:54:34,971 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(857)) - Stopping Block Manager Service.
2019-10-13 08:54:34,971 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:54:34,971 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-13 08:54:34,972 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(879)) - Stopping SCM Event Queue.
2019-10-13 08:54:34,975 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2019-10-13 08:54:34,977 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2019-10-13 08:54:34,993 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:173)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 36 more
2019-10-13 08:54:34,996 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
2019-10-13 08:54:35,020 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:35,021 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds to VolumeSet
2019-10-13 08:54:35,021 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6295d394
2019-10-13 08:54:35,022 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6295d394
2019-10-13 08:54:35,034 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-10-13 08:54:35,034 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:35,035 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:35,035 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:54:35,035 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:35,035 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:35,036 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:35,036 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:35,036 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-10-13 08:54:35,041 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:35,041 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds to VolumeSet
2019-10-13 08:54:35,041 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@15761df8
2019-10-13 08:54:35,042 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@15761df8
2019-10-13 08:54:35,054 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-10-13 08:54:35,055 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:35,056 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:35,056 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:54:35,057 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:35,057 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:35,057 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:35,057 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:35,058 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-10-13 08:54:35,063 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:35,064 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds to VolumeSet
2019-10-13 08:54:35,064 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4f638935
2019-10-13 08:54:35,065 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4f638935
2019-10-13 08:54:35,077 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-10-13 08:54:35,077 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:35,078 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:35,078 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:54:35,078 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:35,078 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:35,078 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:35,078 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:35,079 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-10-13 08:54:35,081 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 940cd160-3776-4bb8-bef3-a6d16dbbdab5 is started using port 39086
2019-10-13 08:54:35,081 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 940cd160-3776-4bb8-bef3-a6d16dbbdab5 at port 0
2019-10-13 08:54:35,085 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 940cd160-3776-4bb8-bef3-a6d16dbbdab5: start RPC server
2019-10-13 08:54:35,086 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 940cd160-3776-4bb8-bef3-a6d16dbbdab5: GrpcService started, listening on 0.0.0.0/0.0.0.0:46250
2019-10-13 08:54:35,086 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 940cd160-3776-4bb8-bef3-a6d16dbbdab5 is started using port 46250
2019-10-13 08:54:35,087 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc d77a07ad-34c1-441d-aee7-8d55af7a3c0b is started using port 39642
2019-10-13 08:54:35,087 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis d77a07ad-34c1-441d-aee7-8d55af7a3c0b at port 0
2019-10-13 08:54:35,092 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d77a07ad-34c1-441d-aee7-8d55af7a3c0b: start RPC server
2019-10-13 08:54:35,093 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d77a07ad-34c1-441d-aee7-8d55af7a3c0b: GrpcService started, listening on 0.0.0.0/0.0.0.0:34536
2019-10-13 08:54:35,093 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis d77a07ad-34c1-441d-aee7-8d55af7a3c0b is started using port 34536
2019-10-13 08:54:35,095 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 3583d3bb-b268-4a04-94cf-7518a443980b is started using port 37136
2019-10-13 08:54:35,095 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 3583d3bb-b268-4a04-94cf-7518a443980b at port 0
2019-10-13 08:54:35,099 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 3583d3bb-b268-4a04-94cf-7518a443980b: start RPC server
2019-10-13 08:54:35,103 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 3583d3bb-b268-4a04-94cf-7518a443980b: GrpcService started, listening on 0.0.0.0/0.0.0.0:41895
2019-10-13 08:54:35,103 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 3583d3bb-b268-4a04-94cf-7518a443980b is started using port 41895
2019-10-13 08:54:35,103 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 940cd160-3776-4bb8-bef3-a6d16dbbdab5: close
2019-10-13 08:54:35,103 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 940cd160-3776-4bb8-bef3-a6d16dbbdab5: shutdown server with port 46250 now
2019-10-13 08:54:35,105 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 940cd160-3776-4bb8-bef3-a6d16dbbdab5: shutdown server with port 46250 successfully
2019-10-13 08:54:35,106 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d77a07ad-34c1-441d-aee7-8d55af7a3c0b: close
2019-10-13 08:54:35,106 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d77a07ad-34c1-441d-aee7-8d55af7a3c0b: shutdown server with port 34536 now
2019-10-13 08:54:35,107 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d77a07ad-34c1-441d-aee7-8d55af7a3c0b: shutdown server with port 34536 successfully
2019-10-13 08:54:35,108 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 3583d3bb-b268-4a04-94cf-7518a443980b: close
2019-10-13 08:54:35,109 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 3583d3bb-b268-4a04-94cf-7518a443980b: shutdown server with port 41895 now
2019-10-13 08:54:35,110 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 3583d3bb-b268-4a04-94cf-7518a443980b: shutdown server with port 41895 successfully
2019-10-13 08:54:35,113 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:35,113 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:35,125 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:35,125 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:35,126 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:35,136 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:35,136 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:35,136 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:35,146 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:35,148 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T : 8192 
2019-10-13 08:54:35,149 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:35,149 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds to VolumeSet
2019-10-13 08:54:35,149 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@72a7c7e0
2019-10-13 08:54:35,149 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@72a7c7e0
2019-10-13 08:54:35,163 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-10-13 08:54:35,165 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:35,165 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:35,166 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:54:35,166 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:35,166 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:35,166 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:35,166 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:35,167 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-10-13 08:54:35,171 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T : 8192 
2019-10-13 08:54:35,171 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:35,171 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds to VolumeSet
2019-10-13 08:54:35,171 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@64cd705f
2019-10-13 08:54:35,172 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@64cd705f
2019-10-13 08:54:35,187 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-10-13 08:54:35,188 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:35,188 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:35,188 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:54:35,188 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:35,189 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:35,189 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:35,189 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:35,189 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-10-13 08:54:35,192 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T : 8192 
2019-10-13 08:54:35,192 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-13 08:54:35,193 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T/hdds to VolumeSet
2019-10-13 08:54:35,193 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7a69b07
2019-10-13 08:54:35,193 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7a69b07
2019-10-13 08:54:35,205 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-10-13 08:54:35,206 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-13 08:54:35,206 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-13 08:54:35,206 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-13 08:54:35,206 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-13 08:54:35,206 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-13 08:54:35,206 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-13 08:54:35,207 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-13 08:54:35,207 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-10-13 08:54:35,208 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:35,208 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:35,217 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:35,218 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:35,218 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:35,227 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-13 08:54:35,227 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-13 08:54:35,227 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/rEr7dUtp7T] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-13 08:54:35,236 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
