2019-09-26 16:23:01,091 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:01,179 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:01,181 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:01,211 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @862ms
2019-09-26 16:23:01,337 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 16:23:01,337 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 16:23:01,337 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 16:23:01,338 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 16:23:01,338 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 16:23:01,338 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 16:23:01,350 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 16:23:01,350 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 16:23:01,352 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 16:23:01,610 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@55141def
2019-09-26 16:23:01,612 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 16:23:01,710 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 16:23:01,712 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 16:23:01,715 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 16:23:01,789 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 16:23:01,804 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:01,864 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 16:23:01,866 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:01,983 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 16:23:02,347 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 16:23:02,375 [Socket Reader #1 for port 43412] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43412
2019-09-26 16:23:02,522 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 16:23:02,524 [Socket Reader #1 for port 38588] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38588
2019-09-26 16:23:02,533 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 16:23:02,534 [Socket Reader #1 for port 41728] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41728
2019-09-26 16:23:02,557 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 16:23:02,740 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 16:23:02,755 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 16:23:02,768 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 16:23:02,772 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 16:23:02,773 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 16:23:02,773 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 16:23:02,815 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:41728
2019-09-26 16:23:02,886 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 16:23:02,901 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 16:23:02,902 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 16:23:03,173 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:41728
2019-09-26 16:23:03,174 [IPC Server listener on 41728] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41728: starting
2019-09-26 16:23:03,174 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 16:23:03,178 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38588
2019-09-26 16:23:03,179 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:38588
2019-09-26 16:23:03,180 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 16:23:03,180 [IPC Server listener on 38588] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38588: starting
2019-09-26 16:23:03,185 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:43412
2019-09-26 16:23:03,185 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:43412
2019-09-26 16:23:03,186 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 16:23:03,187 [IPC Server listener on 43412] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43412: starting
2019-09-26 16:23:03,197 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37971
2019-09-26 16:23:03,199 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 16:23:03,237 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 16:23:03,238 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 16:23:03,271 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5398edd0{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-26 16:23:03,277 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:37971}
2019-09-26 16:23:03,278 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2929ms
2019-09-26 16:23:03,280 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 16:23:03,280 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 16:23:03,281 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:37971
2019-09-26 16:23:03,287 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1095f122] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 16:23:03,289 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:03,396 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-26 16:23:03,397 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 16:23:03,398 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:03,399 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:04,151 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 16:23:04,159 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 16:23:04,160 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 16:23:04,160 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 16:23:04,160 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 16:23:04,160 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 16:23:04,160 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 16:23:04,161 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 16:23:04,161 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 16:23:04,161 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 16:23:04,161 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 16:23:04,162 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 16:23:04,162 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 16:23:04,162 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 16:23:04,162 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 16:23:04,163 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 16:23:04,163 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 16:23:04,163 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 16:23:04,163 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 16:23:04,164 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 16:23:04,164 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 16:23:04,164 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 16:23:04,164 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 16:23:04,165 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 16:23:04,165 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 16:23:04,165 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 16:23:04,748 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 16:23:04,750 [Socket Reader #1 for port 43893] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43893
2019-09-26 16:23:04,780 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:43893
2019-09-26 16:23:04,780 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 16:23:04,782 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 16:23:04,782 [IPC Server listener on 43893] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43893: starting
2019-09-26 16:23:04,794 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 16:23:04,796 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 16:23:04,797 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 16:23:04,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 16:23:04,803 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 16:23:04,803 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 16:23:04,803 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 16:23:04,807 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43682
2019-09-26 16:23:04,807 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 16:23:04,810 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 16:23:04,811 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 16:23:04,819 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@529cfee5{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-26 16:23:04,820 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:43682}
2019-09-26 16:23:04,820 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4472ms
2019-09-26 16:23:04,821 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 16:23:04,822 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:43682
2019-09-26 16:23:05,143 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 16:23:05,220 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 16:23:05,286 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 16:23:05,288 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 16:23:05,291 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-26 16:23:05,311 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-26 16:23:05,427 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 16:23:05,498 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 16:23:05,503 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 16:23:05,504 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 16:23:05,506 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:05,507 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 16:23:05,508 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 16:23:05,696 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis] (custom)
2019-09-26 16:23:05,750 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 16:23:05,753 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 16:23:05,754 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 16:23:05,757 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 16:23:05,759 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 16:23:05,759 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 16:23:05,759 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 16:23:05,761 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38221
2019-09-26 16:23:05,762 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 16:23:05,764 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 16:23:05,765 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 16:23:05,824 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7aac8884{/,file:///tmp/jetty-0.0.0.0-38221-hddsDatanode-_-any-832399757295819770.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 16:23:05,825 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:38221}
2019-09-26 16:23:05,826 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5477ms
2019-09-26 16:23:05,826 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 16:23:05,827 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38221
2019-09-26 16:23:05,829 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 16:23:05,833 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 16:23:05,835 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@41833fa9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 16:23:05,844 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 16:23:05,844 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 16:23:05,845 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-26 16:23:05,846 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-26 16:23:05,869 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 16:23:05,869 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 16:23:05,869 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 16:23:05,870 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 16:23:05,870 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:05,870 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 16:23:05,871 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 16:23:05,871 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis] (custom)
2019-09-26 16:23:05,874 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 16:23:05,876 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 16:23:05,878 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 16:23:05,880 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 16:23:05,881 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 16:23:05,882 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 16:23:05,882 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 16:23:05,883 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40620
2019-09-26 16:23:05,883 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 16:23:05,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 16:23:05,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 16:23:05,930 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7bc44ce8{/,file:///tmp/jetty-0.0.0.0-40620-hddsDatanode-_-any-3143760973635256868.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 16:23:05,931 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:40620}
2019-09-26 16:23:05,932 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5583ms
2019-09-26 16:23:05,933 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 16:23:05,934 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40620
2019-09-26 16:23:05,934 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 16:23:05,938 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6458a3b4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 16:23:05,938 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 16:23:05,949 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 16:23:05,949 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 16:23:05,949 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-26 16:23:05,950 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-26 16:23:05,965 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 16:23:05,965 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 16:23:05,966 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 16:23:05,966 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 16:23:05,966 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:05,967 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 16:23:05,967 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 16:23:05,968 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis] (custom)
2019-09-26 16:23:05,970 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 16:23:05,971 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 16:23:05,972 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 16:23:05,973 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 16:23:05,974 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 16:23:05,974 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 16:23:05,974 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 16:23:05,975 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45869
2019-09-26 16:23:05,975 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 16:23:05,978 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 16:23:05,978 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 16:23:05,990 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/meta/datanode.id
2019-09-26 16:23:05,998 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/meta/datanode.id
2019-09-26 16:23:06,028 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5dd903be{/,file:///tmp/jetty-0.0.0.0-45869-hddsDatanode-_-any-7751972462215997806.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 16:23:06,031 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:45869}
2019-09-26 16:23:06,033 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5685ms
2019-09-26 16:23:06,033 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 16:23:06,035 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45869
2019-09-26 16:23:06,039 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6301cfa1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 16:23:06,040 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 16:23:06,045 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/meta/datanode.id
2019-09-26 16:23:07,040 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 16:23:07,902 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 16:23:07,906 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 16:23:07,906 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis af5a0941-4deb-4be6-888a-fdc3fa675f59 at port 0
2019-09-26 16:23:07,934 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start RPC server
2019-09-26 16:23:07,957 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 16:23:07,964 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 16:23:07,964 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 50e264f2-152d-4343-9b7c-c19341a43184 at port 0
2019-09-26 16:23:07,980 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 50e264f2-152d-4343-9b7c-c19341a43184: start RPC server
2019-09-26 16:23:08,041 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 16:23:08,056 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 16:23:08,059 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 16:23:08,059 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis db3bdbda-baa1-4f60-ab24-3af97f8d83db at port 0
2019-09-26 16:23:08,070 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start RPC server
2019-09-26 16:23:08,099 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: GrpcService started, listening on 0.0.0.0/0.0.0.0:44751
2019-09-26 16:23:08,099 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: GrpcService started, listening on 0.0.0.0/0.0.0.0:33594
2019-09-26 16:23:08,099 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 50e264f2-152d-4343-9b7c-c19341a43184: GrpcService started, listening on 0.0.0.0/0.0.0.0:36225
2019-09-26 16:23:08,101 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis af5a0941-4deb-4be6-888a-fdc3fa675f59 is started using port 33594
2019-09-26 16:23:08,101 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis db3bdbda-baa1-4f60-ab24-3af97f8d83db is started using port 44751
2019-09-26 16:23:08,101 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 50e264f2-152d-4343-9b7c-c19341a43184 is started using port 36225
2019-09-26 16:23:08,109 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc db3bdbda-baa1-4f60-ab24-3af97f8d83db is started using port 45058
2019-09-26 16:23:08,109 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 50e264f2-152d-4343-9b7c-c19341a43184 is started using port 34890
2019-09-26 16:23:08,109 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc af5a0941-4deb-4be6-888a-fdc3fa675f59 is started using port 40680
2019-09-26 16:23:09,042 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 16:23:09,872 [IPC Server handler 8 on 43412] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/af5a0941-4deb-4be6-888a-fdc3fa675f59
2019-09-26 16:23:09,872 [IPC Server handler 8 on 43412] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : af5a0941-4deb-4be6-888a-fdc3fa675f59{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 16:23:09,877 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 16:23:09,877 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 16:23:09,877 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 16:23:09,943 [IPC Server handler 7 on 43412] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:23:09,943 [IPC Server handler 7 on 43412] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 50e264f2-152d-4343-9b7c-c19341a43184{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 16:23:10,043 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-26 16:23:10,044 [IPC Server handler 4 on 43412] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/db3bdbda-baa1-4f60-ab24-3af97f8d83db
2019-09-26 16:23:10,045 [IPC Server handler 4 on 43412] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : db3bdbda-baa1-4f60-ab24-3af97f8d83db{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 16:23:10,383 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: addNew group-764BE4B6F0F8:[af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] returns group-764BE4B6F0F8:java.util.concurrent.CompletableFuture@742aab92[Not completed]
2019-09-26 16:23:10,399 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: new RaftServerImpl for group-764BE4B6F0F8:[af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] with ContainerStateMachine:uninitialized
2019-09-26 16:23:10,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 16:23:10,403 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 16:23:10,403 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 16:23:10,404 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 16:23:10,405 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:10,413 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: ConfigurationManager, init=-1: [af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null, confs=<EMPTY_MAP>
2019-09-26 16:23:10,414 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis] (custom)
2019-09-26 16:23:10,421 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/addb61db-24df-412f-bff6-764be4b6f0f8 does not exist. Creating ...
2019-09-26 16:23:10,438 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/addb61db-24df-412f-bff6-764be4b6f0f8/in_use.lock acquired by nodename 10637@pr-hdds-2162-htzpk-1451759861
2019-09-26 16:23:10,453 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/addb61db-24df-412f-bff6-764be4b6f0f8 has been successfully formatted.
2019-09-26 16:23:10,454 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-764BE4B6F0F8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 16:23:10,455 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 16:23:10,457 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 16:23:10,462 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 16:23:10,462 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:10,464 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 16:23:10,475 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/addb61db-24df-412f-bff6-764be4b6f0f8
2019-09-26 16:23:10,476 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 16:23:10,482 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 16:23:10,508 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 16:23:10,508 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 16:23:10,511 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,511 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 16:23:10,512 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 16:23:10,512 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 16:23:10,513 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 16:23:10,513 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 16:23:10,514 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 16:23:10,521 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 16:23:10,525 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 16:23:10,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 16:23:10,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 16:23:10,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 16:23:10,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 16:23:10,553 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: start as a follower, conf=-1: [af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:10,554 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 16:23:10,555 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start FollowerState
2019-09-26 16:23:10,557 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-764BE4B6F0F8,id=af5a0941-4deb-4be6-888a-fdc3fa675f59
2019-09-26 16:23:10,623 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: addb61db-24df-412f-bff6-764be4b6f0f8, Nodes: af5a0941-4deb-4be6-888a-fdc3fa675f59{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 16:23:10,645 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 50e264f2-152d-4343-9b7c-c19341a43184: addNew group-F9686740EDCA:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225] returns group-F9686740EDCA:java.util.concurrent.CompletableFuture@4c756511[Not completed]
2019-09-26 16:23:10,677 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 50e264f2-152d-4343-9b7c-c19341a43184: new RaftServerImpl for group-F9686740EDCA:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225] with ContainerStateMachine:uninitialized
2019-09-26 16:23:10,679 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 16:23:10,679 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 16:23:10,679 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 16:23:10,679 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 16:23:10,679 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:10,679 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: ConfigurationManager, init=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225], old=null, confs=<EMPTY_MAP>
2019-09-26 16:23:10,680 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis] (custom)
2019-09-26 16:23:10,680 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/50cc76b9-2989-4387-84be-f9686740edca does not exist. Creating ...
2019-09-26 16:23:10,694 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/50cc76b9-2989-4387-84be-f9686740edca/in_use.lock acquired by nodename 10637@pr-hdds-2162-htzpk-1451759861
2019-09-26 16:23:10,707 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/50cc76b9-2989-4387-84be-f9686740edca has been successfully formatted.
2019-09-26 16:23:10,709 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F9686740EDCA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 16:23:10,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 16:23:10,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 16:23:10,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 16:23:10,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:10,711 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,711 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 16:23:10,711 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/50cc76b9-2989-4387-84be-f9686740edca
2019-09-26 16:23:10,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 16:23:10,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 16:23:10,717 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 16:23:10,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 16:23:10,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 16:23:10,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 16:23:10,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 16:23:10,718 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 16:23:10,719 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 16:23:10,719 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 16:23:10,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 16:23:10,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 16:23:10,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 16:23:10,720 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 16:23:10,724 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: start as a follower, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225], old=null
2019-09-26 16:23:10,724 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 16:23:10,725 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start FollowerState
2019-09-26 16:23:10,726 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9686740EDCA,id=50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:23:10,741 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 50cc76b9-2989-4387-84be-f9686740edca, Nodes: 50e264f2-152d-4343-9b7c-c19341a43184{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 16:23:10,762 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: addNew group-D26EB49B1FC4:[db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751] returns group-D26EB49B1FC4:java.util.concurrent.CompletableFuture@58964a69[Not completed]
2019-09-26 16:23:10,782 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: new RaftServerImpl for group-D26EB49B1FC4:[db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751] with ContainerStateMachine:uninitialized
2019-09-26 16:23:10,783 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 16:23:10,783 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 16:23:10,783 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 16:23:10,784 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 16:23:10,784 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:10,784 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: ConfigurationManager, init=-1: [db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751], old=null, confs=<EMPTY_MAP>
2019-09-26 16:23:10,784 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis] (custom)
2019-09-26 16:23:10,785 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/90af12f4-ceb2-45ed-b455-d26eb49b1fc4 does not exist. Creating ...
2019-09-26 16:23:10,798 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/90af12f4-ceb2-45ed-b455-d26eb49b1fc4/in_use.lock acquired by nodename 10637@pr-hdds-2162-htzpk-1451759861
2019-09-26 16:23:10,811 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/90af12f4-ceb2-45ed-b455-d26eb49b1fc4 has been successfully formatted.
2019-09-26 16:23:10,812 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D26EB49B1FC4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 16:23:10,812 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 16:23:10,812 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 16:23:10,813 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 16:23:10,813 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:10,813 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,813 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 16:23:10,814 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/90af12f4-ceb2-45ed-b455-d26eb49b1fc4
2019-09-26 16:23:10,847 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 16:23:10,847 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 16:23:10,848 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,848 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 16:23:10,848 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 16:23:10,848 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 16:23:10,848 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 16:23:10,849 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 16:23:10,849 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 16:23:10,849 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 16:23:10,850 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 16:23:10,850 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 16:23:10,850 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 16:23:10,851 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 16:23:10,851 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 16:23:10,856 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: start as a follower, conf=-1: [db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751], old=null
2019-09-26 16:23:10,856 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 16:23:10,856 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start FollowerState
2019-09-26 16:23:10,857 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D26EB49B1FC4,id=db3bdbda-baa1-4f60-ab24-3af97f8d83db
2019-09-26 16:23:10,869 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 90af12f4-ceb2-45ed-b455-d26eb49b1fc4, Nodes: db3bdbda-baa1-4f60-ab24-3af97f8d83db{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 16:23:10,903 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: addNew group-FE59860B229C:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] returns group-FE59860B229C:java.util.concurrent.CompletableFuture@205d0182[Not completed]
2019-09-26 16:23:10,903 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: addNew group-FE59860B229C:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] returns group-FE59860B229C:java.util.concurrent.CompletableFuture@3c009570[Not completed]
2019-09-26 16:23:10,904 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 50e264f2-152d-4343-9b7c-c19341a43184: addNew group-FE59860B229C:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] returns group-FE59860B229C:java.util.concurrent.CompletableFuture@7ac200cb[Not completed]
2019-09-26 16:23:10,906 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: new RaftServerImpl for group-FE59860B229C:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] with ContainerStateMachine:uninitialized
2019-09-26 16:23:10,906 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 16:23:10,906 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 16:23:10,906 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 16:23:10,907 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 50e264f2-152d-4343-9b7c-c19341a43184: new RaftServerImpl for group-FE59860B229C:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] with ContainerStateMachine:uninitialized
2019-09-26 16:23:10,907 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 16:23:10,907 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 16:23:10,907 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:10,907 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 16:23:10,907 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: ConfigurationManager, init=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null, confs=<EMPTY_MAP>
2019-09-26 16:23:10,907 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 16:23:10,908 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 16:23:10,908 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis] (custom)
2019-09-26 16:23:10,908 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: new RaftServerImpl for group-FE59860B229C:[50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594] with ContainerStateMachine:uninitialized
2019-09-26 16:23:10,908 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:10,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 16:23:10,908 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c does not exist. Creating ...
2019-09-26 16:23:10,908 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: ConfigurationManager, init=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null, confs=<EMPTY_MAP>
2019-09-26 16:23:10,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 16:23:10,909 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis] (custom)
2019-09-26 16:23:10,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 16:23:10,910 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c does not exist. Creating ...
2019-09-26 16:23:10,910 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 16:23:10,910 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:10,910 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: ConfigurationManager, init=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null, confs=<EMPTY_MAP>
2019-09-26 16:23:10,911 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis] (custom)
2019-09-26 16:23:10,911 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c does not exist. Creating ...
2019-09-26 16:23:10,923 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c/in_use.lock acquired by nodename 10637@pr-hdds-2162-htzpk-1451759861
2019-09-26 16:23:10,923 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c/in_use.lock acquired by nodename 10637@pr-hdds-2162-htzpk-1451759861
2019-09-26 16:23:10,923 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c/in_use.lock acquired by nodename 10637@pr-hdds-2162-htzpk-1451759861
2019-09-26 16:23:10,938 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c has been successfully formatted.
2019-09-26 16:23:10,938 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c has been successfully formatted.
2019-09-26 16:23:10,938 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c has been successfully formatted.
2019-09-26 16:23:10,938 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FE59860B229C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 16:23:10,938 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FE59860B229C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 16:23:10,938 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 16:23:10,938 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FE59860B229C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 16:23:10,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 16:23:10,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 16:23:10,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 16:23:10,939 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 16:23:10,939 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:10,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 16:23:10,940 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,939 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 16:23:10,940 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 16:23:10,940 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 16:23:10,940 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c
2019-09-26 16:23:10,940 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 16:23:10,941 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 16:23:10,941 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:10,941 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 16:23:10,941 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:10,941 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,941 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,942 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 16:23:10,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,942 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 16:23:10,942 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 16:23:10,942 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 16:23:10,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 16:23:10,943 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 16:23:10,942 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c
2019-09-26 16:23:10,943 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 16:23:10,943 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c
2019-09-26 16:23:10,943 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 16:23:10,943 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 16:23:10,944 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 16:23:10,944 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 16:23:10,944 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 16:23:10,944 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 16:23:10,944 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 16:23:10,945 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,945 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 16:23:10,944 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 16:23:10,945 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 16:23:10,945 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 16:23:10,945 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 16:23:10,945 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 16:23:10,946 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 16:23:10,946 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 16:23:10,946 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 16:23:10,946 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 16:23:10,947 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 16:23:10,947 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 16:23:10,947 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 16:23:10,947 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 16:23:10,947 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 16:23:10,948 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 16:23:10,948 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 16:23:10,948 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 16:23:10,948 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 16:23:10,948 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 16:23:10,949 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 16:23:10,949 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 16:23:10,949 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 16:23:10,949 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 16:23:10,949 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 16:23:10,949 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 16:23:10,950 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 16:23:10,950 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 16:23:10,950 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 16:23:10,951 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: start as a follower, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:10,951 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 16:23:10,952 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start FollowerState
2019-09-26 16:23:10,952 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE59860B229C,id=50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:23:10,964 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: start as a follower, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:10,964 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 16:23:10,965 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: start as a follower, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:10,965 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start FollowerState
2019-09-26 16:23:10,965 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 16:23:10,965 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start FollowerState
2019-09-26 16:23:10,965 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE59860B229C,id=db3bdbda-baa1-4f60-ab24-3af97f8d83db
2019-09-26 16:23:10,966 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE59860B229C,id=af5a0941-4deb-4be6-888a-fdc3fa675f59
2019-09-26 16:23:10,986 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bd51986c-4252-4b88-b1aa-fe59860b229c, Nodes: af5a0941-4deb-4be6-888a-fdc3fa675f59{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}50e264f2-152d-4343-9b7c-c19341a43184{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}db3bdbda-baa1-4f60-ab24-3af97f8d83db{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-26 16:23:11,044 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-26 16:23:12,237 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:12,883 [Thread-181] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-26 16:23:12,886 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-26 16:23:13,239 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:14,240 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:15,242 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:15,722 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - af5a0941-4deb-4be6-888a-fdc3fa675f59:group-764BE4B6F0F8 changes to CANDIDATE, lastRpcTime:5167, electionTimeout:5166ms
2019-09-26 16:23:15,725 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown FollowerState
2019-09-26 16:23:15,725 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 16:23:15,732 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start LeaderElection
2019-09-26 16:23:15,760 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1: begin an election at term 1 for -1: [af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:15,762 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown LeaderElection
2019-09-26 16:23:15,763 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 16:23:15,764 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: change Leader from null to af5a0941-4deb-4be6-888a-fdc3fa675f59 at term 1 for becomeLeader, leader elected after 5308ms
2019-09-26 16:23:15,772 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 16:23:15,772 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 16:23:15,776 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 16:23:15,779 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 16:23:15,780 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 16:23:15,781 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 16:23:15,797 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start LeaderState
2019-09-26 16:23:15,826 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 16:23:15,834 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(106)) - 50e264f2-152d-4343-9b7c-c19341a43184:group-F9686740EDCA changes to CANDIDATE, lastRpcTime:5109, electionTimeout:5108ms
2019-09-26 16:23:15,836 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown FollowerState
2019-09-26 16:23:15,836 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 16:23:15,836 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start LeaderElection
2019-09-26 16:23:15,839 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: set configuration 0: [af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null at 0
2019-09-26 16:23:15,853 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2: begin an election at term 1 for -1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225], old=null
2019-09-26 16:23:15,854 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown LeaderElection
2019-09-26 16:23:15,854 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 16:23:15,854 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: change Leader from null to 50e264f2-152d-4343-9b7c-c19341a43184 at term 1 for becomeLeader, leader elected after 5144ms
2019-09-26 16:23:15,855 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 16:23:15,855 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 16:23:15,855 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 16:23:15,855 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 16:23:15,856 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 16:23:15,856 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 16:23:15,860 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start LeaderState
2019-09-26 16:23:15,861 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 16:23:15,861 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: set configuration 0: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225], old=null at 0
2019-09-26 16:23:16,005 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/50cc76b9-2989-4387-84be-f9686740edca/current/log_inprogress_0
2019-09-26 16:23:16,005 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/addb61db-24df-412f-bff6-764be4b6f0f8/current/log_inprogress_0
2019-09-26 16:23:16,051 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(106)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db:group-D26EB49B1FC4 changes to CANDIDATE, lastRpcTime:5194, electionTimeout:5194ms
2019-09-26 16:23:16,051 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown FollowerState
2019-09-26 16:23:16,051 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 16:23:16,051 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start LeaderElection
2019-09-26 16:23:16,057 [Thread-200] INFO  impl.FollowerState (FollowerState.java:run(106)) - af5a0941-4deb-4be6-888a-fdc3fa675f59:group-FE59860B229C changes to CANDIDATE, lastRpcTime:5091, electionTimeout:5091ms
2019-09-26 16:23:16,057 [Thread-200] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown FollowerState
2019-09-26 16:23:16,057 [Thread-200] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 16:23:16,058 [Thread-200] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start LeaderElection
2019-09-26 16:23:16,082 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4: begin an election at term 1 for -1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:16,082 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3: begin an election at term 1 for -1: [db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751], old=null
2019-09-26 16:23:16,083 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown LeaderElection
2019-09-26 16:23:16,083 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 16:23:16,083 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: change Leader from null to db3bdbda-baa1-4f60-ab24-3af97f8d83db at term 1 for becomeLeader, leader elected after 5271ms
2019-09-26 16:23:16,083 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 16:23:16,084 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 16:23:16,084 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 16:23:16,084 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 16:23:16,084 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 16:23:16,084 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 16:23:16,088 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start LeaderState
2019-09-26 16:23:16,089 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 16:23:16,089 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: set configuration 0: [db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751], old=null at 0
2019-09-26 16:23:16,122 [Thread-199] INFO  impl.FollowerState (FollowerState.java:run(106)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db:group-FE59860B229C changes to CANDIDATE, lastRpcTime:5157, electionTimeout:5150ms
2019-09-26 16:23:16,122 [Thread-197] INFO  impl.FollowerState (FollowerState.java:run(106)) - 50e264f2-152d-4343-9b7c-c19341a43184:group-FE59860B229C changes to CANDIDATE, lastRpcTime:5170, electionTimeout:5138ms
2019-09-26 16:23:16,122 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown FollowerState
2019-09-26 16:23:16,122 [Thread-197] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown FollowerState
2019-09-26 16:23:16,122 [Thread-199] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 16:23:16,123 [Thread-197] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 16:23:16,123 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start LeaderElection
2019-09-26 16:23:16,123 [Thread-197] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start LeaderElection
2019-09-26 16:23:16,154 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/90af12f4-ceb2-45ed-b455-d26eb49b1fc4/current/log_inprogress_0
2019-09-26 16:23:16,154 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5: begin an election at term 1 for -1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:16,154 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6: begin an election at term 1 for -1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:16,200 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4: Election REJECTED; received 2 response(s) [af5a0941-4deb-4be6-888a-fdc3fa675f59<-50e264f2-152d-4343-9b7c-c19341a43184#0:FAIL-t1, af5a0941-4deb-4be6-888a-fdc3fa675f59<-db3bdbda-baa1-4f60-ab24-3af97f8d83db#0:FAIL-t1] and 0 exception(s); af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:t1, leader=null, voted=af5a0941-4deb-4be6-888a-fdc3fa675f59, raftlog=af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:16,201 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6: Election REJECTED; received 2 response(s) [50e264f2-152d-4343-9b7c-c19341a43184<-db3bdbda-baa1-4f60-ab24-3af97f8d83db#0:FAIL-t1, 50e264f2-152d-4343-9b7c-c19341a43184<-af5a0941-4deb-4be6-888a-fdc3fa675f59#0:FAIL-t1] and 0 exception(s); 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:t1, leader=null, voted=50e264f2-152d-4343-9b7c-c19341a43184, raftlog=50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:16,204 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-26 16:23:16,204 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-26 16:23:16,206 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown LeaderElection
2019-09-26 16:23:16,205 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown LeaderElection
2019-09-26 16:23:16,206 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start FollowerState
2019-09-26 16:23:16,207 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start FollowerState
2019-09-26 16:23:16,212 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5: Election REJECTED; received 2 response(s) [db3bdbda-baa1-4f60-ab24-3af97f8d83db<-50e264f2-152d-4343-9b7c-c19341a43184#0:FAIL-t1, db3bdbda-baa1-4f60-ab24-3af97f8d83db<-af5a0941-4deb-4be6-888a-fdc3fa675f59#0:FAIL-t1] and 0 exception(s); db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:t1, leader=null, voted=db3bdbda-baa1-4f60-ab24-3af97f8d83db, raftlog=db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:16,213 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-26 16:23:16,215 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown LeaderElection
2019-09-26 16:23:16,215 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start FollowerState
2019-09-26 16:23:16,244 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:17,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:18,248 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:19,249 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:20,250 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:21,252 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:21,261 [Thread-238] INFO  impl.FollowerState (FollowerState.java:run(106)) - 50e264f2-152d-4343-9b7c-c19341a43184:group-FE59860B229C changes to CANDIDATE, lastRpcTime:5054, electionTimeout:5053ms
2019-09-26 16:23:21,262 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown FollowerState
2019-09-26 16:23:21,262 [Thread-238] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-26 16:23:21,262 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start LeaderElection
2019-09-26 16:23:21,280 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7: begin an election at term 2 for -1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:21,288 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:23:21,288 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:23:21,288 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown FollowerState
2019-09-26 16:23:21,289 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown FollowerState
2019-09-26 16:23:21,289 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: start FollowerState
2019-09-26 16:23:21,289 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(115)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 16:23:21,289 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: start FollowerState
2019-09-26 16:23:21,289 [Thread-240] INFO  impl.FollowerState (FollowerState.java:run(115)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 16:23:21,316 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7: Election PASSED; received 1 response(s) [50e264f2-152d-4343-9b7c-c19341a43184<-db3bdbda-baa1-4f60-ab24-3af97f8d83db#0:OK-t2] and 0 exception(s); 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:t2, leader=null, voted=50e264f2-152d-4343-9b7c-c19341a43184, raftlog=50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null
2019-09-26 16:23:21,316 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown LeaderElection
2019-09-26 16:23:21,317 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-26 16:23:21,318 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: change Leader from null to 50e264f2-152d-4343-9b7c-c19341a43184 at term 2 for becomeLeader, leader elected after 10379ms
2019-09-26 16:23:21,318 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 16:23:21,318 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 16:23:21,318 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 16:23:21,319 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 16:23:21,319 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 16:23:21,319 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 16:23:21,326 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 16:23:21,327 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:21,327 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 16:23:21,332 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 16:23:21,338 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 16:23:21,338 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:21,340 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 16:23:21,340 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 16:23:21,340 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 16:23:21,341 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 16:23:21,341 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 16:23:21,341 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 16:23:21,345 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 50e264f2-152d-4343-9b7c-c19341a43184: start LeaderState
2019-09-26 16:23:21,345 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 16:23:21,347 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: set configuration 0: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null at 0
2019-09-26 16:23:21,394 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c/current/log_inprogress_0
2019-09-26 16:23:21,409 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: change Leader from null to 50e264f2-152d-4343-9b7c-c19341a43184 at term 2 for appendEntries, leader elected after 10470ms
2019-09-26 16:23:21,409 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: change Leader from null to 50e264f2-152d-4343-9b7c-c19341a43184 at term 2 for appendEntries, leader elected after 10470ms
2019-09-26 16:23:21,444 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: set configuration 0: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null at 0
2019-09-26 16:23:21,444 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: set configuration 0: [50e264f2-152d-4343-9b7c-c19341a43184:192.168.157.234:36225, db3bdbda-baa1-4f60-ab24-3af97f8d83db:192.168.157.234:44751, af5a0941-4deb-4be6-888a-fdc3fa675f59:192.168.157.234:33594], old=null at 0
2019-09-26 16:23:21,444 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 16:23:21,445 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 16:23:21,477 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c/current/log_inprogress_0
2019-09-26 16:23:21,490 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/ratis/bd51986c-4252-4b88-b1aa-fe59860b229c/current/log_inprogress_0
2019-09-26 16:23:22,258 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:23,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:24,261 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:25,263 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:26,264 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:27,265 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:28,267 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:29,268 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:30,269 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:31,271 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:31,273 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 16:23:32,274 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:33,275 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:34,277 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:35,278 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:36,280 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:37,281 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:38,283 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:39,284 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:40,285 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:41,287 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:41,288 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 16:23:42,290 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:43,292 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:44,293 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:45,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:46,296 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:47,297 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:48,298 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:49,300 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:50,301 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:51,303 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:51,304 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 16:23:52,306 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:53,307 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:54,309 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:55,310 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:56,312 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:57,313 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:58,316 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:23:59,317 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:00,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:01,320 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:01,322 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 16:24:02,323 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:03,324 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:04,325 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:05,327 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:06,328 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:07,329 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:08,331 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:09,332 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:10,334 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:11,335 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:11,337 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 16:24:12,338 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:13,339 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:14,341 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:15,342 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:16,344 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:17,345 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:18,347 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:19,348 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:20,350 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:21,351 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:21,353 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 16:24:22,355 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:23,356 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:24,357 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:25,360 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:26,362 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:27,364 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:28,365 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:29,366 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:30,368 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:31,370 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:31,372 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 16:24:32,373 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:33,374 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:34,375 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:35,377 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:36,378 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:37,379 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:38,381 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:39,382 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:40,383 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:41,385 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:41,387 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 16:24:42,388 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:43,390 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:44,391 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:45,393 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:46,395 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:47,396 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:48,397 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:49,401 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:50,403 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:51,404 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:51,406 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 16:24:52,407 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:53,408 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:54,410 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:55,411 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:56,412 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:57,414 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:58,415 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:24:59,416 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:25:00,418 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:25:01,419 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 16:25:01,421 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 16:25:01,425 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.init(TestDeleteWithSlowFollower.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-26 16:25:01,429 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 16:25:01,430 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 16:25:01,430 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 16:25:01,431 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43893
2019-09-26 16:25:01,442 [IPC Server listener on 43893] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43893
2019-09-26 16:25:01,444 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 16:25:01,447 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 16:25:01,453 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 16:25:01,469 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 16:25:01,474 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@529cfee5{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 16:25:01,482 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 16:25:01,483 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 16:25:01,483 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 16:25:01,489 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 16:25:01,516 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 16:25:01,532 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 16:25:06,493 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 16:25:06,493 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 16:25:06,494 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 50e264f2-152d-4343-9b7c-c19341a43184: close
2019-09-26 16:25:06,495 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: close
2019-09-26 16:25:06,498 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: shutdown
2019-09-26 16:25:06,498 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: shutdown
2019-09-26 16:25:06,498 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-764BE4B6F0F8,id=af5a0941-4deb-4be6-888a-fdc3fa675f59
2019-09-26 16:25:06,499 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE59860B229C,id=50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:25:06,499 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown LeaderState
2019-09-26 16:25:06,500 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown LeaderState
2019-09-26 16:25:06,504 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - af5a0941-4deb-4be6-888a-fdc3fa675f59-PendingRequests: sendNotLeaderResponses
2019-09-26 16:25:06,504 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$386/1540574033@2084ec16] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C->af5a0941-4deb-4be6-888a-fdc3fa675f59-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 16:25:06,504 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 50e264f2-152d-4343-9b7c-c19341a43184-PendingRequests: sendNotLeaderResponses
2019-09-26 16:25:06,504 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$386/1540574033@49db1054] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C->db3bdbda-baa1-4f60-ab24-3af97f8d83db-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 16:25:06,509 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-StateMachineUpdater: set stopIndex = 0
2019-09-26 16:25:06,509 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-StateMachineUpdater: set stopIndex = 0
2019-09-26 16:25:06,513 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8: closes. applyIndex: 0
2019-09-26 16:25:06,514 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: Completed APPEND_ENTRIES, lastRequest: 50e264f2-152d-4343-9b7c-c19341a43184->db3bdbda-baa1-4f60-ab24-3af97f8d83db#42-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 16:25:06,514 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C: closes. applyIndex: 0
2019-09-26 16:25:06,514 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: Completed APPEND_ENTRIES, lastRequest: 50e264f2-152d-4343-9b7c-c19341a43184->af5a0941-4deb-4be6-888a-fdc3fa675f59#42-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 16:25:06,519 [50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 16:25:06,519 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 16:25:06,519 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C->db3bdbda-baa1-4f60-ab24-3af97f8d83db-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 16:25:06,519 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C->af5a0941-4deb-4be6-888a-fdc3fa675f59-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 16:25:06,528 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C->db3bdbda-baa1-4f60-ab24-3af97f8d83db: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 16:25:06,529 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-764BE4B6F0F8-SegmentedRaftLogWorker close()
2019-09-26 16:25:06,529 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C-SegmentedRaftLogWorker close()
2019-09-26 16:25:06,533 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: shutdown
2019-09-26 16:25:06,528 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-FE59860B229C->af5a0941-4deb-4be6-888a-fdc3fa675f59: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 16:25:06,536 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE59860B229C,id=af5a0941-4deb-4be6-888a-fdc3fa675f59
2019-09-26 16:25:06,536 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown FollowerState
2019-09-26 16:25:06,536 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: shutdown
2019-09-26 16:25:06,537 [Thread-246] INFO  impl.FollowerState (FollowerState.java:run(115)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 16:25:06,537 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-StateMachineUpdater: set stopIndex = 0
2019-09-26 16:25:06,543 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C: closes. applyIndex: 0
2019-09-26 16:25:06,537 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9686740EDCA,id=50e264f2-152d-4343-9b7c-c19341a43184
2019-09-26 16:25:06,544 [af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 16:25:06,544 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown LeaderState
2019-09-26 16:25:06,546 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - af5a0941-4deb-4be6-888a-fdc3fa675f59@group-FE59860B229C-SegmentedRaftLogWorker close()
2019-09-26 16:25:06,546 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 50e264f2-152d-4343-9b7c-c19341a43184-PendingRequests: sendNotLeaderResponses
2019-09-26 16:25:06,549 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-StateMachineUpdater: set stopIndex = 0
2019-09-26 16:25:06,549 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown server with port 33594 now
2019-09-26 16:25:06,549 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA: closes. applyIndex: 0
2019-09-26 16:25:06,550 [50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 16:25:06,552 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 50e264f2-152d-4343-9b7c-c19341a43184@group-F9686740EDCA-SegmentedRaftLogWorker close()
2019-09-26 16:25:06,557 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown server with port 36225 now
2019-09-26 16:25:06,563 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - af5a0941-4deb-4be6-888a-fdc3fa675f59: shutdown server with port 33594 successfully
2019-09-26 16:25:06,564 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 50e264f2-152d-4343-9b7c-c19341a43184: shutdown server with port 36225 successfully
2019-09-26 16:25:06,567 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 16:25:06,589 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 16:25:06,598 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 16:25:06,604 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 16:25:06,608 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7aac8884{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 16:25:06,609 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 16:25:06,610 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 16:25:06,611 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 16:25:06,614 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 16:25:06,619 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 16:25:06,621 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7bc44ce8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 16:25:06,622 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 16:25:06,622 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 16:25:06,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 16:25:06,631 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 16:25:11,614 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 16:25:11,614 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: close
2019-09-26 16:25:11,615 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: shutdown
2019-09-26 16:25:11,615 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D26EB49B1FC4,id=db3bdbda-baa1-4f60-ab24-3af97f8d83db
2019-09-26 16:25:11,616 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown LeaderState
2019-09-26 16:25:11,616 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db-PendingRequests: sendNotLeaderResponses
2019-09-26 16:25:11,616 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-StateMachineUpdater: set stopIndex = 0
2019-09-26 16:25:11,617 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4: closes. applyIndex: 0
2019-09-26 16:25:11,618 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 16:25:11,619 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-D26EB49B1FC4-SegmentedRaftLogWorker close()
2019-09-26 16:25:11,621 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: shutdown
2019-09-26 16:25:11,621 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE59860B229C,id=db3bdbda-baa1-4f60-ab24-3af97f8d83db
2019-09-26 16:25:11,622 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown FollowerState
2019-09-26 16:25:11,622 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-StateMachineUpdater: set stopIndex = 0
2019-09-26 16:25:11,622 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(115)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 16:25:11,624 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C: closes. applyIndex: 0
2019-09-26 16:25:11,624 [db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 16:25:11,639 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db@group-FE59860B229C-SegmentedRaftLogWorker close()
2019-09-26 16:25:11,641 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown server with port 44751 now
2019-09-26 16:25:11,645 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - db3bdbda-baa1-4f60-ab24-3af97f8d83db: shutdown server with port 44751 successfully
2019-09-26 16:25:11,663 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5db9f4f4-c6ae-4db8-a36f-79b497619f46/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 16:25:11,680 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 16:25:11,684 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 16:25:11,686 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5dd903be{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 16:25:11,687 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 16:25:11,688 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 16:25:11,689 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 16:25:11,690 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 16:25:11,690 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 16:25:11,690 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-26 16:25:11,690 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 16:25:11,691 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 16:25:11,691 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 16:25:11,691 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43412
2019-09-26 16:25:11,693 [IPC Server listener on 43412] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43412
2019-09-26 16:25:11,693 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 16:25:11,751 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 16:25:11,751 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 16:25:11,752 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 16:25:11,752 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38588
2019-09-26 16:25:11,753 [IPC Server listener on 38588] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38588
2019-09-26 16:25:11,753 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 16:25:11,753 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 16:25:11,753 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 16:25:11,754 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41728
2019-09-26 16:25:11,755 [IPC Server listener on 41728] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41728
2019-09-26 16:25:11,755 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 16:25:11,757 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 16:25:11,757 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5398edd0{/,null,UNAVAILABLE}{/scm}
2019-09-26 16:25:11,758 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 16:25:11,759 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 16:25:11,759 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 16:25:11,760 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 16:25:11,760 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 16:25:11,761 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 16:25:11,761 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 16:25:11,768 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-26 16:25:11,774 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 16:25:11,774 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
