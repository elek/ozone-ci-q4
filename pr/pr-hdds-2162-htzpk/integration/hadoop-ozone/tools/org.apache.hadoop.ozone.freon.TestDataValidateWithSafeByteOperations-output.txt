2019-09-26 21:03:21,021 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:21,128 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:21,130 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:21,145 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @901ms
2019-09-26 21:03:21,261 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 21:03:21,262 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 21:03:21,262 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 21:03:21,262 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 21:03:21,263 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 21:03:21,263 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 21:03:21,279 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 21:03:21,280 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 21:03:21,281 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 21:03:21,538 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3e694b3f
2019-09-26 21:03:21,540 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 21:03:21,612 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 21:03:21,614 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 21:03:21,617 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 21:03:21,689 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 21:03:21,704 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:21,800 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 21:03:21,804 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:21,964 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 21:03:22,360 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 21:03:22,390 [Socket Reader #1 for port 44095] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44095
2019-09-26 21:03:22,550 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 21:03:22,552 [Socket Reader #1 for port 35709] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35709
2019-09-26 21:03:22,560 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 21:03:22,561 [Socket Reader #1 for port 38570] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38570
2019-09-26 21:03:22,583 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 21:03:22,704 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:22,716 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:22,724 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:22,726 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 21:03:22,726 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:22,726 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:22,749 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:38570
2019-09-26 21:03:22,792 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 21:03:22,802 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 21:03:22,802 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 21:03:22,974 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:38570
2019-09-26 21:03:22,975 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 21:03:22,975 [IPC Server listener on 38570] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38570: starting
2019-09-26 21:03:22,979 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:35709
2019-09-26 21:03:22,981 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:35709
2019-09-26 21:03:22,981 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 21:03:22,981 [IPC Server listener on 35709] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35709: starting
2019-09-26 21:03:22,985 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:44095
2019-09-26 21:03:22,985 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:44095
2019-09-26 21:03:22,987 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 21:03:22,987 [IPC Server listener on 44095] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44095: starting
2019-09-26 21:03:22,994 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35418
2019-09-26 21:03:22,996 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:23,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:23,028 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:23,089 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9573b3b{/,file:///tmp/jetty-0.0.0.0-35418-scm-_-any-8955320375257650314.dir/webapp/,AVAILABLE}{/scm}
2019-09-26 21:03:23,093 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:35418}
2019-09-26 21:03:23,093 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2850ms
2019-09-26 21:03:23,095 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 21:03:23,095 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 21:03:23,097 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:35418
2019-09-26 21:03:23,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3670f00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 21:03:23,111 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:23,242 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-26 21:03:23,242 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 21:03:23,244 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:23,244 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:23,913 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 21:03:23,921 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 21:03:23,921 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 21:03:23,922 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 21:03:23,922 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 21:03:23,922 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 21:03:23,922 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 21:03:23,923 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 21:03:23,923 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 21:03:23,923 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 21:03:23,923 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 21:03:23,924 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 21:03:23,924 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 21:03:23,924 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 21:03:23,924 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 21:03:23,925 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 21:03:23,925 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 21:03:23,925 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 21:03:23,925 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 21:03:23,926 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 21:03:23,926 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 21:03:23,926 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 21:03:23,926 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 21:03:23,927 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 21:03:23,927 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 21:03:23,927 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 21:03:24,516 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 21:03:24,518 [Socket Reader #1 for port 36860] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36860
2019-09-26 21:03:24,549 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:36860
2019-09-26 21:03:24,549 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 21:03:24,551 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 21:03:24,553 [IPC Server listener on 36860] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36860: starting
2019-09-26 21:03:24,564 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 21:03:24,567 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:24,567 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:24,570 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:24,570 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 21:03:24,571 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:24,571 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:24,573 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40520
2019-09-26 21:03:24,573 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:24,576 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:24,576 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:24,625 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@151335cb{/,file:///tmp/jetty-0.0.0.0-40520-ozoneManager-_-any-308322115402963580.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-26 21:03:24,625 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:40520}
2019-09-26 21:03:24,626 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4382ms
2019-09-26 21:03:24,626 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 21:03:24,628 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:40520
2019-09-26 21:03:24,970 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 21:03:25,022 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 21:03:25,059 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 21:03:25,061 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 21:03:25,064 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-26 21:03:25,083 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-26 21:03:25,198 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 21:03:25,271 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 21:03:25,278 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 21:03:25,279 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 21:03:25,281 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:25,282 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 21:03:25,283 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:25,494 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis] (custom)
2019-09-26 21:03:25,553 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 21:03:25,559 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:25,560 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:25,564 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:25,565 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 21:03:25,565 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:25,565 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:25,567 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38611
2019-09-26 21:03:25,568 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:25,571 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:25,572 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:25,615 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d910b3{/,file:///tmp/jetty-0.0.0.0-38611-hddsDatanode-_-any-2254117618627177259.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 21:03:25,617 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:38611}
2019-09-26 21:03:25,617 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5373ms
2019-09-26 21:03:25,618 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 21:03:25,619 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38611
2019-09-26 21:03:25,621 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 21:03:25,628 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 21:03:25,629 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d4a9da4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 21:03:25,640 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 21:03:25,641 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 21:03:25,641 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-26 21:03:25,643 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-26 21:03:25,667 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 21:03:25,667 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 21:03:25,667 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 21:03:25,668 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 21:03:25,668 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:25,668 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 21:03:25,669 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:25,670 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis] (custom)
2019-09-26 21:03:25,672 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 21:03:25,674 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:25,675 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:25,677 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:25,678 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 21:03:25,678 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:25,679 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:25,680 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44765
2019-09-26 21:03:25,680 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:25,686 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:25,687 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:25,724 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28da7d11{/,file:///tmp/jetty-0.0.0.0-44765-hddsDatanode-_-any-7182315070360446792.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 21:03:25,725 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:44765}
2019-09-26 21:03:25,727 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5483ms
2019-09-26 21:03:25,727 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 21:03:25,728 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44765
2019-09-26 21:03:25,729 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 21:03:25,732 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 21:03:25,732 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61d7e4df] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 21:03:25,742 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 21:03:25,742 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 21:03:25,742 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@a098d76
2019-09-26 21:03:25,743 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@a098d76
2019-09-26 21:03:25,760 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 21:03:25,760 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 21:03:25,760 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 21:03:25,761 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 21:03:25,761 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:25,761 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 21:03:25,761 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:25,762 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/meta/datanode.id
2019-09-26 21:03:25,762 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis] (custom)
2019-09-26 21:03:25,767 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/meta/datanode.id
2019-09-26 21:03:25,767 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 21:03:25,768 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:25,769 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:25,770 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:25,771 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 21:03:25,771 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:25,772 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:25,772 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44294
2019-09-26 21:03:25,772 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:25,774 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ecec90d{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:25,775 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a6fa56e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:25,803 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f6917fb{/,file:///tmp/jetty-0.0.0.0-44294-hddsDatanode-_-any-3219096576673848872.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 21:03:25,804 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41eb94bc{HTTP/1.1,[http/1.1]}{0.0.0.0:44294}
2019-09-26 21:03:25,805 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5561ms
2019-09-26 21:03:25,805 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 21:03:25,807 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44294
2019-09-26 21:03:25,807 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 21:03:25,810 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 21:03:25,811 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56cfc1ca] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 21:03:25,814 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/meta/datanode.id
2019-09-26 21:03:25,820 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 21:03:25,821 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/containers/hdds to VolumeSet
2019-09-26 21:03:25,821 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-26 21:03:25,821 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-26 21:03:25,836 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 21:03:25,836 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 21:03:25,837 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 21:03:25,837 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 21:03:25,837 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:25,837 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 21:03:25,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:25,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis] (custom)
2019-09-26 21:03:25,840 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 21:03:25,841 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:25,841 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:25,843 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:25,844 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 21:03:25,844 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:25,844 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:25,845 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38023
2019-09-26 21:03:25,845 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:25,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:25,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:25,882 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dc3502b{/,file:///tmp/jetty-0.0.0.0-38023-hddsDatanode-_-any-1279573814966173837.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 21:03:25,883 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:38023}
2019-09-26 21:03:25,884 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5640ms
2019-09-26 21:03:25,884 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 21:03:25,885 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38023
2019-09-26 21:03:25,885 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 21:03:25,888 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-htzpk-1451759861 ip:192.168.157.234
2019-09-26 21:03:25,888 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42673db6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 21:03:25,892 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/meta/datanode.id
2019-09-26 21:03:25,895 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 21:03:25,895 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/containers/hdds to VolumeSet
2019-09-26 21:03:25,895 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bd2af5b
2019-09-26 21:03:25,896 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bd2af5b
2019-09-26 21:03:25,909 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 21:03:25,909 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 21:03:25,910 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 21:03:25,910 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 21:03:25,910 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:25,910 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 21:03:25,911 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:25,911 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis] (custom)
2019-09-26 21:03:25,913 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 21:03:25,914 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 21:03:25,915 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 21:03:25,916 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 21:03:25,917 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 21:03:25,917 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 21:03:25,917 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 21:03:25,918 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37977
2019-09-26 21:03:25,918 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 21:03:25,920 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@934b52f{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-26 21:03:25,920 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ea4300e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 21:03:25,949 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cf0a747{/,file:///tmp/jetty-0.0.0.0-37977-hddsDatanode-_-any-1472601509755266782.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 21:03:25,949 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21505815{HTTP/1.1,[http/1.1]}{0.0.0.0:37977}
2019-09-26 21:03:25,950 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5707ms
2019-09-26 21:03:25,950 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 21:03:25,951 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37977
2019-09-26 21:03:25,954 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 21:03:25,955 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38e22b8b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 21:03:25,957 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/meta/datanode.id
2019-09-26 21:03:26,954 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 21:03:27,693 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 21:03:27,698 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 21:03:27,698 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 2875a3b9-6f76-467d-b17b-f590da7fb391 at port 0
2019-09-26 21:03:27,726 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start RPC server
2019-09-26 21:03:27,751 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 21:03:27,756 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 21:03:27,756 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 5a828d89-9008-4d76-8f23-9d4b0ce5df4d at port 0
2019-09-26 21:03:27,766 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: start RPC server
2019-09-26 21:03:27,828 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 21:03:27,830 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 21:03:27,830 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 1d15d09a-1fa3-4436-9148-1b5bf102deba at port 0
2019-09-26 21:03:27,838 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: start RPC server
2019-09-26 21:03:27,898 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: GrpcService started, listening on 0.0.0.0/0.0.0.0:39066
2019-09-26 21:03:27,898 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: GrpcService started, listening on 0.0.0.0/0.0.0.0:40142
2019-09-26 21:03:27,898 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: GrpcService started, listening on 0.0.0.0/0.0.0.0:43397
2019-09-26 21:03:27,900 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 2875a3b9-6f76-467d-b17b-f590da7fb391 is started using port 40142
2019-09-26 21:03:27,900 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 5a828d89-9008-4d76-8f23-9d4b0ce5df4d is started using port 39066
2019-09-26 21:03:27,900 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 1d15d09a-1fa3-4436-9148-1b5bf102deba is started using port 43397
2019-09-26 21:03:27,906 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 21:03:27,908 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 21:03:27,908 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 5f456774-4ac8-4598-857f-d1c030208d08 at port 0
2019-09-26 21:03:27,908 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 1d15d09a-1fa3-4436-9148-1b5bf102deba is started using port 44241
2019-09-26 21:03:27,908 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 5a828d89-9008-4d76-8f23-9d4b0ce5df4d is started using port 43319
2019-09-26 21:03:27,908 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 2875a3b9-6f76-467d-b17b-f590da7fb391 is started using port 35168
2019-09-26 21:03:27,923 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 5f456774-4ac8-4598-857f-d1c030208d08: start RPC server
2019-09-26 21:03:27,926 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 5f456774-4ac8-4598-857f-d1c030208d08: GrpcService started, listening on 0.0.0.0/0.0.0.0:35379
2019-09-26 21:03:27,926 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 5f456774-4ac8-4598-857f-d1c030208d08 is started using port 35379
2019-09-26 21:03:27,928 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 5f456774-4ac8-4598-857f-d1c030208d08 is started using port 46492
2019-09-26 21:03:27,955 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 21:03:27,993 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 21:03:27,999 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 21:03:28,000 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 42034195-a667-4f7c-bc25-5c53d8667078 at port 0
2019-09-26 21:03:28,011 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 42034195-a667-4f7c-bc25-5c53d8667078: start RPC server
2019-09-26 21:03:28,014 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 42034195-a667-4f7c-bc25-5c53d8667078: GrpcService started, listening on 0.0.0.0/0.0.0.0:42939
2019-09-26 21:03:28,015 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 42034195-a667-4f7c-bc25-5c53d8667078 is started using port 42939
2019-09-26 21:03:28,018 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 42034195-a667-4f7c-bc25-5c53d8667078 is started using port 34209
2019-09-26 21:03:28,956 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 21:03:29,675 [IPC Server handler 1 on 44095] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:03:29,676 [IPC Server handler 1 on 44095] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 2875a3b9-6f76-467d-b17b-f590da7fb391{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 21:03:29,681 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 21:03:29,682 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 21:03:29,682 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 21:03:29,736 [IPC Server handler 2 on 44095] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/5a828d89-9008-4d76-8f23-9d4b0ce5df4d
2019-09-26 21:03:29,736 [IPC Server handler 2 on 44095] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 5a828d89-9008-4d76-8f23-9d4b0ce5df4d{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 21:03:29,814 [IPC Server handler 3 on 44095] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/1d15d09a-1fa3-4436-9148-1b5bf102deba
2019-09-26 21:03:29,814 [IPC Server handler 3 on 44095] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 1d15d09a-1fa3-4436-9148-1b5bf102deba{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 21:03:29,893 [IPC Server handler 4 on 44095] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/5f456774-4ac8-4598-857f-d1c030208d08
2019-09-26 21:03:29,893 [IPC Server handler 4 on 44095] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 5f456774-4ac8-4598-857f-d1c030208d08{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 21:03:29,957 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-26 21:03:29,958 [IPC Server handler 5 on 44095] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/42034195-a667-4f7c-bc25-5c53d8667078
2019-09-26 21:03:29,958 [IPC Server handler 5 on 44095] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 42034195-a667-4f7c-bc25-5c53d8667078{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}
2019-09-26 21:03:30,198 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: addNew group-CCC89F8F8673:[2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] returns group-CCC89F8F8673:java.util.concurrent.CompletableFuture@53aa2612[Not completed]
2019-09-26 21:03:30,223 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: new RaftServerImpl for group-CCC89F8F8673:[2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,225 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,227 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,229 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,239 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: ConfigurationManager, init=-1: [2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,240 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis] (custom)
2019-09-26 21:03:30,248 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/d5b2bbee-fa3a-4294-8596-ccc89f8f8673 does not exist. Creating ...
2019-09-26 21:03:30,267 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/d5b2bbee-fa3a-4294-8596-ccc89f8f8673/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:30,290 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/d5b2bbee-fa3a-4294-8596-ccc89f8f8673 has been successfully formatted.
2019-09-26 21:03:30,293 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-CCC89F8F8673: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:30,294 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:30,296 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:30,303 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:30,303 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:30,305 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,310 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:30,317 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/d5b2bbee-fa3a-4294-8596-ccc89f8f8673
2019-09-26 21:03:30,318 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 21:03:30,326 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 21:03:30,359 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:30,359 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:30,362 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,363 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:30,363 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:30,363 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:30,364 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:30,365 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:30,365 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:30,375 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:30,379 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:30,384 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:30,385 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:30,385 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:30,386 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:30,421 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: start as a follower, conf=-1: [2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:30,423 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:30,425 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start FollowerState
2019-09-26 21:03:30,428 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CCC89F8F8673,id=2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:03:30,499 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d5b2bbee-fa3a-4294-8596-ccc89f8f8673, Nodes: 2875a3b9-6f76-467d-b17b-f590da7fb391{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 21:03:30,521 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: addNew group-FF8368D8FE7F:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397] returns group-FF8368D8FE7F:java.util.concurrent.CompletableFuture@400eb9c5[Not completed]
2019-09-26 21:03:30,562 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: new RaftServerImpl for group-FF8368D8FE7F:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: ConfigurationManager, init=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,564 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis] (custom)
2019-09-26 21:03:30,565 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/a53d0f01-c877-482c-87fb-ff8368d8fe7f does not exist. Creating ...
2019-09-26 21:03:30,580 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/a53d0f01-c877-482c-87fb-ff8368d8fe7f/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:30,594 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/a53d0f01-c877-482c-87fb-ff8368d8fe7f has been successfully formatted.
2019-09-26 21:03:30,597 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FF8368D8FE7F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:30,598 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:30,598 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:30,598 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:30,598 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:30,599 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,599 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:30,599 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/a53d0f01-c877-482c-87fb-ff8368d8fe7f
2019-09-26 21:03:30,604 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:30,604 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:30,605 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:30,606 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:30,606 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:30,606 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:30,606 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:30,607 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:30,607 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:30,610 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: start as a follower, conf=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397], old=null
2019-09-26 21:03:30,610 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:30,611 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: start FollowerState
2019-09-26 21:03:30,612 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF8368D8FE7F,id=1d15d09a-1fa3-4436-9148-1b5bf102deba
2019-09-26 21:03:30,631 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a53d0f01-c877-482c-87fb-ff8368d8fe7f, Nodes: 1d15d09a-1fa3-4436-9148-1b5bf102deba{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 21:03:30,654 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: addNew group-827CA8988DB4:[5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066] returns group-827CA8988DB4:java.util.concurrent.CompletableFuture@49609b4a[Not completed]
2019-09-26 21:03:30,676 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: new RaftServerImpl for group-827CA8988DB4:[5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,676 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,676 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,676 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,677 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,677 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,677 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: ConfigurationManager, init=-1: [5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,677 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis] (custom)
2019-09-26 21:03:30,678 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e4c829e3-4319-461b-9cae-827ca8988db4 does not exist. Creating ...
2019-09-26 21:03:30,699 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e4c829e3-4319-461b-9cae-827ca8988db4/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:30,720 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e4c829e3-4319-461b-9cae-827ca8988db4 has been successfully formatted.
2019-09-26 21:03:30,721 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-827CA8988DB4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:30,721 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:30,722 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:30,722 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,722 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:30,722 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e4c829e3-4319-461b-9cae-827ca8988db4
2019-09-26 21:03:30,759 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:30,759 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:30,760 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,760 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:30,760 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:30,760 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:30,760 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:30,761 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:30,761 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:30,761 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:30,762 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:30,762 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:30,762 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:30,763 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:30,763 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:30,769 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: start as a follower, conf=-1: [5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066], old=null
2019-09-26 21:03:30,769 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:30,769 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: start FollowerState
2019-09-26 21:03:30,770 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-827CA8988DB4,id=5a828d89-9008-4d76-8f23-9d4b0ce5df4d
2019-09-26 21:03:30,781 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e4c829e3-4319-461b-9cae-827ca8988db4, Nodes: 5a828d89-9008-4d76-8f23-9d4b0ce5df4d{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 21:03:30,802 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 42034195-a667-4f7c-bc25-5c53d8667078: addNew group-56994B975F95:[42034195-a667-4f7c-bc25-5c53d8667078:192.168.157.234:42939] returns group-56994B975F95:java.util.concurrent.CompletableFuture@6322e5ef[Not completed]
2019-09-26 21:03:30,805 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 42034195-a667-4f7c-bc25-5c53d8667078: new RaftServerImpl for group-56994B975F95:[42034195-a667-4f7c-bc25-5c53d8667078:192.168.157.234:42939] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,806 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,806 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,806 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,806 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,806 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,807 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: ConfigurationManager, init=-1: [42034195-a667-4f7c-bc25-5c53d8667078:192.168.157.234:42939], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,807 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis] (custom)
2019-09-26 21:03:30,807 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis/3a3b025d-eb70-4831-a32c-56994b975f95 does not exist. Creating ...
2019-09-26 21:03:30,820 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis/3a3b025d-eb70-4831-a32c-56994b975f95/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:30,833 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis/3a3b025d-eb70-4831-a32c-56994b975f95 has been successfully formatted.
2019-09-26 21:03:30,833 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-56994B975F95: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:30,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:30,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:30,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:30,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:30,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,835 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:30,835 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis/3a3b025d-eb70-4831-a32c-56994b975f95
2019-09-26 21:03:30,840 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:30,840 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:30,840 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,841 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:30,841 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:30,841 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:30,841 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:30,841 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:30,843 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:30,844 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:30,844 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:30,844 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:30,844 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:30,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:30,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:30,849 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: start as a follower, conf=-1: [42034195-a667-4f7c-bc25-5c53d8667078:192.168.157.234:42939], old=null
2019-09-26 21:03:30,849 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:30,850 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 42034195-a667-4f7c-bc25-5c53d8667078: start FollowerState
2019-09-26 21:03:30,850 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56994B975F95,id=42034195-a667-4f7c-bc25-5c53d8667078
2019-09-26 21:03:30,863 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3a3b025d-eb70-4831-a32c-56994b975f95, Nodes: 42034195-a667-4f7c-bc25-5c53d8667078{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 21:03:30,888 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5f456774-4ac8-4598-857f-d1c030208d08: addNew group-24CB4BD49355:[5f456774-4ac8-4598-857f-d1c030208d08:192.168.157.234:35379] returns group-24CB4BD49355:java.util.concurrent.CompletableFuture@3732b7e7[Not completed]
2019-09-26 21:03:30,890 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5f456774-4ac8-4598-857f-d1c030208d08: new RaftServerImpl for group-24CB4BD49355:[5f456774-4ac8-4598-857f-d1c030208d08:192.168.157.234:35379] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,891 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,891 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,891 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,891 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,891 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,892 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: ConfigurationManager, init=-1: [5f456774-4ac8-4598-857f-d1c030208d08:192.168.157.234:35379], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,892 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis] (custom)
2019-09-26 21:03:30,892 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis/bea64c87-0e18-43f4-81b2-24cb4bd49355 does not exist. Creating ...
2019-09-26 21:03:30,905 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis/bea64c87-0e18-43f4-81b2-24cb4bd49355/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:30,920 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis/bea64c87-0e18-43f4-81b2-24cb4bd49355 has been successfully formatted.
2019-09-26 21:03:30,920 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-24CB4BD49355: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:30,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:30,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:30,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:30,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:30,921 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,922 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:30,922 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis/bea64c87-0e18-43f4-81b2-24cb4bd49355
2019-09-26 21:03:30,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:30,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:30,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:30,926 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:30,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:30,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:30,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:30,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:30,927 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:30,928 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:30,928 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:30,929 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:30,929 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:30,929 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:30,929 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:30,933 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: start as a follower, conf=-1: [5f456774-4ac8-4598-857f-d1c030208d08:192.168.157.234:35379], old=null
2019-09-26 21:03:30,933 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:30,933 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5f456774-4ac8-4598-857f-d1c030208d08: start FollowerState
2019-09-26 21:03:30,933 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-24CB4BD49355,id=5f456774-4ac8-4598-857f-d1c030208d08
2019-09-26 21:03:30,944 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bea64c87-0e18-43f4-81b2-24cb4bd49355, Nodes: 5f456774-4ac8-4598-857f-d1c030208d08{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 21:03:30,958 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-26 21:03:30,989 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: addNew group-A12F973A925D:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] returns group-A12F973A925D:java.util.concurrent.CompletableFuture@2af1ac89[Not completed]
2019-09-26 21:03:30,989 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: addNew group-A12F973A925D:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] returns group-A12F973A925D:java.util.concurrent.CompletableFuture@46461953[Not completed]
2019-09-26 21:03:30,989 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: addNew group-A12F973A925D:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] returns group-A12F973A925D:java.util.concurrent.CompletableFuture@41dc74d8[Not completed]
2019-09-26 21:03:30,991 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: new RaftServerImpl for group-A12F973A925D:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,991 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,992 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,992 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,992 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,992 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,992 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: new RaftServerImpl for group-A12F973A925D:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,992 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: ConfigurationManager, init=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,993 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,993 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis] (custom)
2019-09-26 21:03:30,993 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,993 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: new RaftServerImpl for group-A12F973A925D:[1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142] with ContainerStateMachine:uninitialized
2019-09-26 21:03:30,993 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,993 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 21:03:30,993 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d does not exist. Creating ...
2019-09-26 21:03:30,994 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 21:03:30,994 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,994 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 21:03:30,994 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,994 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 21:03:30,994 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: ConfigurationManager, init=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,994 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:30,995 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis] (custom)
2019-09-26 21:03:30,995 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: ConfigurationManager, init=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null, confs=<EMPTY_MAP>
2019-09-26 21:03:30,995 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d does not exist. Creating ...
2019-09-26 21:03:30,995 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis] (custom)
2019-09-26 21:03:30,995 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d does not exist. Creating ...
2019-09-26 21:03:31,007 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:31,007 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:31,007 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d/in_use.lock acquired by nodename 16680@pr-hdds-2162-htzpk-1451759861
2019-09-26 21:03:31,021 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d has been successfully formatted.
2019-09-26 21:03:31,021 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d has been successfully formatted.
2019-09-26 21:03:31,021 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d has been successfully formatted.
2019-09-26 21:03:31,021 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A12F973A925D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:31,021 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A12F973A925D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:31,021 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A12F973A925D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 21:03:31,021 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:31,021 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:31,022 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:31,021 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 21:03:31,022 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:31,022 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:31,022 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:31,022 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 21:03:31,022 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:31,022 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:31,022 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:31,022 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 21:03:31,023 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d
2019-09-26 21:03:31,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:31,023 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:31,023 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:31,023 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:31,023 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:31,023 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:31,023 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:31,024 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:31,024 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:31,024 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:31,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 21:03:31,024 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:31,024 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d
2019-09-26 21:03:31,024 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:31,024 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d
2019-09-26 21:03:31,025 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:31,024 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:31,025 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:31,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 21:03:31,025 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:31,025 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:31,025 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 21:03:31,026 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:31,025 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:31,026 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:31,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 21:03:31,026 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:31,026 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:31,026 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:31,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 21:03:31,026 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:31,026 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:31,027 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:31,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 21:03:31,027 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:31,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 21:03:31,027 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:31,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 21:03:31,027 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:31,028 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 21:03:31,028 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:31,028 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 21:03:31,028 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:31,028 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 21:03:31,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:31,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:31,029 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 21:03:31,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:31,029 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: start as a follower, conf=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:31,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:31,029 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 21:03:31,029 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:31,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 21:03:31,030 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: start FollowerState
2019-09-26 21:03:31,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 21:03:31,030 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A12F973A925D,id=1d15d09a-1fa3-4436-9148-1b5bf102deba
2019-09-26 21:03:31,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 21:03:31,035 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: start as a follower, conf=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:31,035 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:31,036 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: start FollowerState
2019-09-26 21:03:31,037 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A12F973A925D,id=5a828d89-9008-4d76-8f23-9d4b0ce5df4d
2019-09-26 21:03:31,037 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: start as a follower, conf=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:31,038 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 21:03:31,038 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start FollowerState
2019-09-26 21:03:31,046 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A12F973A925D,id=2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:03:31,070 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e5bd895c-313c-4619-b39e-a12f973a925d, Nodes: 1d15d09a-1fa3-4436-9148-1b5bf102deba{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}2875a3b9-6f76-467d-b17b-f590da7fb391{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}5a828d89-9008-4d76-8f23-9d4b0ce5df4d{ip: 192.168.157.234, host: pr-hdds-2162-htzpk-1451759861, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-26 21:03:32,222 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:32,689 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-26 21:03:32,693 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-26 21:03:33,223 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:34,225 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:35,226 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:35,446 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2875a3b9-6f76-467d-b17b-f590da7fb391:group-CCC89F8F8673 changes to CANDIDATE, lastRpcTime:5021, electionTimeout:5020ms
2019-09-26 21:03:35,448 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown FollowerState
2019-09-26 21:03:35,449 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 21:03:35,455 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start LeaderElection
2019-09-26 21:03:35,474 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1: begin an election at term 1 for -1: [2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:35,476 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown LeaderElection
2019-09-26 21:03:35,476 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 21:03:35,476 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: change Leader from null to 2875a3b9-6f76-467d-b17b-f590da7fb391 at term 1 for becomeLeader, leader elected after 5182ms
2019-09-26 21:03:35,485 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 21:03:35,485 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 21:03:35,489 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 21:03:35,493 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 21:03:35,493 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 21:03:35,494 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 21:03:35,508 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start LeaderState
2019-09-26 21:03:35,534 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:35,543 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: set configuration 0: [2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null at 0
2019-09-26 21:03:35,638 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba:group-FF8368D8FE7F changes to CANDIDATE, lastRpcTime:5027, electionTimeout:5024ms
2019-09-26 21:03:35,640 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown FollowerState
2019-09-26 21:03:35,640 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 21:03:35,641 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: start LeaderElection
2019-09-26 21:03:35,657 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2: begin an election at term 1 for -1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397], old=null
2019-09-26 21:03:35,659 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown LeaderElection
2019-09-26 21:03:35,659 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 21:03:35,659 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: change Leader from null to 1d15d09a-1fa3-4436-9148-1b5bf102deba at term 1 for becomeLeader, leader elected after 5061ms
2019-09-26 21:03:35,661 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 21:03:35,661 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 21:03:35,661 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 21:03:35,662 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 21:03:35,662 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 21:03:35,662 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 21:03:35,665 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: start LeaderState
2019-09-26 21:03:35,666 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:35,666 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: set configuration 0: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397], old=null at 0
2019-09-26 21:03:35,705 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/d5b2bbee-fa3a-4294-8596-ccc89f8f8673/current/log_inprogress_0
2019-09-26 21:03:35,705 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/a53d0f01-c877-482c-87fb-ff8368d8fe7f/current/log_inprogress_0
2019-09-26 21:03:35,924 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:group-827CA8988DB4 changes to CANDIDATE, lastRpcTime:5154, electionTimeout:5154ms
2019-09-26 21:03:35,924 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown FollowerState
2019-09-26 21:03:35,924 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 21:03:35,924 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: start LeaderElection
2019-09-26 21:03:35,942 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3: begin an election at term 1 for -1: [5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066], old=null
2019-09-26 21:03:35,942 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown LeaderElection
2019-09-26 21:03:35,942 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 21:03:35,943 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: change Leader from null to 5a828d89-9008-4d76-8f23-9d4b0ce5df4d at term 1 for becomeLeader, leader elected after 5221ms
2019-09-26 21:03:35,945 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 21:03:35,945 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 21:03:35,945 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 21:03:35,945 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 21:03:35,945 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 21:03:35,946 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 21:03:35,949 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: start LeaderState
2019-09-26 21:03:35,949 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:35,950 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: set configuration 0: [5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066], old=null at 0
2019-09-26 21:03:35,968 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5f456774-4ac8-4598-857f-d1c030208d08:group-24CB4BD49355 changes to CANDIDATE, lastRpcTime:5035, electionTimeout:5034ms
2019-09-26 21:03:35,968 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5f456774-4ac8-4598-857f-d1c030208d08: shutdown FollowerState
2019-09-26 21:03:35,969 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 21:03:35,969 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5f456774-4ac8-4598-857f-d1c030208d08: start LeaderElection
2019-09-26 21:03:35,980 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e4c829e3-4319-461b-9cae-827ca8988db4/current/log_inprogress_0
2019-09-26 21:03:35,980 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4: begin an election at term 1 for -1: [5f456774-4ac8-4598-857f-d1c030208d08:192.168.157.234:35379], old=null
2019-09-26 21:03:35,980 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5f456774-4ac8-4598-857f-d1c030208d08: shutdown LeaderElection
2019-09-26 21:03:35,980 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 21:03:35,980 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: change Leader from null to 5f456774-4ac8-4598-857f-d1c030208d08 at term 1 for becomeLeader, leader elected after 5059ms
2019-09-26 21:03:35,982 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 21:03:35,982 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 21:03:35,982 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 21:03:35,982 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 21:03:35,983 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 21:03:35,983 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 21:03:35,986 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5f456774-4ac8-4598-857f-d1c030208d08: start LeaderState
2019-09-26 21:03:35,986 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:35,986 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: set configuration 0: [5f456774-4ac8-4598-857f-d1c030208d08:192.168.157.234:35379], old=null at 0
2019-09-26 21:03:36,004 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 42034195-a667-4f7c-bc25-5c53d8667078:group-56994B975F95 changes to CANDIDATE, lastRpcTime:5153, electionTimeout:5149ms
2019-09-26 21:03:36,004 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 42034195-a667-4f7c-bc25-5c53d8667078: shutdown FollowerState
2019-09-26 21:03:36,004 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 21:03:36,004 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 42034195-a667-4f7c-bc25-5c53d8667078: start LeaderElection
2019-09-26 21:03:36,016 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/ratis/bea64c87-0e18-43f4-81b2-24cb4bd49355/current/log_inprogress_0
2019-09-26 21:03:36,016 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5: begin an election at term 1 for -1: [42034195-a667-4f7c-bc25-5c53d8667078:192.168.157.234:42939], old=null
2019-09-26 21:03:36,017 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 42034195-a667-4f7c-bc25-5c53d8667078: shutdown LeaderElection
2019-09-26 21:03:36,017 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 21:03:36,017 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: change Leader from null to 42034195-a667-4f7c-bc25-5c53d8667078 at term 1 for becomeLeader, leader elected after 5183ms
2019-09-26 21:03:36,018 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 21:03:36,018 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 21:03:36,019 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 21:03:36,019 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 21:03:36,019 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 21:03:36,019 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 21:03:36,022 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 42034195-a667-4f7c-bc25-5c53d8667078: start LeaderState
2019-09-26 21:03:36,023 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:36,023 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: set configuration 0: [42034195-a667-4f7c-bc25-5c53d8667078:192.168.157.234:42939], old=null at 0
2019-09-26 21:03:36,046 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/ratis/3a3b025d-eb70-4831-a32c-56994b975f95/current/log_inprogress_0
2019-09-26 21:03:36,056 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2875a3b9-6f76-467d-b17b-f590da7fb391:group-A12F973A925D changes to CANDIDATE, lastRpcTime:5017, electionTimeout:5010ms
2019-09-26 21:03:36,056 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown FollowerState
2019-09-26 21:03:36,056 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 21:03:36,057 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start LeaderElection
2019-09-26 21:03:36,072 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6: begin an election at term 1 for -1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:36,097 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:03:36,097 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:03:36,097 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown FollowerState
2019-09-26 21:03:36,097 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown FollowerState
2019-09-26 21:03:36,097 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: start FollowerState
2019-09-26 21:03:36,097 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: start FollowerState
2019-09-26 21:03:36,097 [Thread-226] INFO  impl.FollowerState (FollowerState.java:run(115)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 21:03:36,097 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(115)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 21:03:36,140 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6: Election PASSED; received 1 response(s) [2875a3b9-6f76-467d-b17b-f590da7fb391<-5a828d89-9008-4d76-8f23-9d4b0ce5df4d#0:OK-t1] and 0 exception(s); 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:t1, leader=null, voted=2875a3b9-6f76-467d-b17b-f590da7fb391, raftlog=2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null
2019-09-26 21:03:36,140 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown LeaderElection
2019-09-26 21:03:36,140 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 21:03:36,142 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: change Leader from null to 2875a3b9-6f76-467d-b17b-f590da7fb391 at term 1 for becomeLeader, leader elected after 5120ms
2019-09-26 21:03:36,142 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 21:03:36,142 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 21:03:36,142 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 21:03:36,143 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 21:03:36,143 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 21:03:36,143 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 21:03:36,147 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 21:03:36,147 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:36,147 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 21:03:36,150 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 21:03:36,160 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:36,160 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:36,161 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 21:03:36,161 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 21:03:36,161 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 21:03:36,161 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 21:03:36,162 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 21:03:36,162 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 21:03:36,166 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: start LeaderState
2019-09-26 21:03:36,166 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:36,167 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: set configuration 0: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null at 0
2019-09-26 21:03:36,206 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d/current/log_inprogress_0
2019-09-26 21:03:36,208 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: change Leader from null to 2875a3b9-6f76-467d-b17b-f590da7fb391 at term 1 for appendEntries, leader elected after 5186ms
2019-09-26 21:03:36,208 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: change Leader from null to 2875a3b9-6f76-467d-b17b-f590da7fb391 at term 1 for appendEntries, leader elected after 5186ms
2019-09-26 21:03:36,228 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:36,243 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: set configuration 0: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null at 0
2019-09-26 21:03:36,243 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: set configuration 0: [1d15d09a-1fa3-4436-9148-1b5bf102deba:192.168.157.234:43397, 5a828d89-9008-4d76-8f23-9d4b0ce5df4d:192.168.157.234:39066, 2875a3b9-6f76-467d-b17b-f590da7fb391:192.168.157.234:40142], old=null at 0
2019-09-26 21:03:36,244 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:36,244 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 21:03:36,272 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d/current/log_inprogress_0
2019-09-26 21:03:36,272 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/ratis/e5bd895c-313c-4619-b39e-a12f973a925d/current/log_inprogress_0
2019-09-26 21:03:37,229 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:38,230 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:39,232 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:40,233 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:41,235 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:42,243 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:43,245 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:44,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:45,248 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:46,249 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:47,251 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:48,252 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:49,254 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:50,255 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:51,257 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:51,259 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 21:03:52,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:53,262 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:54,264 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:55,266 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:56,267 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:57,268 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:58,274 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:03:59,277 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:00,286 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:01,289 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:01,291 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 21:04:02,292 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:03,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:04,295 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:05,297 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:06,299 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:07,300 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:08,302 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:09,303 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:10,305 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:11,306 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:11,308 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 21:04:12,310 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:13,311 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:14,313 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:15,315 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:16,316 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:17,318 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:18,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:19,321 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:20,322 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:21,324 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:21,326 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 21:04:22,328 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:23,329 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:24,330 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:25,332 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:26,333 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:27,334 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:28,336 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:29,337 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:30,339 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:31,340 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:31,342 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 21:04:32,344 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:33,345 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:34,346 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:35,348 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:36,349 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:37,350 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:38,351 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:39,353 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:40,354 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:41,356 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:41,358 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 21:04:42,359 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:43,360 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:44,361 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:45,363 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:46,364 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:47,366 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:48,367 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:49,369 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:50,370 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:51,372 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:51,374 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 21:04:52,375 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:53,376 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:54,378 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:55,379 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:56,380 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:57,382 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:58,383 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:04:59,385 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:00,386 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:01,388 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:01,390 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 21:05:02,391 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:03,393 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:04,396 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:05,397 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:06,399 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:07,400 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:08,402 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:09,403 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:10,405 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:11,406 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:11,408 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 21:05:12,409 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:13,411 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:14,412 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:15,413 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:16,415 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:17,416 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:18,417 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:19,419 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:20,420 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:21,422 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:21,424 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 21:05:21,426 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-26 21:05:22,452 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:23,458 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:24,461 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:25,463 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:26,464 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:27,467 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:28,468 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:29,469 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:30,471 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:31,472 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:32,474 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:33,476 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:34,477 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:35,479 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:36,480 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:37,481 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:38,483 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:39,484 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:40,485 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:41,487 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:41,489 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 21:05:42,490 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:43,492 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:44,493 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:45,494 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:46,496 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:47,497 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:48,498 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:49,500 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:50,501 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:51,502 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:51,504 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 21:05:52,506 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:53,507 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:54,508 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:55,510 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:56,511 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:57,513 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:58,514 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:05:59,516 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:00,517 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:01,518 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:01,520 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 21:06:02,522 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:03,523 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:04,525 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:05,526 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:06,527 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:07,529 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:08,530 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:09,531 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:10,533 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:11,534 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:11,537 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 21:06:12,538 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:13,539 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:14,541 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:15,542 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:16,544 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:17,545 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:18,546 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:19,548 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:20,549 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:21,552 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:21,554 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 21:06:22,555 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:23,556 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:24,557 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:25,559 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:26,560 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:27,562 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:28,564 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:29,565 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:30,566 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:31,568 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:31,569 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 21:06:32,584 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:33,587 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:34,590 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:35,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:36,593 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:37,595 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:38,596 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:39,597 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:40,599 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:41,601 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:41,603 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 21:06:42,604 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:43,605 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:44,607 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:45,608 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:46,609 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:47,611 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:48,612 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:49,614 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:50,616 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:51,618 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:51,620 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 21:06:52,622 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:53,623 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:54,625 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:55,627 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:56,628 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:57,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:58,631 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:06:59,632 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:00,633 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:01,635 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:01,636 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 21:07:02,638 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:03,639 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:04,640 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:05,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:06,643 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:07,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:08,646 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:09,648 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:10,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:11,650 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:11,652 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 21:07:11,653 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-26 21:07:12,661 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:13,662 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:14,664 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:15,665 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:16,666 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:17,668 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:18,669 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:19,670 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:20,671 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:21,672 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:22,675 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:23,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:24,678 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:25,680 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:26,681 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:27,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:28,684 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:29,685 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:30,686 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:31,688 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:31,689 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 21:07:32,690 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:33,692 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:34,693 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:35,694 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:36,696 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:37,697 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:38,698 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:39,699 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:40,701 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:41,470 [Thread-249] WARN  util.JavaUtils (JavaUtils.java:sleep(250)) - Unexpected long sleep: sleep(5055ms) actually took 5430ms which is over the threshold 300ms
2019-09-26 21:07:41,470 [Thread-248] WARN  util.JavaUtils (JavaUtils.java:sleep(250)) - Unexpected long sleep: sleep(5122ms) actually took 5468ms which is over the threshold 300ms
2019-09-26 21:07:41,702 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:41,703 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 21:07:42,705 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:43,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:44,708 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:45,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:46,711 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:47,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:48,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:49,717 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:50,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:51,719 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:51,721 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 21:07:52,723 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:53,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:54,725 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:55,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:56,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:57,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:58,730 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:07:59,732 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:00,733 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:01,735 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:01,736 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 21:08:02,737 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:03,738 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:04,740 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:05,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:06,742 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:07,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:08,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:09,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:10,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:11,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:11,750 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 21:08:12,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:13,752 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:14,753 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:15,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:16,756 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:17,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:18,759 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:19,760 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:20,761 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:21,762 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:21,764 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 21:08:22,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:23,766 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:24,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:25,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:26,770 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:27,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:28,772 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:29,774 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:30,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:31,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:31,777 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 21:08:32,694 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-26 21:08:32,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:33,780 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:34,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:35,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:36,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:37,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:38,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:39,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:40,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:41,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:41,790 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 21:08:42,791 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:43,793 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:44,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:45,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:46,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:47,797 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:48,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:49,800 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:50,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:51,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:51,804 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 21:08:52,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:53,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:54,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:55,809 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:56,810 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:57,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:58,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:08:59,814 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:09:00,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:09:01,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 21:09:01,818 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 21:09:01,819 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.validateWriteTest(TestDataValidate.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-26 21:09:01,823 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 21:09:01,824 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 21:09:01,824 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 21:09:01,825 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36860
2019-09-26 21:09:01,839 [IPC Server listener on 36860] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36860
2019-09-26 21:09:01,843 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 21:09:01,849 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 21:09:01,852 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 21:09:01,877 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 21:09:01,885 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@151335cb{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 21:09:01,893 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:01,894 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:01,895 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:01,901 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 21:09:02,771 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 21:09:02,879 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 21:09:06,905 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 21:09:06,905 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 21:09:06,907 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: close
2019-09-26 21:09:06,907 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: close
2019-09-26 21:09:06,910 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: shutdown
2019-09-26 21:09:06,910 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: shutdown
2019-09-26 21:09:06,911 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A12F973A925D,id=1d15d09a-1fa3-4436-9148-1b5bf102deba
2019-09-26 21:09:06,911 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A12F973A925D,id=5a828d89-9008-4d76-8f23-9d4b0ce5df4d
2019-09-26 21:09:06,911 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown FollowerState
2019-09-26 21:09:06,911 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown FollowerState
2019-09-26 21:09:06,912 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:06,912 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(115)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 21:09:06,912 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:06,912 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(115)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 21:09:06,920 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D: closes. applyIndex: 0
2019-09-26 21:09:06,920 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D: closes. applyIndex: 0
2019-09-26 21:09:06,924 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:06,924 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:06,928 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-A12F973A925D-SegmentedRaftLogWorker close()
2019-09-26 21:09:06,928 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-A12F973A925D-SegmentedRaftLogWorker close()
2019-09-26 21:09:06,934 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: shutdown
2019-09-26 21:09:06,934 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: shutdown
2019-09-26 21:09:06,935 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-827CA8988DB4,id=5a828d89-9008-4d76-8f23-9d4b0ce5df4d
2019-09-26 21:09:06,935 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF8368D8FE7F,id=1d15d09a-1fa3-4436-9148-1b5bf102deba
2019-09-26 21:09:06,935 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown LeaderState
2019-09-26 21:09:06,936 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown LeaderState
2019-09-26 21:09:06,937 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d-PendingRequests: sendNotLeaderResponses
2019-09-26 21:09:06,937 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba-PendingRequests: sendNotLeaderResponses
2019-09-26 21:09:06,941 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:06,941 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:06,945 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4: closes. applyIndex: 0
2019-09-26 21:09:06,943 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F: closes. applyIndex: 0
2019-09-26 21:09:06,945 [5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:06,946 [1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:06,947 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d@group-827CA8988DB4-SegmentedRaftLogWorker close()
2019-09-26 21:09:06,949 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba@group-FF8368D8FE7F-SegmentedRaftLogWorker close()
2019-09-26 21:09:06,955 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown server with port 39066 now
2019-09-26 21:09:06,955 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown server with port 43397 now
2019-09-26 21:09:06,967 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: shutdown server with port 39066 successfully
2019-09-26 21:09:06,967 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: shutdown server with port 43397 successfully
2019-09-26 21:09:06,968 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 1d15d09a-1fa3-4436-9148-1b5bf102deba: installSnapshot onError, lastRequest: 2875a3b9-6f76-467d-b17b-f590da7fb391->1d15d09a-1fa3-4436-9148-1b5bf102deba#133-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-26 21:09:06,969 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-26 21:09:06,968 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 5a828d89-9008-4d76-8f23-9d4b0ce5df4d: installSnapshot onError, lastRequest: 2875a3b9-6f76-467d-b17b-f590da7fb391->5a828d89-9008-4d76-8f23-9d4b0ce5df4d#133-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-26 21:09:06,969 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-26 21:09:06,985 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 21:09:06,985 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 21:09:06,987 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 21:09:06,987 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
Sep 26, 2019 9:09:06 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@26990246
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Sep 26, 2019 9:09:06 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@6c06c0b1
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-26 21:09:07,024 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 21:09:07,025 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 21:09:07,031 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 21:09:07,037 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 21:09:07,038 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28da7d11{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 21:09:07,039 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f6917fb{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 21:09:07,039 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:07,040 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:07,041 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41eb94bc{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:07,042 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:07,042 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a6fa56e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:07,043 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ecec90d{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:07,686 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 21:09:08,012 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 21:09:09,475 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-26 21:09:09,475 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-26 21:09:09,480 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba: nextIndex: updateUnconditionally 0 -> 0
2019-09-26 21:09:09,483 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d: nextIndex: updateUnconditionally 0 -> 0
2019-09-26 21:09:11,971 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-26 21:09:11,972 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-26 21:09:11,976 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d: nextIndex: updateUnconditionally 0 -> 0
2019-09-26 21:09:11,978 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba: nextIndex: updateUnconditionally 0 -> 0
2019-09-26 21:09:12,044 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 21:09:12,044 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 21:09:12,044 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: close
2019-09-26 21:09:12,045 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 42034195-a667-4f7c-bc25-5c53d8667078: close
2019-09-26 21:09:12,045 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: shutdown
2019-09-26 21:09:12,045 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: shutdown
2019-09-26 21:09:12,046 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CCC89F8F8673,id=2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:09:12,046 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-56994B975F95,id=42034195-a667-4f7c-bc25-5c53d8667078
2019-09-26 21:09:12,046 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown LeaderState
2019-09-26 21:09:12,047 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 42034195-a667-4f7c-bc25-5c53d8667078: shutdown LeaderState
2019-09-26 21:09:12,047 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 2875a3b9-6f76-467d-b17b-f590da7fb391-PendingRequests: sendNotLeaderResponses
2019-09-26 21:09:12,048 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 42034195-a667-4f7c-bc25-5c53d8667078-PendingRequests: sendNotLeaderResponses
2019-09-26 21:09:12,048 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:12,053 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:12,054 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95: closes. applyIndex: 0
2019-09-26 21:09:12,053 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673: closes. applyIndex: 0
2019-09-26 21:09:12,055 [42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:12,055 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:12,058 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 42034195-a667-4f7c-bc25-5c53d8667078@group-56994B975F95-SegmentedRaftLogWorker close()
2019-09-26 21:09:12,061 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 42034195-a667-4f7c-bc25-5c53d8667078: shutdown server with port 42939 now
2019-09-26 21:09:12,063 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 42034195-a667-4f7c-bc25-5c53d8667078: shutdown server with port 42939 successfully
2019-09-26 21:09:12,070 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-CCC89F8F8673-SegmentedRaftLogWorker close()
2019-09-26 21:09:12,073 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: shutdown
2019-09-26 21:09:12,074 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A12F973A925D,id=2875a3b9-6f76-467d-b17b-f590da7fb391
2019-09-26 21:09:12,074 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown LeaderState
2019-09-26 21:09:12,077 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 2875a3b9-6f76-467d-b17b-f590da7fb391-PendingRequests: sendNotLeaderResponses
2019-09-26 21:09:12,077 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$394/1980681534@32be48f7] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->5a828d89-9008-4d76-8f23-9d4b0ce5df4d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 21:09:12,077 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$394/1980681534@53e1d838] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D->1d15d09a-1fa3-4436-9148-1b5bf102deba-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 21:09:12,078 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:12,080 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D: closes. applyIndex: 0
2019-09-26 21:09:12,080 [2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:12,082 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 2875a3b9-6f76-467d-b17b-f590da7fb391@group-A12F973A925D-SegmentedRaftLogWorker close()
2019-09-26 21:09:12,087 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown server with port 40142 now
2019-09-26 21:09:12,088 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 2875a3b9-6f76-467d-b17b-f590da7fb391: shutdown server with port 40142 successfully
2019-09-26 21:09:12,094 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 21:09:12,095 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 21:09:12,113 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 21:09:12,117 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 21:09:12,117 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 21:09:12,118 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cf0a747{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 21:09:12,121 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 21:09:12,122 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21505815{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:12,124 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d910b3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 21:09:12,124 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ea4300e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:12,124 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@934b52f{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:12,124 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:12,126 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:12,127 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:13,003 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 21:09:17,128 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 21:09:17,129 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 5f456774-4ac8-4598-857f-d1c030208d08: close
2019-09-26 21:09:17,130 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: shutdown
2019-09-26 21:09:17,130 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-24CB4BD49355,id=5f456774-4ac8-4598-857f-d1c030208d08
2019-09-26 21:09:17,131 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 5f456774-4ac8-4598-857f-d1c030208d08: shutdown LeaderState
2019-09-26 21:09:17,131 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 5f456774-4ac8-4598-857f-d1c030208d08-PendingRequests: sendNotLeaderResponses
2019-09-26 21:09:17,132 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-StateMachineUpdater: set stopIndex = 0
2019-09-26 21:09:17,134 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355: closes. applyIndex: 0
2019-09-26 21:09:17,134 [5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 21:09:17,135 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 5f456774-4ac8-4598-857f-d1c030208d08@group-24CB4BD49355-SegmentedRaftLogWorker close()
2019-09-26 21:09:17,137 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 5f456774-4ac8-4598-857f-d1c030208d08: shutdown server with port 35379 now
2019-09-26 21:09:17,139 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 5f456774-4ac8-4598-857f-d1c030208d08: shutdown server with port 35379 successfully
2019-09-26 21:09:17,155 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-e08f2aa5-8be5-4057-aaf4-2318d48143d9/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 21:09:17,173 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 21:09:17,177 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 21:09:17,178 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dc3502b{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 21:09:17,179 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:17,180 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:17,180 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:17,182 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 21:09:17,182 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 21:09:17,182 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-26 21:09:17,182 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 21:09:17,183 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 21:09:17,183 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 21:09:17,183 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44095
2019-09-26 21:09:17,186 [IPC Server listener on 44095] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44095
2019-09-26 21:09:17,186 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 21:09:17,201 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 21:09:17,201 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 21:09:17,201 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 21:09:17,201 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35709
2019-09-26 21:09:17,204 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 21:09:17,205 [IPC Server listener on 35709] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35709
2019-09-26 21:09:17,205 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 21:09:17,205 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 21:09:17,205 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38570
2019-09-26 21:09:17,208 [IPC Server listener on 38570] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38570
2019-09-26 21:09:17,208 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 21:09:17,208 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 21:09:17,209 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9573b3b{/,null,UNAVAILABLE}{/scm}
2019-09-26 21:09:17,210 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 21:09:17,210 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 21:09:17,211 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-26 21:09:17,211 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 21:09:17,212 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 21:09:17,212 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 21:09:17,213 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 21:09:17,219 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-26 21:09:17,229 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 21:09:17,229 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
