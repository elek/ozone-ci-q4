<?xml version="1.0" encoding="UTF-8"?>
<robot rpa="false" generated="20191004 20:32:10.598" generator="Robot 3.1.1 (Python 2.7.5 on linux2)">
<suite source="/opt/ozone/smoketest/mapreduce.robot" id="s1" name="ozonesecure-mr-mapreduce">
<test id="s1-t1" name="Execute PI calculation">
<kw name="Execute" library="commonlib">
<arguments>
<arg>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-${hadoop.version}.jar pi 3 3</arg>
</arguments>
<assign>
<var>${output}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191004 20:32:10.657" level="INFO">Running command 'yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar pi 3 3 2&gt;&amp;1'.</msg>
<msg timestamp="20191004 20:32:14.451" level="INFO">${rc} = 255</msg>
<msg timestamp="20191004 20:32:14.451" level="INFO">${output} = Number of Maps  = 3
Samples per Map = 3
2019-10-04 20:32:13 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-10-04 20:32:13 INFO  MetricsSystemImpl:374 - Scheduled Metr...</msg>
<status status="PASS" endtime="20191004 20:32:14.451" starttime="20191004 20:32:10.654"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191004 20:32:14.453" level="INFO">Number of Maps  = 3
Samples per Map = 3
2019-10-04 20:32:13 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-10-04 20:32:13 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-10-04 20:32:13 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
java.lang.NullPointerException: client is null
	at java.util.Objects.requireNonNull(Objects.java:228)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.getClient(XceiverClientRatis.java:208)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:234)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:332)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:310)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:601)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:459)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:470)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.flush(BlockOutputStream.java:428)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.flush(BlockOutputStreamEntry.java:136)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:443)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.flush(KeyOutputStream.java:397)
	at org.apache.hadoop.fs.ozone.OzoneFSOutputStream.flush(OzoneFSOutputStream.java:51)
	at java.io.FilterOutputStream.flush(FilterOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.io.SequenceFile$Writer.writeFileHeader(SequenceFile.java:1260)
	at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1324)
	at org.apache.hadoop.io.SequenceFile$Writer.&lt;init&gt;(SequenceFile.java:1192)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:332)
	at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:293)
	at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:360)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:368)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</msg>
<status status="PASS" endtime="20191004 20:32:14.454" starttime="20191004 20:32:14.452"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191004 20:32:14.455" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<msg timestamp="20191004 20:32:14.456" level="FAIL">255 != 0</msg>
<status status="FAIL" endtime="20191004 20:32:14.456" starttime="20191004 20:32:14.454"></status>
</kw>
<status status="FAIL" endtime="20191004 20:32:14.456" starttime="20191004 20:32:10.653"></status>
</kw>
<timeout value="4 minutes"></timeout>
<status status="FAIL" endtime="20191004 20:32:14.457" critical="yes" starttime="20191004 20:32:10.652">255 != 0</status>
</test>
<test id="s1-t2" name="Execute WordCount">
<kw name="Generate Random String" library="String">
<doc>Generates a string with a desired ``length`` from the given ``chars``.</doc>
<arguments>
<arg>2</arg>
<arg>[NUMBERS]</arg>
</arguments>
<assign>
<var>${random}</var>
</assign>
<msg timestamp="20191004 20:32:14.460" level="INFO">${random} = 34</msg>
<status status="PASS" endtime="20191004 20:32:14.460" starttime="20191004 20:32:14.459"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-${hadoop.version}.jar wordcount o3fs://bucket1.vol1/key1 o3fs://bucket1.vol1/key1-${random}.count</arg>
</arguments>
<assign>
<var>${output}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191004 20:32:14.464" level="INFO">Running command 'yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar wordcount o3fs://bucket1.vol1/key1 o3fs://bucket1.vol1/key1-34.count 2&gt;&amp;1'.</msg>
<msg timestamp="20191004 20:32:19.252" level="INFO">${rc} = 255</msg>
<msg timestamp="20191004 20:32:19.252" level="INFO">${output} = 2019-10-04 20:32:17 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.18.0.12:8032
2019-10-04 20:32:17 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.18.0.11:10200
2...</msg>
<status status="PASS" endtime="20191004 20:32:19.252" starttime="20191004 20:32:14.461"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191004 20:32:19.254" level="INFO">2019-10-04 20:32:17 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.18.0.12:8032
2019-10-04 20:32:17 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.18.0.11:10200
2019-10-04 20:32:18 INFO  KMSClientProvider:1041 - New token created: (Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1570221138096, maxDate=1570825938096, sequenceNumber=1, masterKeyId=2))
2019-10-04 20:32:18 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: OzoneToken, Service: 172.18.0.8:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1570221137773, maxDate=1570825937773, sequenceNumber=1, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null)
2019-10-04 20:32:18 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1570221138096, maxDate=1570825938096, sequenceNumber=1, masterKeyId=2)
2019-10-04 20:32:18 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-10-04 20:32:18 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-10-04 20:32:18 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
2019-10-04 20:32:19 INFO  JobSubmitter:260 - Cleaning up the staging area /user/hadoop/.staging/job_1570221082293_0001
java.lang.NullPointerException: client is null
	at java.util.Objects.requireNonNull(Objects.java:228)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.getClient(XceiverClientRatis.java:208)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:234)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:332)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:310)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:601)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:459)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:470)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:493)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.fs.ozone.OzoneFSOutputStream.close(OzoneFSOutputStream.java:56)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:70)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:415)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:387)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2369)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2335)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2298)
	at org.apache.hadoop.mapreduce.JobResourceUploader.copyJar(JobResourceUploader.java:763)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadJobJar(JobResourceUploader.java:450)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:209)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:133)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.hadoop.examples.WordCount.main(WordCount.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</msg>
<status status="PASS" endtime="20191004 20:32:19.255" starttime="20191004 20:32:19.253"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191004 20:32:19.256" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<msg timestamp="20191004 20:32:19.257" level="FAIL">255 != 0</msg>
<status status="FAIL" endtime="20191004 20:32:19.257" starttime="20191004 20:32:19.255"></status>
</kw>
<status status="FAIL" endtime="20191004 20:32:19.257" starttime="20191004 20:32:14.460"></status>
</kw>
<timeout value="4 minutes"></timeout>
<status status="FAIL" endtime="20191004 20:32:19.258" critical="yes" starttime="20191004 20:32:14.458">255 != 0</status>
</test>
<doc>Execute MR jobs</doc>
<status status="FAIL" endtime="20191004 20:32:19.259" starttime="20191004 20:32:10.599"></status>
</suite>
<statistics>
<total>
<stat fail="2" pass="0">Critical Tests</stat>
<stat fail="2" pass="0">All Tests</stat>
</total>
<tag>
</tag>
<suite>
<stat fail="2" id="s1" name="ozonesecure-mr-mapreduce" pass="0">ozonesecure-mr-mapreduce</stat>
</suite>
</statistics>
<errors>
</errors>
</robot>
