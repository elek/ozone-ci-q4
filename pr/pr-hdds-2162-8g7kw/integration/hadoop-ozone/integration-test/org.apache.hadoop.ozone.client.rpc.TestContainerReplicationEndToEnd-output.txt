2019-09-28 02:09:11,964 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:12,065 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:12,068 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:12,087 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @966ms
2019-09-28 02:09:12,193 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-28 02:09:12,194 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-28 02:09:12,195 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-28 02:09:12,195 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-28 02:09:12,195 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-28 02:09:12,195 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-28 02:09:12,208 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 02:09:12,209 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 02:09:12,210 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 02:09:12,529 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@71d44a3
2019-09-28 02:09:12,531 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-28 02:09:12,604 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-28 02:09:12,678 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-28 02:09:12,693 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:12,799 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-28 02:09:12,802 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:12,922 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for hdds.scm.replication.thread.interval(2000) assuming MILLISECONDS
2019-09-28 02:09:12,954 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-28 02:09:13,367 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:09:13,399 [Socket Reader #1 for port 46505] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46505
2019-09-28 02:09:13,593 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:09:13,594 [Socket Reader #1 for port 45306] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45306
2019-09-28 02:09:13,607 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:09:13,608 [Socket Reader #1 for port 42345] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42345
2019-09-28 02:09:13,637 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-28 02:09:13,812 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:09:13,821 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:09:13,830 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:09:13,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-28 02:09:13,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:09:13,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:09:13,869 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42345
2019-09-28 02:09:13,942 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-28 02:09:13,957 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-28 02:09:13,957 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-28 02:09:14,226 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(150)) - RPC server for Client  is listening at /0.0.0.0:42345
2019-09-28 02:09:14,227 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:09:14,227 [IPC Server listener on 42345] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42345: starting
2019-09-28 02:09:14,230 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45306
2019-09-28 02:09:14,232 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45306
2019-09-28 02:09:14,232 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:09:14,232 [IPC Server listener on 45306] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45306: starting
2019-09-28 02:09:14,235 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:46505
2019-09-28 02:09:14,235 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:46505
2019-09-28 02:09:14,236 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:09:14,236 [IPC Server listener on 46505] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46505: starting
2019-09-28 02:09:14,240 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36862
2019-09-28 02:09:14,242 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:09:14,281 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@615091b8{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:09:14,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4aa83f4f{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-28 02:09:14,316 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3574e198{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-28 02:09:14,322 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3aa3193a{HTTP/1.1,[http/1.1]}{0.0.0.0:36862}
2019-09-28 02:09:14,322 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3201ms
2019-09-28 02:09:14,324 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-28 02:09:14,325 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-28 02:09:14,327 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:36862
2019-09-28 02:09:14,337 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b366632] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:09:14,342 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:14,476 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-28 02:09:14,476 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-28 02:09:14,477 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:14,478 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:15,266 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:09:15,275 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-28 02:09:15,275 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-28 02:09:15,275 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-28 02:09:15,276 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-28 02:09:15,276 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-28 02:09:15,276 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-28 02:09:15,276 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-28 02:09:15,277 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-28 02:09:15,277 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-28 02:09:15,277 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-28 02:09:15,277 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-28 02:09:15,278 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-28 02:09:15,278 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-28 02:09:15,278 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-28 02:09:15,278 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-28 02:09:15,279 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-28 02:09:15,279 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-28 02:09:15,279 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-28 02:09:15,279 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-28 02:09:15,280 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-28 02:09:15,280 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-28 02:09:15,280 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-28 02:09:15,280 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 02:09:15,281 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 02:09:15,281 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 02:09:15,887 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:09:15,888 [Socket Reader #1 for port 38502] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38502
2019-09-28 02:09:15,912 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:38502
2019-09-28 02:09:15,912 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-28 02:09:15,914 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:09:15,914 [IPC Server listener on 38502] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38502: starting
2019-09-28 02:09:15,920 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-28 02:09:15,923 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:09:15,924 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:09:15,928 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:09:15,930 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-28 02:09:15,930 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:09:15,931 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:09:15,934 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44652
2019-09-28 02:09:15,934 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:09:15,937 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4cafa9aa{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:09:15,938 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67001148{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-28 02:09:15,946 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1ecfcbc9{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-28 02:09:15,947 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1965539b{HTTP/1.1,[http/1.1]}{0.0.0.0:44652}
2019-09-28 02:09:15,948 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4827ms
2019-09-28 02:09:15,949 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:09:15,949 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:44652
2019-09-28 02:09:16,325 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:09:16,390 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:09:16,432 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:09:16,434 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/containers/hdds to VolumeSet
2019-09-28 02:09:16,438 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3cee53dc
2019-09-28 02:09:16,456 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3cee53dc
2019-09-28 02:09:16,568 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:09:16,640 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:09:16,645 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:09:16,646 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:09:16,647 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:16,648 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:09:16,649 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:09:16,809 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis] (custom)
2019-09-28 02:09:16,862 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:09:16,864 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:09:16,865 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:09:16,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:09:16,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:09:16,868 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:09:16,868 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:09:16,869 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40995
2019-09-28 02:09:16,869 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:09:16,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@252dc8c4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:09:16,872 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2643d762{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:09:16,909 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f5ac102{/,file:///tmp/jetty-0.0.0.0-40995-hddsDatanode-_-any-7854004607556353469.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:09:16,910 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5df778c3{HTTP/1.1,[http/1.1]}{0.0.0.0:40995}
2019-09-28 02:09:16,911 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5790ms
2019-09-28 02:09:16,911 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:09:16,913 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40995
2019-09-28 02:09:16,913 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:09:16,916 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:09:16,919 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@620408cd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:09:16,926 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:09:16,927 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/containers/hdds to VolumeSet
2019-09-28 02:09:16,927 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6dd1c3ed
2019-09-28 02:09:16,927 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6dd1c3ed
2019-09-28 02:09:16,942 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:09:16,942 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:09:16,942 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:09:16,942 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:09:16,943 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:16,943 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:09:16,943 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:09:16,944 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis] (custom)
2019-09-28 02:09:16,945 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:09:16,946 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:09:16,947 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:09:16,949 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:09:16,949 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:09:16,949 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:09:16,949 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:09:16,950 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35986
2019-09-28 02:09:16,950 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:09:16,954 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5460b754{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:09:16,955 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c27a3a2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:09:16,984 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@53e800f9{/,file:///tmp/jetty-0.0.0.0-35986-hddsDatanode-_-any-4339049287092923896.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:09:16,985 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@337bbfdf{HTTP/1.1,[http/1.1]}{0.0.0.0:35986}
2019-09-28 02:09:16,985 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5865ms
2019-09-28 02:09:16,986 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:09:16,987 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35986
2019-09-28 02:09:16,988 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:09:16,991 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:09:16,991 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36402ef7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:09:17,000 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:09:17,001 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/containers/hdds to VolumeSet
2019-09-28 02:09:17,002 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7fe82967
2019-09-28 02:09:17,002 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7fe82967
2019-09-28 02:09:17,016 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:09:17,016 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:09:17,016 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:09:17,017 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:09:17,017 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:17,017 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:09:17,017 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:09:17,018 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis] (custom)
2019-09-28 02:09:17,020 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:09:17,021 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:09:17,021 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:09:17,023 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:09:17,024 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:09:17,024 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:09:17,024 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:09:17,025 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46013
2019-09-28 02:09:17,025 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:09:17,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d21c56e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:09:17,028 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7100dea{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:09:17,052 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/meta/datanode.id
2019-09-28 02:09:17,058 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/meta/datanode.id
2019-09-28 02:09:17,061 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b350309{/,file:///tmp/jetty-0.0.0.0-46013-hddsDatanode-_-any-600578130403274607.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:09:17,061 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7ecec90d{HTTP/1.1,[http/1.1]}{0.0.0.0:46013}
2019-09-28 02:09:17,063 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5942ms
2019-09-28 02:09:17,064 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:09:17,065 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46013
2019-09-28 02:09:17,065 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:09:17,068 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:09:17,068 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58304d42] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:09:17,070 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/meta/datanode.id
2019-09-28 02:09:17,076 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:09:17,077 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/containers/hdds to VolumeSet
2019-09-28 02:09:17,077 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@37df14d1
2019-09-28 02:09:17,078 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@37df14d1
2019-09-28 02:09:17,092 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:09:17,093 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:09:17,093 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:09:17,093 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:09:17,093 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:17,094 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:09:17,094 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:09:17,094 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis] (custom)
2019-09-28 02:09:17,096 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:09:17,097 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:09:17,097 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:09:17,099 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:09:17,100 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:09:17,100 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:09:17,100 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:09:17,101 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45253
2019-09-28 02:09:17,101 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:09:17,107 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1305c126{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:09:17,108 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4c1bdcc2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:09:17,137 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56dfab87{/,file:///tmp/jetty-0.0.0.0-45253-hddsDatanode-_-any-8160123904433690214.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:09:17,137 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@715b886f{HTTP/1.1,[http/1.1]}{0.0.0.0:45253}
2019-09-28 02:09:17,138 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6017ms
2019-09-28 02:09:17,138 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:09:17,139 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45253
2019-09-28 02:09:17,141 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-28 02:09:17,143 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b384f2b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:09:17,147 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/meta/datanode.id
2019-09-28 02:09:18,142 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-28 02:09:18,980 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:09:18,984 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:09:18,984 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e21f0720-4123-4e8e-bf33-dad5acb3b0a9 at port 0
2019-09-28 02:09:19,011 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:09:19,019 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:09:19,019 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 0a1853ed-2cd6-48ad-95fc-455668814edb at port 0
2019-09-28 02:09:19,020 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start RPC server
2019-09-28 02:09:19,036 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: start RPC server
2019-09-28 02:09:19,085 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:09:19,087 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:09:19,088 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis fa66c997-38d4-4d58-8ea9-4c05cef23881 at port 0
2019-09-28 02:09:19,098 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start RPC server
2019-09-28 02:09:19,143 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-28 02:09:19,159 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:09:19,161 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:09:19,161 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 4e67c2bc-71aa-46f5-8494-d6c845463647 at port 0
2019-09-28 02:09:19,172 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start RPC server
2019-09-28 02:09:19,232 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: GrpcService started, listening on 0.0.0.0/0.0.0.0:35534
2019-09-28 02:09:19,232 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: GrpcService started, listening on 0.0.0.0/0.0.0.0:34709
2019-09-28 02:09:19,232 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: GrpcService started, listening on 0.0.0.0/0.0.0.0:46340
2019-09-28 02:09:19,232 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: GrpcService started, listening on 0.0.0.0/0.0.0.0:43745
2019-09-28 02:09:19,234 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 4e67c2bc-71aa-46f5-8494-d6c845463647 is started using port 46340
2019-09-28 02:09:19,234 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e21f0720-4123-4e8e-bf33-dad5acb3b0a9 is started using port 34709
2019-09-28 02:09:19,233 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 0a1853ed-2cd6-48ad-95fc-455668814edb is started using port 35534
2019-09-28 02:09:19,234 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis fa66c997-38d4-4d58-8ea9-4c05cef23881 is started using port 43745
2019-09-28 02:09:19,242 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 0a1853ed-2cd6-48ad-95fc-455668814edb is started using port 42994
2019-09-28 02:09:19,242 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e21f0720-4123-4e8e-bf33-dad5acb3b0a9 is started using port 35485
2019-09-28 02:09:19,242 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc fa66c997-38d4-4d58-8ea9-4c05cef23881 is started using port 33133
2019-09-28 02:09:19,242 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 4e67c2bc-71aa-46f5-8494-d6c845463647 is started using port 38078
2019-09-28 02:09:20,143 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 4 DN Heartbeats.
2019-09-28 02:09:20,966 [IPC Server handler 1 on 46505] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:09:20,967 [IPC Server handler 1 on 46505] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:09:20,972 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-28 02:09:20,973 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-28 02:09:20,973 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-28 02:09:20,997 [IPC Server handler 2 on 46505] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0a1853ed-2cd6-48ad-95fc-455668814edb
2019-09-28 02:09:20,997 [IPC Server handler 2 on 46505] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:09:21,072 [IPC Server handler 3 on 46505] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/fa66c997-38d4-4d58-8ea9-4c05cef23881
2019-09-28 02:09:21,072 [IPC Server handler 3 on 46505] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:09:21,145 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 3 of 4 DN Heartbeats.
2019-09-28 02:09:21,146 [IPC Server handler 6 on 46505] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:09:21,146 [IPC Server handler 6 on 46505] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:09:21,503 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: addNew group-46DFCA849A1B:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709] returns group-46DFCA849A1B:java.util.concurrent.CompletableFuture@569e47d8[Not completed]
2019-09-28 02:09:21,525 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: new RaftServerImpl for group-46DFCA849A1B:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709] with ContainerStateMachine:uninitialized
2019-09-28 02:09:21,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:21,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:21,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:21,532 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:21,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:21,544 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:21,545 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis] (custom)
2019-09-28 02:09:21,555 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/fd6cfe45-0532-4c17-b0d4-46dfca849a1b does not exist. Creating ...
2019-09-28 02:09:21,574 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/fd6cfe45-0532-4c17-b0d4-46dfca849a1b/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:21,589 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/fd6cfe45-0532-4c17-b0d4-46dfca849a1b has been successfully formatted.
2019-09-28 02:09:21,593 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-46DFCA849A1B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:21,593 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:21,596 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:21,603 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:21,604 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:21,607 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:21,613 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:21,620 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/fd6cfe45-0532-4c17-b0d4-46dfca849a1b
2019-09-28 02:09:21,622 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-28 02:09:21,630 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-28 02:09:21,675 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:21,676 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:21,681 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:21,682 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:21,682 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:21,683 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:21,684 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:21,685 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:21,686 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:21,697 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:21,703 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:21,709 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:21,710 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:21,711 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:21,712 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:21,743 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709], old=null
2019-09-28 02:09:21,745 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:21,746 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start FollowerState
2019-09-28 02:09:21,748 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-46DFCA849A1B,id=e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:09:21,826 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fd6cfe45-0532-4c17-b0d4-46dfca849a1b, Nodes: e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:21,859 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: addNew group-72990C26929C:[fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] returns group-72990C26929C:java.util.concurrent.CompletableFuture@1b778d88[Not completed]
2019-09-28 02:09:21,900 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: new RaftServerImpl for group-72990C26929C:[fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] with ContainerStateMachine:uninitialized
2019-09-28 02:09:21,903 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:21,903 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:21,903 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:21,903 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:21,903 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:21,904 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: ConfigurationManager, init=-1: [fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:21,904 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis] (custom)
2019-09-28 02:09:21,904 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/5b57393a-6749-45a5-82a4-72990c26929c does not exist. Creating ...
2019-09-28 02:09:21,918 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/5b57393a-6749-45a5-82a4-72990c26929c/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:21,931 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/5b57393a-6749-45a5-82a4-72990c26929c has been successfully formatted.
2019-09-28 02:09:21,932 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-72990C26929C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:21,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:21,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:21,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:21,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:21,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:21,935 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:21,935 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/5b57393a-6749-45a5-82a4-72990c26929c
2019-09-28 02:09:21,941 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:21,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:21,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:21,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:21,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:21,942 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:21,943 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:21,943 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:21,943 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:21,943 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:21,944 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:21,944 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:21,944 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:21,944 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:21,945 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:21,950 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: start as a follower, conf=-1: [fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:21,950 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:21,950 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start FollowerState
2019-09-28 02:09:21,952 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72990C26929C,id=fa66c997-38d4-4d58-8ea9-4c05cef23881
2019-09-28 02:09:21,966 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5b57393a-6749-45a5-82a4-72990c26929c, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:21,985 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: addNew group-9F2E9E7A0C50:[4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340] returns group-9F2E9E7A0C50:java.util.concurrent.CompletableFuture@19df8b8b[Not completed]
2019-09-28 02:09:22,004 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: new RaftServerImpl for group-9F2E9E7A0C50:[4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340] with ContainerStateMachine:uninitialized
2019-09-28 02:09:22,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:22,007 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:22,007 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:22,007 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:22,007 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:22,007 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: ConfigurationManager, init=-1: [4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:22,008 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis] (custom)
2019-09-28 02:09:22,008 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50 does not exist. Creating ...
2019-09-28 02:09:22,022 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:22,036 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50 has been successfully formatted.
2019-09-28 02:09:22,036 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-9F2E9E7A0C50: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:22,036 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:22,036 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:22,037 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:22,037 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:22,037 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,037 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:22,038 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50
2019-09-28 02:09:22,059 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:22,059 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:22,060 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,060 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:22,060 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:22,060 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:22,060 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:22,061 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:22,061 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:22,061 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:22,061 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:22,062 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:22,062 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:22,062 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:22,062 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:22,067 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: start as a follower, conf=-1: [4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340], old=null
2019-09-28 02:09:22,067 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:22,068 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start FollowerState
2019-09-28 02:09:22,068 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9F2E9E7A0C50,id=4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:09:22,077 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:22,092 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: addNew group-93701DFB6DE1:[0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] returns group-93701DFB6DE1:java.util.concurrent.CompletableFuture@3a4f2f6e[Not completed]
2019-09-28 02:09:22,094 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: new RaftServerImpl for group-93701DFB6DE1:[0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] with ContainerStateMachine:uninitialized
2019-09-28 02:09:22,094 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:22,095 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:22,095 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:22,095 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:22,095 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:22,095 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: ConfigurationManager, init=-1: [0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:22,095 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis] (custom)
2019-09-28 02:09:22,096 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/9358a96e-5e2a-458a-bf38-93701dfb6de1 does not exist. Creating ...
2019-09-28 02:09:22,108 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/9358a96e-5e2a-458a-bf38-93701dfb6de1/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:22,121 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/9358a96e-5e2a-458a-bf38-93701dfb6de1 has been successfully formatted.
2019-09-28 02:09:22,121 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-93701DFB6DE1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:22,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:22,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:22,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:22,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:22,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,122 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:22,123 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/9358a96e-5e2a-458a-bf38-93701dfb6de1
2019-09-28 02:09:22,127 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:22,127 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:22,127 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,127 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:22,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:22,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:22,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:22,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:22,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:22,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:22,129 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:22,129 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:22,129 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:22,129 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:22,130 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:22,134 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: start as a follower, conf=-1: [0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null
2019-09-28 02:09:22,134 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:22,134 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: start FollowerState
2019-09-28 02:09:22,135 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-93701DFB6DE1,id=0a1853ed-2cd6-48ad-95fc-455668814edb
2019-09-28 02:09:22,145 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 4 of 4 DN Heartbeats.
2019-09-28 02:09:22,147 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9358a96e-5e2a-458a-bf38-93701dfb6de1, Nodes: 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:22,153 [main] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-28 02:09:22,159 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 4 milliseconds for processing 0 containers.
2019-09-28 02:09:22,200 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: addNew group-5322F5BD3A50:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] returns group-5322F5BD3A50:java.util.concurrent.CompletableFuture@63177a6[Not completed]
2019-09-28 02:09:22,209 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: addNew group-5322F5BD3A50:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] returns group-5322F5BD3A50:java.util.concurrent.CompletableFuture@470c7d9d[Not completed]
2019-09-28 02:09:22,211 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: addNew group-5322F5BD3A50:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] returns group-5322F5BD3A50:java.util.concurrent.CompletableFuture@7b009d6c[Not completed]
2019-09-28 02:09:22,211 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: new RaftServerImpl for group-5322F5BD3A50:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] with ContainerStateMachine:uninitialized
2019-09-28 02:09:22,212 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:22,212 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:22,212 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:22,213 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:22,213 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:22,213 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:22,213 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: new RaftServerImpl for group-5322F5BD3A50:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] with ContainerStateMachine:uninitialized
2019-09-28 02:09:22,214 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis] (custom)
2019-09-28 02:09:22,214 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:22,214 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:22,214 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:22,214 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50 does not exist. Creating ...
2019-09-28 02:09:22,214 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:22,215 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:22,215 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: new RaftServerImpl for group-5322F5BD3A50:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745] with ContainerStateMachine:uninitialized
2019-09-28 02:09:22,215 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:22,215 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:09:22,215 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis] (custom)
2019-09-28 02:09:22,215 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:09:22,216 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:09:22,216 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50 does not exist. Creating ...
2019-09-28 02:09:22,216 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:09:22,216 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:22,216 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null, confs=<EMPTY_MAP>
2019-09-28 02:09:22,217 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis] (custom)
2019-09-28 02:09:22,217 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50 does not exist. Creating ...
2019-09-28 02:09:22,248 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:22,248 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:22,248 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:09:22,262 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50 has been successfully formatted.
2019-09-28 02:09:22,262 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50 has been successfully formatted.
2019-09-28 02:09:22,262 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50 has been successfully formatted.
2019-09-28 02:09:22,262 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5322F5BD3A50: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:22,262 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5322F5BD3A50: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:22,262 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5322F5BD3A50: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:09:22,262 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:22,263 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:22,263 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:09:22,263 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:22,263 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:22,264 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:22,263 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:09:22,264 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:22,264 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:22,264 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,264 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:09:22,265 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:22,264 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:22,265 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50
2019-09-28 02:09:22,265 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:22,265 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,265 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:22,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:22,266 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:09:22,266 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50
2019-09-28 02:09:22,266 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:22,266 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:22,266 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50
2019-09-28 02:09:22,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:22,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,267 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,267 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:09:22,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:22,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:22,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:22,268 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:09:22,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:22,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:22,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:22,269 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:09:22,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:22,269 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:22,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:22,269 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:09:22,270 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:22,269 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:22,270 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:09:22,270 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:22,270 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:22,270 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:22,270 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:09:22,271 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:22,271 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:22,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:09:22,271 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:22,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:09:22,271 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:22,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:09:22,272 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:22,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:09:22,272 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:22,272 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:22,273 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:09:22,273 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:22,273 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:22,273 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:09:22,274 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:22,274 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:09:22,274 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:09:22,275 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:09:22,280 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:22,280 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:22,280 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start FollowerState
2019-09-28 02:09:22,281 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5322F5BD3A50,id=fa66c997-38d4-4d58-8ea9-4c05cef23881
2019-09-28 02:09:22,281 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:22,282 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:22,282 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start FollowerState
2019-09-28 02:09:22,282 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:22,282 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:09:22,282 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5322F5BD3A50,id=e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:09:22,282 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start FollowerState
2019-09-28 02:09:22,284 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5322F5BD3A50,id=4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:09:22,306 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7579321f-16b1-4fa1-846f-5322f5bd3a50, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 02:09:23,420 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:23,981 [Thread-193] INFO  container.ReplicationManager (ReplicationManager.java:start(169)) - Replication Monitor Thread is already running.
2019-09-28 02:09:24,160 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:24,422 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:25,423 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:26,160 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:26,424 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:26,944 [Thread-195] INFO  impl.FollowerState (FollowerState.java:run(106)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9:group-46DFCA849A1B changes to CANDIDATE, lastRpcTime:5198, electionTimeout:5197ms
2019-09-28 02:09:26,946 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown FollowerState
2019-09-28 02:09:26,947 [Thread-195] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:26,953 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(106)) - fa66c997-38d4-4d58-8ea9-4c05cef23881:group-72990C26929C changes to CANDIDATE, lastRpcTime:5003, electionTimeout:5001ms
2019-09-28 02:09:26,955 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start LeaderElection
2019-09-28 02:09:26,955 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown FollowerState
2019-09-28 02:09:26,958 [Thread-198] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:26,959 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start LeaderElection
2019-09-28 02:09:26,984 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1: begin an election at term 1 for -1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709], old=null
2019-09-28 02:09:26,984 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2: begin an election at term 1 for -1: [fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:26,991 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown LeaderElection
2019-09-28 02:09:26,991 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown LeaderElection
2019-09-28 02:09:26,992 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:09:26,992 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:09:26,992 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: change Leader from null to e21f0720-4123-4e8e-bf33-dad5acb3b0a9 at term 1 for becomeLeader, leader elected after 5399ms
2019-09-28 02:09:26,992 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: change Leader from null to fa66c997-38d4-4d58-8ea9-4c05cef23881 at term 1 for becomeLeader, leader elected after 5058ms
2019-09-28 02:09:27,001 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:09:27,001 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:09:27,001 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:09:27,001 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:09:27,005 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:09:27,005 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:09:27,009 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:09:27,009 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:09:27,009 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:09:27,009 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:09:27,010 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:09:27,010 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:09:27,032 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start LeaderState
2019-09-28 02:09:27,032 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start LeaderState
2019-09-28 02:09:27,056 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:27,056 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:27,070 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: set configuration 0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709], old=null at 0
2019-09-28 02:09:27,070 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: set configuration 0: [fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null at 0
2019-09-28 02:09:27,184 [Thread-201] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4e67c2bc-71aa-46f5-8494-d6c845463647:group-9F2E9E7A0C50 changes to CANDIDATE, lastRpcTime:5115, electionTimeout:5115ms
2019-09-28 02:09:27,185 [Thread-201] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown FollowerState
2019-09-28 02:09:27,186 [Thread-201] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:27,186 [Thread-201] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start LeaderElection
2019-09-28 02:09:27,205 [Thread-204] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0a1853ed-2cd6-48ad-95fc-455668814edb:group-93701DFB6DE1 changes to CANDIDATE, lastRpcTime:5070, electionTimeout:5070ms
2019-09-28 02:09:27,205 [Thread-204] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: shutdown FollowerState
2019-09-28 02:09:27,206 [Thread-204] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:27,206 [Thread-204] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: start LeaderElection
2019-09-28 02:09:27,216 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4: begin an election at term 1 for -1: [0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null
2019-09-28 02:09:27,216 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3: begin an election at term 1 for -1: [4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340], old=null
2019-09-28 02:09:27,218 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown LeaderElection
2019-09-28 02:09:27,218 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: shutdown LeaderElection
2019-09-28 02:09:27,218 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:09:27,218 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:09:27,218 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: change Leader from null to 4e67c2bc-71aa-46f5-8494-d6c845463647 at term 1 for becomeLeader, leader elected after 5181ms
2019-09-28 02:09:27,218 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: change Leader from null to 0a1853ed-2cd6-48ad-95fc-455668814edb at term 1 for becomeLeader, leader elected after 5096ms
2019-09-28 02:09:27,220 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:09:27,220 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:09:27,220 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:09:27,220 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:09:27,221 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:09:27,221 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:09:27,221 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:09:27,221 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:09:27,221 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:09:27,221 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:09:27,222 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:09:27,222 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:09:27,228 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start LeaderState
2019-09-28 02:09:27,228 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: start LeaderState
2019-09-28 02:09:27,229 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:27,229 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:27,230 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: set configuration 0: [4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340], old=null at 0
2019-09-28 02:09:27,230 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: set configuration 0: [0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null at 0
2019-09-28 02:09:27,336 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - fa66c997-38d4-4d58-8ea9-4c05cef23881:group-5322F5BD3A50 changes to CANDIDATE, lastRpcTime:5055, electionTimeout:5055ms
2019-09-28 02:09:27,337 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown FollowerState
2019-09-28 02:09:27,337 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:27,338 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start LeaderElection
2019-09-28 02:09:27,348 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/fd6cfe45-0532-4c17-b0d4-46dfca849a1b/current/log_inprogress_0
2019-09-28 02:09:27,348 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/9358a96e-5e2a-458a-bf38-93701dfb6de1/current/log_inprogress_0
2019-09-28 02:09:27,348 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50/current/log_inprogress_0
2019-09-28 02:09:27,348 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/5b57393a-6749-45a5-82a4-72990c26929c/current/log_inprogress_0
2019-09-28 02:09:27,359 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(106)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9:group-5322F5BD3A50 changes to CANDIDATE, lastRpcTime:5077, electionTimeout:5077ms
2019-09-28 02:09:27,360 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown FollowerState
2019-09-28 02:09:27,360 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:27,360 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start LeaderElection
2019-09-28 02:09:27,365 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5: begin an election at term 1 for -1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:27,377 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6: begin an election at term 1 for -1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:27,391 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4e67c2bc-71aa-46f5-8494-d6c845463647:group-5322F5BD3A50 changes to CANDIDATE, lastRpcTime:5108, electionTimeout:5106ms
2019-09-28 02:09:27,393 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown FollowerState
2019-09-28 02:09:27,393 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:09:27,393 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start LeaderElection
2019-09-28 02:09:27,410 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7: begin an election at term 1 for -1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:27,425 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:27,437 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6: Election REJECTED; received 2 response(s) [e21f0720-4123-4e8e-bf33-dad5acb3b0a9<-4e67c2bc-71aa-46f5-8494-d6c845463647#0:FAIL-t1, e21f0720-4123-4e8e-bf33-dad5acb3b0a9<-fa66c997-38d4-4d58-8ea9-4c05cef23881#0:FAIL-t1] and 0 exception(s); e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:t1, leader=null, voted=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, raftlog=e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:27,438 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5: Election REJECTED; received 2 response(s) [fa66c997-38d4-4d58-8ea9-4c05cef23881<-e21f0720-4123-4e8e-bf33-dad5acb3b0a9#0:FAIL-t1, fa66c997-38d4-4d58-8ea9-4c05cef23881<-4e67c2bc-71aa-46f5-8494-d6c845463647#0:FAIL-t1] and 0 exception(s); fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:t1, leader=null, voted=fa66c997-38d4-4d58-8ea9-4c05cef23881, raftlog=fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:27,440 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-28 02:09:27,442 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown LeaderElection
2019-09-28 02:09:27,444 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-28 02:09:27,445 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start FollowerState
2019-09-28 02:09:27,445 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown LeaderElection
2019-09-28 02:09:27,447 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start FollowerState
2019-09-28 02:09:27,462 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7: Election REJECTED; received 2 response(s) [4e67c2bc-71aa-46f5-8494-d6c845463647<-e21f0720-4123-4e8e-bf33-dad5acb3b0a9#0:FAIL-t1, 4e67c2bc-71aa-46f5-8494-d6c845463647<-fa66c997-38d4-4d58-8ea9-4c05cef23881#0:FAIL-t1] and 0 exception(s); 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:t1, leader=null, voted=4e67c2bc-71aa-46f5-8494-d6c845463647, raftlog=4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:27,462 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-28 02:09:27,464 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown LeaderElection
2019-09-28 02:09:27,465 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start FollowerState
2019-09-28 02:09:28,161 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:28,432 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:29,434 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:30,164 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:30,435 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:31,436 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:32,164 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:32,438 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:32,553 [Thread-234] INFO  impl.FollowerState (FollowerState.java:run(106)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9:group-5322F5BD3A50 changes to CANDIDATE, lastRpcTime:5107, electionTimeout:5106ms
2019-09-28 02:09:32,553 [Thread-234] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown FollowerState
2019-09-28 02:09:32,553 [Thread-234] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-28 02:09:32,554 [Thread-234] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start LeaderElection
2019-09-28 02:09:32,579 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8: begin an election at term 2 for -1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:32,588 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:09:32,588 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:09:32,588 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown FollowerState
2019-09-28 02:09:32,588 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown FollowerState
2019-09-28 02:09:32,589 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: start FollowerState
2019-09-28 02:09:32,589 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(115)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:09:32,589 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start FollowerState
2019-09-28 02:09:32,589 [Thread-235] INFO  impl.FollowerState (FollowerState.java:run(115)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:09:32,607 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8: Election PASSED; received 1 response(s) [e21f0720-4123-4e8e-bf33-dad5acb3b0a9<-fa66c997-38d4-4d58-8ea9-4c05cef23881#0:OK-t2] and 0 exception(s); e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:t2, leader=null, voted=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, raftlog=e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null
2019-09-28 02:09:32,608 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown LeaderElection
2019-09-28 02:09:32,609 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-28 02:09:32,609 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: change Leader from null to e21f0720-4123-4e8e-bf33-dad5acb3b0a9 at term 2 for becomeLeader, leader elected after 10346ms
2019-09-28 02:09:32,610 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:09:32,610 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:09:32,610 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:09:32,610 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:09:32,611 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:09:32,611 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:09:32,618 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 02:09:32,619 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:32,619 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 02:09:32,625 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 02:09:32,625 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:09:32,625 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:32,627 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 02:09:32,627 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:09:32,627 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 02:09:32,627 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 02:09:32,628 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:09:32,628 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:09:32,632 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start LeaderState
2019-09-28 02:09:32,633 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:32,634 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: set configuration 0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null at 0
2019-09-28 02:09:32,679 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50/current/log_inprogress_0
2019-09-28 02:09:32,713 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: change Leader from null to e21f0720-4123-4e8e-bf33-dad5acb3b0a9 at term 2 for appendEntries, leader elected after 10450ms
2019-09-28 02:09:32,713 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: change Leader from null to e21f0720-4123-4e8e-bf33-dad5acb3b0a9 at term 2 for appendEntries, leader elected after 10450ms
2019-09-28 02:09:32,752 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: set configuration 0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null at 0
2019-09-28 02:09:32,752 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: set configuration 0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null at 0
2019-09-28 02:09:32,752 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:32,753 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:09:32,803 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50/current/log_inprogress_0
2019-09-28 02:09:32,803 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/7579321f-16b1-4fa1-846f-5322f5bd3a50/current/log_inprogress_0
2019-09-28 02:09:33,444 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:34,165 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:34,446 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:35,447 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:36,165 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:36,449 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:37,450 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:38,166 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:38,451 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:39,452 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:40,166 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:40,454 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:41,455 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:42,167 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:42,456 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:42,458 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-28 02:09:43,459 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:44,167 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:44,461 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:45,462 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:46,168 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:46,464 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:47,465 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:48,169 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:48,466 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:49,467 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:50,169 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:50,468 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:51,470 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:52,170 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:52,471 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:52,473 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-28 02:09:53,474 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:54,170 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:54,475 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:55,477 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:56,171 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:56,478 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:57,479 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:58,171 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:09:58,481 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:59,482 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:00,172 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:00,483 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:01,484 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:02,172 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:02,485 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:02,487 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-28 02:10:03,488 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:04,173 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:04,490 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:05,491 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:06,173 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:06,493 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:07,495 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:08,174 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:08,496 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:09,497 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:10,175 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:10,499 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:11,500 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:12,175 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:12,501 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:12,503 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-28 02:10:13,504 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:14,176 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:14,505 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:15,507 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:16,176 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:16,508 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:17,510 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:18,177 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:18,511 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:19,512 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:20,177 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:20,513 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:21,514 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:22,178 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:22,516 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:22,517 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-28 02:10:23,518 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:24,178 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:24,519 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:25,521 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:26,179 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:26,522 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:27,523 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:28,179 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:28,524 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:29,526 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:30,180 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:30,527 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:31,528 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:32,181 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:32,530 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:32,533 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-28 02:10:33,535 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:34,181 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:34,537 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:35,538 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:36,182 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:36,539 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:37,540 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:38,182 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:38,542 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:39,543 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:40,183 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:40,544 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:41,546 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:42,183 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:42,547 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:42,549 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-28 02:10:43,550 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:44,184 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:44,552 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:45,553 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:46,184 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:46,555 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:47,556 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:48,185 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:48,557 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:49,559 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:50,185 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:50,560 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:51,562 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:52,186 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:52,563 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:52,565 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-28 02:10:53,566 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:54,187 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:54,568 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:55,569 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:56,187 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:56,570 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:57,571 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:58,188 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:10:58,573 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:10:59,574 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:00,188 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:00,576 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:01,577 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:02,189 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:02,578 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:02,580 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-28 02:11:03,581 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:04,189 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:04,582 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:05,585 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:06,190 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:06,586 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:07,588 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:08,191 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:08,589 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:09,590 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:10,191 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:10,591 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:11,593 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:12,192 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:12,594 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:11:12,596 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-28 02:11:12,600 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestContainerReplicationEndToEnd.init(TestContainerReplicationEndToEnd.java:110)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-28 02:11:12,605 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-28 02:11:12,606 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-28 02:11:12,607 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-28 02:11:12,607 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38502
2019-09-28 02:11:12,616 [IPC Server listener on 38502] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38502
2019-09-28 02:11:12,619 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-28 02:11:12,622 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:11:12,632 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-28 02:11:12,648 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-28 02:11:12,654 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1ecfcbc9{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-28 02:11:12,661 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1965539b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:11:12,662 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67001148{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-28 02:11:12,662 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4cafa9aa{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:11:12,667 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-28 02:11:12,708 [Datanode ReportManager Thread - 3] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(50)) - Execution exception when running task in Datanode ReportManager Thread - 3
2019-09-28 02:11:12,709 [Datanode ReportManager Thread - 3] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread Datanode ReportManager Thread - 3: 
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@584e84ac rejected from org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor@568961d5[Shutting down, pool size = 4, active threads = 1, queued tasks = 3, completed tasks = 45]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.hadoop.ozone.container.common.report.ReportPublisher.run(ReportPublisher.java:76)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 02:11:12,832 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:11:14,192 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:14,679 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=5b57393a-6749-45a5-82a4-72990c26929c, PipelineID=7579321f-16b1-4fa1-846f-5322f5bd3a50]
2019-09-28 02:11:14,680 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 5b57393a-6749-45a5-82a4-72990c26929c, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:11:15,048 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 5b57393a-6749-45a5-82a4-72990c26929c, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:11:15,052 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 7579321f-16b1-4fa1-846f-5322f5bd3a50, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 02:11:15,052 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 7579321f-16b1-4fa1-846f-5322f5bd3a50, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-09-28 02:11:16,193 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:16,656 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 5b57393a-6749-45a5-82a4-72990c26929c, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-28 02:11:16,684 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: remove    LEADER fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C:t1, leader=fa66c997-38d4-4d58-8ea9-4c05cef23881, voted=fa66c997-38d4-4d58-8ea9-4c05cef23881, raftlog=fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null RUNNING
2019-09-28 02:11:16,689 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: shutdown
2019-09-28 02:11:16,689 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-72990C26929C,id=fa66c997-38d4-4d58-8ea9-4c05cef23881
2019-09-28 02:11:16,689 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown LeaderState
2019-09-28 02:11:16,690 [grpc-default-executor-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - fa66c997-38d4-4d58-8ea9-4c05cef23881-PendingRequests: sendNotLeaderResponses
2019-09-28 02:11:16,693 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:16,695 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C: closes. applyIndex: 0
2019-09-28 02:11:16,698 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:16,700 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-72990C26929C-SegmentedRaftLogWorker close()
2019-09-28 02:11:16,718 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: 5b57393a-6749-45a5-82a4-72990c26929c, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-28 02:11:16,718 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 7579321f-16b1-4fa1-846f-5322f5bd3a50, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-28 02:11:16,745 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: addNew group-6E0B5BAE2BF5:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] returns group-6E0B5BAE2BF5:java.util.concurrent.CompletableFuture@4e3954a4[Not completed]
2019-09-28 02:11:16,745 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: addNew group-6E0B5BAE2BF5:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] returns group-6E0B5BAE2BF5:java.util.concurrent.CompletableFuture@105ad877[Not completed]
2019-09-28 02:11:16,745 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: addNew group-6E0B5BAE2BF5:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] returns group-6E0B5BAE2BF5:java.util.concurrent.CompletableFuture@340d68fc[Not completed]
2019-09-28 02:11:16,749 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: new RaftServerImpl for group-6E0B5BAE2BF5:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] with ContainerStateMachine:uninitialized
2019-09-28 02:11:16,749 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:11:16,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:11:16,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:11:16,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:11:16,750 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:11:16,750 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null, confs=<EMPTY_MAP>
2019-09-28 02:11:16,750 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: new RaftServerImpl for group-6E0B5BAE2BF5:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] with ContainerStateMachine:uninitialized
2019-09-28 02:11:16,751 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis] (custom)
2019-09-28 02:11:16,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:11:16,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:11:16,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:11:16,751 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: new RaftServerImpl for group-6E0B5BAE2BF5:[e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534] with ContainerStateMachine:uninitialized
2019-09-28 02:11:16,751 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 does not exist. Creating ...
2019-09-28 02:11:16,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:11:16,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:11:16,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:11:16,752 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:11:16,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-28 02:11:16,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:11:16,752 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null, confs=<EMPTY_MAP>
2019-09-28 02:11:16,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:11:16,753 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis] (custom)
2019-09-28 02:11:16,753 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5: ConfigurationManager, init=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null, confs=<EMPTY_MAP>
2019-09-28 02:11:16,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis] (custom)
2019-09-28 02:11:16,753 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 does not exist. Creating ...
2019-09-28 02:11:16,754 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 does not exist. Creating ...
2019-09-28 02:11:16,777 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:11:16,777 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:11:16,777 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5/in_use.lock acquired by nodename 4617@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:11:16,803 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 has been successfully formatted.
2019-09-28 02:11:16,803 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 has been successfully formatted.
2019-09-28 02:11:16,803 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 has been successfully formatted.
2019-09-28 02:11:16,803 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6E0B5BAE2BF5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:11:16,804 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6E0B5BAE2BF5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:11:16,804 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:11:16,804 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6E0B5BAE2BF5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:11:16,804 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:11:16,804 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:11:16,804 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:11:16,804 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-28 02:11:16,804 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:11:16,804 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:11:16,805 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:11:16,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:11:16,805 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:11:16,805 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:11:16,805 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5
2019-09-28 02:11:16,805 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:11:16,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:11:16,805 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:11:16,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:11:16,806 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:11:16,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:11:16,806 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:11:16,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:11:16,806 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:11:16,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:11:16,806 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:11:16,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:11:16,807 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:11:16,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:11:16,807 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5
2019-09-28 02:11:16,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:11:16,807 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/ratis/04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5
2019-09-28 02:11:16,808 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:11:16,807 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:11:16,808 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:11:16,808 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:11:16,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:11:16,808 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:11:16,808 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:11:16,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:11:16,809 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:11:16,809 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:11:16,809 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:11:16,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:11:16,809 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:11:16,809 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:11:16,810 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:11:16,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:11:16,810 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:11:16,810 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:11:16,810 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:11:16,810 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:11:16,810 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:11:16,811 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:11:16,811 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:11:16,811 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:11:16,811 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:11:16,811 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:11:16,812 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:11:16,812 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:11:16,812 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:11:16,812 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:11:16,812 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:11:16,812 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:11:16,813 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:11:16,813 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:11:16,813 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null
2019-09-28 02:11:16,813 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:11:16,813 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:11:16,813 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:11:16,813 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:11:16,814 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: start FollowerState
2019-09-28 02:11:16,814 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E0B5BAE2BF5,id=e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:11:16,824 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null
2019-09-28 02:11:16,824 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:11:16,824 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5: start as a follower, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null
2019-09-28 02:11:16,825 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: start FollowerState
2019-09-28 02:11:16,825 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:11:16,825 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: start FollowerState
2019-09-28 02:11:16,825 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E0B5BAE2BF5,id=0a1853ed-2cd6-48ad-95fc-455668814edb
2019-09-28 02:11:16,826 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E0B5BAE2BF5,id=4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:11:16,839 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 02:11:16,857 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: remove  FOLLOWER fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50:t2, leader=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, voted=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, raftlog=fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null RUNNING
2019-09-28 02:11:16,857 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: shutdown
2019-09-28 02:11:16,857 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5322F5BD3A50,id=fa66c997-38d4-4d58-8ea9-4c05cef23881
2019-09-28 02:11:16,857 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown FollowerState
2019-09-28 02:11:16,857 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:16,859 [Thread-241] INFO  impl.FollowerState (FollowerState.java:run(115)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:11:16,861 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50: closes. applyIndex: 0
2019-09-28 02:11:16,861 [fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:16,863 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - fa66c997-38d4-4d58-8ea9-4c05cef23881@group-5322F5BD3A50-SegmentedRaftLogWorker close()
2019-09-28 02:11:16,879 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: remove  FOLLOWER 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50:t2, leader=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, voted=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, raftlog=4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null RUNNING
2019-09-28 02:11:16,880 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: shutdown
2019-09-28 02:11:16,880 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5322F5BD3A50,id=4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:11:16,880 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown FollowerState
2019-09-28 02:11:16,880 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:16,880 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(115)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:11:16,882 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50: closes. applyIndex: 0
2019-09-28 02:11:16,882 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:16,883 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-5322F5BD3A50-SegmentedRaftLogWorker close()
2019-09-28 02:11:16,905 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: remove    LEADER e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50:t2, leader=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, voted=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, raftlog=e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, fa66c997-38d4-4d58-8ea9-4c05cef23881:192.168.151.82:43745], old=null RUNNING
2019-09-28 02:11:16,905 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: shutdown
2019-09-28 02:11:16,905 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5322F5BD3A50,id=e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:11:16,906 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown LeaderState
2019-09-28 02:11:16,908 [grpc-default-executor-3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9-PendingRequests: sendNotLeaderResponses
2019-09-28 02:11:16,909 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$478/1557709855@2817fa2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50->4e67c2bc-71aa-46f5-8494-d6c845463647-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 02:11:16,911 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:16,909 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$478/1557709855@50acf2be] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50->fa66c997-38d4-4d58-8ea9-4c05cef23881-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 02:11:16,915 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50: closes. applyIndex: 0
2019-09-28 02:11:16,916 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:16,917 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50-SegmentedRaftLogWorker close()
2019-09-28 02:11:16,921 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: Completed APPEND_ENTRIES, lastRequest: e21f0720-4123-4e8e-bf33-dad5acb3b0a9->4e67c2bc-71aa-46f5-8494-d6c845463647#42-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 02:11:16,921 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: Completed APPEND_ENTRIES, lastRequest: e21f0720-4123-4e8e-bf33-dad5acb3b0a9->fa66c997-38d4-4d58-8ea9-4c05cef23881#42-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 02:11:16,928 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50->4e67c2bc-71aa-46f5-8494-d6c845463647-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 02:11:16,936 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50->fa66c997-38d4-4d58-8ea9-4c05cef23881-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 02:11:16,939 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: 7579321f-16b1-4fa1-846f-5322f5bd3a50, Nodes: fa66c997-38d4-4d58-8ea9-4c05cef23881{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] removed from db
2019-09-28 02:11:16,939 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50->4e67c2bc-71aa-46f5-8494-d6c845463647: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 02:11:16,939 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-5322F5BD3A50->fa66c997-38d4-4d58-8ea9-4c05cef23881: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 02:11:16,990 [Datanode ReportManager Thread - 1] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(50)) - Execution exception when running task in Datanode ReportManager Thread - 1
2019-09-28 02:11:16,990 [Datanode ReportManager Thread - 1] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread Datanode ReportManager Thread - 1: 
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5c82e85b rejected from org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor@568961d5[Shutting down, pool size = 4, active threads = 1, queued tasks = 2, completed tasks = 46]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.hadoop.ozone.container.common.report.ReportPublisher.run(ReportPublisher.java:76)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 02:11:16,991 [Datanode ReportManager Thread - 1] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(50)) - Execution exception when running task in Datanode ReportManager Thread - 1
2019-09-28 02:11:16,991 [Datanode ReportManager Thread - 1] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread Datanode ReportManager Thread - 1: 
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@567a832b rejected from org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor@568961d5[Shutting down, pool size = 4, active threads = 1, queued tasks = 1, completed tasks = 47]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.hadoop.ozone.container.common.report.ReportPublisher.run(ReportPublisher.java:76)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 02:11:17,669 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:11:17,672 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:11:17,672 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:11:17,673 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: close
2019-09-28 02:11:17,673 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: close
2019-09-28 02:11:17,676 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: shutdown
2019-09-28 02:11:17,676 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-93701DFB6DE1,id=0a1853ed-2cd6-48ad-95fc-455668814edb
2019-09-28 02:11:17,676 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown server with port 43745 now
2019-09-28 02:11:17,676 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: shutdown LeaderState
2019-09-28 02:11:17,677 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0a1853ed-2cd6-48ad-95fc-455668814edb-PendingRequests: sendNotLeaderResponses
2019-09-28 02:11:17,678 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:17,679 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1: closes. applyIndex: 0
2019-09-28 02:11:17,683 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:17,686 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-93701DFB6DE1-SegmentedRaftLogWorker close()
2019-09-28 02:11:17,689 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5: shutdown
2019-09-28 02:11:17,689 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E0B5BAE2BF5,id=0a1853ed-2cd6-48ad-95fc-455668814edb
2019-09-28 02:11:17,689 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: shutdown FollowerState
2019-09-28 02:11:17,689 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - fa66c997-38d4-4d58-8ea9-4c05cef23881: shutdown server with port 43745 successfully
2019-09-28 02:11:17,690 [Thread-356] INFO  impl.FollowerState (FollowerState.java:run(115)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:11:17,690 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5-StateMachineUpdater: set stopIndex = -1
2019-09-28 02:11:17,693 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5: closes. applyIndex: -1
2019-09-28 02:11:17,693 [0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:17,694 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0a1853ed-2cd6-48ad-95fc-455668814edb@group-6E0B5BAE2BF5-SegmentedRaftLogWorker close()
2019-09-28 02:11:17,697 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: shutdown server with port 35534 now
2019-09-28 02:11:17,698 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0a1853ed-2cd6-48ad-95fc-455668814edb: shutdown server with port 35534 successfully
2019-09-28 02:11:17,702 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:11:17,702 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:11:17,733 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:11:17,734 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:11:17,738 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:11:17,740 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:11:17,744 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b350309{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:11:17,745 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@53e800f9{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:11:17,746 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@337bbfdf{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:11:17,746 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7ecec90d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:11:17,748 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c27a3a2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:11:17,748 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7100dea{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:11:17,749 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5460b754{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:11:17,750 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d21c56e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:11:17,857 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:11:17,857 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:11:18,195 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:19,661 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50, PipelineID=04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5]
2019-09-28 02:11:19,661 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:11:19,661 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:11:19,662 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 02:11:19,662 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-09-28 02:11:19,662 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, PipelineID=fd6cfe45-0532-4c17-b0d4-46dfca849a1b]
2019-09-28 02:11:19,662 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-28 02:11:19,663 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: fd6cfe45-0532-4c17-b0d4-46dfca849a1b, Nodes: e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:11:19,663 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: fd6cfe45-0532-4c17-b0d4-46dfca849a1b, Nodes: e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:11:19,663 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=9358a96e-5e2a-458a-bf38-93701dfb6de1, PipelineID=04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5]
2019-09-28 02:11:19,663 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 9358a96e-5e2a-458a-bf38-93701dfb6de1, Nodes: 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:11:19,663 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 9358a96e-5e2a-458a-bf38-93701dfb6de1, Nodes: 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:11:19,663 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-28 02:11:20,196 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:21,665 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-28 02:11:21,681 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: remove    LEADER 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50:t1, leader=4e67c2bc-71aa-46f5-8494-d6c845463647, voted=4e67c2bc-71aa-46f5-8494-d6c845463647, raftlog=4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340], old=null RUNNING
2019-09-28 02:11:21,682 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: shutdown
2019-09-28 02:11:21,682 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9F2E9E7A0C50,id=4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:11:21,682 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown LeaderState
2019-09-28 02:11:21,683 [grpc-default-executor-4] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4e67c2bc-71aa-46f5-8494-d6c845463647-PendingRequests: sendNotLeaderResponses
2019-09-28 02:11:21,683 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:21,684 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50: closes. applyIndex: 0
2019-09-28 02:11:21,684 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:21,685 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-9F2E9E7A0C50-SegmentedRaftLogWorker close()
2019-09-28 02:11:21,695 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: c5bb1f3f-eaf7-4b12-9656-9f2e9e7a0c50, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-28 02:11:21,696 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-28 02:11:21,708 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: remove  FOLLOWER 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5:t0, leader=null, voted=null, raftlog=4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null RUNNING
2019-09-28 02:11:21,708 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5: shutdown
2019-09-28 02:11:21,709 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E0B5BAE2BF5,id=4e67c2bc-71aa-46f5-8494-d6c845463647
2019-09-28 02:11:21,709 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown FollowerState
2019-09-28 02:11:21,709 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-StateMachineUpdater: set stopIndex = -1
2019-09-28 02:11:21,709 [Thread-357] INFO  impl.FollowerState (FollowerState.java:run(115)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:11:21,712 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5: closes. applyIndex: -1
2019-09-28 02:11:21,712 [4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:21,712 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4e67c2bc-71aa-46f5-8494-d6c845463647@group-6E0B5BAE2BF5-SegmentedRaftLogWorker close()
2019-09-28 02:11:21,737 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: remove  FOLLOWER e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5:t0, leader=null, voted=null, raftlog=e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709, 4e67c2bc-71aa-46f5-8494-d6c845463647:192.168.151.82:46340, 0a1853ed-2cd6-48ad-95fc-455668814edb:192.168.151.82:35534], old=null RUNNING
2019-09-28 02:11:21,738 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5: shutdown
2019-09-28 02:11:21,738 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E0B5BAE2BF5,id=e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:11:21,739 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown FollowerState
2019-09-28 02:11:21,739 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-StateMachineUpdater: set stopIndex = -1
2019-09-28 02:11:21,739 [Thread-354] INFO  impl.FollowerState (FollowerState.java:run(115)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:11:21,739 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5: closes. applyIndex: -1
2019-09-28 02:11:21,742 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:21,742 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-6E0B5BAE2BF5-SegmentedRaftLogWorker close()
2019-09-28 02:11:21,772 [EventQueue-DeadNodeForDeadNodeHandler] WARN  pipeline.RatisPipelineUtils (RatisPipelineUtils.java:destroyPipeline(67)) - Pipeline destroy failed for pipeline=PipelineID=04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5 dn=0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:11:21,773 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: 04b3f960-bf6b-4d1b-b0d4-6e0b5bae2bf5, Nodes: 4e67c2bc-71aa-46f5-8494-d6c845463647{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] removed from db
2019-09-28 02:11:21,774 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: fd6cfe45-0532-4c17-b0d4-46dfca849a1b, Nodes: e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-28 02:11:21,786 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: remove    LEADER e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B:t1, leader=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, voted=e21f0720-4123-4e8e-bf33-dad5acb3b0a9, raftlog=e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [e21f0720-4123-4e8e-bf33-dad5acb3b0a9:192.168.151.82:34709], old=null RUNNING
2019-09-28 02:11:21,787 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: shutdown
2019-09-28 02:11:21,787 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-46DFCA849A1B,id=e21f0720-4123-4e8e-bf33-dad5acb3b0a9
2019-09-28 02:11:21,787 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown LeaderState
2019-09-28 02:11:21,788 [grpc-default-executor-4] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9-PendingRequests: sendNotLeaderResponses
2019-09-28 02:11:21,788 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:11:21,789 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B: closes. applyIndex: 0
2019-09-28 02:11:21,789 [e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:11:21,790 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9@group-46DFCA849A1B-SegmentedRaftLogWorker close()
2019-09-28 02:11:21,800 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: fd6cfe45-0532-4c17-b0d4-46dfca849a1b, Nodes: e21f0720-4123-4e8e-bf33-dad5acb3b0a9{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-28 02:11:21,801 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 9358a96e-5e2a-458a-bf38-93701dfb6de1, Nodes: 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED]
2019-09-28 02:11:21,814 [EventQueue-DeadNodeForDeadNodeHandler] WARN  pipeline.RatisPipelineUtils (RatisPipelineUtils.java:destroyPipeline(67)) - Pipeline destroy failed for pipeline=PipelineID=9358a96e-5e2a-458a-bf38-93701dfb6de1 dn=0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:11:21,814 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(108)) - Pipeline Pipeline[ Id: 9358a96e-5e2a-458a-bf38-93701dfb6de1, Nodes: 0a1853ed-2cd6-48ad-95fc-455668814edb{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-09-28 02:11:22,198 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-28 02:11:22,752 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:11:22,752 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:11:22,753 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: close
2019-09-28 02:11:22,754 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: close
2019-09-28 02:11:22,754 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown server with port 34709 now
2019-09-28 02:11:22,754 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown server with port 46340 now
2019-09-28 02:11:22,758 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 4e67c2bc-71aa-46f5-8494-d6c845463647: shutdown server with port 46340 successfully
2019-09-28 02:11:22,759 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - e21f0720-4123-4e8e-bf33-dad5acb3b0a9: shutdown server with port 34709 successfully
2019-09-28 02:11:22,762 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:11:22,780 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d824f040-4912-421b-9821-2c89c25a3165/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:11:22,792 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:11:22,794 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:11:22,798 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f5ac102{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:11:22,799 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5df778c3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:11:22,800 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2643d762{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:11:22,801 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@252dc8c4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:11:22,803 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:11:22,805 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:11:22,806 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56dfab87{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:11:22,807 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@715b886f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:11:22,807 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4c1bdcc2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:11:22,807 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1305c126{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:11:22,808 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-28 02:11:22,808 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-28 02:11:22,809 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-28 02:11:22,809 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-28 02:11:22,809 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-28 02:11:22,809 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-28 02:11:22,809 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46505
2019-09-28 02:11:22,811 [IPC Server listener on 46505] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46505
2019-09-28 02:11:22,811 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:11:22,867 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-28 02:11:22,868 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-28 02:11:22,868 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-28 02:11:22,868 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45306
2019-09-28 02:11:22,871 [IPC Server listener on 45306] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45306
2019-09-28 02:11:22,871 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-28 02:11:22,871 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(158)) - Stopping the RPC server for Client Protocol
2019-09-28 02:11:22,871 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:11:22,872 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42345
2019-09-28 02:11:22,874 [IPC Server listener on 42345] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42345
2019-09-28 02:11:22,875 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-28 02:11:22,875 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:11:22,876 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3574e198{/,null,UNAVAILABLE}{/scm}
2019-09-28 02:11:22,877 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3aa3193a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:11:22,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4aa83f4f{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-28 02:11:22,878 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@615091b8{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:11:22,879 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-28 02:11:22,879 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 02:11:22,880 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 02:11:22,881 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-28 02:11:22,891 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-28 02:11:22,900 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-28 02:11:22,900 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
