2019-09-28 02:07:00,605 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:00,706 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:00,710 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:00,729 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @996ms
2019-09-28 02:07:00,861 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-28 02:07:00,862 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-28 02:07:00,862 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-28 02:07:00,863 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-28 02:07:00,863 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-28 02:07:00,863 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-28 02:07:00,878 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 02:07:00,878 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 02:07:00,879 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 02:07:01,218 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@a1153bc
2019-09-28 02:07:01,221 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-28 02:07:01,320 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-28 02:07:01,396 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-28 02:07:01,410 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:01,502 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-28 02:07:01,505 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:01,650 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-28 02:07:02,117 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:07:02,149 [Socket Reader #1 for port 41879] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41879
2019-09-28 02:07:02,329 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:07:02,330 [Socket Reader #1 for port 45546] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45546
2019-09-28 02:07:02,343 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:07:02,344 [Socket Reader #1 for port 37021] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37021
2019-09-28 02:07:02,374 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-28 02:07:02,547 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:07:02,555 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:07:02,563 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:07:02,566 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-28 02:07:02,567 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:07:02,567 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:07:02,599 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37021
2019-09-28 02:07:02,680 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-28 02:07:02,701 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-28 02:07:02,702 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-28 02:07:02,950 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(150)) - RPC server for Client  is listening at /0.0.0.0:37021
2019-09-28 02:07:02,951 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:07:02,951 [IPC Server listener on 37021] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37021: starting
2019-09-28 02:07:02,954 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45546
2019-09-28 02:07:02,956 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45546
2019-09-28 02:07:02,956 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:07:02,957 [IPC Server listener on 45546] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45546: starting
2019-09-28 02:07:02,959 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41879
2019-09-28 02:07:02,960 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:41879
2019-09-28 02:07:02,960 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:07:02,960 [IPC Server listener on 41879] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41879: starting
2019-09-28 02:07:02,964 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40055
2019-09-28 02:07:02,966 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:07:03,005 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64ba3208{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:07:03,005 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25a6944c{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-28 02:07:03,039 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cc5b667{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-28 02:07:03,045 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4eeea57d{HTTP/1.1,[http/1.1]}{0.0.0.0:40055}
2019-09-28 02:07:03,046 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3313ms
2019-09-28 02:07:03,048 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-28 02:07:03,048 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-28 02:07:03,050 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:40055
2019-09-28 02:07:03,057 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d6300e8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:07:03,062 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:03,174 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-28 02:07:03,174 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-28 02:07:03,176 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:03,176 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:03,960 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 02:07:03,969 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-28 02:07:03,969 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-28 02:07:03,969 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-28 02:07:03,969 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-28 02:07:03,970 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-28 02:07:03,970 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-28 02:07:03,970 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-28 02:07:03,970 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-28 02:07:03,971 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-28 02:07:03,971 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-28 02:07:03,971 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-28 02:07:03,971 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-28 02:07:03,972 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-28 02:07:03,972 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-28 02:07:03,972 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-28 02:07:03,972 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-28 02:07:03,973 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-28 02:07:03,973 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-28 02:07:03,973 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-28 02:07:03,973 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-28 02:07:03,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-28 02:07:03,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-28 02:07:03,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 02:07:03,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 02:07:03,975 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 02:07:04,685 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 02:07:04,687 [Socket Reader #1 for port 43566] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43566
2019-09-28 02:07:04,720 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:43566
2019-09-28 02:07:04,720 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-28 02:07:04,723 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 02:07:04,723 [IPC Server listener on 43566] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43566: starting
2019-09-28 02:07:04,730 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-28 02:07:04,733 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:07:04,734 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:07:04,738 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:07:04,739 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-28 02:07:04,740 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:07:04,740 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:07:04,743 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37333
2019-09-28 02:07:04,744 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:07:04,747 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@629f066f{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:07:04,748 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ecfbe91{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-28 02:07:04,756 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7ca0863b{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-28 02:07:04,757 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@319854f0{HTTP/1.1,[http/1.1]}{0.0.0.0:37333}
2019-09-28 02:07:04,758 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5025ms
2019-09-28 02:07:04,758 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:07:04,760 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:37333
2019-09-28 02:07:05,082 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:07:05,128 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:07:05,160 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:07:05,162 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/containers/hdds to VolumeSet
2019-09-28 02:07:05,165 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5411dd90
2019-09-28 02:07:05,182 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5411dd90
2019-09-28 02:07:05,297 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:07:05,371 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:07:05,376 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:07:05,377 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:07:05,378 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:05,380 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:07:05,380 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:07:05,520 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis] (custom)
2019-09-28 02:07:05,596 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:07:05,597 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:07:05,598 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:07:05,599 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:07:05,600 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:07:05,600 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:07:05,600 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:07:05,601 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40608
2019-09-28 02:07:05,601 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:07:05,603 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d1dcdff{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:07:05,603 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ff35a3f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:07:05,631 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a66e580{/,file:///tmp/jetty-0.0.0.0-40608-hddsDatanode-_-any-6546115238133917852.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:07:05,631 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b852b49{HTTP/1.1,[http/1.1]}{0.0.0.0:40608}
2019-09-28 02:07:05,632 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5899ms
2019-09-28 02:07:05,633 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:07:05,634 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40608
2019-09-28 02:07:05,634 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:07:05,637 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:07:05,640 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@37dce947] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:07:05,645 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:07:05,646 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/containers/hdds to VolumeSet
2019-09-28 02:07:05,647 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-28 02:07:05,647 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-28 02:07:05,660 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:07:05,660 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:07:05,660 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:07:05,661 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:07:05,661 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:05,661 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:07:05,661 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:07:05,662 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis] (custom)
2019-09-28 02:07:05,663 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:07:05,664 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:07:05,665 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:07:05,667 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:07:05,667 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:07:05,667 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:07:05,668 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:07:05,668 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37214
2019-09-28 02:07:05,668 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:07:05,672 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:07:05,673 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:07:05,726 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7bc44ce8{/,file:///tmp/jetty-0.0.0.0-37214-hddsDatanode-_-any-4155344560321749706.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:07:05,728 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:37214}
2019-09-28 02:07:05,729 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5996ms
2019-09-28 02:07:05,729 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:07:05,730 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37214
2019-09-28 02:07:05,731 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 02:07:05,734 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 02:07:05,734 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54bb6258] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:07:05,743 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 02:07:05,743 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/containers/hdds to VolumeSet
2019-09-28 02:07:05,744 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-28 02:07:05,744 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-28 02:07:05,757 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 02:07:05,757 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 02:07:05,757 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 02:07:05,758 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 02:07:05,758 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:05,758 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 02:07:05,758 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:07:05,759 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis] (custom)
2019-09-28 02:07:05,762 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 02:07:05,764 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 02:07:05,764 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 02:07:05,767 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 02:07:05,767 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 02:07:05,768 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 02:07:05,768 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 02:07:05,769 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41823
2019-09-28 02:07:05,769 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 02:07:05,771 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-28 02:07:05,772 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 02:07:05,796 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/meta/datanode.id
2019-09-28 02:07:05,801 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/meta/datanode.id
2019-09-28 02:07:05,814 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5dd903be{/,file:///tmp/jetty-0.0.0.0-41823-hddsDatanode-_-any-7284316875602453847.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 02:07:05,816 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:41823}
2019-09-28 02:07:05,816 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6083ms
2019-09-28 02:07:05,817 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 02:07:05,818 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41823
2019-09-28 02:07:05,821 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 02:07:05,821 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23b8f0dd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 02:07:05,824 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/meta/datanode.id
2019-09-28 02:07:06,821 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 02:07:07,707 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:07:07,710 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:07:07,711 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis a29cdeed-39ec-4c05-b35f-1948c24ea295 at port 0
2019-09-28 02:07:07,742 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start RPC server
2019-09-28 02:07:07,752 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:07:07,758 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:07:07,758 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 199e213c-6e83-4a97-8b0b-f5c36d230e9b at port 0
2019-09-28 02:07:07,770 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: start RPC server
2019-09-28 02:07:07,822 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 02:07:07,838 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 02:07:07,845 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 02:07:07,846 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis c76e89fb-def7-4f42-8c4c-0f95fffa834b at port 0
2019-09-28 02:07:07,855 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start RPC server
2019-09-28 02:07:07,943 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: GrpcService started, listening on 0.0.0.0/0.0.0.0:33923
2019-09-28 02:07:07,943 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: GrpcService started, listening on 0.0.0.0/0.0.0.0:38401
2019-09-28 02:07:07,943 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: GrpcService started, listening on 0.0.0.0/0.0.0.0:46039
2019-09-28 02:07:07,945 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis a29cdeed-39ec-4c05-b35f-1948c24ea295 is started using port 38401
2019-09-28 02:07:07,945 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis c76e89fb-def7-4f42-8c4c-0f95fffa834b is started using port 33923
2019-09-28 02:07:07,945 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 199e213c-6e83-4a97-8b0b-f5c36d230e9b is started using port 46039
2019-09-28 02:07:07,952 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc a29cdeed-39ec-4c05-b35f-1948c24ea295 is started using port 42143
2019-09-28 02:07:07,952 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 199e213c-6e83-4a97-8b0b-f5c36d230e9b is started using port 42999
2019-09-28 02:07:07,952 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc c76e89fb-def7-4f42-8c4c-0f95fffa834b is started using port 32863
2019-09-28 02:07:08,824 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 02:07:09,690 [IPC Server handler 18 on 41879] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/a29cdeed-39ec-4c05-b35f-1948c24ea295
2019-09-28 02:07:09,691 [IPC Server handler 18 on 41879] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:07:09,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-28 02:07:09,697 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-28 02:07:09,697 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-28 02:07:09,738 [IPC Server handler 16 on 41879] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/199e213c-6e83-4a97-8b0b-f5c36d230e9b
2019-09-28 02:07:09,738 [IPC Server handler 16 on 41879] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:07:09,825 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-28 02:07:09,825 [IPC Server handler 17 on 41879] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c76e89fb-def7-4f42-8c4c-0f95fffa834b
2019-09-28 02:07:09,826 [IPC Server handler 17 on 41879] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 02:07:10,269 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: addNew group-0593AFE8EE3A:[a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401] returns group-0593AFE8EE3A:java.util.concurrent.CompletableFuture@537bcbf1[Not completed]
2019-09-28 02:07:10,290 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: new RaftServerImpl for group-0593AFE8EE3A:[a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401] with ContainerStateMachine:uninitialized
2019-09-28 02:07:10,293 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:07:10,294 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:07:10,294 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 02:07:10,295 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:07:10,297 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:10,306 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: ConfigurationManager, init=-1: [a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401], old=null, confs=<EMPTY_MAP>
2019-09-28 02:07:10,307 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis] (custom)
2019-09-28 02:07:10,316 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/dbbfefd0-7366-43bb-89e8-0593afe8ee3a does not exist. Creating ...
2019-09-28 02:07:10,334 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/dbbfefd0-7366-43bb-89e8-0593afe8ee3a/in_use.lock acquired by nodename 3791@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:07:10,350 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/dbbfefd0-7366-43bb-89e8-0593afe8ee3a has been successfully formatted.
2019-09-28 02:07:10,353 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0593AFE8EE3A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:07:10,353 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 02:07:10,356 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:07:10,363 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:07:10,363 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:10,366 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,372 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:07:10,378 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/dbbfefd0-7366-43bb-89e8-0593afe8ee3a
2019-09-28 02:07:10,384 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-28 02:07:10,391 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-28 02:07:10,422 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:07:10,423 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:07:10,426 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,426 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:07:10,427 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:07:10,427 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:07:10,428 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:07:10,429 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:07:10,429 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:07:10,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:07:10,442 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:07:10,446 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:07:10,447 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:07:10,447 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:07:10,448 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:07:10,473 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: start as a follower, conf=-1: [a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401], old=null
2019-09-28 02:07:10,474 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:07:10,475 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start FollowerState
2019-09-28 02:07:10,477 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0593AFE8EE3A,id=a29cdeed-39ec-4c05-b35f-1948c24ea295
2019-09-28 02:07:10,567 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: dbbfefd0-7366-43bb-89e8-0593afe8ee3a, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:07:10,592 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: addNew group-C134CFBADDC4:[199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] returns group-C134CFBADDC4:java.util.concurrent.CompletableFuture@66f69faf[Not completed]
2019-09-28 02:07:10,629 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: new RaftServerImpl for group-C134CFBADDC4:[199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] with ContainerStateMachine:uninitialized
2019-09-28 02:07:10,631 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:07:10,631 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:07:10,632 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 02:07:10,632 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:07:10,632 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:10,632 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: ConfigurationManager, init=-1: [199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null, confs=<EMPTY_MAP>
2019-09-28 02:07:10,633 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis] (custom)
2019-09-28 02:07:10,633 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/950d5557-ca67-4ccf-bbc4-c134cfbaddc4 does not exist. Creating ...
2019-09-28 02:07:10,659 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/950d5557-ca67-4ccf-bbc4-c134cfbaddc4/in_use.lock acquired by nodename 3791@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:07:10,673 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/950d5557-ca67-4ccf-bbc4-c134cfbaddc4 has been successfully formatted.
2019-09-28 02:07:10,675 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C134CFBADDC4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:07:10,676 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 02:07:10,677 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:07:10,677 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:07:10,677 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:10,678 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,678 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:07:10,678 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/950d5557-ca67-4ccf-bbc4-c134cfbaddc4
2019-09-28 02:07:10,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:07:10,688 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:07:10,689 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,689 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:07:10,689 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:07:10,690 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:07:10,690 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:07:10,690 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:07:10,690 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:07:10,691 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:07:10,692 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:07:10,692 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:07:10,693 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:07:10,693 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:07:10,693 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:07:10,700 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: start as a follower, conf=-1: [199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:10,700 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:07:10,701 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: start FollowerState
2019-09-28 02:07:10,702 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C134CFBADDC4,id=199e213c-6e83-4a97-8b0b-f5c36d230e9b
2019-09-28 02:07:10,718 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 950d5557-ca67-4ccf-bbc4-c134cfbaddc4, Nodes: 199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:07:10,743 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: addNew group-778FEBC75931:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923] returns group-778FEBC75931:java.util.concurrent.CompletableFuture@65aaebd2[Not completed]
2019-09-28 02:07:10,763 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: new RaftServerImpl for group-778FEBC75931:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923] with ContainerStateMachine:uninitialized
2019-09-28 02:07:10,764 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:07:10,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:07:10,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 02:07:10,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:07:10,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:10,765 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: ConfigurationManager, init=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923], old=null, confs=<EMPTY_MAP>
2019-09-28 02:07:10,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis] (custom)
2019-09-28 02:07:10,766 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/fbdd2465-8ee8-4e32-b4da-778febc75931 does not exist. Creating ...
2019-09-28 02:07:10,780 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/fbdd2465-8ee8-4e32-b4da-778febc75931/in_use.lock acquired by nodename 3791@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:07:10,793 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/fbdd2465-8ee8-4e32-b4da-778febc75931 has been successfully formatted.
2019-09-28 02:07:10,794 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-778FEBC75931: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:07:10,794 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 02:07:10,795 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:07:10,795 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:07:10,795 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:10,796 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,796 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:07:10,796 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/fbdd2465-8ee8-4e32-b4da-778febc75931
2019-09-28 02:07:10,822 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:07:10,822 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:07:10,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:07:10,823 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:07:10,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:07:10,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:07:10,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:07:10,824 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:07:10,825 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:07:10,826 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:07:10,826 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:07:10,826 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:07:10,827 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:07:10,827 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:07:10,833 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: start as a follower, conf=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923], old=null
2019-09-28 02:07:10,833 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:07:10,833 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start FollowerState
2019-09-28 02:07:10,834 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-778FEBC75931,id=c76e89fb-def7-4f42-8c4c-0f95fffa834b
2019-09-28 02:07:10,844 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fbdd2465-8ee8-4e32-b4da-778febc75931, Nodes: c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:07:10,875 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: addNew group-AAA329B7BD81:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] returns group-AAA329B7BD81:java.util.concurrent.CompletableFuture@6a783497[Not completed]
2019-09-28 02:07:10,876 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: addNew group-AAA329B7BD81:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] returns group-AAA329B7BD81:java.util.concurrent.CompletableFuture@196708c4[Not completed]
2019-09-28 02:07:10,877 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: addNew group-AAA329B7BD81:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] returns group-AAA329B7BD81:java.util.concurrent.CompletableFuture@2f7aa7bc[Not completed]
2019-09-28 02:07:10,878 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: new RaftServerImpl for group-AAA329B7BD81:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] with ContainerStateMachine:uninitialized
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: ConfigurationManager, init=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null, confs=<EMPTY_MAP>
2019-09-28 02:07:10,879 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis] (custom)
2019-09-28 02:07:10,879 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: new RaftServerImpl for group-AAA329B7BD81:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] with ContainerStateMachine:uninitialized
2019-09-28 02:07:10,880 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:07:10,880 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81 does not exist. Creating ...
2019-09-28 02:07:10,880 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:07:10,880 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 02:07:10,880 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:07:10,881 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:10,881 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: ConfigurationManager, init=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null, confs=<EMPTY_MAP>
2019-09-28 02:07:10,881 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: new RaftServerImpl for group-AAA329B7BD81:[c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039] with ContainerStateMachine:uninitialized
2019-09-28 02:07:10,881 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis] (custom)
2019-09-28 02:07:10,881 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 02:07:10,881 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 02:07:10,881 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81 does not exist. Creating ...
2019-09-28 02:07:10,882 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 02:07:10,882 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 02:07:10,882 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:10,882 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: ConfigurationManager, init=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null, confs=<EMPTY_MAP>
2019-09-28 02:07:10,883 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis] (custom)
2019-09-28 02:07:10,883 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81 does not exist. Creating ...
2019-09-28 02:07:10,894 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81/in_use.lock acquired by nodename 3791@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:07:10,894 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81/in_use.lock acquired by nodename 3791@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:07:10,894 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81/in_use.lock acquired by nodename 3791@pr-hdds-2162-8g7kw-3348123894
2019-09-28 02:07:10,907 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81 has been successfully formatted.
2019-09-28 02:07:10,907 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81 has been successfully formatted.
2019-09-28 02:07:10,907 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AAA329B7BD81: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:07:10,907 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81 has been successfully formatted.
2019-09-28 02:07:10,907 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AAA329B7BD81: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:07:10,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 02:07:10,908 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 02:07:10,908 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AAA329B7BD81: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 02:07:10,908 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:07:10,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:07:10,908 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:07:10,908 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 02:07:10,909 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:10,908 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:07:10,909 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,909 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 02:07:10,909 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:07:10,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:10,909 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81
2019-09-28 02:07:10,909 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 02:07:10,910 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:07:10,909 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,910 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:07:10,910 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:10,910 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,910 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:07:10,910 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:07:10,910 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,911 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:07:10,910 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81
2019-09-28 02:07:10,911 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:07:10,911 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 02:07:10,911 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:07:10,911 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:07:10,911 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:07:10,911 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81
2019-09-28 02:07:10,912 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:07:10,911 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:07:10,912 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 02:07:10,912 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,912 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:07:10,912 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:07:10,912 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 02:07:10,912 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:07:10,913 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 02:07:10,913 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:07:10,913 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 02:07:10,913 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:07:10,913 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:07:10,913 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 02:07:10,913 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:07:10,913 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:07:10,914 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:07:10,913 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 02:07:10,914 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:07:10,914 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 02:07:10,914 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:07:10,914 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 02:07:10,914 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:07:10,915 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 02:07:10,915 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:07:10,915 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 02:07:10,915 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:07:10,915 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 02:07:10,915 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:07:10,915 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:07:10,915 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 02:07:10,916 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:07:10,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 02:07:10,916 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:07:10,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 02:07:10,916 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 02:07:10,920 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: start as a follower, conf=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:10,920 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:07:10,920 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start FollowerState
2019-09-28 02:07:10,920 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: start as a follower, conf=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:10,921 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: start as a follower, conf=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:10,921 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:07:10,921 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 02:07:10,921 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start FollowerState
2019-09-28 02:07:10,921 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AAA329B7BD81,id=c76e89fb-def7-4f42-8c4c-0f95fffa834b
2019-09-28 02:07:10,921 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: start FollowerState
2019-09-28 02:07:10,921 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AAA329B7BD81,id=a29cdeed-39ec-4c05-b35f-1948c24ea295
2019-09-28 02:07:10,922 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AAA329B7BD81,id=199e213c-6e83-4a97-8b0b-f5c36d230e9b
2019-09-28 02:07:10,943 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1325fbdb-1f0d-4152-8b54-aaa329b7bd81, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 02:07:11,061 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:12,062 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:12,705 [Thread-178] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-28 02:07:12,709 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-28 02:07:13,064 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:14,065 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:15,067 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:15,633 [Thread-181] INFO  impl.FollowerState (FollowerState.java:run(106)) - a29cdeed-39ec-4c05-b35f-1948c24ea295:group-0593AFE8EE3A changes to CANDIDATE, lastRpcTime:5158, electionTimeout:5157ms
2019-09-28 02:07:15,635 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown FollowerState
2019-09-28 02:07:15,635 [Thread-181] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:07:15,641 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start LeaderElection
2019-09-28 02:07:15,659 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1: begin an election at term 1 for -1: [a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401], old=null
2019-09-28 02:07:15,661 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown LeaderElection
2019-09-28 02:07:15,662 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:07:15,662 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: change Leader from null to a29cdeed-39ec-4c05-b35f-1948c24ea295 at term 1 for becomeLeader, leader elected after 5309ms
2019-09-28 02:07:15,670 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:07:15,670 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:07:15,674 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:07:15,677 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:07:15,678 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:07:15,679 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:07:15,695 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start LeaderState
2019-09-28 02:07:15,724 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:07:15,734 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: set configuration 0: [a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401], old=null at 0
2019-09-28 02:07:15,839 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(106)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b:group-C134CFBADDC4 changes to CANDIDATE, lastRpcTime:5138, electionTimeout:5137ms
2019-09-28 02:07:15,842 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown FollowerState
2019-09-28 02:07:15,843 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:07:15,843 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: start LeaderElection
2019-09-28 02:07:15,860 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2: begin an election at term 1 for -1: [199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:15,861 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown LeaderElection
2019-09-28 02:07:15,861 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:07:15,861 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: change Leader from null to 199e213c-6e83-4a97-8b0b-f5c36d230e9b at term 1 for becomeLeader, leader elected after 5184ms
2019-09-28 02:07:15,861 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:07:15,861 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:07:15,862 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:07:15,862 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:07:15,862 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:07:15,862 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:07:15,868 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: start LeaderState
2019-09-28 02:07:15,868 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:07:15,869 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: set configuration 0: [199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null at 0
2019-09-28 02:07:15,929 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/950d5557-ca67-4ccf-bbc4-c134cfbaddc4/current/log_inprogress_0
2019-09-28 02:07:15,929 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/dbbfefd0-7366-43bb-89e8-0593afe8ee3a/current/log_inprogress_0
2019-09-28 02:07:15,930 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(106)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b:group-778FEBC75931 changes to CANDIDATE, lastRpcTime:5096, electionTimeout:5096ms
2019-09-28 02:07:15,930 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown FollowerState
2019-09-28 02:07:15,930 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:07:15,931 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start LeaderElection
2019-09-28 02:07:15,946 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3: begin an election at term 1 for -1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923], old=null
2019-09-28 02:07:15,947 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown LeaderElection
2019-09-28 02:07:15,947 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:07:15,947 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: change Leader from null to c76e89fb-def7-4f42-8c4c-0f95fffa834b at term 1 for becomeLeader, leader elected after 5153ms
2019-09-28 02:07:15,948 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:07:15,948 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:07:15,948 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:07:15,948 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:07:15,948 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:07:15,949 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:07:15,953 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start LeaderState
2019-09-28 02:07:15,953 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:07:15,953 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: set configuration 0: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923], old=null at 0
2019-09-28 02:07:15,993 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/fbdd2465-8ee8-4e32-b4da-778febc75931/current/log_inprogress_0
2019-09-28 02:07:15,993 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(106)) - a29cdeed-39ec-4c05-b35f-1948c24ea295:group-AAA329B7BD81 changes to CANDIDATE, lastRpcTime:5072, electionTimeout:5072ms
2019-09-28 02:07:15,994 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown FollowerState
2019-09-28 02:07:15,994 [Thread-193] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:07:15,995 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start LeaderElection
2019-09-28 02:07:16,006 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4: begin an election at term 1 for -1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:16,011 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(106)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b:group-AAA329B7BD81 changes to CANDIDATE, lastRpcTime:5090, electionTimeout:5090ms
2019-09-28 02:07:16,011 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown FollowerState
2019-09-28 02:07:16,011 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 02:07:16,012 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start LeaderElection
2019-09-28 02:07:16,027 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5: begin an election at term 1 for -1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:16,055 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:a29cdeed-39ec-4c05-b35f-1948c24ea295
2019-09-28 02:07:16,055 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown FollowerState
2019-09-28 02:07:16,055 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: start FollowerState
2019-09-28 02:07:16,057 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(115)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:07:16,070 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:16,094 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4: Election PASSED; received 2 response(s) [a29cdeed-39ec-4c05-b35f-1948c24ea295<-c76e89fb-def7-4f42-8c4c-0f95fffa834b#0:FAIL-t1, a29cdeed-39ec-4c05-b35f-1948c24ea295<-199e213c-6e83-4a97-8b0b-f5c36d230e9b#0:OK-t1] and 0 exception(s); a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:t1, leader=null, voted=a29cdeed-39ec-4c05-b35f-1948c24ea295, raftlog=a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:16,094 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5: Election REJECTED; received 2 response(s) [c76e89fb-def7-4f42-8c4c-0f95fffa834b<-a29cdeed-39ec-4c05-b35f-1948c24ea295#0:FAIL-t1, c76e89fb-def7-4f42-8c4c-0f95fffa834b<-199e213c-6e83-4a97-8b0b-f5c36d230e9b#0:FAIL-t1] and 0 exception(s); c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:t1, leader=null, voted=c76e89fb-def7-4f42-8c4c-0f95fffa834b, raftlog=c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null
2019-09-28 02:07:16,094 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown LeaderElection
2019-09-28 02:07:16,095 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 02:07:16,095 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: change Leader from null to a29cdeed-39ec-4c05-b35f-1948c24ea295 at term 1 for becomeLeader, leader elected after 5187ms
2019-09-28 02:07:16,095 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-28 02:07:16,097 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 02:07:16,099 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown LeaderElection
2019-09-28 02:07:16,099 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 02:07:16,100 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: start FollowerState
2019-09-28 02:07:16,100 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 02:07:16,100 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 02:07:16,101 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 02:07:16,101 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 02:07:16,106 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 02:07:16,106 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:16,107 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 02:07:16,110 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 02:07:16,115 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:07:16,115 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:16,116 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 02:07:16,116 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 02:07:16,117 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 02:07:16,117 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 02:07:16,117 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 02:07:16,117 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 02:07:16,121 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: start LeaderState
2019-09-28 02:07:16,121 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:07:16,123 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: set configuration 0: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null at 0
2019-09-28 02:07:16,173 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81/current/log_inprogress_0
2019-09-28 02:07:16,199 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: change Leader from null to a29cdeed-39ec-4c05-b35f-1948c24ea295 at term 1 for appendEntries, leader elected after 5291ms
2019-09-28 02:07:16,199 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: change Leader from null to a29cdeed-39ec-4c05-b35f-1948c24ea295 at term 1 for appendEntries, leader elected after 5290ms
2019-09-28 02:07:16,227 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: set configuration 0: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null at 0
2019-09-28 02:07:16,227 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: set configuration 0: [c76e89fb-def7-4f42-8c4c-0f95fffa834b:192.168.151.82:33923, a29cdeed-39ec-4c05-b35f-1948c24ea295:192.168.151.82:38401, 199e213c-6e83-4a97-8b0b-f5c36d230e9b:192.168.151.82:46039], old=null at 0
2019-09-28 02:07:16,227 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:07:16,227 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 02:07:16,273 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81/current/log_inprogress_0
2019-09-28 02:07:16,273 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/ratis/1325fbdb-1f0d-4152-8b54-aaa329b7bd81/current/log_inprogress_0
2019-09-28 02:07:17,071 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:18,072 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:19,074 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:20,075 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:21,082 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:22,085 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:23,086 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:24,087 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:25,089 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:26,090 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:27,092 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:28,093 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:29,095 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:30,096 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:30,099 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-28 02:07:31,100 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:32,102 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:33,103 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:34,105 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:35,107 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:36,108 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:37,110 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:38,111 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:39,113 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:40,114 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:40,116 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-28 02:07:41,118 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:42,119 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:43,120 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:44,122 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:45,123 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:46,125 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:47,126 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:48,128 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:49,129 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:50,130 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:50,132 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-28 02:07:51,134 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:52,135 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:53,137 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:54,138 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:55,140 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:56,141 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:57,142 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:58,144 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:07:59,145 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:00,147 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:00,148 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-28 02:08:01,149 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:02,150 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:03,152 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:04,153 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:05,154 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:06,156 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:07,157 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:08,159 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:09,160 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:10,162 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:10,164 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-28 02:08:11,165 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:12,166 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:13,168 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:14,169 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:15,171 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:16,172 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:17,174 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:18,175 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:19,176 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:20,178 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:20,180 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-28 02:08:21,181 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:22,182 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:23,184 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:24,185 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:25,187 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:26,188 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:27,190 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:28,191 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:29,193 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:30,194 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:30,196 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-28 02:08:31,198 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:32,199 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:33,200 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:34,202 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:35,203 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:36,205 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:37,206 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:38,207 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:39,209 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:40,211 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:40,213 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-28 02:08:41,214 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:42,215 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:43,217 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:44,218 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:45,220 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:46,225 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:47,226 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:48,228 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:49,229 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:50,230 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:50,232 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-28 02:08:51,234 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:52,235 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:53,236 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:54,238 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:55,239 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:56,240 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:57,242 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:58,243 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:08:59,244 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:00,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 02:09:00,248 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-28 02:09:00,253 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestKeyInputStream.init(TestKeyInputStream.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-28 02:09:00,259 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-28 02:09:00,259 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-28 02:09:00,260 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-28 02:09:00,260 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43566
2019-09-28 02:09:00,269 [IPC Server listener on 43566] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43566
2019-09-28 02:09:00,271 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-28 02:09:00,274 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:09:00,281 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-28 02:09:00,292 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-28 02:09:00,298 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7ca0863b{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-28 02:09:00,305 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@319854f0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:09:00,306 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ecfbe91{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-28 02:09:00,306 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@629f066f{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:09:00,312 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-28 02:09:00,659 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:09:00,746 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:09:02,696 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=1325fbdb-1f0d-4152-8b54-aaa329b7bd81, PipelineID=dbbfefd0-7366-43bb-89e8-0593afe8ee3a]
2019-09-28 02:09:02,697 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 1325fbdb-1f0d-4152-8b54-aaa329b7bd81, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 02:09:02,699 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 1325fbdb-1f0d-4152-8b54-aaa329b7bd81, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-09-28 02:09:02,701 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: dbbfefd0-7366-43bb-89e8-0593afe8ee3a, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:02,702 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: dbbfefd0-7366-43bb-89e8-0593afe8ee3a, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:09:02,797 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=1325fbdb-1f0d-4152-8b54-aaa329b7bd81, PipelineID=950d5557-ca67-4ccf-bbc4-c134cfbaddc4]
2019-09-28 02:09:02,797 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 1325fbdb-1f0d-4152-8b54-aaa329b7bd81, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-28 02:09:02,797 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 950d5557-ca67-4ccf-bbc4-c134cfbaddc4, Nodes: 199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:02,798 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 950d5557-ca67-4ccf-bbc4-c134cfbaddc4, Nodes: 199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:09:05,315 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:09:05,315 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:09:05,319 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: close
2019-09-28 02:09:05,319 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: close
2019-09-28 02:09:05,322 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: shutdown
2019-09-28 02:09:05,322 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: shutdown
2019-09-28 02:09:05,323 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AAA329B7BD81,id=199e213c-6e83-4a97-8b0b-f5c36d230e9b
2019-09-28 02:09:05,323 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AAA329B7BD81,id=a29cdeed-39ec-4c05-b35f-1948c24ea295
2019-09-28 02:09:05,323 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown FollowerState
2019-09-28 02:09:05,324 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown LeaderState
2019-09-28 02:09:05,324 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(115)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:09:05,324 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:09:05,329 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$399/328485299@339aaeda] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81->199e213c-6e83-4a97-8b0b-f5c36d230e9b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 02:09:05,331 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a29cdeed-39ec-4c05-b35f-1948c24ea295-PendingRequests: sendNotLeaderResponses
2019-09-28 02:09:05,329 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$399/328485299@30dbc323] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81->c76e89fb-def7-4f42-8c4c-0f95fffa834b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 02:09:05,332 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81: closes. applyIndex: 0
2019-09-28 02:09:05,336 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:09:05,339 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81: closes. applyIndex: 0
2019-09-28 02:09:05,339 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: Completed APPEND_ENTRIES, lastRequest: a29cdeed-39ec-4c05-b35f-1948c24ea295->199e213c-6e83-4a97-8b0b-f5c36d230e9b#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 02:09:05,339 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: Completed APPEND_ENTRIES, lastRequest: a29cdeed-39ec-4c05-b35f-1948c24ea295->c76e89fb-def7-4f42-8c4c-0f95fffa834b#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 02:09:05,341 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:09:05,341 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:09:05,347 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81->c76e89fb-def7-4f42-8c4c-0f95fffa834b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 02:09:05,347 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81->199e213c-6e83-4a97-8b0b-f5c36d230e9b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 02:09:05,354 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81->c76e89fb-def7-4f42-8c4c-0f95fffa834b: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 02:09:05,354 [grpc-default-executor-5] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81->199e213c-6e83-4a97-8b0b-f5c36d230e9b: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 02:09:05,360 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-AAA329B7BD81-SegmentedRaftLogWorker close()
2019-09-28 02:09:05,360 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-AAA329B7BD81-SegmentedRaftLogWorker close()
2019-09-28 02:09:05,363 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: shutdown
2019-09-28 02:09:05,365 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: shutdown
2019-09-28 02:09:05,365 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0593AFE8EE3A,id=a29cdeed-39ec-4c05-b35f-1948c24ea295
2019-09-28 02:09:05,366 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C134CFBADDC4,id=199e213c-6e83-4a97-8b0b-f5c36d230e9b
2019-09-28 02:09:05,366 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown LeaderState
2019-09-28 02:09:05,366 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown LeaderState
2019-09-28 02:09:05,367 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a29cdeed-39ec-4c05-b35f-1948c24ea295-PendingRequests: sendNotLeaderResponses
2019-09-28 02:09:05,367 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b-PendingRequests: sendNotLeaderResponses
2019-09-28 02:09:05,368 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:09:05,369 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:09:05,370 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A: closes. applyIndex: 0
2019-09-28 02:09:05,371 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4: closes. applyIndex: 0
2019-09-28 02:09:05,371 [a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:09:05,373 [199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:09:05,373 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a29cdeed-39ec-4c05-b35f-1948c24ea295@group-0593AFE8EE3A-SegmentedRaftLogWorker close()
2019-09-28 02:09:05,374 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b@group-C134CFBADDC4-SegmentedRaftLogWorker close()
2019-09-28 02:09:05,378 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown server with port 38401 now
2019-09-28 02:09:05,378 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown server with port 46039 now
2019-09-28 02:09:05,381 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - a29cdeed-39ec-4c05-b35f-1948c24ea295: shutdown server with port 38401 successfully
2019-09-28 02:09:05,381 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 199e213c-6e83-4a97-8b0b-f5c36d230e9b: shutdown server with port 46039 successfully
2019-09-28 02:09:05,402 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:09:05,405 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:09:05,422 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:09:05,422 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:09:05,426 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:09:05,426 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:09:05,428 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7bc44ce8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:09:05,428 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a66e580{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:09:05,429 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:09:05,429 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b852b49{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:09:05,430 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:09:05,430 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ff35a3f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:09:05,431 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:09:05,431 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d1dcdff{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:09:05,839 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 02:09:07,905 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=1325fbdb-1f0d-4152-8b54-aaa329b7bd81, PipelineID=fbdd2465-8ee8-4e32-b4da-778febc75931]
2019-09-28 02:09:07,905 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 1325fbdb-1f0d-4152-8b54-aaa329b7bd81, Nodes: a29cdeed-39ec-4c05-b35f-1948c24ea295{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}199e213c-6e83-4a97-8b0b-f5c36d230e9b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-28 02:09:07,906 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: fbdd2465-8ee8-4e32-b4da-778febc75931, Nodes: c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 02:09:07,906 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: fbdd2465-8ee8-4e32-b4da-778febc75931, Nodes: c76e89fb-def7-4f42-8c4c-0f95fffa834b{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-28 02:09:10,435 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 02:09:10,438 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: close
2019-09-28 02:09:10,439 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: shutdown
2019-09-28 02:09:10,439 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AAA329B7BD81,id=c76e89fb-def7-4f42-8c4c-0f95fffa834b
2019-09-28 02:09:10,440 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown FollowerState
2019-09-28 02:09:10,440 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:09:10,440 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(115)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 02:09:10,443 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81: closes. applyIndex: 0
2019-09-28 02:09:10,444 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:09:10,445 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-AAA329B7BD81-SegmentedRaftLogWorker close()
2019-09-28 02:09:10,447 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: shutdown
2019-09-28 02:09:10,448 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-778FEBC75931,id=c76e89fb-def7-4f42-8c4c-0f95fffa834b
2019-09-28 02:09:10,448 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown LeaderState
2019-09-28 02:09:10,449 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b-PendingRequests: sendNotLeaderResponses
2019-09-28 02:09:10,449 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-StateMachineUpdater: set stopIndex = 0
2019-09-28 02:09:10,451 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931: closes. applyIndex: 0
2019-09-28 02:09:10,451 [c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 02:09:10,457 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b@group-778FEBC75931-SegmentedRaftLogWorker close()
2019-09-28 02:09:10,459 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown server with port 33923 now
2019-09-28 02:09:10,463 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c76e89fb-def7-4f42-8c4c-0f95fffa834b: shutdown server with port 33923 successfully
2019-09-28 02:09:10,478 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b5206e55-c7a1-4a9b-a576-2f17d288d45c/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 02:09:10,497 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 02:09:10,500 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 02:09:10,501 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5dd903be{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 02:09:10,502 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:09:10,503 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 02:09:10,503 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:09:10,504 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-28 02:09:10,505 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-28 02:09:10,505 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-28 02:09:10,505 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-28 02:09:10,505 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-28 02:09:10,505 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-28 02:09:10,506 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41879
2019-09-28 02:09:10,506 [IPC Server listener on 41879] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41879
2019-09-28 02:09:10,507 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:09:10,510 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-28 02:09:10,510 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-28 02:09:10,510 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-28 02:09:10,510 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45546
2019-09-28 02:09:10,511 [IPC Server listener on 45546] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45546
2019-09-28 02:09:10,511 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-28 02:09:10,511 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:09:10,512 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(158)) - Stopping the RPC server for Client Protocol
2019-09-28 02:09:10,512 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37021
2019-09-28 02:09:10,514 [IPC Server listener on 37021] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37021
2019-09-28 02:09:10,514 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-28 02:09:10,514 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 02:09:10,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cc5b667{/,null,UNAVAILABLE}{/scm}
2019-09-28 02:09:10,516 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4eeea57d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 02:09:10,517 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25a6944c{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-28 02:09:10,517 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64ba3208{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-28 02:09:10,519 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-28 02:09:10,519 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 02:09:10,520 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 02:09:10,520 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-28 02:09:10,527 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-28 02:09:10,534 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-28 02:09:10,534 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
