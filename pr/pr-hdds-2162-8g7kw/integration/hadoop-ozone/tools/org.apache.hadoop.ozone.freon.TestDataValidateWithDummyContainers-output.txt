2019-09-28 05:37:44,789 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:44,866 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:44,869 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:44,883 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @782ms
2019-09-28 05:37:44,965 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-28 05:37:44,965 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-28 05:37:44,965 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-28 05:37:44,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-28 05:37:44,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-28 05:37:44,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-28 05:37:44,976 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 05:37:44,976 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 05:37:44,977 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 05:37:45,279 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@51399530
2019-09-28 05:37:45,282 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-28 05:37:45,389 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-28 05:37:45,392 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-28 05:37:45,395 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-28 05:37:45,473 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-28 05:37:45,487 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:45,575 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-28 05:37:45,578 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:45,740 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-28 05:37:46,135 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:37:46,165 [Socket Reader #1 for port 36550] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36550
2019-09-28 05:37:46,329 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:37:46,331 [Socket Reader #1 for port 35554] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35554
2019-09-28 05:37:46,343 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:37:46,344 [Socket Reader #1 for port 44417] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44417
2019-09-28 05:37:46,374 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-28 05:37:46,520 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:46,539 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:46,550 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:46,553 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-28 05:37:46,554 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:46,554 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:46,584 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:44417
2019-09-28 05:37:46,645 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-28 05:37:46,663 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-28 05:37:46,663 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-28 05:37:46,983 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(150)) - RPC server for Client  is listening at /0.0.0.0:44417
2019-09-28 05:37:46,984 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:37:46,984 [IPC Server listener on 44417] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44417: starting
2019-09-28 05:37:46,988 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:35554
2019-09-28 05:37:46,989 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:35554
2019-09-28 05:37:46,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:37:46,990 [IPC Server listener on 35554] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35554: starting
2019-09-28 05:37:46,993 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:36550
2019-09-28 05:37:46,993 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:36550
2019-09-28 05:37:46,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:37:46,993 [IPC Server listener on 36550] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36550: starting
2019-09-28 05:37:46,997 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34822
2019-09-28 05:37:46,999 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:47,036 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d2bd371{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:47,037 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42f8285e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:47,108 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58c540cf{/,file:///tmp/jetty-0.0.0.0-34822-scm-_-any-3158740336468781032.dir/webapp/,AVAILABLE}{/scm}
2019-09-28 05:37:47,113 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1cf2fed4{HTTP/1.1,[http/1.1]}{0.0.0.0:34822}
2019-09-28 05:37:47,114 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3012ms
2019-09-28 05:37:47,116 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-28 05:37:47,116 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-28 05:37:47,117 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:34822
2019-09-28 05:37:47,127 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@687a762c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:37:47,131 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:47,273 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-28 05:37:47,273 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-28 05:37:47,275 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:47,276 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:47,965 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:37:47,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-28 05:37:47,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-28 05:37:47,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-28 05:37:47,974 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-28 05:37:47,975 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-28 05:37:47,975 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-28 05:37:47,975 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-28 05:37:47,975 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-28 05:37:47,976 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-28 05:37:47,976 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-28 05:37:47,976 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-28 05:37:47,976 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-28 05:37:47,977 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-28 05:37:47,977 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-28 05:37:47,977 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-28 05:37:47,977 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-28 05:37:47,978 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-28 05:37:47,978 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-28 05:37:47,978 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-28 05:37:47,978 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-28 05:37:47,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-28 05:37:47,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-28 05:37:47,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 05:37:47,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 05:37:47,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 05:37:48,668 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:37:48,670 [Socket Reader #1 for port 33207] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33207
2019-09-28 05:37:48,696 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:33207
2019-09-28 05:37:48,696 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-28 05:37:48,697 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:37:48,698 [IPC Server listener on 33207] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33207: starting
2019-09-28 05:37:48,703 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-28 05:37:48,705 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:48,706 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:48,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:48,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-28 05:37:48,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:48,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:48,712 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35505
2019-09-28 05:37:48,712 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:48,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@529cfee5{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:48,715 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@319854f0{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:48,766 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ac7aa18{/,file:///tmp/jetty-0.0.0.0-35505-ozoneManager-_-any-4130611514331613641.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-28 05:37:48,767 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4cdd2c73{HTTP/1.1,[http/1.1]}{0.0.0.0:35505}
2019-09-28 05:37:48,768 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4667ms
2019-09-28 05:37:48,768 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:37:48,769 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:35505
2019-09-28 05:37:49,119 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:37:49,178 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:37:49,218 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:37:49,221 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/containers/hdds to VolumeSet
2019-09-28 05:37:49,224 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4a05d8ae
2019-09-28 05:37:49,243 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4a05d8ae
2019-09-28 05:37:49,279 [main] WARN  impl.ChunkManagerFactory (ChunkManagerFactory.java:createChunkManager(83)) - hdds.container.chunk.persistdata is set to false. This should be used only for testing. All user data will be discarded.
2019-09-28 05:37:49,365 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:37:49,439 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:37:49,444 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:37:49,445 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:37:49,447 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:49,448 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:37:49,448 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:37:49,637 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis] (custom)
2019-09-28 05:37:49,699 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:37:49,701 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:49,702 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:49,704 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:49,705 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:37:49,705 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:49,705 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:49,706 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45017
2019-09-28 05:37:49,707 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:49,709 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e33d73e{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:49,710 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@623dcf2a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:49,740 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f1d0bbc{/,file:///tmp/jetty-0.0.0.0-45017-hddsDatanode-_-any-9198391991549030256.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:37:49,741 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5460b754{HTTP/1.1,[http/1.1]}{0.0.0.0:45017}
2019-09-28 05:37:49,742 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5641ms
2019-09-28 05:37:49,743 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:37:49,743 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45017
2019-09-28 05:37:49,744 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:37:49,748 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:37:49,751 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e3772ea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:37:49,758 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:37:49,758 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/containers/hdds to VolumeSet
2019-09-28 05:37:49,759 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7ceb4478
2019-09-28 05:37:49,760 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7ceb4478
2019-09-28 05:37:49,776 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:37:49,776 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:37:49,776 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:37:49,777 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:37:49,777 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:49,777 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:37:49,777 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:37:49,778 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis] (custom)
2019-09-28 05:37:49,780 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:37:49,781 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:49,782 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:49,783 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:49,784 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:37:49,784 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:49,784 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:49,785 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46258
2019-09-28 05:37:49,785 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:49,789 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b5e7036{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:49,790 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cff61fc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:49,820 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7100dea{/,file:///tmp/jetty-0.0.0.0-46258-hddsDatanode-_-any-3300712503888926840.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:37:49,820 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@712cfb63{HTTP/1.1,[http/1.1]}{0.0.0.0:46258}
2019-09-28 05:37:49,821 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5720ms
2019-09-28 05:37:49,822 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:37:49,823 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46258
2019-09-28 05:37:49,824 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:37:49,827 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:37:49,827 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1249bb93] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:37:49,839 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:37:49,840 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/containers/hdds to VolumeSet
2019-09-28 05:37:49,841 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@599e4d41
2019-09-28 05:37:49,842 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@599e4d41
2019-09-28 05:37:49,858 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:37:49,859 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:37:49,859 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:37:49,859 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:37:49,859 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:49,860 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:37:49,860 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:37:49,860 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis] (custom)
2019-09-28 05:37:49,862 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:37:49,864 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:49,864 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:49,866 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:49,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:37:49,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:49,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:49,868 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34877
2019-09-28 05:37:49,868 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:49,870 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6342d610{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:49,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@784abd3e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:49,892 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/meta/datanode.id
2019-09-28 05:37:49,897 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/meta/datanode.id
2019-09-28 05:37:49,916 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72f9f27c{/,file:///tmp/jetty-0.0.0.0-34877-hddsDatanode-_-any-6849438771105488984.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:37:49,918 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c1bdcc2{HTTP/1.1,[http/1.1]}{0.0.0.0:34877}
2019-09-28 05:37:49,919 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5818ms
2019-09-28 05:37:49,920 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:37:49,921 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34877
2019-09-28 05:37:49,921 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:37:49,928 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b8b64b0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:37:49,928 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:37:49,932 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/meta/datanode.id
2019-09-28 05:37:49,941 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:37:49,941 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/containers/hdds to VolumeSet
2019-09-28 05:37:49,941 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@102c577f
2019-09-28 05:37:49,942 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@102c577f
2019-09-28 05:37:49,959 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:37:49,959 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:37:49,960 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:37:49,960 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:37:49,960 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:49,961 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:37:49,961 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:37:49,962 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis] (custom)
2019-09-28 05:37:49,964 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:37:49,966 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:49,967 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:49,970 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:49,971 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:37:49,971 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:49,972 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:49,973 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43192
2019-09-28 05:37:49,973 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:49,980 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1859e2a4{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:49,981 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@176996c3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:50,026 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4228bf58{/,file:///tmp/jetty-0.0.0.0-43192-hddsDatanode-_-any-8338456479267661654.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:37:50,028 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@68b9834c{HTTP/1.1,[http/1.1]}{0.0.0.0:43192}
2019-09-28 05:37:50,028 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5927ms
2019-09-28 05:37:50,029 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:37:50,029 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43192
2019-09-28 05:37:50,030 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:37:50,033 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:37:50,033 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1691f4bd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:37:50,037 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/meta/datanode.id
2019-09-28 05:37:50,041 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:37:50,042 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/containers/hdds to VolumeSet
2019-09-28 05:37:50,042 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@372ca2d6
2019-09-28 05:37:50,043 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@372ca2d6
2019-09-28 05:37:50,059 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:37:50,059 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:37:50,059 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:37:50,060 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:37:50,060 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:50,060 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:37:50,061 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:37:50,061 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis] (custom)
2019-09-28 05:37:50,063 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:37:50,065 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:37:50,066 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:37:50,067 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:37:50,068 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:37:50,068 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:37:50,068 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:37:50,069 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38874
2019-09-28 05:37:50,069 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:37:50,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ff23ae7{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:37:50,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b7962a2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:37:50,102 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f9a6c2d{/,file:///tmp/jetty-0.0.0.0-38874-hddsDatanode-_-any-4400546276600357651.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:37:50,103 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b6fcb9f{HTTP/1.1,[http/1.1]}{0.0.0.0:38874}
2019-09-28 05:37:50,103 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6002ms
2019-09-28 05:37:50,103 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:37:50,104 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38874
2019-09-28 05:37:50,106 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-28 05:37:50,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@94849ef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:37:50,111 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/meta/datanode.id
2019-09-28 05:37:51,107 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-28 05:37:51,812 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:37:51,814 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:37:51,814 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 7d65ca33-c851-4cee-940b-14c0a4ae5542 at port 0
2019-09-28 05:37:51,843 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: start RPC server
2019-09-28 05:37:51,845 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:37:51,851 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:37:51,851 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee at port 0
2019-09-28 05:37:51,860 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start RPC server
2019-09-28 05:37:51,944 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:37:51,946 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:37:51,946 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 175ec8cc-a85e-4fff-99f2-5f91abf68440 at port 0
2019-09-28 05:37:51,955 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start RPC server
2019-09-28 05:37:52,001 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: GrpcService started, listening on 0.0.0.0/0.0.0.0:42668
2019-09-28 05:37:52,001 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: GrpcService started, listening on 0.0.0.0/0.0.0.0:46635
2019-09-28 05:37:52,001 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: GrpcService started, listening on 0.0.0.0/0.0.0.0:46560
2019-09-28 05:37:52,003 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee is started using port 46635
2019-09-28 05:37:52,002 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 175ec8cc-a85e-4fff-99f2-5f91abf68440 is started using port 42668
2019-09-28 05:37:52,003 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 7d65ca33-c851-4cee-940b-14c0a4ae5542 is started using port 46560
2019-09-28 05:37:52,010 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 7d65ca33-c851-4cee-940b-14c0a4ae5542 is started using port 45138
2019-09-28 05:37:52,010 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 175ec8cc-a85e-4fff-99f2-5f91abf68440 is started using port 38126
2019-09-28 05:37:52,010 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee is started using port 36963
2019-09-28 05:37:52,049 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:37:52,051 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:37:52,051 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 59a0ddbb-27bd-43ff-9760-1c766f7e4b67 at port 0
2019-09-28 05:37:52,058 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start RPC server
2019-09-28 05:37:52,061 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: GrpcService started, listening on 0.0.0.0/0.0.0.0:39331
2019-09-28 05:37:52,061 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 59a0ddbb-27bd-43ff-9760-1c766f7e4b67 is started using port 39331
2019-09-28 05:37:52,063 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 59a0ddbb-27bd-43ff-9760-1c766f7e4b67 is started using port 42182
2019-09-28 05:37:52,107 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-28 05:37:52,124 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:37:52,129 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:37:52,129 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 6629995f-1641-4578-a5be-5caf7dd19b87 at port 0
2019-09-28 05:37:52,138 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6629995f-1641-4578-a5be-5caf7dd19b87: start RPC server
2019-09-28 05:37:52,141 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 6629995f-1641-4578-a5be-5caf7dd19b87: GrpcService started, listening on 0.0.0.0/0.0.0.0:42013
2019-09-28 05:37:52,141 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 6629995f-1641-4578-a5be-5caf7dd19b87 is started using port 42013
2019-09-28 05:37:52,144 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 6629995f-1641-4578-a5be-5caf7dd19b87 is started using port 34878
2019-09-28 05:37:53,109 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-28 05:37:53,799 [IPC Server handler 6 on 36550] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/7d65ca33-c851-4cee-940b-14c0a4ae5542
2019-09-28 05:37:53,800 [IPC Server handler 6 on 36550] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 7d65ca33-c851-4cee-940b-14c0a4ae5542{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:37:53,806 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-28 05:37:53,806 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-28 05:37:53,807 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-28 05:37:53,831 [IPC Server handler 12 on 36550] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:37:53,831 [IPC Server handler 12 on 36550] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:37:53,932 [IPC Server handler 4 on 36550] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:37:53,932 [IPC Server handler 4 on 36550] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 175ec8cc-a85e-4fff-99f2-5f91abf68440{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:37:54,038 [IPC Server handler 5 on 36550] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/59a0ddbb-27bd-43ff-9760-1c766f7e4b67
2019-09-28 05:37:54,039 [IPC Server handler 5 on 36550] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 59a0ddbb-27bd-43ff-9760-1c766f7e4b67{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:37:54,111 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-28 05:37:54,112 [IPC Server handler 6 on 36550] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6629995f-1641-4578-a5be-5caf7dd19b87
2019-09-28 05:37:54,112 [IPC Server handler 6 on 36550] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 6629995f-1641-4578-a5be-5caf7dd19b87{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:37:54,382 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: addNew group-FB7B68F99F64:[7d65ca33-c851-4cee-940b-14c0a4ae5542:192.168.151.82:46560] returns group-FB7B68F99F64:java.util.concurrent.CompletableFuture@7ec4f5[Not completed]
2019-09-28 05:37:54,405 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: new RaftServerImpl for group-FB7B68F99F64:[7d65ca33-c851-4cee-940b-14c0a4ae5542:192.168.151.82:46560] with ContainerStateMachine:uninitialized
2019-09-28 05:37:54,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:54,409 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:54,409 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:54,410 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:54,411 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:54,421 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: ConfigurationManager, init=-1: [7d65ca33-c851-4cee-940b-14c0a4ae5542:192.168.151.82:46560], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:54,422 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis] (custom)
2019-09-28 05:37:54,434 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis/787e18bd-64cb-47ac-aa2b-fb7b68f99f64 does not exist. Creating ...
2019-09-28 05:37:54,452 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis/787e18bd-64cb-47ac-aa2b-fb7b68f99f64/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:54,467 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis/787e18bd-64cb-47ac-aa2b-fb7b68f99f64 has been successfully formatted.
2019-09-28 05:37:54,470 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FB7B68F99F64: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:54,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:54,473 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:54,480 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:54,480 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:54,482 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:54,493 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis/787e18bd-64cb-47ac-aa2b-fb7b68f99f64
2019-09-28 05:37:54,494 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-28 05:37:54,501 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-28 05:37:54,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:54,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:54,536 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,537 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:54,537 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:54,538 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:54,539 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:54,539 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:54,539 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:54,550 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:54,554 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:54,558 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:54,559 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:54,560 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:54,560 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:54,590 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: start as a follower, conf=-1: [7d65ca33-c851-4cee-940b-14c0a4ae5542:192.168.151.82:46560], old=null
2019-09-28 05:37:54,591 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:54,592 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: start FollowerState
2019-09-28 05:37:54,594 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FB7B68F99F64,id=7d65ca33-c851-4cee-940b-14c0a4ae5542
2019-09-28 05:37:54,650 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 787e18bd-64cb-47ac-aa2b-fb7b68f99f64, Nodes: 7d65ca33-c851-4cee-940b-14c0a4ae5542{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:37:54,670 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: addNew group-F3F3DE8A6BA0:[175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] returns group-F3F3DE8A6BA0:java.util.concurrent.CompletableFuture@5e397aab[Not completed]
2019-09-28 05:37:54,715 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: new RaftServerImpl for group-F3F3DE8A6BA0:[175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] with ContainerStateMachine:uninitialized
2019-09-28 05:37:54,716 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:54,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:54,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:54,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:54,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:54,717 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: ConfigurationManager, init=-1: [175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:54,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis] (custom)
2019-09-28 05:37:54,718 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/c2ad4245-be99-4b2f-8ccb-f3f3de8a6ba0 does not exist. Creating ...
2019-09-28 05:37:54,748 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/c2ad4245-be99-4b2f-8ccb-f3f3de8a6ba0/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:54,761 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/c2ad4245-be99-4b2f-8ccb-f3f3de8a6ba0 has been successfully formatted.
2019-09-28 05:37:54,763 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F3F3DE8A6BA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:54,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:54,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:54,765 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:54,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:54,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:54,766 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/c2ad4245-be99-4b2f-8ccb-f3f3de8a6ba0
2019-09-28 05:37:54,774 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:54,775 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:54,775 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,775 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:54,775 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:54,776 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:54,776 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:54,776 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:54,776 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:54,777 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:54,777 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:54,777 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:54,778 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:54,778 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:54,778 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:54,784 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: start as a follower, conf=-1: [175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:37:54,784 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:54,784 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start FollowerState
2019-09-28 05:37:54,786 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F3F3DE8A6BA0,id=175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:37:54,803 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c2ad4245-be99-4b2f-8ccb-f3f3de8a6ba0, Nodes: 175ec8cc-a85e-4fff-99f2-5f91abf68440{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:37:54,820 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: addNew group-416EFD5EE8DB:[59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331] returns group-416EFD5EE8DB:java.util.concurrent.CompletableFuture@7e109fa5[Not completed]
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: new RaftServerImpl for group-416EFD5EE8DB:[59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331] with ContainerStateMachine:uninitialized
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:54,833 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: ConfigurationManager, init=-1: [59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:54,834 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis] (custom)
2019-09-28 05:37:54,834 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/581638f1-de14-4543-952d-416efd5ee8db does not exist. Creating ...
2019-09-28 05:37:54,847 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/581638f1-de14-4543-952d-416efd5ee8db/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:54,861 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/581638f1-de14-4543-952d-416efd5ee8db has been successfully formatted.
2019-09-28 05:37:54,861 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-416EFD5EE8DB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:54,862 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/581638f1-de14-4543-952d-416efd5ee8db
2019-09-28 05:37:54,892 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:54,892 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:54,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:54,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:54,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:54,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:54,893 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:54,894 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:54,894 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:54,894 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:54,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:54,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:54,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:54,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:54,900 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: start as a follower, conf=-1: [59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331], old=null
2019-09-28 05:37:54,900 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:54,900 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start FollowerState
2019-09-28 05:37:54,901 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-416EFD5EE8DB,id=59a0ddbb-27bd-43ff-9760-1c766f7e4b67
2019-09-28 05:37:54,910 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 581638f1-de14-4543-952d-416efd5ee8db, Nodes: 59a0ddbb-27bd-43ff-9760-1c766f7e4b67{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:37:54,927 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: addNew group-B87664FE6DDA:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635] returns group-B87664FE6DDA:java.util.concurrent.CompletableFuture@678fa2fd[Not completed]
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: new RaftServerImpl for group-B87664FE6DDA:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635] with ContainerStateMachine:uninitialized
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:54,929 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: ConfigurationManager, init=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:54,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis] (custom)
2019-09-28 05:37:54,930 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/b796a6d2-9177-458c-b7e0-b87664fe6dda does not exist. Creating ...
2019-09-28 05:37:54,943 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/b796a6d2-9177-458c-b7e0-b87664fe6dda/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:54,957 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/b796a6d2-9177-458c-b7e0-b87664fe6dda has been successfully formatted.
2019-09-28 05:37:54,957 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B87664FE6DDA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:54,957 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:54,958 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:54,958 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:54,958 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:54,958 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,958 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:54,958 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/b796a6d2-9177-458c-b7e0-b87664fe6dda
2019-09-28 05:37:54,963 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:54,963 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:54,963 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:54,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:54,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:54,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:54,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:54,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:54,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:54,965 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:54,965 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:54,965 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:54,965 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:54,965 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:54,966 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:54,969 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: start as a follower, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635], old=null
2019-09-28 05:37:54,970 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:54,970 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start FollowerState
2019-09-28 05:37:54,970 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B87664FE6DDA,id=5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:37:54,984 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b796a6d2-9177-458c-b7e0-b87664fe6dda, Nodes: 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:37:55,005 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6629995f-1641-4578-a5be-5caf7dd19b87: addNew group-FB265DA78ED6:[6629995f-1641-4578-a5be-5caf7dd19b87:192.168.151.82:42013] returns group-FB265DA78ED6:java.util.concurrent.CompletableFuture@1292fc42[Not completed]
2019-09-28 05:37:55,008 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 6629995f-1641-4578-a5be-5caf7dd19b87: new RaftServerImpl for group-FB265DA78ED6:[6629995f-1641-4578-a5be-5caf7dd19b87:192.168.151.82:42013] with ContainerStateMachine:uninitialized
2019-09-28 05:37:55,008 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:55,008 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:55,008 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:55,008 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:55,008 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:55,009 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: ConfigurationManager, init=-1: [6629995f-1641-4578-a5be-5caf7dd19b87:192.168.151.82:42013], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:55,009 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis] (custom)
2019-09-28 05:37:55,009 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis/9a0ebe1f-1e60-4059-890e-fb265da78ed6 does not exist. Creating ...
2019-09-28 05:37:55,022 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis/9a0ebe1f-1e60-4059-890e-fb265da78ed6/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:55,036 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis/9a0ebe1f-1e60-4059-890e-fb265da78ed6 has been successfully formatted.
2019-09-28 05:37:55,036 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FB265DA78ED6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:55,036 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:55,036 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:55,036 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:55,037 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:55,037 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,037 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:55,037 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis/9a0ebe1f-1e60-4059-890e-fb265da78ed6
2019-09-28 05:37:55,040 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:55,040 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:55,040 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:55,041 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:55,042 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:55,042 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:55,042 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:55,042 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:55,042 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:55,045 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: start as a follower, conf=-1: [6629995f-1641-4578-a5be-5caf7dd19b87:192.168.151.82:42013], old=null
2019-09-28 05:37:55,046 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:55,046 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6629995f-1641-4578-a5be-5caf7dd19b87: start FollowerState
2019-09-28 05:37:55,046 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FB265DA78ED6,id=6629995f-1641-4578-a5be-5caf7dd19b87
2019-09-28 05:37:55,058 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9a0ebe1f-1e60-4059-890e-fb265da78ed6, Nodes: 6629995f-1641-4578-a5be-5caf7dd19b87{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:37:55,105 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: addNew group-A179FEF59D3D:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] returns group-A179FEF59D3D:java.util.concurrent.CompletableFuture@45622885[Not completed]
2019-09-28 05:37:55,108 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: addNew group-A179FEF59D3D:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] returns group-A179FEF59D3D:java.util.concurrent.CompletableFuture@60ae4d[Not completed]
2019-09-28 05:37:55,108 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: addNew group-A179FEF59D3D:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] returns group-A179FEF59D3D:java.util.concurrent.CompletableFuture@6844751e[Not completed]
2019-09-28 05:37:55,109 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: new RaftServerImpl for group-A179FEF59D3D:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] with ContainerStateMachine:uninitialized
2019-09-28 05:37:55,109 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:55,109 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:55,109 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:55,110 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:55,110 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:55,110 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: ConfigurationManager, init=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:55,110 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis] (custom)
2019-09-28 05:37:55,110 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: new RaftServerImpl for group-A179FEF59D3D:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] with ContainerStateMachine:uninitialized
2019-09-28 05:37:55,111 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d does not exist. Creating ...
2019-09-28 05:37:55,111 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:55,111 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:55,111 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:55,111 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-28 05:37:55,111 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: new RaftServerImpl for group-A179FEF59D3D:[5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668] with ContainerStateMachine:uninitialized
2019-09-28 05:37:55,111 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:55,112 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:37:55,112 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:55,112 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:37:55,112 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: ConfigurationManager, init=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:55,112 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:37:55,112 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:37:55,112 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis] (custom)
2019-09-28 05:37:55,113 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:37:55,113 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: ConfigurationManager, init=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null, confs=<EMPTY_MAP>
2019-09-28 05:37:55,113 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d does not exist. Creating ...
2019-09-28 05:37:55,113 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis] (custom)
2019-09-28 05:37:55,113 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d does not exist. Creating ...
2019-09-28 05:37:55,117 [main] INFO  freon.TestDataValidate (TestDataValidateWithDummyContainers.java:validateWriteTest(64)) - Skipping validateWriteTest for non-persistent containers.
2019-09-28 05:37:55,123 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-28 05:37:55,124 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:55,124 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:55,124 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/in_use.lock acquired by nodename 17628@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:37:55,139 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d has been successfully formatted.
2019-09-28 05:37:55,139 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d has been successfully formatted.
2019-09-28 05:37:55,139 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d has been successfully formatted.
2019-09-28 05:37:55,139 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A179FEF59D3D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:55,139 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A179FEF59D3D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:55,139 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:55,139 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A179FEF59D3D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:37:55,140 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:55,139 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:55,140 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:55,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:37:55,140 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:55,140 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:55,141 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:37:55,141 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:55,141 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:55,141 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d
2019-09-28 05:37:55,141 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:37:55,141 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:55,141 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:55,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:55,142 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:37:55,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,142 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:55,142 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,143 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:55,143 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:55,143 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:55,143 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:37:55,143 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:55,143 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d
2019-09-28 05:37:55,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:55,144 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d
2019-09-28 05:37:55,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:55,144 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:55,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:55,144 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:37:55,145 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:55,145 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:55,145 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:37:55,145 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,145 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:37:55,145 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:55,146 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:55,146 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:37:55,146 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:55,146 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:55,147 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:55,146 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:37:55,147 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:55,147 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:55,147 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:55,147 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:37:55,148 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:55,148 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:55,148 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:55,148 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:37:55,148 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:55,149 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:37:55,149 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:55,149 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:37:55,149 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:55,149 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:55,149 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:37:55,149 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:55,150 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:37:55,150 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:37:55,150 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:37:55,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:37:55,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:37:55,152 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: start as a follower, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:37:55,153 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:55,153 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start FollowerState
2019-09-28 05:37:55,153 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A179FEF59D3D,id=5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:37:55,154 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: start as a follower, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:37:55,154 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:55,154 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start FollowerState
2019-09-28 05:37:55,155 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A179FEF59D3D,id=59a0ddbb-27bd-43ff-9760-1c766f7e4b67
2019-09-28 05:37:55,158 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: start as a follower, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:37:55,160 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:37:55,161 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start FollowerState
2019-09-28 05:37:55,167 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A179FEF59D3D,id=175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:37:55,187 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bd5ef748-74b5-44f7-a589-a179fef59d3d, Nodes: 175ec8cc-a85e-4fff-99f2-5f91abf68440{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}59a0ddbb-27bd-43ff-9760-1c766f7e4b67{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}5ecd22a4-0dac-4855-8c4a-f5adec0e20ee{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 05:37:56,381 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:37:56,826 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-28 05:37:56,830 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 2 milliseconds for processing 0 containers.
2019-09-28 05:37:57,383 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:37:58,384 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:37:59,386 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:37:59,726 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542:group-FB7B68F99F64 changes to CANDIDATE, lastRpcTime:5133, electionTimeout:5133ms
2019-09-28 05:37:59,728 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: shutdown FollowerState
2019-09-28 05:37:59,728 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:37:59,733 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: start LeaderElection
2019-09-28 05:37:59,750 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1: begin an election at term 1 for -1: [7d65ca33-c851-4cee-940b-14c0a4ae5542:192.168.151.82:46560], old=null
2019-09-28 05:37:59,751 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: shutdown LeaderElection
2019-09-28 05:37:59,752 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:37:59,752 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: change Leader from null to 7d65ca33-c851-4cee-940b-14c0a4ae5542 at term 1 for becomeLeader, leader elected after 5281ms
2019-09-28 05:37:59,760 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:37:59,760 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:37:59,762 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:37:59,764 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:37:59,765 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:37:59,766 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:37:59,777 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: start LeaderState
2019-09-28 05:37:59,797 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:37:59,804 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: set configuration 0: [7d65ca33-c851-4cee-940b-14c0a4ae5542:192.168.151.82:46560], old=null at 0
2019-09-28 05:37:59,962 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440:group-F3F3DE8A6BA0 changes to CANDIDATE, lastRpcTime:5177, electionTimeout:5176ms
2019-09-28 05:37:59,965 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown FollowerState
2019-09-28 05:37:59,965 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:37:59,965 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start LeaderElection
2019-09-28 05:37:59,974 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/ratis/787e18bd-64cb-47ac-aa2b-fb7b68f99f64/current/log_inprogress_0
2019-09-28 05:37:59,974 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2: begin an election at term 1 for -1: [175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:37:59,976 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown LeaderElection
2019-09-28 05:37:59,976 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:37:59,976 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: change Leader from null to 175ec8cc-a85e-4fff-99f2-5f91abf68440 at term 1 for becomeLeader, leader elected after 5211ms
2019-09-28 05:37:59,978 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:37:59,978 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:37:59,978 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:37:59,978 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:37:59,978 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:37:59,979 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:37:59,982 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start LeaderState
2019-09-28 05:37:59,982 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:37:59,983 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: set configuration 0: [175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null at 0
2019-09-28 05:38:00,019 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/c2ad4245-be99-4b2f-8ccb-f3f3de8a6ba0/current/log_inprogress_0
2019-09-28 05:38:00,087 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:group-416EFD5EE8DB changes to CANDIDATE, lastRpcTime:5186, electionTimeout:5186ms
2019-09-28 05:38:00,087 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown FollowerState
2019-09-28 05:38:00,087 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:38:00,088 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start LeaderElection
2019-09-28 05:38:00,090 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:group-B87664FE6DDA changes to CANDIDATE, lastRpcTime:5120, electionTimeout:5118ms
2019-09-28 05:38:00,091 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown FollowerState
2019-09-28 05:38:00,091 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:38:00,091 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start LeaderElection
2019-09-28 05:38:00,106 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4: begin an election at term 1 for -1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635], old=null
2019-09-28 05:38:00,106 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3: begin an election at term 1 for -1: [59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331], old=null
2019-09-28 05:38:00,107 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown LeaderElection
2019-09-28 05:38:00,107 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown LeaderElection
2019-09-28 05:38:00,107 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:38:00,107 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:38:00,107 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: change Leader from null to 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee at term 1 for becomeLeader, leader elected after 5149ms
2019-09-28 05:38:00,107 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: change Leader from null to 59a0ddbb-27bd-43ff-9760-1c766f7e4b67 at term 1 for becomeLeader, leader elected after 5245ms
2019-09-28 05:38:00,108 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:38:00,109 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:38:00,109 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:38:00,110 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:38:00,110 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:38:00,110 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:38:00,110 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:38:00,110 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:38:00,110 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:38:00,110 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:38:00,111 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:38:00,111 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:38:00,114 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start LeaderState
2019-09-28 05:38:00,114 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:00,114 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: set configuration 0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635], old=null at 0
2019-09-28 05:38:00,141 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start LeaderState
2019-09-28 05:38:00,142 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:00,142 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: set configuration 0: [59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331], old=null at 0
2019-09-28 05:38:00,166 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/b796a6d2-9177-458c-b7e0-b87664fe6dda/current/log_inprogress_0
2019-09-28 05:38:00,166 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:group-A179FEF59D3D changes to CANDIDATE, lastRpcTime:5013, electionTimeout:5013ms
2019-09-28 05:38:00,167 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown FollowerState
2019-09-28 05:38:00,167 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:38:00,167 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start LeaderElection
2019-09-28 05:38:00,179 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/581638f1-de14-4543-952d-416efd5ee8db/current/log_inprogress_0
2019-09-28 05:38:00,179 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5: begin an election at term 1 for -1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:38:00,196 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6629995f-1641-4578-a5be-5caf7dd19b87:group-FB265DA78ED6 changes to CANDIDATE, lastRpcTime:5150, electionTimeout:5150ms
2019-09-28 05:38:00,197 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6629995f-1641-4578-a5be-5caf7dd19b87: shutdown FollowerState
2019-09-28 05:38:00,197 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:38:00,197 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6629995f-1641-4578-a5be-5caf7dd19b87: start LeaderElection
2019-09-28 05:38:00,200 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440:group-A179FEF59D3D changes to CANDIDATE, lastRpcTime:5038, electionTimeout:5034ms
2019-09-28 05:38:00,200 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown FollowerState
2019-09-28 05:38:00,200 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:38:00,200 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start LeaderElection
2019-09-28 05:38:00,203 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:38:00,203 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: changes role from CANDIDATE to FOLLOWER at term 1 for recognizeCandidate:5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:38:00,203 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown FollowerState
2019-09-28 05:38:00,204 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown LeaderElection
2019-09-28 05:38:00,204 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start FollowerState
2019-09-28 05:38:00,204 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start FollowerState
2019-09-28 05:38:00,204 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(115)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:38:00,214 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6: begin an election at term 1 for -1: [6629995f-1641-4578-a5be-5caf7dd19b87:192.168.151.82:42013], old=null
2019-09-28 05:38:00,214 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6629995f-1641-4578-a5be-5caf7dd19b87: shutdown LeaderElection
2019-09-28 05:38:00,214 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:38:00,214 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: change Leader from null to 6629995f-1641-4578-a5be-5caf7dd19b87 at term 1 for becomeLeader, leader elected after 5177ms
2019-09-28 05:38:00,216 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:38:00,216 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:38:00,217 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:38:00,217 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:38:00,217 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:38:00,217 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:38:00,227 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6629995f-1641-4578-a5be-5caf7dd19b87: start LeaderState
2019-09-28 05:38:00,227 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5: Election PASSED; received 1 response(s) [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee<-59a0ddbb-27bd-43ff-9760-1c766f7e4b67#0:OK-t1] and 0 exception(s); 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:t1, leader=null, voted=5ecd22a4-0dac-4855-8c4a-f5adec0e20ee, raftlog=5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:38:00,227 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:00,228 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown LeaderElection
2019-09-28 05:38:00,232 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection7: begin an election at term 2 for -1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:38:00,232 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:38:00,232 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: change Leader from null to 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee at term 1 for becomeLeader, leader elected after 5092ms
2019-09-28 05:38:00,232 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: set configuration 0: [6629995f-1641-4578-a5be-5caf7dd19b87:192.168.151.82:42013], old=null at 0
2019-09-28 05:38:00,232 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:38:00,255 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection7: Election REJECTED; received 0 response(s) [] and 0 exception(s); 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:t2, leader=null, voted=175ec8cc-a85e-4fff-99f2-5f91abf68440, raftlog=175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:38:00,255 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:38:00,258 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:38:00,259 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:38:00,259 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:38:00,261 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:38:00,268 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/ratis/9a0ebe1f-1e60-4059-890e-fb265da78ed6/current/log_inprogress_0
2019-09-28 05:38:00,272 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 05:38:00,272 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:38:00,273 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:38:00,274 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown FollowerState
2019-09-28 05:38:00,275 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 05:38:00,275 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start FollowerState
2019-09-28 05:38:00,275 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(115)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:38:00,279 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 05:38:00,288 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:38:00,289 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:38:00,293 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 05:38:00,293 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:38:00,295 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 05:38:00,296 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 05:38:00,296 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:38:00,296 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:38:00,299 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start LeaderState
2019-09-28 05:38:00,299 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:00,301 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: set configuration 0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null at 0
2019-09-28 05:38:00,323 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: change Leader from 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee to null at term 2 for updateCurrentTerm
2019-09-28 05:38:00,324 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: changes role from    LEADER to FOLLOWER at term 2 for recognizeCandidate:175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:38:00,324 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown LeaderState
2019-09-28 05:38:00,328 [grpc-default-executor-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee-PendingRequests: sendNotLeaderResponses
2019-09-28 05:38:00,330 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start FollowerState
2019-09-28 05:38:00,334 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$385/1680748125@11c3809d] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D->59a0ddbb-27bd-43ff-9760-1c766f7e4b67-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 05:38:00,334 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$385/1680748125@2b73f2ec] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D->175ec8cc-a85e-4fff-99f2-5f91abf68440-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 05:38:00,338 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/current/log_inprogress_0
2019-09-28 05:38:00,344 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: Completed APPEND_ENTRIES, lastRequest: null
2019-09-28 05:38:00,344 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: Completed APPEND_ENTRIES, lastRequest: null
2019-09-28 05:38:00,348 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D->175ec8cc-a85e-4fff-99f2-5f91abf68440-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 05:38:00,348 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D->59a0ddbb-27bd-43ff-9760-1c766f7e4b67-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 05:38:00,353 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D->59a0ddbb-27bd-43ff-9760-1c766f7e4b67: nextIndex: updateUnconditionally 0 -> 0
2019-09-28 05:38:00,353 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D->175ec8cc-a85e-4fff-99f2-5f91abf68440: nextIndex: updateUnconditionally 0 -> 0
2019-09-28 05:38:00,387 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:01,388 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:02,389 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:03,390 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:04,391 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:05,264 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(106)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440:group-A179FEF59D3D changes to CANDIDATE, lastRpcTime:5060, electionTimeout:5059ms
2019-09-28 05:38:05,264 [Thread-249] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown FollowerState
2019-09-28 05:38:05,264 [Thread-249] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-09-28 05:38:05,265 [Thread-249] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start LeaderElection
2019-09-28 05:38:05,281 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8: begin an election at term 3 for -1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:38:05,287 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:38:05,287 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:38:05,287 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown FollowerState
2019-09-28 05:38:05,287 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown FollowerState
2019-09-28 05:38:05,288 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(115)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:38:05,288 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start FollowerState
2019-09-28 05:38:05,288 [Thread-257] INFO  impl.FollowerState (FollowerState.java:run(115)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:38:05,288 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: start FollowerState
2019-09-28 05:38:05,310 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8: Election PASSED; received 2 response(s) [175ec8cc-a85e-4fff-99f2-5f91abf68440<-5ecd22a4-0dac-4855-8c4a-f5adec0e20ee#0:FAIL-t3, 175ec8cc-a85e-4fff-99f2-5f91abf68440<-59a0ddbb-27bd-43ff-9760-1c766f7e4b67#0:OK-t3] and 0 exception(s); 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:t3, leader=null, voted=175ec8cc-a85e-4fff-99f2-5f91abf68440, raftlog=175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:38:05,310 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown LeaderElection
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: change Leader from null to 175ec8cc-a85e-4fff-99f2-5f91abf68440 at term 3 for becomeLeader, leader elected after 10172ms
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:38:05,312 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:38:05,315 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 05:38:05,315 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:38:05,315 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 05:38:05,315 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 05:38:05,316 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:38:05,316 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:38:05,317 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: start LeaderState
2019-09-28 05:38:05,318 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:05,318 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: set configuration 0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null at 0
2019-09-28 05:38:05,353 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: change Leader from null to 175ec8cc-a85e-4fff-99f2-5f91abf68440 at term 3 for appendEntries, leader elected after 10213ms
2019-09-28 05:38:05,353 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: change Leader from null to 175ec8cc-a85e-4fff-99f2-5f91abf68440 at term 3 for appendEntries, leader elected after 5029ms
2019-09-28 05:38:05,357 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/current/log_inprogress_0
2019-09-28 05:38:05,381 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: set configuration 0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null at 0
2019-09-28 05:38:05,381 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: set configuration 0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null at 0
2019-09-28 05:38:05,382 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:05,384 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:truncate(396)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: Truncating segments toTruncate: null
  toDelete: [(0, 0) isOpen? true, length=0, newEndIndex=-1], start index 0
2019-09-28 05:38:05,385 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:38:05,386 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(633)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: Deleted log file /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/current/log_inprogress_0
2019-09-28 05:38:05,386 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:38:05,393 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:05,423 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/current/log_inprogress_0
2019-09-28 05:38:05,423 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/ratis/bd5ef748-74b5-44f7-a589-a179fef59d3d/current/log_inprogress_0
2019-09-28 05:38:06,398 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:07,399 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:08,401 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:09,402 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:10,403 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:11,404 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:12,406 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:13,408 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:14,409 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:15,411 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:15,413 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-28 05:38:16,414 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:17,415 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:18,417 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:19,419 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:20,420 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:21,421 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:22,423 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:23,424 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:24,425 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:25,427 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:25,428 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-28 05:38:26,430 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:27,431 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:28,432 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:29,434 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:30,435 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:31,437 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:32,438 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:33,439 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:34,441 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:35,442 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:35,443 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-28 05:38:36,445 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:37,446 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:38,448 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:39,449 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:40,450 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:41,451 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:42,453 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:43,454 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:44,455 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:45,457 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:45,459 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-28 05:38:46,460 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:47,461 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:48,463 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:49,464 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:50,465 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:51,467 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:52,468 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:53,469 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:54,470 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:55,471 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:55,473 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-28 05:38:56,473 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:57,475 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:58,476 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:38:59,477 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:00,478 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:01,479 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:02,481 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:03,482 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:04,483 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:05,484 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:05,485 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-28 05:39:06,486 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:07,487 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:08,489 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:09,490 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:10,491 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:11,492 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:12,495 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:13,496 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:14,497 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:15,498 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:15,500 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-28 05:39:16,501 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:17,502 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:18,504 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:19,505 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:20,506 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:21,507 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:22,509 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:23,510 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:24,511 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:25,512 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:25,514 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-28 05:39:26,515 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:27,517 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:28,521 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:29,522 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:30,523 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:31,524 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:32,526 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:33,527 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:34,528 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:35,529 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:35,531 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-28 05:39:36,532 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:37,533 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:38,534 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:39,536 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:40,537 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:41,539 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:42,540 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:43,541 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:44,542 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:45,544 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:45,545 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-28 05:39:45,547 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-28 05:39:45,562 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-28 05:39:46,565 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:47,567 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:48,568 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:49,569 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:50,570 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:51,571 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:52,572 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:53,573 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:54,574 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:55,575 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:56,577 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:57,579 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:58,580 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:39:59,581 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:00,582 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:01,584 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:02,585 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:03,586 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:04,588 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:05,589 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:05,590 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-28 05:40:06,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:07,593 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:08,594 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:09,595 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:10,596 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:11,598 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:12,599 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:13,608 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:14,611 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:15,613 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:15,615 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-28 05:40:16,616 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:17,618 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:18,619 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:19,621 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:20,622 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:21,623 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:22,624 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:23,625 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:24,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:25,627 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:25,629 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-28 05:40:26,631 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:27,632 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:28,633 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:29,634 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:30,636 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:31,637 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:32,638 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:33,639 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:34,640 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:35,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:35,644 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-28 05:40:36,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:37,647 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:38,648 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:39,650 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:40,651 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:41,653 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:42,655 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:43,656 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:44,657 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:45,659 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:45,660 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-28 05:40:46,661 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:47,662 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:48,664 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:49,665 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:50,666 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:51,667 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:52,668 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:53,669 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:54,671 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:55,672 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:55,674 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-28 05:40:56,686 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:57,688 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:58,690 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:40:59,692 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:00,693 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:01,695 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:02,696 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:03,697 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:04,699 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:05,701 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:05,702 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-28 05:41:06,703 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:07,705 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:08,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:09,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:10,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:11,711 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:12,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:13,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:14,716 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:15,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:15,719 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-28 05:41:16,721 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:17,722 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:18,723 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:19,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:20,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:21,728 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:22,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:23,731 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:24,732 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:25,733 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:25,735 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-28 05:41:26,736 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:27,737 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:28,738 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:29,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:30,740 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:31,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:32,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:33,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:34,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:35,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:41:35,749 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-28 05:41:35,750 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-28 05:41:35,754 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-28 05:41:35,755 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-28 05:41:35,755 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-28 05:41:35,755 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33207
2019-09-28 05:41:35,771 [IPC Server listener on 33207] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33207
2019-09-28 05:41:35,781 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-28 05:41:35,783 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:41:35,783 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-28 05:41:35,786 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-28 05:41:35,793 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ac7aa18{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-28 05:41:35,801 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4cdd2c73{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:35,801 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@319854f0{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:35,802 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@529cfee5{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:36,214 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-28 05:41:37,203 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:41:37,203 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:41:41,218 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:41:41,218 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:41:41,219 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: close
2019-09-28 05:41:41,219 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: close
2019-09-28 05:41:41,222 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: shutdown
2019-09-28 05:41:41,222 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: shutdown
2019-09-28 05:41:41,222 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F3F3DE8A6BA0,id=175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:41:41,222 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A179FEF59D3D,id=5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:41:41,223 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown LeaderState
2019-09-28 05:41:41,223 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown FollowerState
2019-09-28 05:41:41,224 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440-PendingRequests: sendNotLeaderResponses
2019-09-28 05:41:41,225 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(115)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:41:41,225 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:41,226 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:41,229 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D: closes. applyIndex: 0
2019-09-28 05:41:41,231 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0: closes. applyIndex: 0
2019-09-28 05:41:41,232 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:41,232 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:41,235 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-A179FEF59D3D-SegmentedRaftLogWorker close()
2019-09-28 05:41:41,236 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-F3F3DE8A6BA0-SegmentedRaftLogWorker close()
2019-09-28 05:41:41,238 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: shutdown
2019-09-28 05:41:41,241 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: shutdown
2019-09-28 05:41:41,241 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B87664FE6DDA,id=5ecd22a4-0dac-4855-8c4a-f5adec0e20ee
2019-09-28 05:41:41,241 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A179FEF59D3D,id=175ec8cc-a85e-4fff-99f2-5f91abf68440
2019-09-28 05:41:41,242 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown LeaderState
2019-09-28 05:41:41,242 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown LeaderState
2019-09-28 05:41:41,242 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee-PendingRequests: sendNotLeaderResponses
2019-09-28 05:41:41,245 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$385/1680748125@7003edba] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D->59a0ddbb-27bd-43ff-9760-1c766f7e4b67-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 05:41:41,245 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440-PendingRequests: sendNotLeaderResponses
2019-09-28 05:41:41,245 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$385/1680748125@7efd0c95] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D->5ecd22a4-0dac-4855-8c4a-f5adec0e20ee-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 05:41:41,253 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:41,253 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: Completed APPEND_ENTRIES, lastRequest: 175ec8cc-a85e-4fff-99f2-5f91abf68440->59a0ddbb-27bd-43ff-9760-1c766f7e4b67#87-t3, previous=(t:3, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 05:41:41,253 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D: closes. applyIndex: 0
2019-09-28 05:41:41,245 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:41,254 [175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:41,253 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: Completed APPEND_ENTRIES, lastRequest: 175ec8cc-a85e-4fff-99f2-5f91abf68440->5ecd22a4-0dac-4855-8c4a-f5adec0e20ee#87-t3, previous=(t:3, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 05:41:41,254 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA: closes. applyIndex: 0
2019-09-28 05:41:41,256 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D->59a0ddbb-27bd-43ff-9760-1c766f7e4b67-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 05:41:41,256 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D-SegmentedRaftLogWorker close()
2019-09-28 05:41:41,259 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D->59a0ddbb-27bd-43ff-9760-1c766f7e4b67: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 05:41:41,257 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D->5ecd22a4-0dac-4855-8c4a-f5adec0e20ee-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 05:41:41,256 [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:41,264 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown server with port 42668 now
2019-09-28 05:41:41,264 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440@group-A179FEF59D3D->5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 05:41:41,267 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee@group-B87664FE6DDA-SegmentedRaftLogWorker close()
2019-09-28 05:41:41,270 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown server with port 46635 now
2019-09-28 05:41:41,272 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 175ec8cc-a85e-4fff-99f2-5f91abf68440: shutdown server with port 42668 successfully
2019-09-28 05:41:41,272 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 5ecd22a4-0dac-4855-8c4a-f5adec0e20ee: shutdown server with port 46635 successfully
2019-09-28 05:41:41,275 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:41:41,278 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:41:41,304 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:41:41,309 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:41:41,310 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72f9f27c{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:41:41,311 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c1bdcc2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:41,311 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@784abd3e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:41,312 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:41:41,313 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6342d610{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:41,316 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:41:41,319 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7100dea{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:41:41,320 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@712cfb63{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:41,321 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cff61fc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:41,323 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b5e7036{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:41,782 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:41:42,210 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:41:46,316 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:41:46,317 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 6629995f-1641-4578-a5be-5caf7dd19b87: close
2019-09-28 05:41:46,318 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: shutdown
2019-09-28 05:41:46,318 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FB265DA78ED6,id=6629995f-1641-4578-a5be-5caf7dd19b87
2019-09-28 05:41:46,319 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6629995f-1641-4578-a5be-5caf7dd19b87: shutdown LeaderState
2019-09-28 05:41:46,319 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6629995f-1641-4578-a5be-5caf7dd19b87-PendingRequests: sendNotLeaderResponses
2019-09-28 05:41:46,320 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:46,322 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6: closes. applyIndex: 0
2019-09-28 05:41:46,323 [6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:46,325 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6629995f-1641-4578-a5be-5caf7dd19b87@group-FB265DA78ED6-SegmentedRaftLogWorker close()
2019-09-28 05:41:46,325 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:41:46,327 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 6629995f-1641-4578-a5be-5caf7dd19b87: shutdown server with port 42013 now
2019-09-28 05:41:46,328 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: close
2019-09-28 05:41:46,329 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: shutdown
2019-09-28 05:41:46,329 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 6629995f-1641-4578-a5be-5caf7dd19b87: shutdown server with port 42013 successfully
2019-09-28 05:41:46,330 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FB7B68F99F64,id=7d65ca33-c851-4cee-940b-14c0a4ae5542
2019-09-28 05:41:46,331 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: shutdown LeaderState
2019-09-28 05:41:46,331 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542-PendingRequests: sendNotLeaderResponses
2019-09-28 05:41:46,332 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:46,333 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64: closes. applyIndex: 0
2019-09-28 05:41:46,334 [7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:46,337 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542@group-FB7B68F99F64-SegmentedRaftLogWorker close()
2019-09-28 05:41:46,343 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:41:46,343 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: shutdown server with port 46560 now
2019-09-28 05:41:46,345 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 7d65ca33-c851-4cee-940b-14c0a4ae5542: shutdown server with port 46560 successfully
2019-09-28 05:41:46,354 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:41:46,366 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:41:46,369 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:41:46,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f9a6c2d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:41:46,371 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:41:46,372 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b6fcb9f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:46,372 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b7962a2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:46,374 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:41:46,375 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ff23ae7{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:46,378 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f1d0bbc{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:41:46,379 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5460b754{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:46,380 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@623dcf2a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:46,381 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e33d73e{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:47,209 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:41:49,332 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(106)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:group-A179FEF59D3D changes to CANDIDATE, lastRpcTime:8121, electionTimeout:5037ms
2019-09-28 05:41:49,333 [Thread-261] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown FollowerState
2019-09-28 05:41:49,333 [Thread-261] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2019-09-28 05:41:49,333 [Thread-261] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start LeaderElection
2019-09-28 05:41:49,335 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: change Leader from 175ec8cc-a85e-4fff-99f2-5f91abf68440 to null at term 3 for initElection
2019-09-28 05:41:49,349 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9: begin an election at term 4 for 0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:41:49,366 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.151.82:46635
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-28 05:41:49,368 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.151.82:42668
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-28 05:41:49,369 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9: Election REJECTED; received 0 response(s) [] and 2 exception(s); 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:t4, leader=null, voted=59a0ddbb-27bd-43ff-9760-1c766f7e4b67, raftlog=59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [5ecd22a4-0dac-4855-8c4a-f5adec0e20ee:192.168.151.82:46635, 59a0ddbb-27bd-43ff-9760-1c766f7e4b67:192.168.151.82:39331, 175ec8cc-a85e-4fff-99f2-5f91abf68440:192.168.151.82:42668], old=null
2019-09-28 05:41:49,370 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.151.82:46635
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-28 05:41:49,370 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.151.82:42668
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-28 05:41:49,372 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: changes role from CANDIDATE to FOLLOWER at term 4 for DISCOVERED_A_NEW_TERM
2019-09-28 05:41:49,373 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown LeaderElection
2019-09-28 05:41:49,373 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: start FollowerState
2019-09-28 05:41:51,378 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:41:51,380 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: close
2019-09-28 05:41:51,381 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: shutdown
2019-09-28 05:41:51,381 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: shutdown
2019-09-28 05:41:51,381 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-416EFD5EE8DB,id=59a0ddbb-27bd-43ff-9760-1c766f7e4b67
2019-09-28 05:41:51,382 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown LeaderState
2019-09-28 05:41:51,381 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A179FEF59D3D,id=59a0ddbb-27bd-43ff-9760-1c766f7e4b67
2019-09-28 05:41:51,382 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67-PendingRequests: sendNotLeaderResponses
2019-09-28 05:41:51,382 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown FollowerState
2019-09-28 05:41:51,383 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:51,383 [Thread-484] INFO  impl.FollowerState (FollowerState.java:run(115)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:41:51,384 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB: closes. applyIndex: 0
2019-09-28 05:41:51,383 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:41:51,385 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:51,385 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D: closes. applyIndex: 0
2019-09-28 05:41:51,386 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-416EFD5EE8DB-SegmentedRaftLogWorker close()
2019-09-28 05:41:51,386 [59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:41:51,389 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67@group-A179FEF59D3D-SegmentedRaftLogWorker close()
2019-09-28 05:41:51,390 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown server with port 39331 now
2019-09-28 05:41:51,394 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 59a0ddbb-27bd-43ff-9760-1c766f7e4b67: shutdown server with port 39331 successfully
2019-09-28 05:41:51,406 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-f29b7757-bce0-404a-8cb2-455bc9c57774/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:41:51,417 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:41:51,420 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:41:51,421 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4228bf58{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:41:51,422 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@68b9834c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:51,422 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@176996c3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:51,423 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1859e2a4{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:51,423 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-28 05:41:51,423 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-28 05:41:51,423 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-28 05:41:51,424 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-28 05:41:51,424 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-28 05:41:51,424 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-28 05:41:51,424 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36550
2019-09-28 05:41:51,426 [IPC Server listener on 36550] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36550
2019-09-28 05:41:51,426 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:41:51,523 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-28 05:41:51,524 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-28 05:41:51,524 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-28 05:41:51,524 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35554
2019-09-28 05:41:51,526 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-28 05:41:51,526 [IPC Server listener on 35554] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35554
2019-09-28 05:41:51,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:41:51,526 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(158)) - Stopping the RPC server for Client Protocol
2019-09-28 05:41:51,527 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44417
2019-09-28 05:41:51,529 [IPC Server listener on 44417] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44417
2019-09-28 05:41:51,529 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-28 05:41:51,530 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:41:51,531 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58c540cf{/,null,UNAVAILABLE}{/scm}
2019-09-28 05:41:51,532 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1cf2fed4{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:41:51,532 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@42f8285e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:41:51,533 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d2bd371{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:41:51,533 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-28 05:41:51,533 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 05:41:51,534 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 05:41:51,534 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-28 05:41:51,542 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-28 05:41:51,550 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-28 05:41:51,551 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
