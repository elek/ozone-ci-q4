2019-09-28 05:41:52,973 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:53,077 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:53,081 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:53,099 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @931ms
2019-09-28 05:41:53,203 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-28 05:41:53,203 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-28 05:41:53,204 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-28 05:41:53,204 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-28 05:41:53,204 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-28 05:41:53,205 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-28 05:41:53,216 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 05:41:53,216 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 05:41:53,217 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 05:41:53,519 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@34123d65
2019-09-28 05:41:53,521 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-28 05:41:53,597 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-28 05:41:53,673 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-28 05:41:53,688 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:53,782 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-28 05:41:53,786 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:53,922 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-28 05:41:54,317 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:41:54,346 [Socket Reader #1 for port 33502] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33502
2019-09-28 05:41:54,500 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:41:54,502 [Socket Reader #1 for port 46650] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46650
2019-09-28 05:41:54,514 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:41:54,515 [Socket Reader #1 for port 35494] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35494
2019-09-28 05:41:54,546 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-28 05:41:54,705 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:41:54,722 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:41:54,731 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:41:54,734 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-28 05:41:54,734 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:41:54,735 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:41:54,764 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35494
2019-09-28 05:41:54,815 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-28 05:41:54,828 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-28 05:41:54,828 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-28 05:41:55,050 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(150)) - RPC server for Client  is listening at /0.0.0.0:35494
2019-09-28 05:41:55,051 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:41:55,051 [IPC Server listener on 35494] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35494: starting
2019-09-28 05:41:55,055 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:46650
2019-09-28 05:41:55,057 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:46650
2019-09-28 05:41:55,057 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:41:55,058 [IPC Server listener on 46650] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46650: starting
2019-09-28 05:41:55,061 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33502
2019-09-28 05:41:55,061 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:33502
2019-09-28 05:41:55,061 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:41:55,061 [IPC Server listener on 33502] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33502: starting
2019-09-28 05:41:55,065 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43464
2019-09-28 05:41:55,067 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:41:55,102 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:41:55,103 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:41:55,176 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@544630b7{/,file:///tmp/jetty-0.0.0.0-43464-scm-_-any-7228537134933551724.dir/webapp/,AVAILABLE}{/scm}
2019-09-28 05:41:55,181 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:43464}
2019-09-28 05:41:55,181 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3014ms
2019-09-28 05:41:55,184 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-28 05:41:55,184 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-28 05:41:55,187 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:43464
2019-09-28 05:41:55,196 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@790174f2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:41:55,200 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:55,315 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-28 05:41:55,315 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-28 05:41:55,316 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:55,317 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:56,039 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-28 05:41:56,047 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-28 05:41:56,047 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-28 05:41:56,047 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-28 05:41:56,047 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-28 05:41:56,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-28 05:41:56,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-28 05:41:56,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-28 05:41:56,048 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-28 05:41:56,049 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-28 05:41:56,049 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-28 05:41:56,049 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-28 05:41:56,049 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-28 05:41:56,050 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-28 05:41:56,050 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-28 05:41:56,050 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-28 05:41:56,050 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-28 05:41:56,051 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-28 05:41:56,051 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-28 05:41:56,051 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-28 05:41:56,051 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-28 05:41:56,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-28 05:41:56,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-28 05:41:56,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-28 05:41:56,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-28 05:41:56,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-28 05:41:56,748 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-28 05:41:56,749 [Socket Reader #1 for port 40144] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40144
2019-09-28 05:41:56,773 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40144
2019-09-28 05:41:56,773 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-28 05:41:56,775 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-28 05:41:56,775 [IPC Server listener on 40144] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40144: starting
2019-09-28 05:41:56,780 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-28 05:41:56,783 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:41:56,784 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:41:56,786 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:41:56,788 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-28 05:41:56,788 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:41:56,788 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:41:56,791 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44995
2019-09-28 05:41:56,791 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:41:56,794 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:41:56,795 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cbb3d3b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:41:56,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e850122{/,file:///tmp/jetty-0.0.0.0-44995-ozoneManager-_-any-5010171121871620292.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-28 05:41:56,854 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27fde870{HTTP/1.1,[http/1.1]}{0.0.0.0:44995}
2019-09-28 05:41:56,855 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4687ms
2019-09-28 05:41:56,855 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:41:56,856 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:44995
2019-09-28 05:41:57,207 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:41:57,270 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:41:57,305 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:41:57,306 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/containers/hdds to VolumeSet
2019-09-28 05:41:57,309 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-28 05:41:57,326 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-28 05:41:57,438 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:41:57,506 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:41:57,511 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:41:57,512 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:41:57,513 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:41:57,514 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:41:57,515 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:41:57,688 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis] (custom)
2019-09-28 05:41:57,743 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:41:57,746 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:41:57,747 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:41:57,748 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:41:57,749 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:41:57,750 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:41:57,750 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:41:57,751 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42608
2019-09-28 05:41:57,752 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:41:57,754 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:41:57,755 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:41:57,803 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d910b3{/,file:///tmp/jetty-0.0.0.0-42608-hddsDatanode-_-any-2228944076405217314.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:41:57,805 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:42608}
2019-09-28 05:41:57,805 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5638ms
2019-09-28 05:41:57,806 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:41:57,807 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42608
2019-09-28 05:41:57,809 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:41:57,813 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:41:57,815 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fcc5ef4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:41:57,821 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:41:57,823 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/containers/hdds to VolumeSet
2019-09-28 05:41:57,823 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-28 05:41:57,824 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-28 05:41:57,847 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:41:57,847 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:41:57,848 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:41:57,848 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:41:57,849 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:41:57,849 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:41:57,849 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:41:57,850 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis] (custom)
2019-09-28 05:41:57,853 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:41:57,854 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:41:57,855 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:41:57,857 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:41:57,858 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:41:57,858 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:41:57,858 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:41:57,859 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45814
2019-09-28 05:41:57,860 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:41:57,864 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:41:57,865 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:41:57,897 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28da7d11{/,file:///tmp/jetty-0.0.0.0-45814-hddsDatanode-_-any-4574796822413707919.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:41:57,899 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:45814}
2019-09-28 05:41:57,901 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5733ms
2019-09-28 05:41:57,901 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:41:57,902 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45814
2019-09-28 05:41:57,903 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-28 05:41:57,906 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f2a304f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:41:57,906 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-8g7kw-3348123894 ip:192.168.151.82
2019-09-28 05:41:57,914 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-28 05:41:57,914 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/containers/hdds to VolumeSet
2019-09-28 05:41:57,915 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@40e37b06
2019-09-28 05:41:57,915 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@40e37b06
2019-09-28 05:41:57,930 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-28 05:41:57,931 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-28 05:41:57,931 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-28 05:41:57,932 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-28 05:41:57,932 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:41:57,933 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-28 05:41:57,933 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:41:57,934 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis] (custom)
2019-09-28 05:41:57,936 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-28 05:41:57,937 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-28 05:41:57,937 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-28 05:41:57,938 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/meta/datanode.id
2019-09-28 05:41:57,941 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/meta/datanode.id
2019-09-28 05:41:57,942 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 05:41:57,943 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-28 05:41:57,943 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 05:41:57,944 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 05:41:57,945 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33670
2019-09-28 05:41:57,945 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-28 05:41:57,952 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588f63c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-28 05:41:57,954 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1981d861{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-28 05:41:57,989 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@41eb94bc{/,file:///tmp/jetty-0.0.0.0-33670-hddsDatanode-_-any-3832738497639003024.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-28 05:41:57,991 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@378cfecf{HTTP/1.1,[http/1.1]}{0.0.0.0:33670}
2019-09-28 05:41:57,992 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5824ms
2019-09-28 05:41:57,992 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-28 05:41:57,993 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33670
2019-09-28 05:41:57,996 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75662268] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-28 05:41:57,997 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 05:41:58,002 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/meta/datanode.id
2019-09-28 05:41:58,998 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 05:41:59,872 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:41:59,875 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:41:59,875 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis db2345f5-3244-4519-8080-7868dac645ff at port 0
2019-09-28 05:41:59,895 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - db2345f5-3244-4519-8080-7868dac645ff: start RPC server
2019-09-28 05:41:59,922 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:41:59,927 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:41:59,927 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f at port 0
2019-09-28 05:41:59,937 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start RPC server
2019-09-28 05:41:59,998 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 05:42:00,013 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-28 05:42:00,015 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-28 05:42:00,015 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b6225337-d522-49ee-b186-fb6fa5e92794 at port 0
2019-09-28 05:42:00,025 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b6225337-d522-49ee-b186-fb6fa5e92794: start RPC server
2019-09-28 05:42:00,065 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - db2345f5-3244-4519-8080-7868dac645ff: GrpcService started, listening on 0.0.0.0/0.0.0.0:36474
2019-09-28 05:42:00,065 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: GrpcService started, listening on 0.0.0.0/0.0.0.0:41056
2019-09-28 05:42:00,065 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b6225337-d522-49ee-b186-fb6fa5e92794: GrpcService started, listening on 0.0.0.0/0.0.0.0:45249
2019-09-28 05:42:00,066 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f is started using port 41056
2019-09-28 05:42:00,065 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis db2345f5-3244-4519-8080-7868dac645ff is started using port 36474
2019-09-28 05:42:00,066 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b6225337-d522-49ee-b186-fb6fa5e92794 is started using port 45249
2019-09-28 05:42:00,072 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f is started using port 43246
2019-09-28 05:42:00,072 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b6225337-d522-49ee-b186-fb6fa5e92794 is started using port 36704
2019-09-28 05:42:00,072 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc db2345f5-3244-4519-8080-7868dac645ff is started using port 33637
2019-09-28 05:42:00,999 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-28 05:42:01,859 [IPC Server handler 1 on 33502] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/db2345f5-3244-4519-8080-7868dac645ff
2019-09-28 05:42:01,860 [IPC Server handler 1 on 33502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : db2345f5-3244-4519-8080-7868dac645ff{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:42:01,864 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-28 05:42:01,864 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-28 05:42:01,864 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-28 05:42:01,911 [IPC Server handler 2 on 33502] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f
2019-09-28 05:42:01,911 [IPC Server handler 2 on 33502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:42:01,999 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-28 05:42:02,000 [IPC Server handler 3 on 33502] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b6225337-d522-49ee-b186-fb6fa5e92794
2019-09-28 05:42:02,000 [IPC Server handler 3 on 33502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b6225337-d522-49ee-b186-fb6fa5e92794{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}
2019-09-28 05:42:02,363 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db2345f5-3244-4519-8080-7868dac645ff: addNew group-4D132C569727:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474] returns group-4D132C569727:java.util.concurrent.CompletableFuture@366e68b5[Not completed]
2019-09-28 05:42:02,380 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - db2345f5-3244-4519-8080-7868dac645ff: new RaftServerImpl for group-4D132C569727:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474] with ContainerStateMachine:uninitialized
2019-09-28 05:42:02,383 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:42:02,384 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:42:02,385 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:42:02,386 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:42:02,387 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:02,397 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: ConfigurationManager, init=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474], old=null, confs=<EMPTY_MAP>
2019-09-28 05:42:02,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis] (custom)
2019-09-28 05:42:02,407 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e57e007c-8983-4cde-88d0-4d132c569727 does not exist. Creating ...
2019-09-28 05:42:02,425 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e57e007c-8983-4cde-88d0-4d132c569727/in_use.lock acquired by nodename 18878@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:42:02,441 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e57e007c-8983-4cde-88d0-4d132c569727 has been successfully formatted.
2019-09-28 05:42:02,444 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4D132C569727: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:42:02,445 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:42:02,447 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:42:02,454 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:42:02,454 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:02,456 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,461 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:42:02,467 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e57e007c-8983-4cde-88d0-4d132c569727
2019-09-28 05:42:02,468 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-28 05:42:02,474 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-28 05:42:02,502 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:42:02,503 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:42:02,506 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,506 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:42:02,507 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:42:02,507 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:42:02,508 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:42:02,508 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:42:02,509 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:42:02,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:42:02,522 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:42:02,526 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:42:02,526 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:42:02,527 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:42:02,527 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:42:02,552 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: start as a follower, conf=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474], old=null
2019-09-28 05:42:02,553 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:42:02,554 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db2345f5-3244-4519-8080-7868dac645ff: start FollowerState
2019-09-28 05:42:02,556 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4D132C569727,id=db2345f5-3244-4519-8080-7868dac645ff
2019-09-28 05:42:02,614 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e57e007c-8983-4cde-88d0-4d132c569727, Nodes: db2345f5-3244-4519-8080-7868dac645ff{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:42:02,632 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b6225337-d522-49ee-b186-fb6fa5e92794: addNew group-D0F8DB585A3F:[b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249] returns group-D0F8DB585A3F:java.util.concurrent.CompletableFuture@8ca98c6[Not completed]
2019-09-28 05:42:02,667 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b6225337-d522-49ee-b186-fb6fa5e92794: new RaftServerImpl for group-D0F8DB585A3F:[b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249] with ContainerStateMachine:uninitialized
2019-09-28 05:42:02,669 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:42:02,669 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:42:02,669 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:42:02,669 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:42:02,670 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:02,670 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: ConfigurationManager, init=-1: [b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249], old=null, confs=<EMPTY_MAP>
2019-09-28 05:42:02,670 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis] (custom)
2019-09-28 05:42:02,671 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/50739ec2-2514-45d2-8011-d0f8db585a3f does not exist. Creating ...
2019-09-28 05:42:02,685 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/50739ec2-2514-45d2-8011-d0f8db585a3f/in_use.lock acquired by nodename 18878@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:42:02,705 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/50739ec2-2514-45d2-8011-d0f8db585a3f has been successfully formatted.
2019-09-28 05:42:02,706 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D0F8DB585A3F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:42:02,707 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:42:02,708 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:42:02,708 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:42:02,708 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:02,708 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,709 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:42:02,709 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/50739ec2-2514-45d2-8011-d0f8db585a3f
2019-09-28 05:42:02,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:42:02,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:42:02,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,717 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:42:02,718 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:42:02,718 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:42:02,718 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:42:02,718 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:42:02,718 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:42:02,719 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:42:02,719 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:42:02,720 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:42:02,720 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:42:02,720 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:42:02,721 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:42:02,727 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: start as a follower, conf=-1: [b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249], old=null
2019-09-28 05:42:02,727 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:42:02,727 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b6225337-d522-49ee-b186-fb6fa5e92794: start FollowerState
2019-09-28 05:42:02,729 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D0F8DB585A3F,id=b6225337-d522-49ee-b186-fb6fa5e92794
2019-09-28 05:42:02,742 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 50739ec2-2514-45d2-8011-d0f8db585a3f, Nodes: b6225337-d522-49ee-b186-fb6fa5e92794{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:42:02,760 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: addNew group-0B9DAB814119:[de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] returns group-0B9DAB814119:java.util.concurrent.CompletableFuture@7a7d0d5d[Not completed]
2019-09-28 05:42:02,777 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: new RaftServerImpl for group-0B9DAB814119:[de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] with ContainerStateMachine:uninitialized
2019-09-28 05:42:02,778 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:42:02,779 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:42:02,779 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:42:02,779 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:42:02,780 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:02,780 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: ConfigurationManager, init=-1: [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null, confs=<EMPTY_MAP>
2019-09-28 05:42:02,780 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis] (custom)
2019-09-28 05:42:02,781 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/d3a562ee-fcb8-4ecd-a600-0b9dab814119 does not exist. Creating ...
2019-09-28 05:42:02,794 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/d3a562ee-fcb8-4ecd-a600-0b9dab814119/in_use.lock acquired by nodename 18878@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:42:02,808 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/d3a562ee-fcb8-4ecd-a600-0b9dab814119 has been successfully formatted.
2019-09-28 05:42:02,808 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0B9DAB814119: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:42:02,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:42:02,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:42:02,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:42:02,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:02,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:42:02,810 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/d3a562ee-fcb8-4ecd-a600-0b9dab814119
2019-09-28 05:42:02,839 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:42:02,839 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:42:02,839 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,840 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:42:02,840 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:42:02,840 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:42:02,840 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:42:02,840 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:42:02,841 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:42:02,841 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:42:02,842 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:42:02,842 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:42:02,842 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:42:02,843 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:42:02,843 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:42:02,849 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: start as a follower, conf=-1: [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:02,849 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:42:02,849 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start FollowerState
2019-09-28 05:42:02,850 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B9DAB814119,id=de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f
2019-09-28 05:42:02,862 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d3a562ee-fcb8-4ecd-a600-0b9dab814119, Nodes: de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-28 05:42:02,891 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: addNew group-548B1EAFF199:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] returns group-548B1EAFF199:java.util.concurrent.CompletableFuture@6a0a5d2b[Not completed]
2019-09-28 05:42:02,894 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b6225337-d522-49ee-b186-fb6fa5e92794: addNew group-548B1EAFF199:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] returns group-548B1EAFF199:java.util.concurrent.CompletableFuture@2b375710[Not completed]
2019-09-28 05:42:02,894 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db2345f5-3244-4519-8080-7868dac645ff: addNew group-548B1EAFF199:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] returns group-548B1EAFF199:java.util.concurrent.CompletableFuture@b2c44a7[Not completed]
2019-09-28 05:42:02,896 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: new RaftServerImpl for group-548B1EAFF199:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] with ContainerStateMachine:uninitialized
2019-09-28 05:42:02,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:42:02,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:42:02,896 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:42:02,897 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:42:02,897 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - db2345f5-3244-4519-8080-7868dac645ff: new RaftServerImpl for group-548B1EAFF199:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] with ContainerStateMachine:uninitialized
2019-09-28 05:42:02,897 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:02,897 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:42:02,897 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: ConfigurationManager, init=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null, confs=<EMPTY_MAP>
2019-09-28 05:42:02,897 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:42:02,897 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis] (custom)
2019-09-28 05:42:02,897 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b6225337-d522-49ee-b186-fb6fa5e92794: new RaftServerImpl for group-548B1EAFF199:[db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056] with ContainerStateMachine:uninitialized
2019-09-28 05:42:02,897 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:42:02,898 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-28 05:42:02,898 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:42:02,898 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-28 05:42:02,898 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199 does not exist. Creating ...
2019-09-28 05:42:02,898 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-28 05:42:02,898 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:02,898 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-28 05:42:02,898 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: ConfigurationManager, init=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null, confs=<EMPTY_MAP>
2019-09-28 05:42:02,898 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:02,899 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis] (custom)
2019-09-28 05:42:02,899 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: ConfigurationManager, init=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null, confs=<EMPTY_MAP>
2019-09-28 05:42:02,899 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis] (custom)
2019-09-28 05:42:02,899 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199 does not exist. Creating ...
2019-09-28 05:42:02,899 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199 does not exist. Creating ...
2019-09-28 05:42:02,912 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199/in_use.lock acquired by nodename 18878@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:42:02,912 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199/in_use.lock acquired by nodename 18878@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:42:02,912 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199/in_use.lock acquired by nodename 18878@pr-hdds-2162-8g7kw-3348123894
2019-09-28 05:42:02,926 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199 has been successfully formatted.
2019-09-28 05:42:02,926 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-548B1EAFF199: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:42:02,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:42:02,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:42:02,926 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199 has been successfully formatted.
2019-09-28 05:42:02,926 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199 has been successfully formatted.
2019-09-28 05:42:02,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:42:02,927 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-548B1EAFF199: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:42:02,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:02,927 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-548B1EAFF199: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-28 05:42:02,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,927 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:42:02,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:42:02,928 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-28 05:42:02,928 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199
2019-09-28 05:42:02,928 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:42:02,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:42:02,928 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:42:02,928 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-28 05:42:02,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:02,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:42:02,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,929 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-28 05:42:02,929 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:42:02,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,929 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199
2019-09-28 05:42:02,929 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:02,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:42:02,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:42:02,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:42:02,930 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:42:02,930 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:42:02,930 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-28 05:42:02,931 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:42:02,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:42:02,931 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:42:02,931 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199
2019-09-28 05:42:02,931 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:42:02,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:42:02,931 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:42:02,931 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-28 05:42:02,932 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:42:02,932 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:42:02,932 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:42:02,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-28 05:42:02,932 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:42:02,932 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:42:02,932 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-28 05:42:02,933 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:42:02,933 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:42:02,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-28 05:42:02,933 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:42:02,933 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:42:02,933 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-28 05:42:02,934 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:42:02,934 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:42:02,934 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:42:02,934 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-28 05:42:02,934 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:42:02,935 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-28 05:42:02,935 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:42:02,935 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-28 05:42:02,935 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:42:02,935 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-28 05:42:02,936 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-28 05:42:02,936 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-28 05:42:02,937 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-28 05:42:02,937 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-28 05:42:02,937 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-28 05:42:02,937 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-28 05:42:02,940 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: start as a follower, conf=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:02,940 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:42:02,941 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start FollowerState
2019-09-28 05:42:02,941 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-548B1EAFF199,id=de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f
2019-09-28 05:42:02,944 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: start as a follower, conf=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:02,945 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:42:02,946 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db2345f5-3244-4519-8080-7868dac645ff: start FollowerState
2019-09-28 05:42:02,947 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: start as a follower, conf=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:02,947 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-548B1EAFF199,id=db2345f5-3244-4519-8080-7868dac645ff
2019-09-28 05:42:02,948 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-28 05:42:02,949 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b6225337-d522-49ee-b186-fb6fa5e92794: start FollowerState
2019-09-28 05:42:02,950 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-548B1EAFF199,id=b6225337-d522-49ee-b186-fb6fa5e92794
2019-09-28 05:42:02,964 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e0911c4e-dc02-46a1-b22b-548b1eaff199, Nodes: db2345f5-3244-4519-8080-7868dac645ff{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}b6225337-d522-49ee-b186-fb6fa5e92794{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f{ip: 192.168.151.82, host: pr-hdds-2162-8g7kw-3348123894, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-28 05:42:03,000 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-28 05:42:04,193 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:04,927 [Thread-178] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-28 05:42:04,931 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-28 05:42:05,194 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:06,196 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:07,197 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:07,622 [Thread-180] INFO  impl.FollowerState (FollowerState.java:run(106)) - db2345f5-3244-4519-8080-7868dac645ff:group-4D132C569727 changes to CANDIDATE, lastRpcTime:5067, electionTimeout:5067ms
2019-09-28 05:42:07,625 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown FollowerState
2019-09-28 05:42:07,625 [Thread-180] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:42:07,633 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db2345f5-3244-4519-8080-7868dac645ff: start LeaderElection
2019-09-28 05:42:07,651 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1: begin an election at term 1 for -1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474], old=null
2019-09-28 05:42:07,653 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown LeaderElection
2019-09-28 05:42:07,654 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:42:07,655 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: change Leader from null to db2345f5-3244-4519-8080-7868dac645ff at term 1 for becomeLeader, leader elected after 5209ms
2019-09-28 05:42:07,663 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:42:07,663 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:42:07,668 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:42:07,672 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:42:07,672 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:42:07,674 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:42:07,690 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db2345f5-3244-4519-8080-7868dac645ff: start LeaderState
2019-09-28 05:42:07,715 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:42:07,724 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: set configuration 0: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474], old=null at 0
2019-09-28 05:42:07,768 [Thread-183] INFO  impl.FollowerState (FollowerState.java:run(106)) - b6225337-d522-49ee-b186-fb6fa5e92794:group-D0F8DB585A3F changes to CANDIDATE, lastRpcTime:5040, electionTimeout:5039ms
2019-09-28 05:42:07,769 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown FollowerState
2019-09-28 05:42:07,770 [Thread-183] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:42:07,770 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b6225337-d522-49ee-b186-fb6fa5e92794: start LeaderElection
2019-09-28 05:42:07,787 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2: begin an election at term 1 for -1: [b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249], old=null
2019-09-28 05:42:07,788 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown LeaderElection
2019-09-28 05:42:07,789 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:42:07,789 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: change Leader from null to b6225337-d522-49ee-b186-fb6fa5e92794 at term 1 for becomeLeader, leader elected after 5081ms
2019-09-28 05:42:07,789 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:42:07,789 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:42:07,789 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:42:07,790 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:42:07,790 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:42:07,790 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:42:07,795 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b6225337-d522-49ee-b186-fb6fa5e92794: start LeaderState
2019-09-28 05:42:07,796 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:42:07,796 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: set configuration 0: [b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249], old=null at 0
2019-09-28 05:42:07,915 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:group-0B9DAB814119 changes to CANDIDATE, lastRpcTime:5065, electionTimeout:5059ms
2019-09-28 05:42:07,919 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown FollowerState
2019-09-28 05:42:07,919 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:42:07,919 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start LeaderElection
2019-09-28 05:42:07,944 [Thread-191] INFO  impl.FollowerState (FollowerState.java:run(106)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:group-548B1EAFF199 changes to CANDIDATE, lastRpcTime:5003, electionTimeout:5003ms
2019-09-28 05:42:07,944 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown FollowerState
2019-09-28 05:42:07,945 [Thread-191] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:42:07,945 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start LeaderElection
2019-09-28 05:42:07,967 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3: begin an election at term 1 for -1: [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:07,967 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown LeaderElection
2019-09-28 05:42:07,967 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:42:07,967 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: change Leader from null to de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f at term 1 for becomeLeader, leader elected after 5158ms
2019-09-28 05:42:07,967 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:42:07,968 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:42:07,968 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:42:07,968 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:42:07,968 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:42:07,968 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:42:07,971 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start LeaderState
2019-09-28 05:42:07,972 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:42:07,972 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: set configuration 0: [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null at 0
2019-09-28 05:42:07,997 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(106)) - b6225337-d522-49ee-b186-fb6fa5e92794:group-548B1EAFF199 changes to CANDIDATE, lastRpcTime:5048, electionTimeout:5024ms
2019-09-28 05:42:07,997 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4: begin an election at term 1 for -1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:07,997 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/50739ec2-2514-45d2-8011-d0f8db585a3f/current/log_inprogress_0
2019-09-28 05:42:07,997 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e57e007c-8983-4cde-88d0-4d132c569727/current/log_inprogress_0
2019-09-28 05:42:07,998 [Thread-194] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown FollowerState
2019-09-28 05:42:07,999 [Thread-194] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-28 05:42:07,999 [Thread-194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b6225337-d522-49ee-b186-fb6fa5e92794: start LeaderElection
2019-09-28 05:42:08,011 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/d3a562ee-fcb8-4ecd-a600-0b9dab814119/current/log_inprogress_0
2019-09-28 05:42:08,012 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5: begin an election at term 1 for -1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:08,046 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f
2019-09-28 05:42:08,047 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown FollowerState
2019-09-28 05:42:08,047 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db2345f5-3244-4519-8080-7868dac645ff: start FollowerState
2019-09-28 05:42:08,047 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(115)) - db2345f5-3244-4519-8080-7868dac645ff: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:42:08,079 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5: Election REJECTED; received 2 response(s) [b6225337-d522-49ee-b186-fb6fa5e92794<-db2345f5-3244-4519-8080-7868dac645ff#0:FAIL-t1, b6225337-d522-49ee-b186-fb6fa5e92794<-de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f#0:FAIL-t1] and 0 exception(s); b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:t1, leader=null, voted=b6225337-d522-49ee-b186-fb6fa5e92794, raftlog=b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:08,080 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4: Election PASSED; received 2 response(s) [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f<-db2345f5-3244-4519-8080-7868dac645ff#0:OK-t1, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f<-b6225337-d522-49ee-b186-fb6fa5e92794#0:FAIL-t1] and 0 exception(s); de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:t1, leader=null, voted=de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f, raftlog=de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null
2019-09-28 05:42:08,080 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-28 05:42:08,083 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown LeaderElection
2019-09-28 05:42:08,083 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown LeaderElection
2019-09-28 05:42:08,084 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b6225337-d522-49ee-b186-fb6fa5e92794: start FollowerState
2019-09-28 05:42:08,084 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-28 05:42:08,085 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: change Leader from null to de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f at term 1 for becomeLeader, leader elected after 5156ms
2019-09-28 05:42:08,085 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-28 05:42:08,085 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-28 05:42:08,085 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-28 05:42:08,086 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-28 05:42:08,086 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-28 05:42:08,086 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-28 05:42:08,093 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 05:42:08,093 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:08,094 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 05:42:08,098 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 05:42:08,102 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:42:08,102 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:08,104 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-28 05:42:08,104 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-28 05:42:08,104 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-28 05:42:08,104 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-28 05:42:08,105 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-28 05:42:08,105 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-28 05:42:08,109 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: start LeaderState
2019-09-28 05:42:08,109 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:42:08,110 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: set configuration 0: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null at 0
2019-09-28 05:42:08,148 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199/current/log_inprogress_0
2019-09-28 05:42:08,159 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: change Leader from null to de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f at term 1 for appendEntries, leader elected after 5230ms
2019-09-28 05:42:08,159 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: change Leader from null to de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f at term 1 for appendEntries, leader elected after 5232ms
2019-09-28 05:42:08,186 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: set configuration 0: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null at 0
2019-09-28 05:42:08,186 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: set configuration 0: [db2345f5-3244-4519-8080-7868dac645ff:192.168.151.82:36474, b6225337-d522-49ee-b186-fb6fa5e92794:192.168.151.82:45249, de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f:192.168.151.82:41056], old=null at 0
2019-09-28 05:42:08,187 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:42:08,187 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-28 05:42:08,199 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:08,225 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199/current/log_inprogress_0
2019-09-28 05:42:08,225 [db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/ratis/e0911c4e-dc02-46a1-b22b-548b1eaff199/current/log_inprogress_0
2019-09-28 05:42:09,200 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:10,201 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:11,202 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:12,203 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:13,205 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:14,211 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:15,212 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:16,213 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:17,215 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:18,216 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:19,217 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:20,219 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:21,220 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:22,222 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:23,223 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:23,225 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-28 05:42:24,226 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:25,227 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:26,229 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:27,230 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:28,232 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:29,233 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:30,234 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:31,236 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:32,237 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:33,239 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:33,240 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-28 05:42:34,242 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:35,243 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:36,244 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:37,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:38,247 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:39,249 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:40,251 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:41,252 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:42,254 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:43,255 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:43,257 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-28 05:42:44,258 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:45,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:46,261 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:47,263 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:48,264 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:49,265 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:50,267 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:51,268 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:52,270 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:53,271 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:53,272 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-28 05:42:54,274 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:55,276 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:56,277 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:57,278 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:58,279 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:42:59,281 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:00,282 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:01,283 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:02,285 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:03,286 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:03,287 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-28 05:43:04,288 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:05,289 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:06,290 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:07,292 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:08,293 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:09,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:10,295 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:11,297 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:12,298 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:13,299 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:13,301 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-28 05:43:14,302 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:15,304 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:16,305 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:17,306 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:18,307 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:19,309 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:20,310 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:21,311 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:22,313 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:23,314 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:23,316 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-28 05:43:24,318 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:25,320 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:26,321 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:27,323 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:28,324 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:29,326 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:30,327 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:31,329 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:32,330 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:33,331 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:33,333 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-28 05:43:34,335 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:35,336 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:36,337 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:37,339 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:38,340 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:39,342 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:40,343 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:41,345 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:42,346 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:43,347 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:43,349 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-28 05:43:44,350 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:45,351 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:46,353 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:47,354 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:48,355 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:49,357 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:50,358 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:51,359 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:52,360 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:53,361 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 05:43:53,363 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-28 05:43:53,365 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestFreonWithPipelineDestroy.startFreon(TestFreonWithPipelineDestroy.java:87)
	at org.apache.hadoop.ozone.freon.TestFreonWithPipelineDestroy.testRestart(TestFreonWithPipelineDestroy.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 57 more
2019-09-28 05:43:53,381 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-28 05:43:53,382 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-28 05:43:53,382 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-28 05:43:53,382 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40144
2019-09-28 05:43:53,390 [IPC Server listener on 40144] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40144
2019-09-28 05:43:53,390 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-28 05:43:53,392 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:43:53,398 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-28 05:43:53,406 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-28 05:43:53,410 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e850122{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-28 05:43:53,415 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27fde870{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:43:53,415 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cbb3d3b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:43:53,415 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:43:53,419 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-28 05:43:53,882 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:43:53,921 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:43:58,422 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:43:58,422 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:43:58,423 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: close
2019-09-28 05:43:58,423 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - db2345f5-3244-4519-8080-7868dac645ff: close
2019-09-28 05:43:58,425 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: shutdown
2019-09-28 05:43:58,425 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: shutdown
2019-09-28 05:43:58,425 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-548B1EAFF199,id=de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f
2019-09-28 05:43:58,425 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-548B1EAFF199,id=db2345f5-3244-4519-8080-7868dac645ff
2019-09-28 05:43:58,425 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown LeaderState
2019-09-28 05:43:58,426 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown FollowerState
2019-09-28 05:43:58,428 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(115)) - db2345f5-3244-4519-8080-7868dac645ff: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:43:58,428 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:43:58,429 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f-PendingRequests: sendNotLeaderResponses
2019-09-28 05:43:58,428 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$402/873336076@1addf258] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199->db2345f5-3244-4519-8080-7868dac645ff-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 05:43:58,428 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$402/873336076@234a756d] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199->b6225337-d522-49ee-b186-fb6fa5e92794-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-28 05:43:58,430 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199: closes. applyIndex: 0
2019-09-28 05:43:58,432 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:43:58,434 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199: closes. applyIndex: 0
2019-09-28 05:43:58,435 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - b6225337-d522-49ee-b186-fb6fa5e92794: Completed APPEND_ENTRIES, lastRequest: de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f->b6225337-d522-49ee-b186-fb6fa5e92794#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 05:43:58,435 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - db2345f5-3244-4519-8080-7868dac645ff: Completed APPEND_ENTRIES, lastRequest: de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f->db2345f5-3244-4519-8080-7868dac645ff#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-28 05:43:58,435 [db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:43:58,435 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:43:58,437 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199-SegmentedRaftLogWorker close()
2019-09-28 05:43:58,437 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - db2345f5-3244-4519-8080-7868dac645ff@group-548B1EAFF199-SegmentedRaftLogWorker close()
2019-09-28 05:43:58,440 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: shutdown
2019-09-28 05:43:58,440 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: shutdown
2019-09-28 05:43:58,440 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199->b6225337-d522-49ee-b186-fb6fa5e92794-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 05:43:58,440 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199->db2345f5-3244-4519-8080-7868dac645ff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-28 05:43:58,440 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B9DAB814119,id=de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f
2019-09-28 05:43:58,440 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4D132C569727,id=db2345f5-3244-4519-8080-7868dac645ff
2019-09-28 05:43:58,442 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown LeaderState
2019-09-28 05:43:58,444 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199->b6225337-d522-49ee-b186-fb6fa5e92794: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 05:43:58,444 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f-PendingRequests: sendNotLeaderResponses
2019-09-28 05:43:58,444 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-548B1EAFF199->db2345f5-3244-4519-8080-7868dac645ff: nextIndex: updateUnconditionally 1 -> 0
2019-09-28 05:43:58,443 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown LeaderState
2019-09-28 05:43:58,445 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:43:58,446 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - db2345f5-3244-4519-8080-7868dac645ff-PendingRequests: sendNotLeaderResponses
2019-09-28 05:43:58,447 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119: closes. applyIndex: 0
2019-09-28 05:43:58,447 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:43:58,448 [de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:43:58,449 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727: closes. applyIndex: 0
2019-09-28 05:43:58,449 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f@group-0B9DAB814119-SegmentedRaftLogWorker close()
2019-09-28 05:43:58,450 [db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:43:58,453 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - db2345f5-3244-4519-8080-7868dac645ff@group-4D132C569727-SegmentedRaftLogWorker close()
2019-09-28 05:43:58,454 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown server with port 41056 now
2019-09-28 05:43:58,455 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown server with port 36474 now
2019-09-28 05:43:58,458 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - de4d9d04-70cb-4ce0-9a8e-e03ca4013a3f: shutdown server with port 41056 successfully
2019-09-28 05:43:58,458 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - db2345f5-3244-4519-8080-7868dac645ff: shutdown server with port 36474 successfully
2019-09-28 05:43:58,463 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:43:58,463 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:43:58,483 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:43:58,484 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:43:58,486 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:43:58,487 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:43:58,489 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28da7d11{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:43:58,489 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d910b3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:43:58,490 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:43:58,490 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:43:58,490 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:43:58,491 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:43:58,491 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:43:58,491 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:43:59,017 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-28 05:44:03,493 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-28 05:44:03,494 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - b6225337-d522-49ee-b186-fb6fa5e92794: close
2019-09-28 05:44:03,494 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: shutdown
2019-09-28 05:44:03,495 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D0F8DB585A3F,id=b6225337-d522-49ee-b186-fb6fa5e92794
2019-09-28 05:44:03,495 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown LeaderState
2019-09-28 05:44:03,496 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b6225337-d522-49ee-b186-fb6fa5e92794-PendingRequests: sendNotLeaderResponses
2019-09-28 05:44:03,496 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:44:03,498 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F: closes. applyIndex: 0
2019-09-28 05:44:03,498 [b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:44:03,499 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-D0F8DB585A3F-SegmentedRaftLogWorker close()
2019-09-28 05:44:03,500 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: shutdown
2019-09-28 05:44:03,501 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-548B1EAFF199,id=b6225337-d522-49ee-b186-fb6fa5e92794
2019-09-28 05:44:03,501 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown FollowerState
2019-09-28 05:44:03,502 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-StateMachineUpdater: set stopIndex = 0
2019-09-28 05:44:03,502 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(115)) - b6225337-d522-49ee-b186-fb6fa5e92794: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-28 05:44:03,504 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199: closes. applyIndex: 0
2019-09-28 05:44:03,504 [b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-28 05:44:03,510 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b6225337-d522-49ee-b186-fb6fa5e92794@group-548B1EAFF199-SegmentedRaftLogWorker close()
2019-09-28 05:44:03,512 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown server with port 45249 now
2019-09-28 05:44:03,514 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - b6225337-d522-49ee-b186-fb6fa5e92794: shutdown server with port 45249 successfully
2019-09-28 05:44:03,527 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-ff657173-4fb5-4c04-9c54-5d6197161101/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-28 05:44:03,547 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-28 05:44:03,549 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-28 05:44:03,550 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@41eb94bc{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-28 05:44:03,551 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@378cfecf{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:44:03,551 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1981d861{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:44:03,552 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588f63c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:44:03,552 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-28 05:44:03,553 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-28 05:44:03,553 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-28 05:44:03,553 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-28 05:44:03,553 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-28 05:44:03,553 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-28 05:44:03,553 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33502
2019-09-28 05:44:03,556 [IPC Server listener on 33502] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33502
2019-09-28 05:44:03,556 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:44:03,629 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-28 05:44:03,629 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-28 05:44:03,629 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-28 05:44:03,630 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46650
2019-09-28 05:44:03,631 [IPC Server listener on 46650] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46650
2019-09-28 05:44:03,631 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-28 05:44:03,631 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:44:03,632 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(158)) - Stopping the RPC server for Client Protocol
2019-09-28 05:44:03,632 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35494
2019-09-28 05:44:03,634 [IPC Server listener on 35494] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35494
2019-09-28 05:44:03,634 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-28 05:44:03,634 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-28 05:44:03,635 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@544630b7{/,null,UNAVAILABLE}{/scm}
2019-09-28 05:44:03,636 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-28 05:44:03,636 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-28 05:44:03,636 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-28 05:44:03,637 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-28 05:44:03,637 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 05:44:03,638 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-28 05:44:03,638 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-28 05:44:03,643 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-28 05:44:03,649 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-28 05:44:03,649 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
