2019-09-27 13:36:23,150 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:23,235 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:23,238 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:23,255 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @905ms
2019-09-27 13:36:23,355 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-27 13:36:23,355 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-27 13:36:23,356 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-27 13:36:23,356 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-27 13:36:23,356 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-27 13:36:23,357 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-27 13:36:23,369 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 13:36:23,369 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 13:36:23,370 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 13:36:23,602 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@411f53a0
2019-09-27 13:36:23,604 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-27 13:36:23,676 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 13:36:23,678 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 13:36:23,680 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-27 13:36:23,751 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-27 13:36:23,765 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:23,830 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-27 13:36:23,834 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:23,945 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-27 13:36:24,311 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 13:36:24,340 [Socket Reader #1 for port 46687] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46687
2019-09-27 13:36:24,474 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 13:36:24,476 [Socket Reader #1 for port 37956] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37956
2019-09-27 13:36:24,484 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 13:36:24,485 [Socket Reader #1 for port 43137] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43137
2019-09-27 13:36:24,513 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-27 13:36:24,637 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:24,652 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:24,661 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:24,664 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-27 13:36:24,664 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:24,665 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:24,690 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43137
2019-09-27 13:36:24,735 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-27 13:36:24,747 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-27 13:36:24,747 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-27 13:36:24,980 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:43137
2019-09-27 13:36:24,981 [IPC Server listener on 43137] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43137: starting
2019-09-27 13:36:24,981 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 13:36:24,984 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37956
2019-09-27 13:36:24,985 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:37956
2019-09-27 13:36:24,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 13:36:24,986 [IPC Server listener on 37956] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37956: starting
2019-09-27 13:36:24,988 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:46687
2019-09-27 13:36:24,988 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:46687
2019-09-27 13:36:24,989 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 13:36:24,989 [IPC Server listener on 46687] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46687: starting
2019-09-27 13:36:24,993 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45289
2019-09-27 13:36:24,994 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:25,028 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:25,028 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:25,097 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@544630b7{/,file:///tmp/jetty-0.0.0.0-45289-scm-_-any-9103002793408603962.dir/webapp/,AVAILABLE}{/scm}
2019-09-27 13:36:25,101 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:45289}
2019-09-27 13:36:25,101 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2752ms
2019-09-27 13:36:25,103 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-27 13:36:25,104 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-27 13:36:25,105 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:45289
2019-09-27 13:36:25,113 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@790174f2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 13:36:25,116 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:25,211 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-27 13:36:25,212 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-27 13:36:25,213 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:25,214 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:25,893 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 13:36:25,900 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-27 13:36:25,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-27 13:36:25,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-27 13:36:25,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-27 13:36:25,901 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-27 13:36:25,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-27 13:36:25,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-27 13:36:25,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-27 13:36:25,902 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-27 13:36:25,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-27 13:36:25,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-27 13:36:25,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-27 13:36:25,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-27 13:36:25,903 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-27 13:36:25,904 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-27 13:36:25,904 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-27 13:36:25,904 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-27 13:36:25,905 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-27 13:36:25,905 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-27 13:36:25,905 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-27 13:36:25,905 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-27 13:36:25,905 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-27 13:36:25,906 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 13:36:25,906 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 13:36:25,906 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 13:36:26,397 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 13:36:26,398 [Socket Reader #1 for port 45292] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45292
2019-09-27 13:36:26,419 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45292
2019-09-27 13:36:26,419 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-27 13:36:26,420 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 13:36:26,420 [IPC Server listener on 45292] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45292: starting
2019-09-27 13:36:26,424 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-27 13:36:26,426 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:26,427 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:26,430 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:26,431 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-27 13:36:26,431 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:26,431 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:26,434 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43666
2019-09-27 13:36:26,435 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:26,437 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7df60067{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:26,438 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@529cfee5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:26,504 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27fde870{/,file:///tmp/jetty-0.0.0.0-43666-ozoneManager-_-any-4689283855589807770.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-27 13:36:26,505 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b4c3c29{HTTP/1.1,[http/1.1]}{0.0.0.0:43666}
2019-09-27 13:36:26,505 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4156ms
2019-09-27 13:36:26,506 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 13:36:26,506 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:43666
2019-09-27 13:36:26,814 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 13:36:26,885 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 13:36:26,938 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 13:36:26,940 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/containers/hdds to VolumeSet
2019-09-27 13:36:26,943 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6df3e44c
2019-09-27 13:36:26,962 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6df3e44c
2019-09-27 13:36:27,008 [main] WARN  impl.ChunkManagerFactory (ChunkManagerFactory.java:createChunkManager(83)) - hdds.container.chunk.persistdata is set to false. This should be used only for testing. All user data will be discarded.
2019-09-27 13:36:27,104 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 13:36:27,184 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 13:36:27,190 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 13:36:27,192 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 13:36:27,194 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:27,195 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 13:36:27,196 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:27,396 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis] (custom)
2019-09-27 13:36:27,448 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 13:36:27,452 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:27,453 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:27,456 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:27,457 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 13:36:27,457 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:27,458 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:27,460 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40876
2019-09-27 13:36:27,461 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:27,464 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6edcad64{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:27,465 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e33d73e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:27,508 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cd64ee8{/,file:///tmp/jetty-0.0.0.0-40876-hddsDatanode-_-any-3190928662291254030.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 13:36:27,509 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@620c8641{HTTP/1.1,[http/1.1]}{0.0.0.0:40876}
2019-09-27 13:36:27,510 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5160ms
2019-09-27 13:36:27,511 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 13:36:27,512 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40876
2019-09-27 13:36:27,513 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 13:36:27,517 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 13:36:27,520 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78f49be6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 13:36:27,527 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 13:36:27,528 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/containers/hdds to VolumeSet
2019-09-27 13:36:27,528 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3c3a0032
2019-09-27 13:36:27,529 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3c3a0032
2019-09-27 13:36:27,547 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 13:36:27,547 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 13:36:27,548 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 13:36:27,548 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 13:36:27,548 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:27,549 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 13:36:27,549 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:27,550 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis] (custom)
2019-09-27 13:36:27,551 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 13:36:27,553 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:27,554 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:27,556 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:27,556 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 13:36:27,557 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:27,557 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:27,558 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41146
2019-09-27 13:36:27,558 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:27,560 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@524a076e{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:27,561 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62dbe64e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:27,594 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@726aa968{/,file:///tmp/jetty-0.0.0.0-41146-hddsDatanode-_-any-5855852137074306864.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 13:36:27,595 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7100dea{HTTP/1.1,[http/1.1]}{0.0.0.0:41146}
2019-09-27 13:36:27,598 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5245ms
2019-09-27 13:36:27,598 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 13:36:27,599 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41146
2019-09-27 13:36:27,600 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 13:36:27,603 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 13:36:27,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@406c35a1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 13:36:27,612 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 13:36:27,612 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/containers/hdds to VolumeSet
2019-09-27 13:36:27,612 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@70887727
2019-09-27 13:36:27,613 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@70887727
2019-09-27 13:36:27,626 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 13:36:27,626 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 13:36:27,627 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 13:36:27,627 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 13:36:27,627 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:27,628 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 13:36:27,628 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:27,628 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis] (custom)
2019-09-27 13:36:27,630 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 13:36:27,631 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:27,632 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:27,633 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:27,634 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 13:36:27,634 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:27,634 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:27,635 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35174
2019-09-27 13:36:27,635 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:27,641 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53f4c1e6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:27,641 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6342d610{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:27,651 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/meta/datanode.id
2019-09-27 13:36:27,656 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/meta/datanode.id
2019-09-27 13:36:27,673 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43af351a{/,file:///tmp/jetty-0.0.0.0-35174-hddsDatanode-_-any-7616240588329793842.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 13:36:27,674 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1305c126{HTTP/1.1,[http/1.1]}{0.0.0.0:35174}
2019-09-27 13:36:27,674 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5325ms
2019-09-27 13:36:27,676 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 13:36:27,677 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35174
2019-09-27 13:36:27,677 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 13:36:27,680 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 13:36:27,680 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@34b5fc78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 13:36:27,684 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/meta/datanode.id
2019-09-27 13:36:27,687 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 13:36:27,689 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/containers/hdds to VolumeSet
2019-09-27 13:36:27,689 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6caf7803
2019-09-27 13:36:27,689 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6caf7803
2019-09-27 13:36:27,705 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 13:36:27,705 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 13:36:27,706 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 13:36:27,706 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 13:36:27,706 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:27,706 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 13:36:27,706 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:27,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis] (custom)
2019-09-27 13:36:27,709 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 13:36:27,710 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:27,711 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:27,712 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:27,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 13:36:27,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:27,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:27,714 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42984
2019-09-27 13:36:27,714 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:27,716 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18b8d173{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:27,716 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44f24a20{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:27,745 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1457fde{/,file:///tmp/jetty-0.0.0.0-42984-hddsDatanode-_-any-9056808105137686635.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 13:36:27,746 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6f94fb9d{HTTP/1.1,[http/1.1]}{0.0.0.0:42984}
2019-09-27 13:36:27,747 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5397ms
2019-09-27 13:36:27,748 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 13:36:27,749 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42984
2019-09-27 13:36:27,749 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 13:36:27,753 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@143bf2cc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 13:36:27,753 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 13:36:27,755 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/meta/datanode.id
2019-09-27 13:36:27,762 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 13:36:27,762 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/containers/hdds to VolumeSet
2019-09-27 13:36:27,763 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@16727bf0
2019-09-27 13:36:27,763 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@16727bf0
2019-09-27 13:36:27,780 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 13:36:27,780 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 13:36:27,780 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 13:36:27,781 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 13:36:27,781 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:27,781 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 13:36:27,781 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:27,782 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis] (custom)
2019-09-27 13:36:27,784 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 13:36:27,785 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 13:36:27,786 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 13:36:27,788 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 13:36:27,788 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 13:36:27,789 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 13:36:27,789 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 13:36:27,789 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36413
2019-09-27 13:36:27,790 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 13:36:27,794 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56637cff{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 13:36:27,794 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@127a7272{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 13:36:27,838 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12eedfee{/,file:///tmp/jetty-0.0.0.0-36413-hddsDatanode-_-any-6492656224770098010.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 13:36:27,841 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c3c4a71{HTTP/1.1,[http/1.1]}{0.0.0.0:36413}
2019-09-27 13:36:27,842 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5492ms
2019-09-27 13:36:27,842 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 13:36:27,843 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36413
2019-09-27 13:36:27,846 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8d46ee9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 13:36:27,846 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 13:36:27,849 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/meta/datanode.id
2019-09-27 13:36:28,846 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 13:36:29,569 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 13:36:29,571 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 13:36:29,571 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 93238805-6c3b-4f37-b48b-125b403d7948 at port 0
2019-09-27 13:36:29,592 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 93238805-6c3b-4f37-b48b-125b403d7948: start RPC server
2019-09-27 13:36:29,613 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 13:36:29,614 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 13:36:29,615 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 6d2115e7-2387-46ef-9dff-f1092adf22a8 at port 0
2019-09-27 13:36:29,622 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: start RPC server
2019-09-27 13:36:29,687 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 13:36:29,689 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 13:36:29,689 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 08207814-19ac-4e65-ae6c-673e09624768 at port 0
2019-09-27 13:36:29,698 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 08207814-19ac-4e65-ae6c-673e09624768: start RPC server
2019-09-27 13:36:29,725 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: GrpcService started, listening on 0.0.0.0/0.0.0.0:39733
2019-09-27 13:36:29,725 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 08207814-19ac-4e65-ae6c-673e09624768: GrpcService started, listening on 0.0.0.0/0.0.0.0:44575
2019-09-27 13:36:29,725 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 93238805-6c3b-4f37-b48b-125b403d7948: GrpcService started, listening on 0.0.0.0/0.0.0.0:33994
2019-09-27 13:36:29,726 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 08207814-19ac-4e65-ae6c-673e09624768 is started using port 44575
2019-09-27 13:36:29,726 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 6d2115e7-2387-46ef-9dff-f1092adf22a8 is started using port 39733
2019-09-27 13:36:29,727 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 93238805-6c3b-4f37-b48b-125b403d7948 is started using port 33994
2019-09-27 13:36:29,734 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 93238805-6c3b-4f37-b48b-125b403d7948 is started using port 42158
2019-09-27 13:36:29,734 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 6d2115e7-2387-46ef-9dff-f1092adf22a8 is started using port 38231
2019-09-27 13:36:29,735 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 08207814-19ac-4e65-ae6c-673e09624768 is started using port 44797
2019-09-27 13:36:29,768 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 13:36:29,769 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 13:36:29,770 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis d67bad60-2d89-4d07-88f6-da90aa48785a at port 0
2019-09-27 13:36:29,775 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start RPC server
2019-09-27 13:36:29,778 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d67bad60-2d89-4d07-88f6-da90aa48785a: GrpcService started, listening on 0.0.0.0/0.0.0.0:44785
2019-09-27 13:36:29,778 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis d67bad60-2d89-4d07-88f6-da90aa48785a is started using port 44785
2019-09-27 13:36:29,780 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc d67bad60-2d89-4d07-88f6-da90aa48785a is started using port 40558
2019-09-27 13:36:29,847 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 13:36:29,873 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 13:36:29,880 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 13:36:29,880 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 22cb26a1-1640-496f-8576-0d3ad7b2657b at port 0
2019-09-27 13:36:29,886 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start RPC server
2019-09-27 13:36:29,890 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: GrpcService started, listening on 0.0.0.0/0.0.0.0:40262
2019-09-27 13:36:29,890 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 22cb26a1-1640-496f-8576-0d3ad7b2657b is started using port 40262
2019-09-27 13:36:29,892 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 22cb26a1-1640-496f-8576-0d3ad7b2657b is started using port 40683
2019-09-27 13:36:30,848 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 13:36:31,564 [IPC Server handler 2 on 46687] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/93238805-6c3b-4f37-b48b-125b403d7948
2019-09-27 13:36:31,565 [IPC Server handler 2 on 46687] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 93238805-6c3b-4f37-b48b-125b403d7948{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 13:36:31,571 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-27 13:36:31,571 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-27 13:36:31,571 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-27 13:36:31,606 [IPC Server handler 1 on 46687] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6d2115e7-2387-46ef-9dff-f1092adf22a8
2019-09-27 13:36:31,607 [IPC Server handler 1 on 46687] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 6d2115e7-2387-46ef-9dff-f1092adf22a8{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 13:36:31,684 [IPC Server handler 4 on 46687] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/08207814-19ac-4e65-ae6c-673e09624768
2019-09-27 13:36:31,684 [IPC Server handler 4 on 46687] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 08207814-19ac-4e65-ae6c-673e09624768{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 13:36:31,756 [IPC Server handler 3 on 46687] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d67bad60-2d89-4d07-88f6-da90aa48785a
2019-09-27 13:36:31,756 [IPC Server handler 3 on 46687] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : d67bad60-2d89-4d07-88f6-da90aa48785a{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 13:36:31,848 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-27 13:36:31,848 [IPC Server handler 5 on 46687] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:36:31,849 [IPC Server handler 5 on 46687] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 22cb26a1-1640-496f-8576-0d3ad7b2657b{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 13:36:31,852 [main] INFO  freon.TestDataValidate (TestDataValidateWithDummyContainers.java:validateWriteTest(64)) - Skipping validateWriteTest for non-persistent containers.
2019-09-27 13:36:31,856 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-27 13:36:32,120 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 93238805-6c3b-4f37-b48b-125b403d7948: addNew group-F0BAD47587B8:[93238805-6c3b-4f37-b48b-125b403d7948:192.168.151.103:33994] returns group-F0BAD47587B8:java.util.concurrent.CompletableFuture@34e3c717[Not completed]
2019-09-27 13:36:32,142 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 93238805-6c3b-4f37-b48b-125b403d7948: new RaftServerImpl for group-F0BAD47587B8:[93238805-6c3b-4f37-b48b-125b403d7948:192.168.151.103:33994] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,143 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,145 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,145 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,146 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,147 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,155 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: ConfigurationManager, init=-1: [93238805-6c3b-4f37-b48b-125b403d7948:192.168.151.103:33994], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,155 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis] (custom)
2019-09-27 13:36:32,162 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis/f1cdf474-1efa-446c-92f0-f0bad47587b8 does not exist. Creating ...
2019-09-27 13:36:32,170 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis/f1cdf474-1efa-446c-92f0-f0bad47587b8/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,176 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis/f1cdf474-1efa-446c-92f0-f0bad47587b8 has been successfully formatted.
2019-09-27 13:36:32,178 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F0BAD47587B8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,178 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,180 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,185 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,185 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,191 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,197 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis/f1cdf474-1efa-446c-92f0-f0bad47587b8
2019-09-27 13:36:32,199 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-27 13:36:32,205 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-27 13:36:32,233 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,234 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,237 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,237 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,238 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,238 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,239 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,239 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,239 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,249 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,254 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,258 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,259 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,259 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,260 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,285 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: start as a follower, conf=-1: [93238805-6c3b-4f37-b48b-125b403d7948:192.168.151.103:33994], old=null
2019-09-27 13:36:32,286 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,287 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 93238805-6c3b-4f37-b48b-125b403d7948: start FollowerState
2019-09-27 13:36:32,289 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F0BAD47587B8,id=93238805-6c3b-4f37-b48b-125b403d7948
2019-09-27 13:36:32,352 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f1cdf474-1efa-446c-92f0-f0bad47587b8, Nodes: 93238805-6c3b-4f37-b48b-125b403d7948{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 13:36:32,375 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: addNew group-7AFBE965483C:[22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262] returns group-7AFBE965483C:java.util.concurrent.CompletableFuture@5f1f51be[Not completed]
2019-09-27 13:36:32,426 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: new RaftServerImpl for group-7AFBE965483C:[22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,427 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,427 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,427 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,427 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,428 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,428 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: ConfigurationManager, init=-1: [22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,428 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis] (custom)
2019-09-27 13:36:32,429 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/14cabd27-2fbb-450f-a317-7afbe965483c does not exist. Creating ...
2019-09-27 13:36:32,443 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/14cabd27-2fbb-450f-a317-7afbe965483c/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,465 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/14cabd27-2fbb-450f-a317-7afbe965483c has been successfully formatted.
2019-09-27 13:36:32,467 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7AFBE965483C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,468 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,468 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,468 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,469 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,469 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/14cabd27-2fbb-450f-a317-7afbe965483c
2019-09-27 13:36:32,475 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,476 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,476 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,476 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,476 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,476 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,477 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,477 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,477 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,477 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,478 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,478 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,478 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,478 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,478 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,483 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: start as a follower, conf=-1: [22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262], old=null
2019-09-27 13:36:32,483 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,483 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start FollowerState
2019-09-27 13:36:32,485 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7AFBE965483C,id=22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:36:32,504 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 14cabd27-2fbb-450f-a317-7afbe965483c, Nodes: 22cb26a1-1640-496f-8576-0d3ad7b2657b{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 13:36:32,522 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d67bad60-2d89-4d07-88f6-da90aa48785a: addNew group-4EA5834C8F82:[d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] returns group-4EA5834C8F82:java.util.concurrent.CompletableFuture@472b85a8[Not completed]
2019-09-27 13:36:32,539 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d67bad60-2d89-4d07-88f6-da90aa48785a: new RaftServerImpl for group-4EA5834C8F82:[d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,539 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,539 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,540 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,540 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,540 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,540 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: ConfigurationManager, init=-1: [d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,540 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis] (custom)
2019-09-27 13:36:32,540 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f5f34a9a-ec27-4821-bd12-4ea5834c8f82 does not exist. Creating ...
2019-09-27 13:36:32,554 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f5f34a9a-ec27-4821-bd12-4ea5834c8f82/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,567 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f5f34a9a-ec27-4821-bd12-4ea5834c8f82 has been successfully formatted.
2019-09-27 13:36:32,567 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4EA5834C8F82: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,567 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,567 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,568 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,568 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,568 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,568 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,568 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f5f34a9a-ec27-4821-bd12-4ea5834c8f82
2019-09-27 13:36:32,603 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,603 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,604 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,604 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,604 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,604 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,604 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,604 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,605 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,605 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,605 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,606 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,606 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,606 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,606 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,613 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: start as a follower, conf=-1: [d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:32,613 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,613 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start FollowerState
2019-09-27 13:36:32,614 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EA5834C8F82,id=d67bad60-2d89-4d07-88f6-da90aa48785a
2019-09-27 13:36:32,627 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f5f34a9a-ec27-4821-bd12-4ea5834c8f82, Nodes: d67bad60-2d89-4d07-88f6-da90aa48785a{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 13:36:32,647 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 08207814-19ac-4e65-ae6c-673e09624768: addNew group-FACD4759C689:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575] returns group-FACD4759C689:java.util.concurrent.CompletableFuture@69490250[Not completed]
2019-09-27 13:36:32,650 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 08207814-19ac-4e65-ae6c-673e09624768: new RaftServerImpl for group-FACD4759C689:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,650 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,650 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,651 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,651 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: ConfigurationManager, init=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,652 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis] (custom)
2019-09-27 13:36:32,652 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/fd9c4182-5cdd-4abd-af6a-facd4759c689 does not exist. Creating ...
2019-09-27 13:36:32,665 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/fd9c4182-5cdd-4abd-af6a-facd4759c689/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,679 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/fd9c4182-5cdd-4abd-af6a-facd4759c689 has been successfully formatted.
2019-09-27 13:36:32,680 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FACD4759C689: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,680 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,680 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,680 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,681 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,681 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,681 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,681 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/fd9c4182-5cdd-4abd-af6a-facd4759c689
2019-09-27 13:36:32,688 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,688 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,689 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,689 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,689 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,689 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,689 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,690 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,690 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,690 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,691 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,691 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,691 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,692 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,692 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,698 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: start as a follower, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575], old=null
2019-09-27 13:36:32,698 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,698 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start FollowerState
2019-09-27 13:36:32,699 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FACD4759C689,id=08207814-19ac-4e65-ae6c-673e09624768
2019-09-27 13:36:32,711 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fd9c4182-5cdd-4abd-af6a-facd4759c689, Nodes: 08207814-19ac-4e65-ae6c-673e09624768{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 13:36:32,736 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: addNew group-C882A96D4461:[6d2115e7-2387-46ef-9dff-f1092adf22a8:192.168.151.103:39733] returns group-C882A96D4461:java.util.concurrent.CompletableFuture@485b9aeb[Not completed]
2019-09-27 13:36:32,738 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: new RaftServerImpl for group-C882A96D4461:[6d2115e7-2387-46ef-9dff-f1092adf22a8:192.168.151.103:39733] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,738 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,739 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,739 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,739 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,739 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,740 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: ConfigurationManager, init=-1: [6d2115e7-2387-46ef-9dff-f1092adf22a8:192.168.151.103:39733], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,740 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis] (custom)
2019-09-27 13:36:32,740 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis/5011ddeb-a144-4073-9666-c882a96d4461 does not exist. Creating ...
2019-09-27 13:36:32,754 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis/5011ddeb-a144-4073-9666-c882a96d4461/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,767 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis/5011ddeb-a144-4073-9666-c882a96d4461 has been successfully formatted.
2019-09-27 13:36:32,768 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C882A96D4461: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,768 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,768 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,768 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,769 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,769 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,769 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,769 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis/5011ddeb-a144-4073-9666-c882a96d4461
2019-09-27 13:36:32,774 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,774 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,776 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,776 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,776 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,777 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,777 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,777 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,777 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,778 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,784 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: start as a follower, conf=-1: [6d2115e7-2387-46ef-9dff-f1092adf22a8:192.168.151.103:39733], old=null
2019-09-27 13:36:32,784 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,784 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: start FollowerState
2019-09-27 13:36:32,785 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C882A96D4461,id=6d2115e7-2387-46ef-9dff-f1092adf22a8
2019-09-27 13:36:32,797 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5011ddeb-a144-4073-9666-c882a96d4461, Nodes: 6d2115e7-2387-46ef-9dff-f1092adf22a8{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 13:36:32,837 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d67bad60-2d89-4d07-88f6-da90aa48785a: addNew group-1224532D134F:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] returns group-1224532D134F:java.util.concurrent.CompletableFuture@76794750[Not completed]
2019-09-27 13:36:32,840 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: addNew group-1224532D134F:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] returns group-1224532D134F:java.util.concurrent.CompletableFuture@46ee0d98[Not completed]
2019-09-27 13:36:32,840 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 08207814-19ac-4e65-ae6c-673e09624768: addNew group-1224532D134F:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] returns group-1224532D134F:java.util.concurrent.CompletableFuture@69b28efd[Not completed]
2019-09-27 13:36:32,842 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d67bad60-2d89-4d07-88f6-da90aa48785a: new RaftServerImpl for group-1224532D134F:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,842 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,843 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,843 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,843 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,843 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,843 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: ConfigurationManager, init=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,844 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 08207814-19ac-4e65-ae6c-673e09624768: new RaftServerImpl for group-1224532D134F:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,844 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis] (custom)
2019-09-27 13:36:32,844 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,844 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,844 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,844 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f does not exist. Creating ...
2019-09-27 13:36:32,844 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,844 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: new RaftServerImpl for group-1224532D134F:[08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785] with ContainerStateMachine:uninitialized
2019-09-27 13:36:32,845 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 13:36:32,845 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: ConfigurationManager, init=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 13:36:32,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 13:36:32,845 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis] (custom)
2019-09-27 13:36:32,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 13:36:32,846 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:32,846 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: ConfigurationManager, init=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null, confs=<EMPTY_MAP>
2019-09-27 13:36:32,846 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f does not exist. Creating ...
2019-09-27 13:36:32,846 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis] (custom)
2019-09-27 13:36:32,846 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f does not exist. Creating ...
2019-09-27 13:36:32,858 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,858 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,858 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f/in_use.lock acquired by nodename 15546@pr-hdds2162-4fxhj-20988671
2019-09-27 13:36:32,872 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f has been successfully formatted.
2019-09-27 13:36:32,872 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f has been successfully formatted.
2019-09-27 13:36:32,872 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f has been successfully formatted.
2019-09-27 13:36:32,872 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1224532D134F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,872 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1224532D134F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,872 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1224532D134F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 13:36:32,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,873 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,873 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 13:36:32,873 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,873 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,873 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,873 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 13:36:32,874 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,873 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,874 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,874 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 13:36:32,874 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,874 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,875 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f
2019-09-27 13:36:32,874 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:32,875 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,875 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,875 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,875 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,876 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,875 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,876 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,876 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 13:36:32,876 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,876 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f
2019-09-27 13:36:32,877 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,876 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f
2019-09-27 13:36:32,877 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,877 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,877 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,877 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 13:36:32,878 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,877 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,878 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 13:36:32,878 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,878 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,878 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,878 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 13:36:32,879 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,879 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,879 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 13:36:32,879 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,879 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,880 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,879 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 13:36:32,880 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,880 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,880 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,880 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 13:36:32,880 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,881 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 13:36:32,881 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,881 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 13:36:32,881 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,881 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 13:36:32,881 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,882 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 13:36:32,882 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,882 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,882 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 13:36:32,882 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,882 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 13:36:32,882 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,883 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 13:36:32,883 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 13:36:32,883 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 13:36:32,885 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: start as a follower, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:32,885 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,886 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start FollowerState
2019-09-27 13:36:32,886 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1224532D134F,id=d67bad60-2d89-4d07-88f6-da90aa48785a
2019-09-27 13:36:32,888 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: start as a follower, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:32,889 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,889 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start FollowerState
2019-09-27 13:36:32,891 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1224532D134F,id=22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:36:32,892 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: start as a follower, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:32,892 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 13:36:32,893 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start FollowerState
2019-09-27 13:36:32,897 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1224532D134F,id=08207814-19ac-4e65-ae6c-673e09624768
2019-09-27 13:36:32,915 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f9dbb8dd-d535-484e-add1-1224532d134f, Nodes: 22cb26a1-1640-496f-8576-0d3ad7b2657b{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}d67bad60-2d89-4d07-88f6-da90aa48785a{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}08207814-19ac-4e65-ae6c-673e09624768{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-27 13:36:33,069 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:34,071 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:34,577 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-27 13:36:34,581 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-27 13:36:35,072 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:36,074 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:37,075 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:37,425 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(106)) - 93238805-6c3b-4f37-b48b-125b403d7948:group-F0BAD47587B8 changes to CANDIDATE, lastRpcTime:5137, electionTimeout:5137ms
2019-09-27 13:36:37,427 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 93238805-6c3b-4f37-b48b-125b403d7948: shutdown FollowerState
2019-09-27 13:36:37,428 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,431 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 93238805-6c3b-4f37-b48b-125b403d7948: start LeaderElection
2019-09-27 13:36:37,442 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1: begin an election at term 1 for -1: [93238805-6c3b-4f37-b48b-125b403d7948:192.168.151.103:33994], old=null
2019-09-27 13:36:37,444 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 93238805-6c3b-4f37-b48b-125b403d7948: shutdown LeaderElection
2019-09-27 13:36:37,445 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 13:36:37,445 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: change Leader from null to 93238805-6c3b-4f37-b48b-125b403d7948 at term 1 for becomeLeader, leader elected after 5266ms
2019-09-27 13:36:37,453 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 13:36:37,453 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 13:36:37,456 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 13:36:37,459 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 13:36:37,459 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 13:36:37,460 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 13:36:37,473 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 93238805-6c3b-4f37-b48b-125b403d7948: start LeaderState
2019-09-27 13:36:37,496 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:37,507 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: set configuration 0: [93238805-6c3b-4f37-b48b-125b403d7948:192.168.151.103:33994], old=null at 0
2019-09-27 13:36:37,602 [Thread-214] INFO  impl.FollowerState (FollowerState.java:run(106)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b:group-7AFBE965483C changes to CANDIDATE, lastRpcTime:5118, electionTimeout:5117ms
2019-09-27 13:36:37,604 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown FollowerState
2019-09-27 13:36:37,604 [Thread-214] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,606 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start LeaderElection
2019-09-27 13:36:37,622 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2: begin an election at term 1 for -1: [22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262], old=null
2019-09-27 13:36:37,623 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown LeaderElection
2019-09-27 13:36:37,623 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 13:36:37,624 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: change Leader from null to 22cb26a1-1640-496f-8576-0d3ad7b2657b at term 1 for becomeLeader, leader elected after 5155ms
2019-09-27 13:36:37,625 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 13:36:37,625 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 13:36:37,626 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 13:36:37,626 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 13:36:37,626 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 13:36:37,626 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 13:36:37,630 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start LeaderState
2019-09-27 13:36:37,630 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:37,631 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: set configuration 0: [22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262], old=null at 0
2019-09-27 13:36:37,699 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(106)) - 08207814-19ac-4e65-ae6c-673e09624768:group-FACD4759C689 changes to CANDIDATE, lastRpcTime:5000, electionTimeout:5000ms
2019-09-27 13:36:37,699 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown FollowerState
2019-09-27 13:36:37,699 [Thread-220] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,699 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start LeaderElection
2019-09-27 13:36:37,738 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/14cabd27-2fbb-450f-a317-7afbe965483c/current/log_inprogress_0
2019-09-27 13:36:37,738 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3: begin an election at term 1 for -1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575], old=null
2019-09-27 13:36:37,738 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/ratis/f1cdf474-1efa-446c-92f0-f0bad47587b8/current/log_inprogress_0
2019-09-27 13:36:37,739 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown LeaderElection
2019-09-27 13:36:37,739 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 13:36:37,739 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: change Leader from null to 08207814-19ac-4e65-ae6c-673e09624768 at term 1 for becomeLeader, leader elected after 5059ms
2019-09-27 13:36:37,741 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 13:36:37,741 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 13:36:37,741 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 13:36:37,741 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 13:36:37,742 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 13:36:37,742 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 13:36:37,745 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start LeaderState
2019-09-27 13:36:37,746 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:37,746 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: set configuration 0: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575], old=null at 0
2019-09-27 13:36:37,785 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(106)) - d67bad60-2d89-4d07-88f6-da90aa48785a:group-4EA5834C8F82 changes to CANDIDATE, lastRpcTime:5171, electionTimeout:5171ms
2019-09-27 13:36:37,785 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown FollowerState
2019-09-27 13:36:37,785 [Thread-217] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,786 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start LeaderElection
2019-09-27 13:36:37,789 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/fd9c4182-5cdd-4abd-af6a-facd4759c689/current/log_inprogress_0
2019-09-27 13:36:37,803 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4: begin an election at term 1 for -1: [d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:37,803 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown LeaderElection
2019-09-27 13:36:37,803 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 13:36:37,803 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: change Leader from null to d67bad60-2d89-4d07-88f6-da90aa48785a at term 1 for becomeLeader, leader elected after 5235ms
2019-09-27 13:36:37,805 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 13:36:37,805 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 13:36:37,805 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 13:36:37,805 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 13:36:37,805 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 13:36:37,805 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 13:36:37,808 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start LeaderState
2019-09-27 13:36:37,809 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:37,809 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: set configuration 0: [d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null at 0
2019-09-27 13:36:37,851 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f5f34a9a-ec27-4821-bd12-4ea5834c8f82/current/log_inprogress_0
2019-09-27 13:36:37,937 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8:group-C882A96D4461 changes to CANDIDATE, lastRpcTime:5152, electionTimeout:5152ms
2019-09-27 13:36:37,937 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: shutdown FollowerState
2019-09-27 13:36:37,937 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,937 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: start LeaderElection
2019-09-27 13:36:37,951 [Thread-228] INFO  impl.FollowerState (FollowerState.java:run(106)) - d67bad60-2d89-4d07-88f6-da90aa48785a:group-1224532D134F changes to CANDIDATE, lastRpcTime:5065, electionTimeout:5065ms
2019-09-27 13:36:37,951 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown FollowerState
2019-09-27 13:36:37,951 [Thread-228] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,951 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start LeaderElection
2019-09-27 13:36:37,955 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5: begin an election at term 1 for -1: [6d2115e7-2387-46ef-9dff-f1092adf22a8:192.168.151.103:39733], old=null
2019-09-27 13:36:37,955 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: shutdown LeaderElection
2019-09-27 13:36:37,955 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 13:36:37,955 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: change Leader from null to 6d2115e7-2387-46ef-9dff-f1092adf22a8 at term 1 for becomeLeader, leader elected after 5187ms
2019-09-27 13:36:37,957 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 13:36:37,957 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 13:36:37,957 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 13:36:37,957 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 13:36:37,958 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 13:36:37,958 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 13:36:37,961 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: start LeaderState
2019-09-27 13:36:37,962 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:37,962 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: set configuration 0: [6d2115e7-2387-46ef-9dff-f1092adf22a8:192.168.151.103:39733], old=null at 0
2019-09-27 13:36:37,995 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(106)) - 08207814-19ac-4e65-ae6c-673e09624768:group-1224532D134F changes to CANDIDATE, lastRpcTime:5101, electionTimeout:5100ms
2019-09-27 13:36:37,995 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown FollowerState
2019-09-27 13:36:37,995 [Thread-232] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:37,995 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start LeaderElection
2019-09-27 13:36:37,995 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b:group-1224532D134F changes to CANDIDATE, lastRpcTime:5106, electionTimeout:5079ms
2019-09-27 13:36:37,997 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6: begin an election at term 1 for -1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:37,997 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown FollowerState
2019-09-27 13:36:38,000 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 13:36:38,000 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start LeaderElection
2019-09-27 13:36:38,008 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/ratis/5011ddeb-a144-4073-9666-c882a96d4461/current/log_inprogress_0
2019-09-27 13:36:38,008 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7: begin an election at term 1 for -1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:38,008 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8: begin an election at term 1 for -1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:38,076 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:38,077 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6: Election REJECTED; received 2 response(s) [d67bad60-2d89-4d07-88f6-da90aa48785a<-08207814-19ac-4e65-ae6c-673e09624768#0:FAIL-t1, d67bad60-2d89-4d07-88f6-da90aa48785a<-22cb26a1-1640-496f-8576-0d3ad7b2657b#0:FAIL-t1] and 0 exception(s); d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:t1, leader=null, voted=d67bad60-2d89-4d07-88f6-da90aa48785a, raftlog=d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:38,077 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8: Election REJECTED; received 2 response(s) [22cb26a1-1640-496f-8576-0d3ad7b2657b<-08207814-19ac-4e65-ae6c-673e09624768#0:FAIL-t1, 22cb26a1-1640-496f-8576-0d3ad7b2657b<-d67bad60-2d89-4d07-88f6-da90aa48785a#0:FAIL-t1] and 0 exception(s); 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:t1, leader=null, voted=22cb26a1-1640-496f-8576-0d3ad7b2657b, raftlog=22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:38,078 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7: Election REJECTED; received 2 response(s) [08207814-19ac-4e65-ae6c-673e09624768<-22cb26a1-1640-496f-8576-0d3ad7b2657b#0:FAIL-t1, 08207814-19ac-4e65-ae6c-673e09624768<-d67bad60-2d89-4d07-88f6-da90aa48785a#0:FAIL-t1] and 0 exception(s); 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:t1, leader=null, voted=08207814-19ac-4e65-ae6c-673e09624768, raftlog=08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:38,084 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 13:36:38,088 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 13:36:38,089 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 13:36:38,089 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown LeaderElection
2019-09-27 13:36:38,089 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown LeaderElection
2019-09-27 13:36:38,089 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown LeaderElection
2019-09-27 13:36:38,090 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start FollowerState
2019-09-27 13:36:38,090 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start FollowerState
2019-09-27 13:36:38,090 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start FollowerState
2019-09-27 13:36:39,077 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:40,078 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:41,080 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:42,081 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:43,087 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:43,099 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(106)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b:group-1224532D134F changes to CANDIDATE, lastRpcTime:5009, electionTimeout:5008ms
2019-09-27 13:36:43,100 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown FollowerState
2019-09-27 13:36:43,100 [Thread-256] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-27 13:36:43,100 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start LeaderElection
2019-09-27 13:36:43,115 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9: begin an election at term 2 for -1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:43,123 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:36:43,124 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown FollowerState
2019-09-27 13:36:43,123 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:36:43,124 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 08207814-19ac-4e65-ae6c-673e09624768: start FollowerState
2019-09-27 13:36:43,124 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(115)) - 08207814-19ac-4e65-ae6c-673e09624768: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 13:36:43,124 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown FollowerState
2019-09-27 13:36:43,126 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d67bad60-2d89-4d07-88f6-da90aa48785a: start FollowerState
2019-09-27 13:36:43,126 [Thread-255] INFO  impl.FollowerState (FollowerState.java:run(115)) - d67bad60-2d89-4d07-88f6-da90aa48785a: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 13:36:43,149 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9: Election PASSED; received 1 response(s) [22cb26a1-1640-496f-8576-0d3ad7b2657b<-d67bad60-2d89-4d07-88f6-da90aa48785a#0:OK-t2] and 0 exception(s); 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:t2, leader=null, voted=22cb26a1-1640-496f-8576-0d3ad7b2657b, raftlog=22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null
2019-09-27 13:36:43,155 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown LeaderElection
2019-09-27 13:36:43,158 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-27 13:36:43,158 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: change Leader from null to 22cb26a1-1640-496f-8576-0d3ad7b2657b at term 2 for becomeLeader, leader elected after 10286ms
2019-09-27 13:36:43,159 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 13:36:43,159 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 13:36:43,159 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 13:36:43,160 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 13:36:43,160 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 13:36:43,160 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 13:36:43,167 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 13:36:43,167 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:43,168 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 13:36:43,172 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 13:36:43,173 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:43,174 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:43,175 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 13:36:43,175 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 13:36:43,175 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 13:36:43,176 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 13:36:43,176 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 13:36:43,176 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 13:36:43,180 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: start LeaderState
2019-09-27 13:36:43,180 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:43,181 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: set configuration 0: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null at 0
2019-09-27 13:36:43,226 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f/current/log_inprogress_0
2019-09-27 13:36:43,246 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: change Leader from null to 22cb26a1-1640-496f-8576-0d3ad7b2657b at term 2 for appendEntries, leader elected after 10373ms
2019-09-27 13:36:43,246 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: change Leader from null to 22cb26a1-1640-496f-8576-0d3ad7b2657b at term 2 for appendEntries, leader elected after 10373ms
2019-09-27 13:36:43,278 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: set configuration 0: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null at 0
2019-09-27 13:36:43,278 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: set configuration 0: [08207814-19ac-4e65-ae6c-673e09624768:192.168.151.103:44575, 22cb26a1-1640-496f-8576-0d3ad7b2657b:192.168.151.103:40262, d67bad60-2d89-4d07-88f6-da90aa48785a:192.168.151.103:44785], old=null at 0
2019-09-27 13:36:43,278 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:43,279 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 13:36:43,318 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f/current/log_inprogress_0
2019-09-27 13:36:43,318 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/ratis/f9dbb8dd-d535-484e-add1-1224532d134f/current/log_inprogress_0
2019-09-27 13:36:44,088 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:45,090 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:46,091 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:47,092 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:48,094 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:49,095 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:50,096 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:51,097 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:52,099 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:52,101 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 13:36:53,102 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:54,103 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:55,104 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:56,106 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:57,107 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:58,108 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:36:59,110 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:00,111 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:01,112 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:02,114 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:02,115 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 13:37:03,116 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:04,118 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:05,119 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:06,120 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:07,121 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:08,123 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:09,124 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:10,125 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:11,127 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:12,128 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:12,130 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 13:37:13,131 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:14,132 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:15,134 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:16,135 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:17,136 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:18,138 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:19,139 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:20,140 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:21,142 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:22,143 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:22,145 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 13:37:23,146 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:24,147 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:25,148 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:26,150 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:27,151 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:28,152 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:29,153 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:30,154 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:31,156 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:32,157 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:32,159 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 13:37:33,160 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:34,161 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:35,163 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:36,164 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:37,166 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:38,167 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:39,168 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:40,169 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:41,170 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:42,172 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:42,173 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 13:37:43,175 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:44,176 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:45,177 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:46,178 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:47,180 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:48,181 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:49,182 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:50,183 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:51,185 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:52,186 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:52,188 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 13:37:53,189 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:54,190 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:55,191 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:56,192 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:57,194 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:58,195 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:37:59,196 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:00,197 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:01,198 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:02,200 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:02,201 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 13:38:03,203 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:04,204 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:05,205 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:06,206 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:07,207 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:08,209 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:09,210 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:10,212 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:11,213 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:12,214 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:12,215 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 13:38:13,217 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:14,218 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:15,219 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:16,220 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:17,222 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:18,223 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:19,224 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:20,225 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:21,226 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:22,227 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:22,229 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 13:38:22,233 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-27 13:38:22,256 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-27 13:38:23,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:24,262 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:25,263 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:26,266 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:27,267 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:28,268 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:29,269 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:30,271 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:31,272 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:32,273 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:33,276 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:34,277 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:35,278 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:36,280 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:37,281 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:38,282 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:39,283 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:40,284 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:41,285 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:42,286 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:42,288 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 13:38:43,289 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:44,290 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:45,291 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:46,293 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:47,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:48,295 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:49,296 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:50,297 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:51,298 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:52,300 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:52,301 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 13:38:53,303 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:54,304 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:55,305 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:56,306 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:57,308 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:58,309 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:38:59,310 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:00,311 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:01,312 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:02,314 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:02,315 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 13:39:03,317 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:04,318 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:05,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:06,320 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:07,321 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:08,322 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:09,323 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:10,325 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:11,326 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:12,327 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:12,329 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 13:39:13,330 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:14,331 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:15,332 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:16,333 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:17,334 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:18,335 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:19,337 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:20,338 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:21,339 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:22,340 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:22,342 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 13:39:23,343 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:24,344 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:25,345 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:26,346 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:27,348 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:28,349 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:29,350 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:30,351 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:31,352 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:32,353 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:32,354 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 13:39:33,365 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:34,367 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:35,371 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:36,373 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:37,375 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:38,376 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:39,377 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:40,378 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:41,380 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:42,381 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:42,383 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 13:39:43,385 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:44,387 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:45,388 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:46,390 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:47,391 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:48,392 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:49,394 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:50,395 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:51,397 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:52,399 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:52,400 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 13:39:53,402 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:54,403 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:55,404 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:56,405 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:57,406 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:58,408 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:39:59,409 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:00,410 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:01,411 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:02,412 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:02,414 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 13:40:03,415 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:04,416 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:05,417 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:06,418 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:07,420 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:08,421 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:09,422 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:10,423 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:11,425 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:12,426 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 13:40:12,427 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 13:40:12,428 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-27 13:40:12,431 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-27 13:40:12,432 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-27 13:40:12,432 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-27 13:40:12,433 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45292
2019-09-27 13:40:12,434 [IPC Server listener on 45292] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45292
2019-09-27 13:40:12,434 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-27 13:40:12,435 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 13:40:12,436 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-27 13:40:12,437 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-27 13:40:12,444 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27fde870{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-27 13:40:12,451 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b4c3c29{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:12,452 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@529cfee5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:12,452 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7df60067{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:12,458 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-27 13:40:12,626 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 13:40:12,707 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 13:40:17,462 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 13:40:17,462 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 13:40:17,464 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 08207814-19ac-4e65-ae6c-673e09624768: close
2019-09-27 13:40:17,464 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: close
2019-09-27 13:40:17,467 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: shutdown
2019-09-27 13:40:17,467 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: shutdown
2019-09-27 13:40:17,468 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FACD4759C689,id=08207814-19ac-4e65-ae6c-673e09624768
2019-09-27 13:40:17,468 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C882A96D4461,id=6d2115e7-2387-46ef-9dff-f1092adf22a8
2019-09-27 13:40:17,468 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown LeaderState
2019-09-27 13:40:17,468 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: shutdown LeaderState
2019-09-27 13:40:17,470 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8-PendingRequests: sendNotLeaderResponses
2019-09-27 13:40:17,470 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 08207814-19ac-4e65-ae6c-673e09624768-PendingRequests: sendNotLeaderResponses
2019-09-27 13:40:17,848 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:17,848 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:17,852 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689: closes. applyIndex: 0
2019-09-27 13:40:17,852 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461: closes. applyIndex: 0
2019-09-27 13:40:17,855 [08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:17,855 [6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:17,859 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 08207814-19ac-4e65-ae6c-673e09624768@group-FACD4759C689-SegmentedRaftLogWorker close()
2019-09-27 13:40:17,859 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8@group-C882A96D4461-SegmentedRaftLogWorker close()
2019-09-27 13:40:17,867 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: shutdown
2019-09-27 13:40:17,868 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1224532D134F,id=08207814-19ac-4e65-ae6c-673e09624768
2019-09-27 13:40:17,868 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown FollowerState
2019-09-27 13:40:17,868 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: shutdown server with port 39733 now
2019-09-27 13:40:17,869 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(115)) - 08207814-19ac-4e65-ae6c-673e09624768: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 13:40:17,868 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:17,879 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F: closes. applyIndex: 0
2019-09-27 13:40:17,880 [08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:17,881 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 08207814-19ac-4e65-ae6c-673e09624768@group-1224532D134F-SegmentedRaftLogWorker close()
2019-09-27 13:40:17,885 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown server with port 44575 now
2019-09-27 13:40:17,887 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 6d2115e7-2387-46ef-9dff-f1092adf22a8: shutdown server with port 39733 successfully
2019-09-27 13:40:17,895 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 13:40:17,896 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 08207814-19ac-4e65-ae6c-673e09624768: shutdown server with port 44575 successfully
2019-09-27 13:40:17,896 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 08207814-19ac-4e65-ae6c-673e09624768: installSnapshot onError, lastRequest: 22cb26a1-1640-496f-8576-0d3ad7b2657b->08207814-19ac-4e65-ae6c-673e09624768#86-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-27 13:40:17,905 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
Sep 27, 2019 1:40:17 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@5049befd
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-27 13:40:17,908 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-27 13:40:17,910 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768: nextIndex: updateUnconditionally 1 -> 0
2019-09-27 13:40:17,933 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 13:40:17,933 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 13:40:17,938 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 13:40:17,939 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 13:40:17,942 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43af351a{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 13:40:17,942 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@726aa968{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 13:40:17,943 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1305c126{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:17,943 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7100dea{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:17,943 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6342d610{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:17,944 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62dbe64e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:17,944 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53f4c1e6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:17,945 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@524a076e{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:18,845 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 13:40:18,867 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 13:40:18,894 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 13:40:18,897 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 13:40:21,391 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 13:40:21,392 [grpc-default-executor-6] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 13:40:22,948 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 13:40:22,948 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 13:40:22,949 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 93238805-6c3b-4f37-b48b-125b403d7948: close
2019-09-27 13:40:22,949 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: close
2019-09-27 13:40:22,950 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: shutdown
2019-09-27 13:40:22,950 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: shutdown
2019-09-27 13:40:22,950 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F0BAD47587B8,id=93238805-6c3b-4f37-b48b-125b403d7948
2019-09-27 13:40:22,950 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1224532D134F,id=22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:40:22,951 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 93238805-6c3b-4f37-b48b-125b403d7948: shutdown LeaderState
2019-09-27 13:40:22,951 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown LeaderState
2019-09-27 13:40:22,952 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 93238805-6c3b-4f37-b48b-125b403d7948-PendingRequests: sendNotLeaderResponses
2019-09-27 13:40:22,956 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b-PendingRequests: sendNotLeaderResponses
2019-09-27 13:40:22,956 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:22,957 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8: closes. applyIndex: 0
2019-09-27 13:40:22,956 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$405/1798970671@b4e9c62] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->08207814-19ac-4e65-ae6c-673e09624768-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 13:40:22,956 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$405/1798970671@c327aef] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->d67bad60-2d89-4d07-88f6-da90aa48785a-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 13:40:22,957 [93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:22,956 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:22,959 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 93238805-6c3b-4f37-b48b-125b403d7948@group-F0BAD47587B8-SegmentedRaftLogWorker close()
2019-09-27 13:40:22,959 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F: closes. applyIndex: 0
2019-09-27 13:40:22,962 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 93238805-6c3b-4f37-b48b-125b403d7948: shutdown server with port 33994 now
2019-09-27 13:40:22,962 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:22,964 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F-SegmentedRaftLogWorker close()
2019-09-27 13:40:22,965 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 93238805-6c3b-4f37-b48b-125b403d7948: shutdown server with port 33994 successfully
2019-09-27 13:40:22,968 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: shutdown
2019-09-27 13:40:22,968 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - d67bad60-2d89-4d07-88f6-da90aa48785a: Completed APPEND_ENTRIES, lastRequest: 22cb26a1-1640-496f-8576-0d3ad7b2657b->d67bad60-2d89-4d07-88f6-da90aa48785a#88-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 13:40:22,970 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7AFBE965483C,id=22cb26a1-1640-496f-8576-0d3ad7b2657b
2019-09-27 13:40:22,970 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown LeaderState
2019-09-27 13:40:22,971 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b-PendingRequests: sendNotLeaderResponses
2019-09-27 13:40:22,971 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:22,972 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C: closes. applyIndex: 0
2019-09-27 13:40:22,973 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->d67bad60-2d89-4d07-88f6-da90aa48785a-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-27 13:40:22,973 [22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:22,976 [grpc-default-executor-6] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-1224532D134F->d67bad60-2d89-4d07-88f6-da90aa48785a: nextIndex: updateUnconditionally 1 -> 0
2019-09-27 13:40:22,976 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b@group-7AFBE965483C-SegmentedRaftLogWorker close()
2019-09-27 13:40:22,978 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown server with port 40262 now
2019-09-27 13:40:22,979 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 22cb26a1-1640-496f-8576-0d3ad7b2657b: shutdown server with port 40262 successfully
2019-09-27 13:40:22,981 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 13:40:22,982 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 13:40:23,011 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 13:40:23,011 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 13:40:23,014 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 13:40:23,015 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 13:40:23,019 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12eedfee{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 13:40:23,019 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cd64ee8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 13:40:23,020 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@620c8641{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:23,020 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c3c4a71{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:23,022 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e33d73e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:23,022 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@127a7272{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:23,023 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6edcad64{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:23,023 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56637cff{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:23,845 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 13:40:28,025 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 13:40:28,026 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d67bad60-2d89-4d07-88f6-da90aa48785a: close
2019-09-27 13:40:28,026 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: shutdown
2019-09-27 13:40:28,027 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EA5834C8F82,id=d67bad60-2d89-4d07-88f6-da90aa48785a
2019-09-27 13:40:28,027 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown LeaderState
2019-09-27 13:40:28,027 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - d67bad60-2d89-4d07-88f6-da90aa48785a-PendingRequests: sendNotLeaderResponses
2019-09-27 13:40:28,027 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:28,028 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82: closes. applyIndex: 0
2019-09-27 13:40:28,028 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:28,029 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-4EA5834C8F82-SegmentedRaftLogWorker close()
2019-09-27 13:40:28,031 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: shutdown
2019-09-27 13:40:28,031 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1224532D134F,id=d67bad60-2d89-4d07-88f6-da90aa48785a
2019-09-27 13:40:28,031 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown FollowerState
2019-09-27 13:40:28,032 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-StateMachineUpdater: set stopIndex = 0
2019-09-27 13:40:28,032 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(115)) - d67bad60-2d89-4d07-88f6-da90aa48785a: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 13:40:28,032 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F: closes. applyIndex: 0
2019-09-27 13:40:28,033 [d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 13:40:28,034 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d67bad60-2d89-4d07-88f6-da90aa48785a@group-1224532D134F-SegmentedRaftLogWorker close()
2019-09-27 13:40:28,035 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown server with port 44785 now
2019-09-27 13:40:28,037 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d67bad60-2d89-4d07-88f6-da90aa48785a: shutdown server with port 44785 successfully
2019-09-27 13:40:28,041 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-24f113d1-7dab-4224-a498-959ad3fc9ddc/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 13:40:28,059 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 13:40:28,061 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 13:40:28,064 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1457fde{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 13:40:28,064 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6f94fb9d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:28,065 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44f24a20{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:28,066 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18b8d173{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:28,067 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-27 13:40:28,067 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-27 13:40:28,067 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-27 13:40:28,067 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-27 13:40:28,067 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-27 13:40:28,068 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-27 13:40:28,068 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46687
2019-09-27 13:40:28,070 [IPC Server listener on 46687] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46687
2019-09-27 13:40:28,070 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 13:40:28,158 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-27 13:40:28,159 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-27 13:40:28,159 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-27 13:40:28,159 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37956
2019-09-27 13:40:28,162 [IPC Server listener on 37956] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37956
2019-09-27 13:40:28,162 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-27 13:40:28,162 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 13:40:28,162 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-27 13:40:28,163 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43137
2019-09-27 13:40:28,165 [IPC Server listener on 43137] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43137
2019-09-27 13:40:28,165 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-27 13:40:28,165 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 13:40:28,166 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@544630b7{/,null,UNAVAILABLE}{/scm}
2019-09-27 13:40:28,167 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 13:40:28,168 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 13:40:28,168 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 13:40:28,169 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-27 13:40:28,169 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 13:40:28,170 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 13:40:28,170 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-27 13:40:28,177 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-27 13:40:28,185 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-27 13:40:28,186 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
