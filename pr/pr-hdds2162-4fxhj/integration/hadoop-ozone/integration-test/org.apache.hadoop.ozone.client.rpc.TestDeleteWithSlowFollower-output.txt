2019-09-27 09:49:51,703 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:51,784 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:51,787 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:51,802 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @836ms
2019-09-27 09:49:51,883 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-27 09:49:51,884 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-27 09:49:51,884 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-27 09:49:51,884 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-27 09:49:51,884 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-27 09:49:51,885 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-27 09:49:51,893 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 09:49:51,894 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 09:49:51,895 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 09:49:52,097 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@55141def
2019-09-27 09:49:52,100 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-27 09:49:52,202 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 09:49:52,204 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 09:49:52,207 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-27 09:49:52,283 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-27 09:49:52,297 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:52,354 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-27 09:49:52,357 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:52,484 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-27 09:49:52,836 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 09:49:52,863 [Socket Reader #1 for port 33903] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33903
2019-09-27 09:49:53,029 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 09:49:53,030 [Socket Reader #1 for port 37063] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37063
2019-09-27 09:49:53,043 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 09:49:53,044 [Socket Reader #1 for port 35912] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35912
2019-09-27 09:49:53,071 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-27 09:49:53,245 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 09:49:53,254 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 09:49:53,264 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 09:49:53,267 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-27 09:49:53,267 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 09:49:53,267 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 09:49:53,303 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35912
2019-09-27 09:49:53,368 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-27 09:49:53,390 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-27 09:49:53,390 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-27 09:49:53,635 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:35912
2019-09-27 09:49:53,636 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 09:49:53,636 [IPC Server listener on 35912] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35912: starting
2019-09-27 09:49:53,639 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37063
2019-09-27 09:49:53,641 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:37063
2019-09-27 09:49:53,641 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 09:49:53,642 [IPC Server listener on 37063] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37063: starting
2019-09-27 09:49:53,645 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33903
2019-09-27 09:49:53,645 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:33903
2019-09-27 09:49:53,646 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 09:49:53,646 [IPC Server listener on 33903] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33903: starting
2019-09-27 09:49:53,650 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37839
2019-09-27 09:49:53,651 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 09:49:53,689 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-27 09:49:53,690 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-27 09:49:53,723 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5398edd0{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-27 09:49:53,729 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:37839}
2019-09-27 09:49:53,729 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2764ms
2019-09-27 09:49:53,731 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-27 09:49:53,731 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-27 09:49:53,733 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:37839
2019-09-27 09:49:53,742 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1095f122] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 09:49:53,746 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:53,885 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-27 09:49:53,886 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-27 09:49:53,887 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:53,888 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:54,689 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 09:49:54,697 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-27 09:49:54,697 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-27 09:49:54,697 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-27 09:49:54,698 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-27 09:49:54,698 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-27 09:49:54,698 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-27 09:49:54,698 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-27 09:49:54,699 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-27 09:49:54,699 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-27 09:49:54,699 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-27 09:49:54,699 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-27 09:49:54,700 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-27 09:49:54,700 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-27 09:49:54,700 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-27 09:49:54,700 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-27 09:49:54,701 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-27 09:49:54,701 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-27 09:49:54,701 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-27 09:49:54,701 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-27 09:49:54,702 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-27 09:49:54,702 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-27 09:49:54,702 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-27 09:49:54,702 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 09:49:54,703 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 09:49:54,703 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 09:49:55,162 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 09:49:55,163 [Socket Reader #1 for port 46587] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46587
2019-09-27 09:49:55,186 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:46587
2019-09-27 09:49:55,187 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-27 09:49:55,188 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 09:49:55,189 [IPC Server listener on 46587] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46587: starting
2019-09-27 09:49:55,194 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-27 09:49:55,197 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 09:49:55,198 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 09:49:55,201 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 09:49:55,203 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-27 09:49:55,203 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 09:49:55,203 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 09:49:55,207 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39470
2019-09-27 09:49:55,207 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 09:49:55,210 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-27 09:49:55,210 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-27 09:49:55,218 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@529cfee5{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-27 09:49:55,219 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:39470}
2019-09-27 09:49:55,220 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4255ms
2019-09-27 09:49:55,220 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 09:49:55,221 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:39470
2019-09-27 09:49:55,581 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 09:49:55,633 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 09:49:55,676 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 09:49:55,679 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/containers/hdds to VolumeSet
2019-09-27 09:49:55,683 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-27 09:49:55,729 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-27 09:49:55,885 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 09:49:55,952 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 09:49:55,957 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 09:49:55,958 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 09:49:55,960 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:49:55,960 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 09:49:55,961 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 09:49:56,130 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis] (custom)
2019-09-27 09:49:56,219 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 09:49:56,222 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 09:49:56,223 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 09:49:56,226 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 09:49:56,227 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 09:49:56,227 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 09:49:56,227 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 09:49:56,229 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43183
2019-09-27 09:49:56,230 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 09:49:56,233 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-27 09:49:56,234 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 09:49:56,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7aac8884{/,file:///tmp/jetty-0.0.0.0-43183-hddsDatanode-_-any-4758086996400213473.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 09:49:56,283 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:43183}
2019-09-27 09:49:56,284 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5319ms
2019-09-27 09:49:56,285 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 09:49:56,285 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43183
2019-09-27 09:49:56,286 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 09:49:56,290 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 09:49:56,293 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ed6beb6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 09:49:56,301 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 09:49:56,302 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/containers/hdds to VolumeSet
2019-09-27 09:49:56,303 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-27 09:49:56,305 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5f7989fa
2019-09-27 09:49:56,320 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 09:49:56,320 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 09:49:56,321 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 09:49:56,321 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 09:49:56,321 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:49:56,321 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 09:49:56,322 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 09:49:56,322 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis] (custom)
2019-09-27 09:49:56,324 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 09:49:56,325 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 09:49:56,326 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 09:49:56,328 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 09:49:56,329 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 09:49:56,329 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 09:49:56,330 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 09:49:56,330 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44599
2019-09-27 09:49:56,330 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 09:49:56,335 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-27 09:49:56,335 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 09:49:56,366 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7bc44ce8{/,file:///tmp/jetty-0.0.0.0-44599-hddsDatanode-_-any-1740223738645992550.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 09:49:56,367 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:44599}
2019-09-27 09:49:56,368 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5403ms
2019-09-27 09:49:56,369 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 09:49:56,370 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44599
2019-09-27 09:49:56,370 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 09:49:56,374 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds2162-4fxhj-20988671 ip:192.168.151.103
2019-09-27 09:49:56,374 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@50663c4c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 09:49:56,383 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 09:49:56,384 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/containers/hdds to VolumeSet
2019-09-27 09:49:56,384 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@467b684d
2019-09-27 09:49:56,384 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@467b684d
2019-09-27 09:49:56,399 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 09:49:56,399 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 09:49:56,400 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 09:49:56,400 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 09:49:56,400 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:49:56,400 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 09:49:56,401 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 09:49:56,401 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis] (custom)
2019-09-27 09:49:56,403 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 09:49:56,404 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 09:49:56,405 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 09:49:56,406 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 09:49:56,407 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 09:49:56,407 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 09:49:56,407 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 09:49:56,408 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33521
2019-09-27 09:49:56,408 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 09:49:56,411 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d95a72e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-27 09:49:56,412 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77b919a3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 09:49:56,416 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/meta/datanode.id
2019-09-27 09:49:56,421 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/meta/datanode.id
2019-09-27 09:49:56,444 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@59cda16e{/,file:///tmp/jetty-0.0.0.0-33521-hddsDatanode-_-any-7158896757493564413.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 09:49:56,445 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5dd903be{HTTP/1.1,[http/1.1]}{0.0.0.0:33521}
2019-09-27 09:49:56,445 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5480ms
2019-09-27 09:49:56,446 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 09:49:56,447 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33521
2019-09-27 09:49:56,449 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 09:49:56,450 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54ed0b1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 09:49:56,453 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/meta/datanode.id
2019-09-27 09:49:57,449 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 09:49:58,363 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 09:49:58,366 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 09:49:58,366 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 92c2aa47-904a-4470-a9e0-4adfb7a731be at port 0
2019-09-27 09:49:58,392 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 09:49:58,402 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 09:49:58,402 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis d038ac22-855c-4dd8-8556-1732bca3cf25 at port 0
2019-09-27 09:49:58,413 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start RPC server
2019-09-27 09:49:58,418 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start RPC server
2019-09-27 09:49:58,450 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 09:49:58,468 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 09:49:58,470 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 09:49:58,470 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 938e73be-7ed6-4980-bddd-2d31dd7c4d41 at port 0
2019-09-27 09:49:58,483 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: start RPC server
2019-09-27 09:49:58,598 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d038ac22-855c-4dd8-8556-1732bca3cf25: GrpcService started, listening on 0.0.0.0/0.0.0.0:40884
2019-09-27 09:49:58,598 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: GrpcService started, listening on 0.0.0.0/0.0.0.0:34190
2019-09-27 09:49:58,598 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: GrpcService started, listening on 0.0.0.0/0.0.0.0:45985
2019-09-27 09:49:58,600 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 938e73be-7ed6-4980-bddd-2d31dd7c4d41 is started using port 34190
2019-09-27 09:49:58,599 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis d038ac22-855c-4dd8-8556-1732bca3cf25 is started using port 40884
2019-09-27 09:49:58,600 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 92c2aa47-904a-4470-a9e0-4adfb7a731be is started using port 45985
2019-09-27 09:49:58,607 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 92c2aa47-904a-4470-a9e0-4adfb7a731be is started using port 42671
2019-09-27 09:49:58,607 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 938e73be-7ed6-4980-bddd-2d31dd7c4d41 is started using port 40330
2019-09-27 09:49:58,608 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc d038ac22-855c-4dd8-8556-1732bca3cf25 is started using port 42533
2019-09-27 09:49:59,451 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 09:50:00,338 [IPC Server handler 0 on 33903] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/92c2aa47-904a-4470-a9e0-4adfb7a731be
2019-09-27 09:50:00,339 [IPC Server handler 0 on 33903] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 92c2aa47-904a-4470-a9e0-4adfb7a731be{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 09:50:00,345 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-27 09:50:00,345 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-27 09:50:00,345 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-27 09:50:00,377 [IPC Server handler 1 on 33903] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d038ac22-855c-4dd8-8556-1732bca3cf25
2019-09-27 09:50:00,378 [IPC Server handler 1 on 33903] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : d038ac22-855c-4dd8-8556-1732bca3cf25{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 09:50:00,452 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-27 09:50:00,453 [IPC Server handler 2 on 33903] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/938e73be-7ed6-4980-bddd-2d31dd7c4d41
2019-09-27 09:50:00,454 [IPC Server handler 2 on 33903] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 938e73be-7ed6-4980-bddd-2d31dd7c4d41{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}
2019-09-27 09:50:00,910 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: addNew group-83C694710F86:[92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] returns group-83C694710F86:java.util.concurrent.CompletableFuture@d04e25[Not completed]
2019-09-27 09:50:00,929 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: new RaftServerImpl for group-83C694710F86:[92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] with ContainerStateMachine:uninitialized
2019-09-27 09:50:00,932 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 09:50:00,934 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 09:50:00,934 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-27 09:50:00,935 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 09:50:00,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:00,947 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: ConfigurationManager, init=-1: [92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null, confs=<EMPTY_MAP>
2019-09-27 09:50:00,947 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis] (custom)
2019-09-27 09:50:00,957 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/de6c3077-9d30-4a9a-bf78-83c694710f86 does not exist. Creating ...
2019-09-27 09:50:00,976 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/de6c3077-9d30-4a9a-bf78-83c694710f86/in_use.lock acquired by nodename 25663@pr-hdds2162-4fxhj-20988671
2019-09-27 09:50:00,991 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/de6c3077-9d30-4a9a-bf78-83c694710f86 has been successfully formatted.
2019-09-27 09:50:00,993 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-83C694710F86: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 09:50:00,994 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-27 09:50:00,996 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 09:50:01,002 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 09:50:01,002 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:01,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,008 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 09:50:01,014 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/de6c3077-9d30-4a9a-bf78-83c694710f86
2019-09-27 09:50:01,015 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-27 09:50:01,021 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-27 09:50:01,048 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 09:50:01,049 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 09:50:01,052 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,052 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 09:50:01,053 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 09:50:01,053 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 09:50:01,054 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 09:50:01,055 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 09:50:01,055 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 09:50:01,063 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 09:50:01,067 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 09:50:01,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 09:50:01,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 09:50:01,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 09:50:01,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 09:50:01,098 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: start as a follower, conf=-1: [92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:01,099 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 09:50:01,101 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start FollowerState
2019-09-27 09:50:01,102 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-83C694710F86,id=92c2aa47-904a-4470-a9e0-4adfb7a731be
2019-09-27 09:50:01,173 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: de6c3077-9d30-4a9a-bf78-83c694710f86, Nodes: 92c2aa47-904a-4470-a9e0-4adfb7a731be{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 09:50:01,195 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: addNew group-98D9370A73AF:[938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190] returns group-98D9370A73AF:java.util.concurrent.CompletableFuture@3c3ce85b[Not completed]
2019-09-27 09:50:01,230 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: new RaftServerImpl for group-98D9370A73AF:[938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190] with ContainerStateMachine:uninitialized
2019-09-27 09:50:01,231 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 09:50:01,232 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 09:50:01,232 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-27 09:50:01,232 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 09:50:01,232 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:01,233 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: ConfigurationManager, init=-1: [938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190], old=null, confs=<EMPTY_MAP>
2019-09-27 09:50:01,233 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis] (custom)
2019-09-27 09:50:01,233 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/d1199ee6-4b78-4fa1-ad00-98d9370a73af does not exist. Creating ...
2019-09-27 09:50:01,280 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/d1199ee6-4b78-4fa1-ad00-98d9370a73af/in_use.lock acquired by nodename 25663@pr-hdds2162-4fxhj-20988671
2019-09-27 09:50:01,294 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/d1199ee6-4b78-4fa1-ad00-98d9370a73af has been successfully formatted.
2019-09-27 09:50:01,295 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-98D9370A73AF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 09:50:01,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-27 09:50:01,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 09:50:01,297 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 09:50:01,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:01,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,298 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 09:50:01,298 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/d1199ee6-4b78-4fa1-ad00-98d9370a73af
2019-09-27 09:50:01,306 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 09:50:01,307 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 09:50:01,307 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,307 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 09:50:01,308 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 09:50:01,308 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 09:50:01,308 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 09:50:01,308 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 09:50:01,309 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 09:50:01,309 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 09:50:01,309 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 09:50:01,310 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 09:50:01,310 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 09:50:01,310 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 09:50:01,311 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 09:50:01,317 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: start as a follower, conf=-1: [938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190], old=null
2019-09-27 09:50:01,317 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 09:50:01,317 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: start FollowerState
2019-09-27 09:50:01,319 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-98D9370A73AF,id=938e73be-7ed6-4980-bddd-2d31dd7c4d41
2019-09-27 09:50:01,333 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d1199ee6-4b78-4fa1-ad00-98d9370a73af, Nodes: 938e73be-7ed6-4980-bddd-2d31dd7c4d41{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 09:50:01,356 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d038ac22-855c-4dd8-8556-1732bca3cf25: addNew group-3600D2628B2F:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884] returns group-3600D2628B2F:java.util.concurrent.CompletableFuture@7017c9bd[Not completed]
2019-09-27 09:50:01,377 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d038ac22-855c-4dd8-8556-1732bca3cf25: new RaftServerImpl for group-3600D2628B2F:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884] with ContainerStateMachine:uninitialized
2019-09-27 09:50:01,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 09:50:01,379 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 09:50:01,379 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-27 09:50:01,379 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 09:50:01,379 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:01,379 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: ConfigurationManager, init=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884], old=null, confs=<EMPTY_MAP>
2019-09-27 09:50:01,380 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis] (custom)
2019-09-27 09:50:01,380 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/83aa03e3-31de-47b2-a08a-3600d2628b2f does not exist. Creating ...
2019-09-27 09:50:01,401 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/83aa03e3-31de-47b2-a08a-3600d2628b2f/in_use.lock acquired by nodename 25663@pr-hdds2162-4fxhj-20988671
2019-09-27 09:50:01,415 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/83aa03e3-31de-47b2-a08a-3600d2628b2f has been successfully formatted.
2019-09-27 09:50:01,415 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-3600D2628B2F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 09:50:01,415 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-27 09:50:01,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 09:50:01,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 09:50:01,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:01,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,417 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 09:50:01,417 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/83aa03e3-31de-47b2-a08a-3600d2628b2f
2019-09-27 09:50:01,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 09:50:01,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 09:50:01,448 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,448 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 09:50:01,448 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 09:50:01,449 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 09:50:01,449 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 09:50:01,449 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 09:50:01,449 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 09:50:01,450 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 09:50:01,450 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 09:50:01,451 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 09:50:01,451 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 09:50:01,451 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 09:50:01,452 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 09:50:01,453 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-27 09:50:01,457 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: start as a follower, conf=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884], old=null
2019-09-27 09:50:01,458 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 09:50:01,458 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start FollowerState
2019-09-27 09:50:01,458 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3600D2628B2F,id=d038ac22-855c-4dd8-8556-1732bca3cf25
2019-09-27 09:50:01,472 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 83aa03e3-31de-47b2-a08a-3600d2628b2f, Nodes: d038ac22-855c-4dd8-8556-1732bca3cf25{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 09:50:01,528 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d038ac22-855c-4dd8-8556-1732bca3cf25: addNew group-981D4E58C61B:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] returns group-981D4E58C61B:java.util.concurrent.CompletableFuture@58f39b1b[Not completed]
2019-09-27 09:50:01,528 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: addNew group-981D4E58C61B:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] returns group-981D4E58C61B:java.util.concurrent.CompletableFuture@6b06c4b7[Not completed]
2019-09-27 09:50:01,528 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: addNew group-981D4E58C61B:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] returns group-981D4E58C61B:java.util.concurrent.CompletableFuture@67ad902[Not completed]
2019-09-27 09:50:01,530 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d038ac22-855c-4dd8-8556-1732bca3cf25: new RaftServerImpl for group-981D4E58C61B:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] with ContainerStateMachine:uninitialized
2019-09-27 09:50:01,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 09:50:01,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 09:50:01,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-27 09:50:01,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 09:50:01,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:01,531 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: ConfigurationManager, init=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null, confs=<EMPTY_MAP>
2019-09-27 09:50:01,532 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis] (custom)
2019-09-27 09:50:01,532 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: new RaftServerImpl for group-981D4E58C61B:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] with ContainerStateMachine:uninitialized
2019-09-27 09:50:01,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 09:50:01,532 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b does not exist. Creating ...
2019-09-27 09:50:01,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 09:50:01,533 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-27 09:50:01,534 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: new RaftServerImpl for group-981D4E58C61B:[d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985] with ContainerStateMachine:uninitialized
2019-09-27 09:50:01,534 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 09:50:01,535 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 09:50:01,535 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:01,535 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 09:50:01,535 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: ConfigurationManager, init=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null, confs=<EMPTY_MAP>
2019-09-27 09:50:01,535 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-27 09:50:01,536 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 09:50:01,536 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis] (custom)
2019-09-27 09:50:01,536 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:01,536 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: ConfigurationManager, init=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null, confs=<EMPTY_MAP>
2019-09-27 09:50:01,536 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b does not exist. Creating ...
2019-09-27 09:50:01,536 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis] (custom)
2019-09-27 09:50:01,537 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b does not exist. Creating ...
2019-09-27 09:50:01,553 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b/in_use.lock acquired by nodename 25663@pr-hdds2162-4fxhj-20988671
2019-09-27 09:50:01,553 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b/in_use.lock acquired by nodename 25663@pr-hdds2162-4fxhj-20988671
2019-09-27 09:50:01,553 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b/in_use.lock acquired by nodename 25663@pr-hdds2162-4fxhj-20988671
2019-09-27 09:50:01,566 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b has been successfully formatted.
2019-09-27 09:50:01,566 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b has been successfully formatted.
2019-09-27 09:50:01,566 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b has been successfully formatted.
2019-09-27 09:50:01,566 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-981D4E58C61B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 09:50:01,566 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-981D4E58C61B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 09:50:01,567 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-981D4E58C61B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 09:50:01,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-27 09:50:01,567 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-27 09:50:01,567 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-27 09:50:01,567 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 09:50:01,567 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 09:50:01,568 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 09:50:01,568 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 09:50:01,568 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:01,568 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 09:50:01,569 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,568 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 09:50:01,569 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 09:50:01,569 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:01,569 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b
2019-09-27 09:50:01,569 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:01,570 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 09:50:01,570 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,570 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 09:50:01,570 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,571 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,570 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 09:50:01,571 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 09:50:01,571 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 09:50:01,571 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 09:50:01,571 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b
2019-09-27 09:50:01,572 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 09:50:01,571 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b
2019-09-27 09:50:01,572 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 09:50:01,572 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 09:50:01,572 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 09:50:01,573 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 09:50:01,573 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 09:50:01,573 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,573 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 09:50:01,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 09:50:01,573 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 09:50:01,574 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 09:50:01,574 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 09:50:01,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 09:50:01,574 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 09:50:01,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 09:50:01,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 09:50:01,575 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 09:50:01,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 09:50:01,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 09:50:01,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 09:50:01,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 09:50:01,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 09:50:01,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 09:50:01,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 09:50:01,577 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 09:50:01,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 09:50:01,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 09:50:01,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 09:50:01,577 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 09:50:01,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 09:50:01,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 09:50:01,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 09:50:01,578 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 09:50:01,579 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 09:50:01,579 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 09:50:01,579 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 09:50:01,579 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 09:50:01,580 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 09:50:01,580 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 09:50:01,580 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 09:50:01,585 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: start as a follower, conf=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:01,585 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 09:50:01,586 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start FollowerState
2019-09-27 09:50:01,586 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: start as a follower, conf=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:01,586 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-981D4E58C61B,id=d038ac22-855c-4dd8-8556-1732bca3cf25
2019-09-27 09:50:01,586 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 09:50:01,587 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: start as a follower, conf=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:01,587 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: start FollowerState
2019-09-27 09:50:01,587 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 09:50:01,587 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start FollowerState
2019-09-27 09:50:01,588 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-981D4E58C61B,id=938e73be-7ed6-4980-bddd-2d31dd7c4d41
2019-09-27 09:50:01,589 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-981D4E58C61B,id=92c2aa47-904a-4470-a9e0-4adfb7a731be
2019-09-27 09:50:01,620 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9018c6ff-0dbb-476d-8e82-981d4e58c61b, Nodes: 938e73be-7ed6-4980-bddd-2d31dd7c4d41{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}92c2aa47-904a-4470-a9e0-4adfb7a731be{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}d038ac22-855c-4dd8-8556-1732bca3cf25{ip: 192.168.151.103, host: pr-hdds2162-4fxhj-20988671, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-27 09:50:02,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:03,352 [Thread-181] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-27 09:50:03,357 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-27 09:50:03,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:04,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:05,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:06,153 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be:group-83C694710F86 changes to CANDIDATE, lastRpcTime:5053, electionTimeout:5052ms
2019-09-27 09:50:06,156 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown FollowerState
2019-09-27 09:50:06,157 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 09:50:06,165 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start LeaderElection
2019-09-27 09:50:06,182 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1: begin an election at term 1 for -1: [92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:06,184 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown LeaderElection
2019-09-27 09:50:06,184 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 09:50:06,185 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: change Leader from null to 92c2aa47-904a-4470-a9e0-4adfb7a731be at term 1 for becomeLeader, leader elected after 5190ms
2019-09-27 09:50:06,192 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 09:50:06,193 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 09:50:06,196 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 09:50:06,200 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 09:50:06,200 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 09:50:06,201 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 09:50:06,216 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start LeaderState
2019-09-27 09:50:06,239 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 09:50:06,248 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: set configuration 0: [92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null at 0
2019-09-27 09:50:06,400 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(106)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41:group-98D9370A73AF changes to CANDIDATE, lastRpcTime:5082, electionTimeout:5081ms
2019-09-27 09:50:06,416 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown FollowerState
2019-09-27 09:50:06,417 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 09:50:06,417 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: start LeaderElection
2019-09-27 09:50:06,433 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/de6c3077-9d30-4a9a-bf78-83c694710f86/current/log_inprogress_0
2019-09-27 09:50:06,433 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2: begin an election at term 1 for -1: [938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190], old=null
2019-09-27 09:50:06,435 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown LeaderElection
2019-09-27 09:50:06,435 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 09:50:06,435 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: change Leader from null to 938e73be-7ed6-4980-bddd-2d31dd7c4d41 at term 1 for becomeLeader, leader elected after 5138ms
2019-09-27 09:50:06,435 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 09:50:06,436 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 09:50:06,436 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 09:50:06,436 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 09:50:06,436 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 09:50:06,437 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 09:50:06,441 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: start LeaderState
2019-09-27 09:50:06,441 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 09:50:06,442 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: set configuration 0: [938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190], old=null at 0
2019-09-27 09:50:06,495 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/d1199ee6-4b78-4fa1-ad00-98d9370a73af/current/log_inprogress_0
2019-09-27 09:50:06,603 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(106)) - d038ac22-855c-4dd8-8556-1732bca3cf25:group-3600D2628B2F changes to CANDIDATE, lastRpcTime:5144, electionTimeout:5144ms
2019-09-27 09:50:06,603 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown FollowerState
2019-09-27 09:50:06,603 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 09:50:06,604 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start LeaderElection
2019-09-27 09:50:06,620 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3: begin an election at term 1 for -1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884], old=null
2019-09-27 09:50:06,620 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown LeaderElection
2019-09-27 09:50:06,620 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 09:50:06,620 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: change Leader from null to d038ac22-855c-4dd8-8556-1732bca3cf25 at term 1 for becomeLeader, leader elected after 5205ms
2019-09-27 09:50:06,621 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 09:50:06,621 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 09:50:06,621 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 09:50:06,622 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 09:50:06,622 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 09:50:06,622 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 09:50:06,624 [Thread-200] INFO  impl.FollowerState (FollowerState.java:run(106)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be:group-981D4E58C61B changes to CANDIDATE, lastRpcTime:5036, electionTimeout:5034ms
2019-09-27 09:50:06,624 [Thread-200] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown FollowerState
2019-09-27 09:50:06,624 [Thread-200] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 09:50:06,624 [Thread-200] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start LeaderElection
2019-09-27 09:50:06,631 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start LeaderState
2019-09-27 09:50:06,631 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 09:50:06,632 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: set configuration 0: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884], old=null at 0
2019-09-27 09:50:06,671 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4: begin an election at term 1 for -1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:06,682 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/83aa03e3-31de-47b2-a08a-3600d2628b2f/current/log_inprogress_0
2019-09-27 09:50:06,702 [Thread-197] INFO  impl.FollowerState (FollowerState.java:run(106)) - d038ac22-855c-4dd8-8556-1732bca3cf25:group-981D4E58C61B changes to CANDIDATE, lastRpcTime:5116, electionTimeout:5112ms
2019-09-27 09:50:06,703 [Thread-197] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown FollowerState
2019-09-27 09:50:06,703 [Thread-197] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 09:50:06,703 [Thread-197] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start LeaderElection
2019-09-27 09:50:06,717 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5: begin an election at term 1 for -1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:06,719 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:92c2aa47-904a-4470-a9e0-4adfb7a731be
2019-09-27 09:50:06,720 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown FollowerState
2019-09-27 09:50:06,720 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: start FollowerState
2019-09-27 09:50:06,720 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(115)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 09:50:06,749 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:06,769 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5: Election REJECTED; received 2 response(s) [d038ac22-855c-4dd8-8556-1732bca3cf25<-938e73be-7ed6-4980-bddd-2d31dd7c4d41#0:FAIL-t1, d038ac22-855c-4dd8-8556-1732bca3cf25<-92c2aa47-904a-4470-a9e0-4adfb7a731be#0:FAIL-t1] and 0 exception(s); d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:t1, leader=null, voted=d038ac22-855c-4dd8-8556-1732bca3cf25, raftlog=d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:06,770 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4: Election PASSED; received 2 response(s) [92c2aa47-904a-4470-a9e0-4adfb7a731be<-d038ac22-855c-4dd8-8556-1732bca3cf25#0:FAIL-t1, 92c2aa47-904a-4470-a9e0-4adfb7a731be<-938e73be-7ed6-4980-bddd-2d31dd7c4d41#0:OK-t1] and 0 exception(s); 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:t1, leader=null, voted=92c2aa47-904a-4470-a9e0-4adfb7a731be, raftlog=92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null
2019-09-27 09:50:06,770 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 09:50:06,771 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown LeaderElection
2019-09-27 09:50:06,776 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown LeaderElection
2019-09-27 09:50:06,777 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 09:50:06,778 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d038ac22-855c-4dd8-8556-1732bca3cf25: start FollowerState
2019-09-27 09:50:06,778 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: change Leader from null to 92c2aa47-904a-4470-a9e0-4adfb7a731be at term 1 for becomeLeader, leader elected after 5211ms
2019-09-27 09:50:06,779 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 09:50:06,779 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 09:50:06,780 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 09:50:06,780 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 09:50:06,780 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 09:50:06,780 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 09:50:06,788 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 09:50:06,788 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:06,789 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 09:50:06,794 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 09:50:06,795 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 09:50:06,795 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:06,797 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 09:50:06,797 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 09:50:06,797 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 09:50:06,798 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 09:50:06,798 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 09:50:06,798 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 09:50:06,803 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: start LeaderState
2019-09-27 09:50:06,803 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 09:50:06,804 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: set configuration 0: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null at 0
2019-09-27 09:50:06,859 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b/current/log_inprogress_0
2019-09-27 09:50:06,869 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: change Leader from null to 92c2aa47-904a-4470-a9e0-4adfb7a731be at term 1 for appendEntries, leader elected after 5302ms
2019-09-27 09:50:06,869 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: change Leader from null to 92c2aa47-904a-4470-a9e0-4adfb7a731be at term 1 for appendEntries, leader elected after 5302ms
2019-09-27 09:50:06,902 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: set configuration 0: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null at 0
2019-09-27 09:50:06,902 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: set configuration 0: [d038ac22-855c-4dd8-8556-1732bca3cf25:192.168.151.103:40884, 938e73be-7ed6-4980-bddd-2d31dd7c4d41:192.168.151.103:34190, 92c2aa47-904a-4470-a9e0-4adfb7a731be:192.168.151.103:45985], old=null at 0
2019-09-27 09:50:06,902 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 09:50:06,902 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 09:50:06,946 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b/current/log_inprogress_0
2019-09-27 09:50:06,946 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/ratis/9018c6ff-0dbb-476d-8e82-981d4e58c61b/current/log_inprogress_0
2019-09-27 09:50:07,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:08,753 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:09,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:10,755 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:11,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:12,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:13,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:14,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:15,767 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:16,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:17,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:18,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:19,772 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:20,773 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:21,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:21,777 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 09:50:22,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:23,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:24,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:25,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:26,786 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:27,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:28,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:29,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:30,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:31,793 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:31,795 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 09:50:32,797 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:33,798 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:34,800 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:35,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:36,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:37,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:38,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:39,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:40,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:41,809 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:41,811 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 09:50:42,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:43,814 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:44,816 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:45,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:46,819 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:47,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:48,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:49,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:50,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:51,826 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:51,829 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 09:50:52,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:53,832 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:54,833 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:55,835 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:56,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:57,837 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:58,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:50:59,840 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:00,842 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:01,845 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:01,847 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 09:51:02,849 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:03,850 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:04,851 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:05,853 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:06,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:07,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:08,857 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:09,859 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:10,860 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:11,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:11,863 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 09:51:12,864 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:13,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:14,867 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:15,868 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:16,870 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:17,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:18,873 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:19,874 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:20,877 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:21,880 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:21,882 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 09:51:22,883 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:23,885 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:24,886 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:25,888 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:26,889 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:27,890 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:28,892 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:29,893 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:30,895 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:31,896 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:31,898 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 09:51:32,899 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:33,901 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:34,902 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:35,903 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:36,905 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:37,906 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:38,908 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:39,909 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:40,910 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:41,911 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:41,914 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 09:51:42,915 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:43,916 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:44,918 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:45,919 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:46,921 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:47,922 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:48,923 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:49,925 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:50,926 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:51,927 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 09:51:51,929 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 09:51:51,933 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.init(TestDeleteWithSlowFollower.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-27 09:51:51,938 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-27 09:51:51,939 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-27 09:51:51,939 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-27 09:51:51,939 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46587
2019-09-27 09:51:51,951 [IPC Server listener on 46587] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46587
2019-09-27 09:51:51,952 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-27 09:51:51,952 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 09:51:51,957 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-27 09:51:51,970 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-27 09:51:51,976 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@529cfee5{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-27 09:51:51,985 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 09:51:51,985 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-27 09:51:51,986 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-27 09:51:51,994 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-27 09:51:52,075 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 09:51:52,080 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 09:51:56,998 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 09:51:56,998 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 09:51:57,000 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: close
2019-09-27 09:51:57,000 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d038ac22-855c-4dd8-8556-1732bca3cf25: close
2019-09-27 09:51:57,004 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: shutdown
2019-09-27 09:51:57,004 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: shutdown
2019-09-27 09:51:57,004 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-83C694710F86,id=92c2aa47-904a-4470-a9e0-4adfb7a731be
2019-09-27 09:51:57,005 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3600D2628B2F,id=d038ac22-855c-4dd8-8556-1732bca3cf25
2019-09-27 09:51:57,005 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown LeaderState
2019-09-27 09:51:57,005 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown LeaderState
2019-09-27 09:51:57,007 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be-PendingRequests: sendNotLeaderResponses
2019-09-27 09:51:57,007 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - d038ac22-855c-4dd8-8556-1732bca3cf25-PendingRequests: sendNotLeaderResponses
2019-09-27 09:51:57,012 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-StateMachineUpdater: set stopIndex = 0
2019-09-27 09:51:57,012 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-StateMachineUpdater: set stopIndex = 0
2019-09-27 09:51:57,017 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86: closes. applyIndex: 0
2019-09-27 09:51:57,017 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F: closes. applyIndex: 0
2019-09-27 09:51:57,019 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 09:51:57,019 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 09:51:57,022 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-3600D2628B2F-SegmentedRaftLogWorker close()
2019-09-27 09:51:57,022 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-83C694710F86-SegmentedRaftLogWorker close()
2019-09-27 09:51:57,027 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: shutdown
2019-09-27 09:51:57,027 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: shutdown
2019-09-27 09:51:57,027 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-981D4E58C61B,id=92c2aa47-904a-4470-a9e0-4adfb7a731be
2019-09-27 09:51:57,028 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-981D4E58C61B,id=d038ac22-855c-4dd8-8556-1732bca3cf25
2019-09-27 09:51:57,028 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown LeaderState
2019-09-27 09:51:57,029 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown FollowerState
2019-09-27 09:51:57,031 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$378/47384843@77a0ad70] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B->938e73be-7ed6-4980-bddd-2d31dd7c4d41-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 09:51:57,031 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$378/47384843@e7d0d24] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B->d038ac22-855c-4dd8-8556-1732bca3cf25-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 09:51:57,031 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be-PendingRequests: sendNotLeaderResponses
2019-09-27 09:51:57,034 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(115)) - d038ac22-855c-4dd8-8556-1732bca3cf25: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 09:51:57,033 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-StateMachineUpdater: set stopIndex = 0
2019-09-27 09:51:57,037 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-StateMachineUpdater: set stopIndex = 0
2019-09-27 09:51:57,041 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B: closes. applyIndex: 0
2019-09-27 09:51:57,040 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B: closes. applyIndex: 0
2019-09-27 09:51:57,041 [92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 09:51:57,042 [d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 09:51:57,043 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B-SegmentedRaftLogWorker close()
2019-09-27 09:51:57,045 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d038ac22-855c-4dd8-8556-1732bca3cf25@group-981D4E58C61B-SegmentedRaftLogWorker close()
2019-09-27 09:51:57,045 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - d038ac22-855c-4dd8-8556-1732bca3cf25: Completed APPEND_ENTRIES, lastRequest: 92c2aa47-904a-4470-a9e0-4adfb7a731be->d038ac22-855c-4dd8-8556-1732bca3cf25#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 09:51:57,045 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: Completed APPEND_ENTRIES, lastRequest: 92c2aa47-904a-4470-a9e0-4adfb7a731be->938e73be-7ed6-4980-bddd-2d31dd7c4d41#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 09:51:57,052 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown server with port 45985 now
2019-09-27 09:51:57,052 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown server with port 40884 now
2019-09-27 09:51:57,055 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B->d038ac22-855c-4dd8-8556-1732bca3cf25-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-27 09:51:57,055 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B->938e73be-7ed6-4980-bddd-2d31dd7c4d41-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-27 09:51:57,067 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d038ac22-855c-4dd8-8556-1732bca3cf25: shutdown server with port 40884 successfully
2019-09-27 09:51:57,067 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B->d038ac22-855c-4dd8-8556-1732bca3cf25: nextIndex: updateUnconditionally 1 -> 0
2019-09-27 09:51:57,067 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be@group-981D4E58C61B->938e73be-7ed6-4980-bddd-2d31dd7c4d41: nextIndex: updateUnconditionally 1 -> 0
2019-09-27 09:51:57,070 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 92c2aa47-904a-4470-a9e0-4adfb7a731be: shutdown server with port 45985 successfully
2019-09-27 09:51:57,091 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 09:51:57,091 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 09:51:57,115 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 09:51:57,115 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 09:51:57,120 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 09:51:57,123 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 09:51:57,124 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7aac8884{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 09:51:57,125 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7bc44ce8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 09:51:57,125 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 09:51:57,125 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59072e9d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 09:51:57,126 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 09:51:57,126 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@620c8641{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 09:51:57,127 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-27 09:51:57,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@277b8fa4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-27 09:51:57,183 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 09:52:02,129 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 09:52:02,130 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: close
2019-09-27 09:52:02,130 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: shutdown
2019-09-27 09:52:02,131 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-98D9370A73AF,id=938e73be-7ed6-4980-bddd-2d31dd7c4d41
2019-09-27 09:52:02,131 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown LeaderState
2019-09-27 09:52:02,132 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41-PendingRequests: sendNotLeaderResponses
2019-09-27 09:52:02,132 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-StateMachineUpdater: set stopIndex = 0
2019-09-27 09:52:02,134 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF: closes. applyIndex: 0
2019-09-27 09:52:02,135 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 09:52:02,136 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-98D9370A73AF-SegmentedRaftLogWorker close()
2019-09-27 09:52:02,138 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: shutdown
2019-09-27 09:52:02,138 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-981D4E58C61B,id=938e73be-7ed6-4980-bddd-2d31dd7c4d41
2019-09-27 09:52:02,138 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown FollowerState
2019-09-27 09:52:02,139 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-StateMachineUpdater: set stopIndex = 0
2019-09-27 09:52:02,139 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(115)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 09:52:02,141 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B: closes. applyIndex: 0
2019-09-27 09:52:02,142 [938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 09:52:02,147 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41@group-981D4E58C61B-SegmentedRaftLogWorker close()
2019-09-27 09:52:02,149 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown server with port 34190 now
2019-09-27 09:52:02,149 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 938e73be-7ed6-4980-bddd-2d31dd7c4d41: shutdown server with port 34190 successfully
2019-09-27 09:52:02,167 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-166d2f08-fb0e-4e0b-b192-7c0537a0f43a/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 09:52:02,186 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 09:52:02,190 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 09:52:02,193 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@59cda16e{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 09:52:02,194 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5dd903be{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 09:52:02,195 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77b919a3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 09:52:02,196 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d95a72e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-27 09:52:02,197 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-27 09:52:02,197 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-27 09:52:02,197 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-27 09:52:02,198 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-27 09:52:02,198 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-27 09:52:02,198 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-27 09:52:02,199 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33903
2019-09-27 09:52:02,201 [IPC Server listener on 33903] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33903
2019-09-27 09:52:02,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 09:52:02,213 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-27 09:52:02,213 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-27 09:52:02,213 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-27 09:52:02,213 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37063
2019-09-27 09:52:02,215 [IPC Server listener on 37063] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37063
2019-09-27 09:52:02,215 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 09:52:02,215 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-27 09:52:02,216 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-27 09:52:02,216 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35912
2019-09-27 09:52:02,218 [IPC Server listener on 35912] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35912
2019-09-27 09:52:02,218 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 09:52:02,218 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-27 09:52:02,219 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5398edd0{/,null,UNAVAILABLE}{/scm}
2019-09-27 09:52:02,220 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 09:52:02,221 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-27 09:52:02,221 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-27 09:52:02,222 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-27 09:52:02,222 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 09:52:02,223 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 09:52:02,223 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-27 09:52:02,230 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-27 09:52:02,237 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-27 09:52:02,238 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
