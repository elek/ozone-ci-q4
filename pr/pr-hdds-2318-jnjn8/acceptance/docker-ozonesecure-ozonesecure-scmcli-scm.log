Attaching to ozonesecure_datanode_2, ozonesecure_om_1, ozonesecure_datanode_3, ozonesecure_s3g_1, ozonesecure_kms_1, ozonesecure_recon_1, ozonesecure_scm_1, ozonesecure_kdc_1, ozonesecure_datanode_1
datanode_2  | Sleeping for 5 seconds
datanode_2  | Setting up kerberos!!
datanode_2  | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Sleeping for 5 seconds
datanode_2  | Got 200, KDC service ready!!
datanode_2  | Download dn/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | --2019-10-18 06:52:59--  http://kdc:8081/keytab/ed25c35f2081/dn
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 158 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
om_1        | Sleeping for 5 seconds
s3g_1       | Sleeping for 5 seconds
datanode_2  | 
om_1        | Setting up kerberos!!
s3g_1       | Setting up kerberos!!
s3g_1       | KDC ISSUER_SERVER => kdc:8081
om_1        | KDC ISSUER_SERVER => kdc:8081
datanode_2  |      0K                                                       100% 12.1M=0s
s3g_1       | Sleeping for 5 seconds
datanode_2  | 
om_1        | Sleeping for 5 seconds
s3g_1       | Got 200, KDC service ready!!
datanode_2  | 2019-10-18 06:53:00 (12.1 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
om_1        | Got 200, KDC service ready!!
datanode_3  | Sleeping for 5 seconds
s3g_1       | Download dn/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | 
om_1        | Download dn/om@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
recon_1     | Sleeping for 5 seconds
datanode_3  | Setting up kerberos!!
scm_1       | Sleeping for 5 seconds
s3g_1       | --2019-10-18 06:52:59--  http://kdc:8081/keytab/s3g/dn
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
om_1        | --2019-10-18 06:52:59--  http://kdc:8081/keytab/om/dn
kdc_1       | Issuer is listening on : 8081krb5kdc: starting...
recon_1     | Waiting for the service om:9874
datanode_3  | KDC ISSUER_SERVER => kdc:8081
scm_1       | Setting up kerberos!!
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
kms_1       | Sleeping for 5 seconds
datanode_2  | KVNO Timestamp         Principal
om_1        | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | kadmind: starting...
recon_1     | Setting up kerberos!!
datanode_3  | Sleeping for 5 seconds
scm_1       | KDC ISSUER_SERVER => kdc:8081
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       | Setting up kerberos!!
datanode_2  | ---- ----------------- --------------------------------------------------------
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | otp: Loaded
recon_1     | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Got 200, KDC service ready!!
scm_1       | Sleeping for 5 seconds
s3g_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | KDC ISSUER_SERVER => kdc:8081
datanode_2  |    2 10/18/19 06:53:00 dn/ed25c35f2081@EXAMPLE.COM
om_1        | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 18 06:52:49 kdc krb5kdc[9](info): setting up network...
recon_1     | Sleeping for 5 seconds
scm_1       | Got 200, KDC service ready!!
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
datanode_1  | Sleeping for 5 seconds
s3g_1       | Length: 140 [application/octet-stream]
datanode_3  | Download dn/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  |    2 10/18/19 06:53:00 dn/ed25c35f2081@EXAMPLE.COM
om_1        | Length: 138 [application/octet-stream]
kdc_1       | krb5kdc: setsockopt(9,IPV6_V6ONLY,1) worked
recon_1     | Got 200, KDC service ready!!
scm_1       | Download dn/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
kms_1       | Sleeping for  seconds
datanode_1  | Setting up kerberos!!
s3g_1       | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_3  | --2019-10-18 06:53:00--  http://kdc:8081/keytab/b59f5315e11c/dn
datanode_2  | Download om/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | Saving to: '/etc/security/keytabs/dn.keytab'
recon_1     | Download dn/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
scm_1       | --2019-10-18 06:52:58--  http://kdc:8081/keytab/scm/dn
kdc_1       | krb5kdc: setsockopt(11,IPV6_V6ONLY,1) worked
kms_1       | Got 200, KDC service ready!!
datanode_1  | KDC ISSUER_SERVER => kdc:8081
s3g_1       | 
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | --2019-10-18 06:53:00--  http://kdc:8081/keytab/ed25c35f2081/om
om_1        | 
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/dn
scm_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 18 06:52:49 kdc krb5kdc[9](info): set up 4 sockets
kms_1       | Download dn/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | Sleeping for 5 seconds
s3g_1       |      0K                                                       100% 9.73M=0s
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
om_1        |      0K                                                       100% 14.5M=0s
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Oct 18 06:52:49 kdc krb5kdc[9](info): commencing operation
kms_1       | --2019-10-18 06:53:00--  http://kdc:8081/keytab/d71a100b5ba6/dn
recon_1     | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | Got 200, KDC service ready!!
datanode_3  | HTTP request sent, awaiting response... 200 OK
s3g_1       | 
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | 
scm_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 18 06:52:13 93745b2332fb kadmin.local[1](info): No dictionary file specified, continuing without one.
kms_1       | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | Download dn/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_3  | Length: 158 [application/octet-stream]
s3g_1       | 2019-10-18 06:53:00 (9.73 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
datanode_2  | HTTP request sent, awaiting response... 200 OK
om_1        | 2019-10-18 06:53:00 (14.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [138/138]
scm_1       | Length: 140 [application/octet-stream]
kdc_1       | Oct 18 06:52:14 098baa1354c2 kadmin.local[1](info): No dictionary file specified, continuing without one.
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_1  | --2019-10-18 06:52:58--  http://kdc:8081/keytab/713c90b40e6d/dn
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
s3g_1       | 
datanode_2  | Length: 158 [application/octet-stream]
om_1        | 
scm_1       | Saving to: '/etc/security/keytabs/dn.keytab'
kms_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 144 [application/octet-stream]
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | Saving to: '/etc/security/keytabs/om.keytab'
kdc_1       | Oct 18 06:52:53 kdc kadmind[15](info): No dictionary file specified, continuing without one.
om_1        | Keytab name: FILE:/etc/security/keytabs/dn.keytab
scm_1       | 
kms_1       | Length: 158 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | KVNO Timestamp         Principal
datanode_3  |      0K                                                       100% 16.6M=0s
datanode_2  | 
kdc_1       | Oct 18 06:52:53 kdc kadmind[15](info): setting up network...
om_1        | KVNO Timestamp         Principal
scm_1       |      0K                                                       100% 10.1M=0s
kms_1       | Saving to: '/etc/security/keytabs/dn.keytab'
recon_1     | 
datanode_1  | HTTP request sent, awaiting response... 200 OK
s3g_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | 
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
datanode_2  |      0K                                                       100% 12.1M=0s
om_1        | ---- ----------------- --------------------------------------------------------
scm_1       | 
kms_1       | 
recon_1     |      0K                                                       100% 11.0M=0s
datanode_1  | Length: 158 [application/octet-stream]
s3g_1       |    2 10/18/19 06:53:00 dn/s3g@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:01 (16.6 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
datanode_2  | 
om_1        |    2 10/18/19 06:53:00 dn/om@EXAMPLE.COM
scm_1       | 2019-10-18 06:52:58 (10.1 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
kms_1       |      0K                                                       100% 20.3M=0s
recon_1     | 
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
s3g_1       |    2 10/18/19 06:53:00 dn/s3g@EXAMPLE.COM
datanode_3  | 
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
datanode_2  | 2019-10-18 06:53:00 (12.1 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
om_1        |    2 10/18/19 06:53:00 dn/om@EXAMPLE.COM
scm_1       | 
kms_1       | 
recon_1     | 2019-10-18 06:53:20 (11.0 MB/s) - '/etc/security/keytabs/dn.keytab' saved [144/144]
datanode_1  | 
s3g_1       | Download om/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
kdc_1       | Oct 18 06:52:53 kdc kadmind[15](info): set up 6 sockets
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | 
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
scm_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kms_1       | 2019-10-18 06:53:01 (20.3 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
recon_1     | 
datanode_1  |      0K                                                       100% 15.1M=0s
s3g_1       | --2019-10-18 06:53:00--  http://kdc:8081/keytab/s3g/om
kdc_1       | Oct 18 06:52:53 kdc kadmind[15](info): Seeding random number generator
datanode_3  | KVNO Timestamp         Principal
datanode_2  | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_2  | KVNO Timestamp         Principal
om_1        | --2019-10-18 06:53:00--  http://kdc:8081/keytab/om/om
scm_1       | KVNO Timestamp         Principal
kms_1       | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | 
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 18 06:52:53 kdc kadmind[15](info): starting
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | ---- ----------------- --------------------------------------------------------
om_1        | Resolving kdc (kdc)... 172.18.0.3
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
recon_1     | KVNO Timestamp         Principal
datanode_1  | 2019-10-18 06:52:58 (15.1 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Generiting keytab
datanode_3  |    2 10/18/19 06:53:01 dn/b59f5315e11c@EXAMPLE.COM
datanode_2  |    2 10/18/19 06:53:00 om/ed25c35f2081@EXAMPLE.COM
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       |    2 10/18/19 06:52:58 dn/scm@EXAMPLE.COM
kms_1       | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
s3g_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  |    2 10/18/19 06:53:01 dn/b59f5315e11c@EXAMPLE.COM
datanode_2  |    2 10/18/19 06:53:00 om/ed25c35f2081@EXAMPLE.COM
scm_1       |    2 10/18/19 06:52:58 dn/scm@EXAMPLE.COM
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
kms_1       | ---- ----------------- --------------------------------------------------------
recon_1     |    2 10/18/19 06:53:20 dn/recon@EXAMPLE.COM
s3g_1       | Length: 140 [application/octet-stream]
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
datanode_3  | Download om/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
scm_1       | Download om/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_2  | Download scm/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
om_1        | Length: 138 [application/octet-stream]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kms_1       |    2 10/18/19 06:53:01 dn/d71a100b5ba6@EXAMPLE.COM
recon_1     |    2 10/18/19 06:53:20 dn/recon@EXAMPLE.COM
s3g_1       | Saving to: '/etc/security/keytabs/om.keytab'
datanode_3  | --2019-10-18 06:53:01--  http://kdc:8081/keytab/b59f5315e11c/om
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
scm_1       | --2019-10-18 06:52:59--  http://kdc:8081/keytab/scm/om
datanode_2  | --2019-10-18 06:53:00--  http://kdc:8081/keytab/ed25c35f2081/scm
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
datanode_1  | KVNO Timestamp         Principal
kms_1       |    2 10/18/19 06:53:01 dn/d71a100b5ba6@EXAMPLE.COM
recon_1     | Download om/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       | 
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
om_1        | 
datanode_1  | ---- ----------------- --------------------------------------------------------
kms_1       | Download om/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/om
s3g_1       |      0K                                                       100% 10.5M=0s
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        |      0K                                                       100% 10.4M=0s
kms_1       | --2019-10-18 06:53:01--  http://kdc:8081/keytab/d71a100b5ba6/om
datanode_1  |    2 10/18/19 06:52:58 dn/713c90b40e6d@EXAMPLE.COM
recon_1     | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | 
datanode_3  | HTTP request sent, awaiting response... 200 OK
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_2  | HTTP request sent, awaiting response... 200 OK
om_1        | 
datanode_1  |    2 10/18/19 06:52:58 dn/713c90b40e6d@EXAMPLE.COM
kms_1       | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | 2019-10-18 06:53:01 (10.5 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
datanode_3  | Length: 158 [application/octet-stream]
kdc_1       | Generiting keytab
scm_1       | Length: 140 [application/octet-stream]
datanode_2  | Length: 160 [application/octet-stream]
om_1        | 2019-10-18 06:53:00 (10.4 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
datanode_1  | Download om/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
s3g_1       | 
datanode_3  | Saving to: '/etc/security/keytabs/om.keytab'
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  | Saving to: '/etc/security/keytabs/scm.keytab'
om_1        | 
datanode_1  | --2019-10-18 06:52:58--  http://kdc:8081/keytab/713c90b40e6d/om
kms_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 144 [application/octet-stream]
s3g_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_3  | 
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 
datanode_2  | 
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
kms_1       | Length: 158 [application/octet-stream]
s3g_1       | KVNO Timestamp         Principal
datanode_3  |      0K                                                       100% 13.2M=0s
recon_1     | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  |      0K                                                       100% 15.4M=0s
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       |      0K                                                       100% 10.7M=0s
om_1        | KVNO Timestamp         Principal
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       | Saving to: '/etc/security/keytabs/om.keytab'
s3g_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | 
recon_1     | 
datanode_2  | 
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 
om_1        | ---- ----------------- --------------------------------------------------------
datanode_1  | HTTP request sent, awaiting response... 200 OK
kms_1       | 
s3g_1       |    2 10/18/19 06:53:01 om/s3g@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:01 (13.2 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
recon_1     |      0K                                                       100% 11.4M=0s
datanode_2  | 2019-10-18 06:53:01 (15.4 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 06:52:59 (10.7 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
om_1        |    2 10/18/19 06:53:00 om/om@EXAMPLE.COM
datanode_1  | Length: 158 [application/octet-stream]
kms_1       |      0K                                                       100% 21.9M=0s
s3g_1       |    2 10/18/19 06:53:01 om/s3g@EXAMPLE.COM
datanode_3  | 
recon_1     | 
datanode_2  | 
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 
om_1        |    2 10/18/19 06:53:00 om/om@EXAMPLE.COM
datanode_1  | Saving to: '/etc/security/keytabs/om.keytab'
kms_1       | 
s3g_1       | Download scm/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_3  | Keytab name: FILE:/etc/security/keytabs/om.keytab
recon_1     | 2019-10-18 06:53:20 (11.4 MB/s) - '/etc/security/keytabs/om.keytab' saved [144/144]
datanode_2  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | Download scm/om@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kms_1       | 2019-10-18 06:53:02 (21.9 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
datanode_1  | 
s3g_1       | --2019-10-18 06:53:01--  http://kdc:8081/keytab/s3g/scm
recon_1     | 
datanode_2  | KVNO Timestamp         Principal
scm_1       | KVNO Timestamp         Principal
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | KVNO Timestamp         Principal
om_1        | --2019-10-18 06:53:00--  http://kdc:8081/keytab/om/scm
datanode_1  |      0K                                                       100% 14.0M=0s
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Keytab name: FILE:/etc/security/keytabs/om.keytab
kms_1       | 
datanode_2  | ---- ----------------- --------------------------------------------------------
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_1  | 
om_1        | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | KVNO Timestamp         Principal
kms_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_2  |    2 10/18/19 06:53:01 scm/ed25c35f2081@EXAMPLE.COM
scm_1       |    2 10/18/19 06:52:59 om/scm@EXAMPLE.COM
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
datanode_3  |    2 10/18/19 06:53:01 om/b59f5315e11c@EXAMPLE.COM
datanode_1  | 2019-10-18 06:52:58 (14.0 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 10/18/19 06:53:01 scm/ed25c35f2081@EXAMPLE.COM
scm_1       |    2 10/18/19 06:52:59 om/scm@EXAMPLE.COM
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  |    2 10/18/19 06:53:01 om/b59f5315e11c@EXAMPLE.COM
datanode_1  | 
om_1        | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 142 [application/octet-stream]
recon_1     |    2 10/18/19 06:53:20 om/recon@EXAMPLE.COM
kms_1       | KVNO Timestamp         Principal
datanode_2  | Download HTTP/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | Download scm/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/om.keytab
om_1        | Length: 140 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     |    2 10/18/19 06:53:20 om/recon@EXAMPLE.COM
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | --2019-10-18 06:53:01--  http://kdc:8081/keytab/ed25c35f2081/HTTP
scm_1       | --2019-10-18 06:52:59--  http://kdc:8081/keytab/scm/scm
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | --2019-10-18 06:53:01--  http://kdc:8081/keytab/b59f5315e11c/scm
datanode_1  | KVNO Timestamp         Principal
om_1        | Saving to: '/etc/security/keytabs/scm.keytab'
s3g_1       | 
kms_1       |    2 10/18/19 06:53:02 om/d71a100b5ba6@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download scm/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | ---- ----------------- --------------------------------------------------------
om_1        | 
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
s3g_1       |      0K                                                       100% 11.8M=0s
kms_1       |    2 10/18/19 06:53:02 om/d71a100b5ba6@EXAMPLE.COM
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/scm
kdc_1       | WARNING: no policy specified for dn/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  |    2 10/18/19 06:52:58 om/713c90b40e6d@EXAMPLE.COM
om_1        |      0K                                                       100% 17.4M=0s
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | 
kms_1       | Download scm/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Principal "dn/713c90b40e6d@EXAMPLE.COM" created.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_1  |    2 10/18/19 06:52:58 om/713c90b40e6d@EXAMPLE.COM
om_1        | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
s3g_1       | 2019-10-18 06:53:01 (11.8 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
kms_1       | --2019-10-18 06:53:02--  http://kdc:8081/keytab/d71a100b5ba6/scm
scm_1       | Length: 142 [application/octet-stream]
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | Download scm/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_3  | Length: 160 [application/octet-stream]
om_1        | 2019-10-18 06:53:01 (17.4 MB/s) - '/etc/security/keytabs/scm.keytab' saved [140/140]
datanode_2  | Length: 162 [application/octet-stream]
s3g_1       | 
kms_1       | Resolving kdc (kdc)... 172.18.0.3
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
kdc_1       | Entry for principal dn/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.713c90b40e6d.keytab.
datanode_1  | --2019-10-18 06:52:58--  http://kdc:8081/keytab/713c90b40e6d/scm
datanode_3  | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
om_1        | 
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | 
kdc_1       | Entry for principal dn/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.713c90b40e6d.keytab.
datanode_3  | 
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Length: 146 [application/octet-stream]
om_1        | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_2  | 
s3g_1       | KVNO Timestamp         Principal
kms_1       | HTTP request sent, awaiting response... 200 OK
scm_1       |      0K                                                       100% 15.2M=0s
kdc_1       | Generiting keytab
datanode_3  |      0K                                                       100% 8.11M=0s
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | Saving to: '/etc/security/keytabs/scm.keytab'
om_1        | KVNO Timestamp         Principal
datanode_2  |      0K                                                       100% 13.3M=0s
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Length: 160 [application/octet-stream]
scm_1       | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 
datanode_1  | HTTP request sent, awaiting response... 200 OK
recon_1     | 
om_1        | ---- ----------------- --------------------------------------------------------
datanode_2  | 
s3g_1       |    2 10/18/19 06:53:01 scm/s3g@EXAMPLE.COM
scm_1       | 2019-10-18 06:52:59 (15.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
kdc_1       | WARNING: no policy specified for om/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-10-18 06:53:02 (8.11 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
kms_1       | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_1  | Length: 160 [application/octet-stream]
recon_1     |      0K                                                       100% 11.3M=0s
om_1        |    2 10/18/19 06:53:01 scm/om@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:02 (13.3 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
s3g_1       |    2 10/18/19 06:53:01 scm/s3g@EXAMPLE.COM
scm_1       | 
kdc_1       | Principal "om/713c90b40e6d@EXAMPLE.COM" created.
datanode_3  | 
kms_1       | 
datanode_1  | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     | 
om_1        |    2 10/18/19 06:53:01 scm/om@EXAMPLE.COM
datanode_2  | 
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       |      0K                                                       100% 22.0M=0s
datanode_3  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
recon_1     | 2019-10-18 06:53:20 (11.3 MB/s) - '/etc/security/keytabs/scm.keytab' saved [146/146]
datanode_1  | 
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | --2019-10-18 06:53:01--  http://kdc:8081/keytab/s3g/HTTP
scm_1       | KVNO Timestamp         Principal
kdc_1       | Entry for principal om/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.713c90b40e6d.keytab.
kms_1       | 
datanode_3  | KVNO Timestamp         Principal
recon_1     | 
datanode_1  |      0K                                                       100% 11.9M=0s
om_1        | --2019-10-18 06:53:01--  http://kdc:8081/keytab/om/HTTP
datanode_2  | KVNO Timestamp         Principal
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Entry for principal om/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.713c90b40e6d.keytab.
kms_1       | 2019-10-18 06:53:02 (22.0 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
datanode_3  | ---- ----------------- --------------------------------------------------------
recon_1     | Keytab name: FILE:/etc/security/keytabs/scm.keytab
om_1        | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_1  | 
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       |    2 10/18/19 06:52:59 scm/scm@EXAMPLE.COM
kdc_1       | Generiting keytab
kms_1       | 
datanode_3  |    2 10/18/19 06:53:02 scm/b59f5315e11c@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  |    2 10/18/19 06:53:02 HTTP/ed25c35f2081@EXAMPLE.COM
datanode_1  | 2019-10-18 06:52:58 (11.9 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
s3g_1       | HTTP request sent, awaiting response... 200 OK
scm_1       |    2 10/18/19 06:52:59 scm/scm@EXAMPLE.COM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 10/18/19 06:53:02 scm/b59f5315e11c@EXAMPLE.COM
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_2  |    2 10/18/19 06:53:02 HTTP/ed25c35f2081@EXAMPLE.COM
datanode_1  | 
s3g_1       | Length: 144 [application/octet-stream]
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
kdc_1       | WARNING: no policy specified for scm/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
kms_1       | KVNO Timestamp         Principal
recon_1     |    2 10/18/19 06:53:20 scm/recon@EXAMPLE.COM
datanode_3  | Download HTTP/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | Length: 142 [application/octet-stream]
datanode_2  | Download testuser/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
scm_1       | --2019-10-18 06:52:59--  http://kdc:8081/keytab/scm/HTTP
kdc_1       | Principal "scm/713c90b40e6d@EXAMPLE.COM" created.
kms_1       | ---- ----------------- --------------------------------------------------------
recon_1     |    2 10/18/19 06:53:20 scm/recon@EXAMPLE.COM
datanode_3  | --2019-10-18 06:53:02--  http://kdc:8081/keytab/b59f5315e11c/HTTP
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_2  | --2019-10-18 06:53:02--  http://kdc:8081/keytab/ed25c35f2081/testuser
datanode_1  | KVNO Timestamp         Principal
scm_1       | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       |    2 10/18/19 06:53:02 scm/d71a100b5ba6@EXAMPLE.COM
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
om_1        | 
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       |      0K                                                       100% 12.0M=0s
kdc_1       | Entry for principal scm/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.713c90b40e6d.keytab.
kms_1       |    2 10/18/19 06:53:02 scm/d71a100b5ba6@EXAMPLE.COM
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/HTTP
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        |      0K                                                       100% 21.0M=0s
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  |    2 10/18/19 06:52:58 scm/713c90b40e6d@EXAMPLE.COM
scm_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | 
kdc_1       | Entry for principal scm/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.713c90b40e6d.keytab.
kms_1       | Download HTTP/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | HTTP request sent, awaiting response... 200 OK
om_1        | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_1  |    2 10/18/19 06:52:58 scm/713c90b40e6d@EXAMPLE.COM
scm_1       | Length: 144 [application/octet-stream]
s3g_1       | 2019-10-18 06:53:02 (12.0 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
kdc_1       | Generiting keytab
kms_1       | --2019-10-18 06:53:02--  http://kdc:8081/keytab/d71a100b5ba6/HTTP
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | Length: 162 [application/octet-stream]
om_1        | 2019-10-18 06:53:02 (21.0 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
datanode_2  | Length: 170 [application/octet-stream]
datanode_1  | Download HTTP/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | Resolving kdc (kdc)... 172.18.0.3
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | 
datanode_1  | --2019-10-18 06:52:58--  http://kdc:8081/keytab/713c90b40e6d/HTTP
datanode_2  | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kdc_1       | WARNING: no policy specified for dn/scm@EXAMPLE.COM; defaulting to no policy
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | Length: 148 [application/octet-stream]
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | 
datanode_3  | 
scm_1       |      0K                                                       100% 10.7M=0s
s3g_1       | KVNO Timestamp         Principal
kdc_1       | Principal "dn/scm@EXAMPLE.COM" created.
kms_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | KVNO Timestamp         Principal
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  |      0K                                                       100% 25.5M=0s
datanode_3  |      0K                                                       100% 21.7M=0s
s3g_1       | ---- ----------------- --------------------------------------------------------
scm_1       | 
kms_1       | Length: 162 [application/octet-stream]
om_1        | ---- ----------------- --------------------------------------------------------
datanode_1  | HTTP request sent, awaiting response... 200 OK
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 
datanode_3  | 
s3g_1       |    2 10/18/19 06:53:02 HTTP/s3g@EXAMPLE.COM
scm_1       | 2019-10-18 06:53:00 (10.7 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
recon_1     | 
kms_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        |    2 10/18/19 06:53:02 HTTP/om@EXAMPLE.COM
datanode_1  | Length: 162 [application/octet-stream]
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
datanode_3  | 2019-10-18 06:53:03 (21.7 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
s3g_1       |    2 10/18/19 06:53:02 HTTP/s3g@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:02 (25.5 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
scm_1       | 
recon_1     |      0K                                                       100% 11.2M=0s
kms_1       | 
om_1        |    2 10/18/19 06:53:02 HTTP/om@EXAMPLE.COM
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
datanode_3  | 
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_2  | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
recon_1     | 
kms_1       |      0K                                                       100% 21.3M=0s
om_1        | Download testuser/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_1  | 
kdc_1       | Generiting keytab
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
recon_1     | 2019-10-18 06:53:20 (11.2 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
scm_1       | KVNO Timestamp         Principal
kms_1       | 
s3g_1       | --2019-10-18 06:53:02--  http://kdc:8081/keytab/s3g/testuser
om_1        | --2019-10-18 06:53:02--  http://kdc:8081/keytab/om/testuser
datanode_1  |      0K                                                       100% 15.1M=0s
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | KVNO Timestamp         Principal
datanode_2  | KVNO Timestamp         Principal
recon_1     | 
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | 2019-10-18 06:53:03 (21.3 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
om_1        | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | 
kdc_1       | WARNING: no policy specified for HTTP/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | ---- ----------------- --------------------------------------------------------
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       |    2 10/18/19 06:53:00 HTTP/scm@EXAMPLE.COM
kms_1       | 
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | 2019-10-18 06:52:59 (15.1 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
kdc_1       | Principal "HTTP/713c90b40e6d@EXAMPLE.COM" created.
datanode_3  |    2 10/18/19 06:53:03 HTTP/b59f5315e11c@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
datanode_2  |    2 10/18/19 06:53:02 testuser/ed25c35f2081@EXAMPLE.COM
scm_1       |    2 10/18/19 06:53:00 HTTP/scm@EXAMPLE.COM
kms_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | HTTP request sent, awaiting response... 200 OK
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  |    2 10/18/19 06:53:03 HTTP/b59f5315e11c@EXAMPLE.COM
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 10/18/19 06:53:02 testuser/ed25c35f2081@EXAMPLE.COM
kms_1       | KVNO Timestamp         Principal
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | Length: 152 [application/octet-stream]
om_1        | Length: 150 [application/octet-stream]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kdc_1       | Entry for principal HTTP/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.713c90b40e6d.keytab.
datanode_3  | Download testuser/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
recon_1     |    2 10/18/19 06:53:20 HTTP/recon@EXAMPLE.COM
datanode_2  | Download testuser2/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
kms_1       | ---- ----------------- --------------------------------------------------------
scm_1       | --2019-10-18 06:53:00--  http://kdc:8081/keytab/scm/testuser
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
om_1        | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_1  | KVNO Timestamp         Principal
kdc_1       | Entry for principal HTTP/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.713c90b40e6d.keytab.
datanode_3  | --2019-10-18 06:53:03--  http://kdc:8081/keytab/b59f5315e11c/testuser
recon_1     |    2 10/18/19 06:53:20 HTTP/recon@EXAMPLE.COM
datanode_2  | --2019-10-18 06:53:03--  http://kdc:8081/keytab/ed25c35f2081/testuser2
kms_1       |    2 10/18/19 06:53:03 HTTP/d71a100b5ba6@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | 
om_1        | 
datanode_1  | ---- ----------------- --------------------------------------------------------
kdc_1       | Generiting keytab
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download testuser/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
kms_1       |    2 10/18/19 06:53:03 HTTP/d71a100b5ba6@EXAMPLE.COM
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       |      0K                                                       100% 15.1M=0s
om_1        |      0K                                                       100% 16.4M=0s
datanode_1  |    2 10/18/19 06:52:59 HTTP/713c90b40e6d@EXAMPLE.COM
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/testuser
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | Download testuser/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 
om_1        | 
datanode_1  |    2 10/18/19 06:52:59 HTTP/713c90b40e6d@EXAMPLE.COM
datanode_3  | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 152 [application/octet-stream]
kms_1       | --2019-10-18 06:53:03--  http://kdc:8081/keytab/d71a100b5ba6/testuser
kdc_1       | WARNING: no policy specified for om/scm@EXAMPLE.COM; defaulting to no policy
s3g_1       | 2019-10-18 06:53:03 (15.1 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
om_1        | 2019-10-18 06:53:03 (16.4 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [150/150]
datanode_1  | Download testuser/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_3  | Length: 170 [application/octet-stream]
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | Length: 172 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
kms_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Principal "om/scm@EXAMPLE.COM" created.
s3g_1       | 
om_1        | 
datanode_1  | --2019-10-18 06:52:59--  http://kdc:8081/keytab/713c90b40e6d/testuser
datanode_3  | Saving to: '/etc/security/keytabs/testuser.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_2  | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | 
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Length: 156 [application/octet-stream]
datanode_2  | 
scm_1       |      0K                                                       100% 10.5M=0s
kms_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | KVNO Timestamp         Principal
om_1        | KVNO Timestamp         Principal
datanode_3  |      0K                                                       100% 23.8M=0s
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_2  |      0K                                                       100% 15.1M=0s
scm_1       | 
kms_1       | Length: 170 [application/octet-stream]
s3g_1       | ---- ----------------- --------------------------------------------------------
om_1        | ---- ----------------- --------------------------------------------------------
datanode_3  | 
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
datanode_1  | HTTP request sent, awaiting response... 200 OK
recon_1     | 
datanode_2  | 
scm_1       | 2019-10-18 06:53:01 (10.5 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
kms_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       |    2 10/18/19 06:53:03 testuser/s3g@EXAMPLE.COM
om_1        |    2 10/18/19 06:53:03 testuser/om@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:04 (23.8 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
kdc_1       | Generiting keytab
datanode_1  | Length: 170 [application/octet-stream]
recon_1     |      0K                                                       100% 12.1M=0s
datanode_2  | 2019-10-18 06:53:03 (15.1 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
scm_1       | 
kms_1       | 
s3g_1       |    2 10/18/19 06:53:03 testuser/s3g@EXAMPLE.COM
om_1        |    2 10/18/19 06:53:03 testuser/om@EXAMPLE.COM
datanode_3  | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | Saving to: '/etc/security/keytabs/testuser.keytab'
recon_1     | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kms_1       |      0K                                                       100% 15.9M=0s
datanode_2  | 
s3g_1       | Download testuser2/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
om_1        | Download testuser2/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kdc_1       | WARNING: no policy specified for testuser/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
datanode_1  | 
recon_1     | 2019-10-18 06:53:20 (12.1 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [156/156]
scm_1       | KVNO Timestamp         Principal
kms_1       | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
s3g_1       | --2019-10-18 06:53:03--  http://kdc:8081/keytab/s3g/testuser2
om_1        | --2019-10-18 06:53:03--  http://kdc:8081/keytab/om/testuser2
datanode_3  | KVNO Timestamp         Principal
kdc_1       | Principal "testuser/713c90b40e6d@EXAMPLE.COM" created.
recon_1     | 
datanode_1  |      0K                                                       100% 9.98M=0s
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | 2019-10-18 06:53:04 (15.9 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
datanode_2  | KVNO Timestamp         Principal
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
om_1        | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | ---- ----------------- --------------------------------------------------------
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_1  | 
scm_1       |    2 10/18/19 06:53:01 testuser/scm@EXAMPLE.COM
kms_1       | 
datanode_2  | ---- ----------------- --------------------------------------------------------
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  |    2 10/18/19 06:53:04 testuser/b59f5315e11c@EXAMPLE.COM
kdc_1       | Entry for principal testuser/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.713c90b40e6d.keytab.
recon_1     | KVNO Timestamp         Principal
datanode_1  | 2019-10-18 06:52:59 (9.98 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
scm_1       |    2 10/18/19 06:53:01 testuser/scm@EXAMPLE.COM
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_2  |    2 10/18/19 06:53:03 testuser2/ed25c35f2081@EXAMPLE.COM
om_1        | HTTP request sent, awaiting response... 200 OK
s3g_1       | HTTP request sent, awaiting response... 200 OK
datanode_3  |    2 10/18/19 06:53:04 testuser/b59f5315e11c@EXAMPLE.COM
kdc_1       | Entry for principal testuser/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.713c90b40e6d.keytab.
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_1  | 
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
kms_1       | KVNO Timestamp         Principal
datanode_2  |    2 10/18/19 06:53:03 testuser2/ed25c35f2081@EXAMPLE.COM
om_1        | Length: 152 [application/octet-stream]
s3g_1       | Length: 154 [application/octet-stream]
datanode_3  | Download testuser2/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
kdc_1       | Generiting keytab
recon_1     |    2 10/18/19 06:53:20 testuser/recon@EXAMPLE.COM
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | --2019-10-18 06:53:01--  http://kdc:8081/keytab/scm/testuser2
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | Download s3g/ed25c35f2081@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
om_1        | Saving to: '/etc/security/keytabs/testuser2.keytab'
s3g_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_3  | --2019-10-18 06:53:04--  http://kdc:8081/keytab/b59f5315e11c/testuser2
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     |    2 10/18/19 06:53:20 testuser/recon@EXAMPLE.COM
datanode_1  | KVNO Timestamp         Principal
scm_1       | Resolving kdc (kdc)... 172.18.0.3
kms_1       |    2 10/18/19 06:53:04 testuser/d71a100b5ba6@EXAMPLE.COM
datanode_2  | --2019-10-18 06:53:03--  http://kdc:8081/keytab/ed25c35f2081/s3g
om_1        | 
s3g_1       | 
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download testuser2/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       |    2 10/18/19 06:53:04 testuser/d71a100b5ba6@EXAMPLE.COM
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
om_1        |      0K                                                       100% 12.2M=0s
s3g_1       |      0K                                                       100% 12.0M=0s
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/testuser2
datanode_1  |    2 10/18/19 06:52:59 testuser/713c90b40e6d@EXAMPLE.COM
scm_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | Download testuser2/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | 
om_1        | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_1  |    2 10/18/19 06:52:59 testuser/713c90b40e6d@EXAMPLE.COM
scm_1       | Length: 154 [application/octet-stream]
kms_1       | --2019-10-18 06:53:04--  http://kdc:8081/keytab/d71a100b5ba6/testuser2
datanode_2  | HTTP request sent, awaiting response... 200 OK
s3g_1       | 2019-10-18 06:53:03 (12.0 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
om_1        | 2019-10-18 06:53:03 (12.2 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [152/152]
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | Length: 172 [application/octet-stream]
datanode_1  | Download testuser2/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
kms_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | Length: 160 [application/octet-stream]
s3g_1       | 
om_1        | 
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | Saving to: '/etc/security/keytabs/testuser2.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_1  | --2019-10-18 06:52:59--  http://kdc:8081/keytab/713c90b40e6d/testuser2
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_2  | Saving to: '/etc/security/keytabs/s3g.keytab'
scm_1       | 
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 
recon_1     | Length: 158 [application/octet-stream]
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Length: 172 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/testuser2.keytab'
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       |    2 10/18/19 06:53:03 testuser2/s3g@EXAMPLE.COM
datanode_3  |      0K                                                       100% 17.2M=0s
datanode_2  | 
kms_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
om_1        | KVNO Timestamp         Principal
scm_1       |      0K                                                       100% 14.4M=0s
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLEOct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | HTTP request sent, awaiting response... 200 OK
s3g_1       |    2 10/18/19 06:53:03 testuser2/s3g@EXAMPLE.COM
datanode_3  | 
datanode_2  |      0K                                                       100% 22.1M=0s
om_1        | ---- ----------------- --------------------------------------------------------
kms_1       | 
recon_1     | 
scm_1       | 
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_1  | Length: 172 [application/octet-stream]
datanode_3  | 2019-10-18 06:53:06 (17.2 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_2  | 
kms_1       |      0K                                                       100% 15.1M=0s
om_1        |    2 10/18/19 06:53:03 testuser2/om@EXAMPLE.COM
recon_1     |      0K                                                       100% 17.1M=0s
scm_1       | 2019-10-18 06:53:01 (14.4 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | --2019-10-18 06:53:04--  http://kdc:8081/keytab/s3g/s3g
datanode_1  | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_3  | 
datanode_2  | 2019-10-18 06:53:04 (22.1 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
kms_1       | 
om_1        |    2 10/18/19 06:53:03 testuser2/om@EXAMPLE.COM
recon_1     | 
scm_1       | 
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_2  | 
kms_1       | 2019-10-18 06:53:06 (15.1 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
om_1        | Download s3g/om@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
recon_1     | 2019-10-18 06:53:20 (17.1 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [158/158]
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  |      0K                                                       100% 13.8M=0s
datanode_3  | KVNO Timestamp         Principal
datanode_2  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kms_1       | 
om_1        | --2019-10-18 06:53:03--  http://kdc:8081/keytab/om/s3g
recon_1     | 
scm_1       | KVNO Timestamp         Principal
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | KVNO Timestamp         Principal
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
om_1        | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 18 0.COM
s3g_1       | Length: 142 [application/octet-stream]
datanode_1  | 2019-10-18 06:53:00 (13.8 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 10/18/19 06:53:06 testuser2/b59f5315e11c@EXAMPLE.COM
kms_1       | KVNO Timestamp         Principal
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | KVNO Timestamp         Principal
scm_1       |    2 10/18/19 06:53:01 testuser2/scm@EXAMPLE.COM
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_1  | 
datanode_2  |    2 10/18/19 06:53:04 s3g/ed25c35f2081@EXAMPLE.COM
datanode_3  |    2 10/18/19 06:53:06 testuser2/b59f5315e11c@EXAMPLE.COM
kms_1       | ---- ----------------- --------------------------------------------------------
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     | ---- ----------------- --------------------------------------------------------
scm_1       |    2 10/18/19 06:53:01 testuser2/scm@EXAMPLE.COM
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_2  |    2 10/18/19 06:53:04 s3g/ed25c35f2081@EXAMPLE.COM
datanode_3  | Download s3g/b59f5315e11c@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kms_1       |    2 10/18/19 06:53:06 testuser2/d71a100b5ba6@EXAMPLE.COM
om_1        | Length: 140 [application/octet-stream]
recon_1     |    2 10/18/19 06:53:20 testuser2/recon@EXAMPLE.COM
scm_1       | Download s3g/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       |      0K                                                       100% 13.0M=0s
datanode_1  | KVNO Timestamp         Principal
datanode_2  | 2019-10-18 06:53:05,623 [main] INFO       - STARTUP_MSG: 
datanode_3  | --2019-10-18 06:53:06--  http://kdc:8081/keytab/b59f5315e11c/s3g
kms_1       |    2 10/18/19 06:53:06 testuser2/d71a100b5ba6@EXAMPLE.COM
om_1        | Saving to: '/etc/security/keytabs/s3g.keytab'
recon_1     |    2 10/18/19 06:53:20 testuser2/recon@EXAMPLE.COM
scm_1       | --2019-10-18 06:53:01--  http://kdc:8081/keytab/scm/s3g
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_2  | /************************************************************
kms_1       | Download s3g/d71a100b5ba6@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
om_1        | 
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download s3g/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
scm_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerber6:52:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-18 06:53:06 (13.0 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
datanode_1  |    2 10/18/19 06:53:00 testuser2/713c90b40e6d@EXAMPLE.COM
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
kms_1       | --2019-10-18 06:53:06--  http://kdc:8081/keytab/d71a100b5ba6/s3g
om_1        |      0K                                                       100% 17.3M=0s
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-18 06:53:20--  http://kdc:8081/keytab/recon/s3g
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
s3g_1       | 
datanode_1  |    2 10/18/19 06:53:00 testuser2/713c90b40e6d@EXAMPLE.COM
datanode_2  | STARTUP_MSG:   host = ed25c35f2081/172.18.0.10
kms_1       | Resolving kdc (kdc)... 172.18.0.3
om_1        | 
datanode_3  | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.3
scm_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_1  | Download s3g/713c90b40e6d@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_2  | STARTUP_MSG:   args = []
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | 2019-10-18 06:53:06 (17.3 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [140/140]
datanode_3  | Length: 160 [application/octet-stream]
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | Length: 142 [application/octet-stream]
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | --2019-10-18 06:53:00--  http://kdc:8081/keytab/713c90b40e6d/s3g
s3g_1       | KVNO Timestamp         Principal
datanode_2  | STARTUP_MSG:   version = 3.2.0
kms_1       | HTTP request sent, awaiting response... 200 OK
om_1        | 
datanode_3  | Saving to: '/etc/security/keytabs/s3g.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
scm_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Length: 160 [application/octet-stream]
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_3  | 
recon_1     | Length: 146 [application/octet-stream]
scm_1       | 
om_1        | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1       |    2 10/18/19 06:53:06 s3g/s3g@EXAMPLE.COM
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  |      0K                                                       100% 21.6M=0s
recon_1     | Saving to: '/etc/security/keytabs/s3g.keytab'
scm_1       |      0K                                                       100% 14.8M=0s
om_1        | KVNO Timestamp         Principal
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | HTTP request sent, awaiting response... 200 OK
kms_1       | 
s3g_1       |    2 10/18/19 06:53:06 s3g/s3g@EXAMPLE.COM
datanode_3  | 
datanode_2  | STARTUP_MSG:   java = 11.0.3
recon_1     | 
scm_1       | 
om_1        | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | Length: 160 [application/octet-stream]
kms_1       |      0K                                                       100% 17.5M=0s
s3g_1       | WARNING: An illegal reflective access operation has occurred
datanode_3  | 2019-10-18 06:53:06 (21.6 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_2  | ************************************************************/
recon_1     |      0K                                                       100% 11.8M=0s
scm_1       | 2019-10-18 06:53:02 (14.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
om_1        |    2 10/18/19 06:53:06 s3g/om@EXAMPLE.COM
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | Saving to: '/etc/security/keytabs/s3g.keytab'
kms_1       | 
s3g_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_3  | 
datanode_2  | 2019-10-18 06:53:05,636 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 
scm_1       | 
om_1        |    2 10/18/19 06:53:06 s3g/om@EXAMPLE.COM
datanode_1  | 
kms_1       | 2019-10-18 06:53:06 (17.5 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_3  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_2  | 2019-10-18 06:53:05,893 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2019-10-18 06:53:21 (11.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [146/146]
scm_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
om_1        | 2019-10-18 06:53:07,029 [main] INFO       - STARTUP_MSG: 
datanode_1  |      0K                                                       100% 4.83M=0s
kms_1       | 
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | KVNO Timestamp         Principal
datanode_2  | 2019-10-18 06:53:06,048 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 
scm_1       | KVNO Timestamp         Principal
om_1        | /************************************************************
datanode_1  | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | ---- ----------------- --------------------------------------------------------
s3g_1       | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-10-18 06:53:06,048 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
recon_1     | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
scm_1       | ---- ----------------- --------------------------------------------------------
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_1  | 2019-10-18 06:53:00 (4.83 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
kms_1       | KVNO Timestamp         Principal
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXos database
datanode_3  |    2 10/18/19 06:53:06 s3g/b59f5315e11c@EXAMPLE.COM
s3g_1       | 2019-10-18 06:53:07,509 INFO hdfs.DFSUtil: Starting web server as: HTTP/s3g@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:06,229 [main] INFO       - HddsDatanodeService host:ed25c35f2081 ip:172.18.0.10
recon_1     | KVNO Timestamp         Principal
scm_1       |    2 10/18/19 06:53:02 s3g/scm@EXAMPLE.COM
om_1        | STARTUP_MSG:   host = om/172.18.0.7
datanode_1  | 
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 10/18/19 06:53:06 s3g/b59f5315e11c@EXAMPLE.COM
s3g_1       | 2019-10-18 06:53:07,510 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:06,546 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
recon_1     | ---- ----------------- --------------------------------------------------------
scm_1       |    2 10/18/19 06:53:02 s3g/scm@EXAMPLE.COM
om_1        | STARTUP_MSG:   args = [--init]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kms_1       |    2 10/18/19 06:53:06 s3g/d71a100b5ba6@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:07,485 [main] INFO       - STARTUP_MSG: 
s3g_1       | 2019-10-18 06:53:07,562 INFO util.log: Logging initialized @1210ms
datanode_2  | WARNING: An illegal reflective access operation has occurred
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     |    2 10/18/19 06:53:21 s3g/recon@EXAMPLE.COM
scm_1       | 2019-10-18 06:53:03,402 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_1  | KVNO Timestamp         Principal
kms_1       |    2 10/18/19 06:53:06 s3g/d71a100b5ba6@EXAMPLE.COM
datanode_3  | /************************************************************
s3g_1       | 2019-10-18 06:53:07,692 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
recon_1     |    2 10/18/19 06:53:21 s3g/recon@EXAMPLE.COM
scm_1       | /************************************************************
datanode_1  | ---- ----------------- --------------------------------------------------------
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
s3g_1       | 2019-10-18 06:53:07,720 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     | WARNING: An illegal reflective access operation has occurred
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  |    2 10/18/19 06:53:00 s3g/713c90b40e6d@EXAMPLE.COM
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
datanode_3  | STARTUP_MSG:   host = b59f5315e11c/172.18.0.9
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
s3g_1       | 2019-10-18 06:53:07,730 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1       | Oct 18 06:52:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381578, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/aAMPLE.COM, addr=127.0.0.1
scm_1       | STARTUP_MSG:   host = scm/172.18.0.4
datanode_1  |    2 10/18/19 06:53:00 s3g/713c90b40e6d@EXAMPLE.COM
kms_1       | # this work for additional information regarding copyright ownership.
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
datanode_3  | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   java = 11.0.3
s3g_1       | 2019-10-18 06:53:07,734 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
datanode_2  | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-18 06:53:01,641 [main] INFO       - STARTUP_MSG: 
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
datanode_3  | STARTUP_MSG:   version = 3.2.0
om_1        | ************************************************************/
s3g_1       | 2019-10-18 06:53:07,734 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | STARTUP_MSG:   args = [--init]
datanode_1  | /************************************************************
datanode_2  | 2019-10-18 06:53:06,803 INFO security.UserGroupInformation: Login successful for user dn/ed25c35f2081@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       | # (the "License"); you may not use this file except in compliance with
om_1        | 2019-10-18 06:53:07,040 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2019-10-18 06:53:07,734 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | 2019-10-18 06:53:06,803 [main] INFO       - Hdds Datanode login successful.
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
kms_1       | # the License.  You may obtain a copy of the License at
om_1        | 2019-10-18 06:53:08,046 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.7:9862
s3g_1       | 2019-10-18 06:53:07,758 [main] INFO       - Starting Ozone S3 gateway
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   host = 713c90b40e6d/172.18.0.2
recon_1     | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-10-18 06:53:06,803 [main] INFO       - Initializing secure Datanode.
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | #
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | 2019-10-18 06:53:08,047 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
s3g_1       | 2019-10-18 06:53:07,772 INFO http.HttpServer2: Jetty bound to port 9878
recon_1     | 2019-10-18 06:53:22,282 [main] INFO       - rest([/api/*]).packages(org.apache.hadoop.ozone.recon.api)
datanode_2  | 2019-10-18 06:53:06,804 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
datanode_3  | STARTUP_MSG:   java = 11.0.3
om_1        | WARNING: An illegal reflective access operation has occurred
recon_1     | 2019-10-18 06:53:22,480 [main] INFO       - Initializing Recon server...
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 06:53:06,804 INFO client.DNCertificateClient: Certificate client init case: 0
s3g_1       | 2019-10-18 06:53:07,773 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1  | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   java = 11.0.3
kms_1       | #
datanode_3  | ************************************************************/
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
recon_1     | 2019-10-18 06:53:22,649 [main] ERROR      - Error during initializing Recon server.
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 06:53:06,805 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
s3g_1       | 2019-10-18 06:53:07,830 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | ************************************************************/
kms_1       | # Unless required by applicable law or agreed to in writing, software
datanode_3  | 2019-10-18 06:53:07,497 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
recon_1     | java.sql.SQLException: path to '//data/metadata/recon/ozone_recon_sqlite.db': '/data/metadata' does not exist
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, clientdmin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:07,191 [main] INFO       - Init response: GETCERT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
s3g_1       | 2019-10-18 06:53:07,851 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
scm_1       | 2019-10-18 06:53:03,409 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
datanode_3  | 2019-10-18 06:53:07,821 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | 	at org.sqlite.SQLiteConnection.open(SQLiteConnection.java:215)
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-18 06:53:07,210 [main] INFO       - Adding ip:172.18.0.10,host:ed25c35f2081
s3g_1       | 2019-10-18 06:53:07,895 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68878f6d{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | 2019-10-18 06:53:03,559 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
datanode_3  | 2019-10-18 06:53:07,988 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:07,211 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
recon_1     | 	at org.sqlite.SQLiteConnection.<init>(SQLiteConnection.java:61)
s3g_1       | 2019-10-18 06:53:07,896 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@78fa769e{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | STARTUP_MSG:   java = 11.0.3
scm_1       | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-e93fddb4-2e04-44a1-adc1-10879bd01d05
kms_1       | # See the License for the specific language governing permissions and
datanode_3  | 2019-10-18 06:53:07,989 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1        | 2019-10-18 06:53:08,279 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-18 06:53:07,217 [main] INFO       - Creating csr for DN-> subject:root@ed25c35f2081
recon_1     | 	at org.sqlite.jdbc3.JDBC3Connection.<init>(JDBC3Connection.java:28)
datanode_1  | ************************************************************/
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
scm_1       | 2019-10-18 06:53:03,606 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_3  | 2019-10-18 06:53:08,190 [main] INFO       - HddsDatanodeService host:b59f5315e11c ip:172.18.0.9
om_1        | 2019-10-18 06:53:08,280 [main] INFO       - Ozone Manager login successful.
kms_1       | # limitations under the License.
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:09,696 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
recon_1     | 	at org.sqlite.jdbc4.JDBC4Connection.<init>(JDBC4Connection.java:21)
datanode_1  | 2019-10-18 06:53:01,655 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2019-10-18 06:53:09,946 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
scm_1       | /************************************************************
datanode_3  | 2019-10-18 06:53:08,512 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
om_1        | 2019-10-18 06:53:08,284 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not fou=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | 
datanode_2  | 2019-10-18 06:53:09,822 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
recon_1     | 	at org.sqlite.JDBC.createConnection(JDBC.java:116)
datanode_1  | 2019-10-18 06:53:01,928 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | Oct 18, 2019 6:53:10 AM org.glassfish.jersey.internal.Errors logErrors
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.4
datanode_3  | WARNING: An illegal reflective access operation has occurred
om_1        | 2019-10-18 06:53:09,350 [main] INFO       - Initializing secure OzoneManager.
kms_1       | [logging]
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:410)
datanode_2  | 2019-10-18 06:53:09,826 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2019-10-18 06:53:02,096 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
scm_1       | ************************************************************/
datanode_3  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
om_1        | 2019-10-18 06:53:09,895 ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
kms_1       |  default = FILE:/var/log/krb5libs.log
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:398)
datanode_2  | 2019-10-18 06:53:09,834 [main] INFO       - Scheduling a check for /data/hdds/hdds
datanode_1  | 2019-10-18 06:53:02,097 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
s3g_1       | 
scm_1       | 2019-10-18 06:53:04,636 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | 2019-10-18 06:53:09,896 INFO client.OMCertificateClient: Certificate client init case: 0
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | 	at org.hadoop.ozone.recon.schema.StatsSchemaDefinition.initializeSchema(StatsSchemaDefinition.java:44)
datanode_2  | 2019-10-18 06:53:09,869 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2019-10-18 06:53:02,286 [main] INFO       - HddsDatanodeService host:713c90b40e6d ip:172.18.0.2
s3g_1       | 2019-10-18 06:53:10,856 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4bf80c29{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-13835309460630412274.dir/webapp/,AVAILABLE}{/s3gateway}
scm_1       | /************************************************************
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | 2019-10-18 06:53:09,897 INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
kms_1       |  admin_server = FILE:/var/log/kadmind.log
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:78)
datanode_2  | 2019-10-18 06:53:10,478 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2019-10-18 06:53:02,614 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
s3g_1       | 2019-10-18 06:53:10,863 INFO server.AbstractConnector: Started ServerConnector@9b47400{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_3  | WARNING: All illegal access operations will be denied in a future release
om_1        | 2019-10-18 06:53:10,382 [main] INFO       - Init response: GETCERT
kms_1       | 
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
datanode_2  | 2019-10-18 06:53:10,521 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | WARNING: An illegal reflective access operation has occurred
s3g_1       | 2019-10-18 06:53:10,863 INFO server.Server: Started @4514ms
scm_1       | STARTUP_MSG:   host = scm/172.18.0.4
datanode_3  | 2019-10-18 06:53:08,718 INFO security.UserGroupInformation: Login successful for user dn/b59f5315e11c@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
om_1        | 2019-10-18 06:53:10,416 [main] INFO       - Adding ip:172.18.0.7,host:om
kms_1       | [libdefaults]
kdc_1       | Oct 18 06:52:58 kdc kadmind[15](info): closing down fd 18
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
datanode_2  | 2019-10-18 06:53:10,611 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_1  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
s3g_1       | 2019-10-18 06:53:10,866 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
scm_1       | STARTUP_MSG:   args = []
datanode_3  | 2019-10-18 06:53:08,719 [main] INFO       - Hdds Datanode login successful.
om_1        | 2019-10-18 06:53:10,417 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
kms_1       |  dns_canonicalize_hostname = false
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, snd in Kerberos database
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
datanode_2  | 2019-10-18 06:53:10,613 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
s3g_1       | 2019-10-18 07:00:08,222 [qtp359368949-110] INFO       - Location is /bucket-test123
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_3  | 2019-10-18 06:53:08,719 [main] INFO       - Initializing secure Datanode.
om_1        | 2019-10-18 06:53:10,422 [main] INFO       - Creating csr for OM->dns:om,ip:172.18.0.7,scmId:19b63d4b-172b-4c97-826c-c2ce496d8d30,clusterId:CID-e93fddb4-2e04-44a1-adc1-10879bd01d05,subject:root@om
kms_1       |  dns_lookup_realm = false
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
datanode_2  | 2019-10-18 06:53:10,615 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | 2019-10-18 07:00:11,646 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:08,719 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om_1        | 2019-10-18 06:53:10,537 [main] INFO       - OzoneManager ports added:[name: "RPC"
kms_1       |  ticket_lifetime = 24h
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
datanode_2  | 2019-10-18 06:53:10,616 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | WARNING: All illegal access operations will be denied in a future release
datanode_3  | 2019-10-18 06:53:08,719 INFO client.DNCertificateClient: Certificate client init case: 0
om_1        | value: 9862
kms_1       |  renew_lifetime = 7d
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:10,616 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
s3g_1       | 20191018T070011Z
datanode_1  | 2019-10-18 06:53:02,830 INFO security.UserGroupInformation: Login successful for user dn/713c90b40e6d@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_3  | 2019-10-18 06:53:08,721 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | ]
kms_1       |  forwardable = true
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
scm_1       | STARTUP_MSG:   java = 11.0.3
datanode_2  | 2019-10-18 06:53:10,749 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-18 06:53:02,830 [main] INFO       - Hdds Datanode login successful.
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:09,176 [main] INFO       - Init response: GETCERT
om_1        | 2019-10-18 06:53:10,627 [main] INFO       - Successfully stored SCM signed certificate.
kms_1       |  rdns = false
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
scm_1       | ************************************************************/
datanode_2  | 2019-10-18 06:53:10,814 INFO hdfs.DFSUtil: Starting web server as: HTTP/ed25c35f2081@EXAMPLE.COM
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM uccess, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-18 06:53:02,831 [main] INFO       - Initializing secure Datanode.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:09,194 [main] INFO       - Adding ip:172.18.0.9,host:b59f5315e11c
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-e93fddb4-2e04-44a1-adc1-10879bd01d05
kms_1       |  default_realm = EXAMPLE.COM
scm_1       | 2019-10-18 06:53:04,643 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2019-10-18 06:53:10,815 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
datanode_1  | 2019-10-18 06:53:02,831 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
s3g_1       | 2019-10-18 07:00:11,659 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:09,194 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
om_1        | 2019-10-18 06:53:10,678 [shutdown-hook-0] INFO       - SHUTDOWN_MSG: 
kms_1       | 
scm_1       | 2019-10-18 06:53:04,808 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2019-10-18 06:53:10,835 INFO util.log: Logging initialized @6138ms
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
datanode_1  | 2019-10-18 06:53:02,831 INFO client.DNCertificateClient: Certificate client init case: 0
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:09,202 [main] INFO       - Creating csr for DN-> subject:root@b59f5315e11c
om_1        | /************************************************************
kms_1       | [realms]
scm_1       | WARNING: An illegal reflective access operation has occurred
datanode_2  | 2019-10-18 06:53:10,914 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
datanode_1  | 2019-10-18 06:53:02,832 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:09,803 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.7
kms_1       |  EXAMPLE.COM = {
scm_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_2  | 2019-10-18 06:53:10,917 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
recon_1     | 2019-10-18 06:53:22,651 [main] INFO       - Stopping Recon server
datanode_1  | 2019-10-18 06:53:03,235 [main] INFO       - Init response: GETCERT
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:09,868 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
om_1        | ************************************************************/
kms_1       |   kdc = kdc
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | 2019-10-18 06:53:10,925 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | java.lang.NullPointerException
datanode_1  | 2019-10-18 06:53:03,247 [main] INFO       - Adding ip:172.18.0.2,host:713c90b40e6d
s3g_1       | 2019-10-18 07:00:11,659 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:09,875 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
om_1        | 2019-10-18 06:53:11,598 [main] INFO       - STARTUP_MSG: 
kms_1       |   admin_server = kdc
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | 2019-10-18 06:53:10,927 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.stop(ReconServer.java:115)
datanode_1  | 2019-10-18 06:53:03,247 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:09,889 [main] INFO       - Scheduling a check for /data/hdds/hdds
om_1        | /************************************************************
scm_1       | WARNING: All illegal access operations will be denied in a future release
kms_1       |  }
datanode_2  | 2019-10-18 06:53:10,927 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/713c90b40e6d@EXAfor kadmin/admin@EXAMPLE.COM
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:100)
datanode_1  | 2019-10-18 06:53:03,253 [main] INFO       - Creating csr for DN-> subject:root@713c90b40e6d
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:09,912 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
om_1        | STARTUP_MSG: Starting OzoneManager
scm_1       | 2019-10-18 06:53:05,024 INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
kms_1       | 
datanode_2  | 2019-10-18 06:53:10,927 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
datanode_1  | 2019-10-18 06:53:04,421 INFO ipc.Client: Retrying connect to server: scm/172.18.0.4:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
datanode_3  | 2019-10-18 06:53:10,575 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | STARTUP_MSG:   host = om/172.18.0.7
scm_1       | 2019-10-18 06:53:05,025 INFO server.StorageContainerManager: SCM login successful.
kms_1       | [domain_realm]
datanode_2  | 2019-10-18 06:53:10,952 INFO http.HttpServer2: Jetty bound to port 9882
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
datanode_1  | 2019-10-18 06:53:05,422 INFO ipc.Client: Retrying connect to server: scm/172.18.0.4:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | 2019-10-18 07:00:11,665 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:10,615 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om_1        | STARTUP_MSG:   args = []
scm_1       | 2019-10-18 06:53:05,026 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kms_1       |  .example.com = EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:10,953 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
datanode_1  | 2019-10-18 06:53:06,423 INFO ipc.Client: Retrying connect to server: scm/172.18.0.4:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:10,688 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
om_1        | STARTUP_MSG:   version = 3.2.0
scm_1       | 2019-10-18 06:53:05,196 INFO util.log: Logging initialized @1400ms
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode_2  | 2019-10-18 06:53:10,980 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
datanode_1  | 2019-10-18 06:53:07,424 INFO ipc.Client: Retrying connect to server: scm/172.18.0.4:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:10,689 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
scm_1       | 2019-10-18 06:53:05,427 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
kms_1       | WARNING: /opt/hadoop/logs does not exist. Creating.
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_2  | 2019-10-18 06:53:10,982 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/ed25c35f2081@EXAMPLE.COM
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, SeMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
datanode_1  | 2019-10-18 06:53:09,676 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:10,691 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-18 06:53:05,427 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
kms_1       | Oct 18, 2019 6:53:08 AM com.sun.jersey.api.core.PackagesResourceConfig init
datanode_2  | 2019-10-18 06:53:10,984 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bee8621{/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
datanode_1  | 2019-10-18 06:53:09,744 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
s3g_1       | 2019-10-18 07:00:11,665 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:10,692 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2019-10-18 06:53:05,427 INFO db.DBStoreBuilder: using custom profile for table: validCerts
kms_1       | INFO: Scanning for root resource and provider classes in the packages:
datanode_2  | 2019-10-18 06:53:10,985 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10a18e3e{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | STARTUP_MSG:   java = 11.0.3
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-18 06:53:09,751 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:10,693 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-18 06:53:05,427 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
kms_1       |   org.apache.hadoop.crypto.key.kms.server
datanode_2  | 2019-10-18 06:53:11,043 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/ed25c35f2081@EXAMPLE.COM
om_1        | ************************************************************/
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 06:53:09,761 [main] INFO       - Scheduling a check for /data/hdds/hdds
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:10,827 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-18 06:53:05,427 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
kms_1       | Oct 18, 2019 6:53:08 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
datanode_2  | 2019-10-18 06:53:11,047 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@510689af{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-13860295716673056071.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1        | 2019-10-18 06:53:11,608 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 06:53:09,790 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
datanode_3  | 2019-10-18 06:53:10,901 INFO hdfs.DFSUtil: Starting web server as: HTTP/b59f5315e11c@EXAMPLE.COM
scm_1       | 2019-10-18 06:53:05,427 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
kms_1       | INFO: Root resource classes found:
om_1        | 2019-10-18 06:53:12,481 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.7:9862
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 06:53:11,052 INFO server.AbstractConnector: Started ServerConnector@9df564f{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2019-10-18 06:53:10,360 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
s3g_1       | 2019-10-18 07:00:11,671 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:10,901 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | 2019-10-18 06:53:05,437 INFO db.DBStoreBuilder: using custom profile for table: default
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMS
om_1        | 2019-10-18 06:53:12,481 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
datanode_2  | 2019-10-18 06:53:11,052 INFO server.Server: Started @6355ms
datanode_1  | 2019-10-18 06:53:10,422 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:10,928 INFO util.log: Logging initialized @4263ms
scm_1       | 2019-10-18 06:53:05,437 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
kms_1       | Oct 18, 2019 6:53:08 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
om_1        | 2019-10-18 06:53:12,485 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 06:53:11,055 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2019-10-18 06:53:10,505 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:11,020 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2019-10-18 06:53:05,439 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
kms_1       | INFO: Provider classes found:
om_1        | WARNING: An illegal reflective access operation has occurred
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 06:53:11,055 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2019-10-18 06:53:10,506 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:11,022 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
scm_1       | 2019-10-18 06:53:07,078 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 06:53:11,057 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
s3g_1       | 2019-10-18 07:00:11,671 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-18 06:53:10,508 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-18 06:53:11,028 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1       | 2019-10-18 06:53:07,110 INFO ipc.Server: Starting Socket Reader #1 for port 9961
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 06:53:11,070 INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1       | 20191018T070011Z
datanode_1  | 2019-10-18 06:53:10,509 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_3  | 2019-10-18 06:53:11,031 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
scm_1       | 2019-10-18 06:53:07,237 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@6ad6fa53
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 06:53:13,218 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_1  | 2019-10-18 06:53:10,510 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-18 06:53:07,240 INFO net.NodeSchemaLoader: Loading network topology layer schema file
kms_1       | Oct 18, 2019 6:53:08 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
om_1        | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 06:53:13,223 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
datanode_1  | 2019-10-18 06:53:10,655 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-18 06:53:07,372 INFO node.SCMNodeManager: Entering startup safe mode.
om_1        | 2019-10-18 06:53:12,667 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
kms_1       | INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
datanode_3  | 2019-10-18 06:53:11,031 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 06:53:13,224 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 05927fc9-2042-483a-98e5-6075d8118b6c at port 9858
s3g_1       | 2019-10-18 07:00:11,677 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-18 06:53:10,730 INFO hdfs.DFSUtil: Starting web server as: HTTP/713c90b40e6d@EXAMPLE.COM
scm_1       | 2019-10-18 06:53:07,482 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om_1        | 2019-10-18 06:53:12,667 [main] INFO       - Ozone Manager login successful.
datanode_3  | 2019-10-18 06:53:11,031 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
kdc_1       | Oct 18 06:52:59 kdc rver not found in Kerberos database
datanode_1  | 2019-10-18 06:53:10,730 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | 2019-10-18 06:53:07,495 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 20191018T070011Z
datanode_2  | 2019-10-18 06:53:13,258 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: start RPC server
om_1        | 2019-10-18 06:53:12,667 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | 2019-10-18 06:53:11,054 INFO http.HttpServer2: Jetty bound to port 9882
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-18 06:53:10,755 INFO util.log: Logging initialized @9827ms
scm_1       | 2019-10-18 06:53:07,651 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 06:53:13,460 INFO server.GrpcService: 05927fc9-2042-483a-98e5-6075d8118b6c: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
om_1        | 2019-10-18 06:53:13,536 INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
datanode_3  | 2019-10-18 06:53:11,055 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1  | 2019-10-18 06:53:10,854 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2019-10-18 06:53:07,653 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 06:53:16,749 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: addNew group-F15AF2A99F3B:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858] returns group-F15AF2A99F3B:java.util.concurrent.CompletableFuture@497e7c2c[Not completed]
om_1        | 2019-10-18 06:53:13,641 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/11728348918507398.crt.
datanode_3  | 2019-10-18 06:53:11,082 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2019-10-18 06:53:10,858 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
scm_1       | 2019-10-18 06:53:07,754 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
s3g_1       | 2019-10-18 07:00:11,678 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 06:53:16,769 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c: new RaftServerImpl for group-F15AF2A99F3B:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858] with ContainerStateMachine:uninitialized
om_1        | 2019-10-18 06:53:13,655 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
datanode_3  | 2019-10-18 06:53:11,084 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/b59f5315e11c@EXAMPLE.COM
datanode_1  | 2019-10-18 06:53:10,865 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
s3g_1       | 20191018T070011Z
scm_1       | 2019-10-18 06:53:08,181 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 06:53:16,771 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2019-10-18 06:53:13,682 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | 2019-10-18 06:53:11,086 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3a38f122{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2019-10-18 06:53:10,867 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
s3g_1       | 20191018/us-west-1/s3/aws4_request
scm_1       | 2019-10-18 06:53:08,188 INFO ipc.Server: Starting Socket Reader #1 for port 9861
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 06:53:16,771 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2019-10-18 06:53:13,712 INFO util.log: Logging initialized @2838ms
datanode_2  | 2019-10-18 06:53:16,771 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-10-18 06:53:10,868 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
scm_1       | 2019-10-18 06:53:08,226 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:11,087 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bee8621{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2019-10-18 06:53:13,808 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_2  | 2019-10-18 06:53:16,772 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2019-10-18 06:53:10,868 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 2019-10-18 07:00:11,683 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-18 06:53:08,227 INFO ipc.Server: Starting Socket Reader #1 for port 9863
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:11,144 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/b59f5315e11c@EXAMPLE.COM
om_1        | 2019-10-18 06:53:13,808 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_2  | 2019-10-18 06:53:16,773 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-18 06:53:10,889 INFO http.HttpServer2: Jetty bound to port 9882
s3g_1       | 20191018T070011Z
scm_1       | 2019-10-18 06:53:08,275 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 06:53:11,148 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a65a360{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-13384195369374830876.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1        | 2019-10-18 06:53:13,808 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_1  | 2019-10-18 06:53:10,891 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
scm_1       | 2019-10-18 06:53:08,276 INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_2  | 2019-10-18 06:53:16,780 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-18 06:53:11,153 INFO server.AbstractConnector: Started ServerConnector@6b63abdc{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
datanode_1  | 2019-10-18 06:53:10,918 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
scm_1       | 2019-10-18 06:53:08,319 INFO hdfs.DFSUtil: Starting web server as: HTTP/scm@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:16,780 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-18 06:53:11,154 INFO server.Server: Started @4488ms
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_1  | 2019-10-18 06:53:10,920 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/713c90b40e6d@EXAMPLE.COM
s3g_1       | 2019-10-18 07:00:11,683 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Generiting keytab
scm_1       | 2019-10-18 06:53:08,319 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_2  | 2019-10-18 06:53:16,785 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2019-10-18 06:53:11,161 INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
datanode_1  | 2019-10-18 06:53:10,923 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4792f119{/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 20191018T070011Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:53:08,446 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-18 06:53:16,787 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4cfc27b5-8884-4177-946c-f15af2a99f3b does not exist. Creating ...
datanode_3  | 2019-10-18 06:53:11,161 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2019-10-18 06:53:10,924 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4cc01c7f{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: using custom profile for table: keyTable
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | WARNING: no policy specified for testuser2/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-18 06:53:08,464 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
datanode_2  | 2019-10-18 06:53:18,057 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4cfc27b5-8884-4177-946c-f15af2a99f3b/in_use.lock acquired by nodename 7@ed25c35f2081
datanode_3  | 2019-10-18 06:53:11,163 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_1  | 2019-10-18 06:53:10,982 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/713c90b40e6d@EXAMPLE.COM
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
kdc_1       | Principal "testuser2/713c90b40e6d@EXAMPLE.COM" created.
scm_1       | 2019-10-18 06:53:08,475 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2019-10-18 06:53:18,169 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4cfc27b5-8884-4177-946c-f15af2a99f3b has been successfully formatted.
datanode_3  | 2019-10-18 06:53:11,180 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2019-10-18 06:53:10,986 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4017fe2c{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-8814102203301143940.dir/webapp/,AVAILABLE}{/hddsDatanode}
s3g_1       | 2019-10-18 07:00:11,688 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
scm_1       | 2019-10-18 06:53:08,477 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
datanode_3  | 2019-10-18 06:53:13,317 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
datanode_2  | 2019-10-18 06:53:18,172 [pool-9-thread-1] INFO       - group-F15AF2A99F3B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-18 06:53:10,990 INFO server.AbstractConnector: Started ServerConnector@622d7e4{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
s3g_1       | 20191018T070011Z
kdc_1       | Entry for principal testuser2/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.713c90b40e6d.keytab.
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
scm_1       | 2019-10-18 06:53:08,478 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2019-10-18 06:53:13,319 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_2  | 2019-10-18 06:53:18,173 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-10-18 06:53:10,990 INFO server.Server: Started @10062ms
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Entry for principal testuser2/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.713c90b40e6d.keytab.
om_1        | 2019-10-18 06:53:13,809 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
scm_1       | 2019-10-18 06:53:08,478 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2019-10-18 06:53:13,320 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 9b428cf8-0805-4b46-95f2-cb42dae54452 at port 9858
datanode_2  | 2019-10-18 06:53:18,175 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_1  | 2019-10-18 06:53:10,993 INFO impl.MetricsSinkAdapter: Sink prometheus started
kdc_1       | Generiting keytab
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
scm_1       | 2019-10-18 06:53:08,515 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_2  | 2019-10-18 06:53:18,180 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1       | 2019-10-18 07:00:11,688 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-18 06:53:10,993 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2019-10-18 06:53:13,339 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: start RPC server
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: using custom profile for table: s3Table
scm_1       | 2019-10-18 06:53:08,575 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2019-10-18 06:53:18,180 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 20191018T070011Z
datanode_1  | 2019-10-18 06:53:10,994 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
kdc_1       | WARNING: no policy specified for dn/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
scm_1       | 2019-10-18 06:53:08,620 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2019-10-18 06:53:18,182 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Principal "dn/ed25c35f2081@EXAMPLE.COM" created.
scm_1       | 2019-10-18 06:53:08,620 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
datanode_2  | 2019-10-18 06:53:18,184 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
datanode_3  | 2019-10-18 06:53:13,572 INFO server.GrpcService: 9b428cf8-0805-4b46-95f2-cb42dae54452: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2019-10-18 06:53:11,010 INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
datanode_2  | 2019-10-18 06:53:18,190 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2019-10-18 06:53:18,596 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: addNew group-F5C0C2437F07:[9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-F5C0C2437F07:java.util.concurrent.CompletableFuture@74a0a947[Not completed]
datanode_1  | 2019-10-18 06:53:13,152 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
scm_1       | 2019-10-18 06:53:08,809 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
s3g_1       | 2019-10-18 07:00:11,693 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal dn/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.ed25c35f2081.keytab.
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
datanode_2  | 2019-10-18 06:53:18,230 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2019-10-18 06:53:18,613 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452: new RaftServerImpl for group-F5C0C2437F07:[9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
scm_1       | 2019-10-18 06:53:08,810 INFO ipc.Server: IPC Server Responder: starting
s3g_1       | 20191018T070011Z
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
kdc_1       | Entry for principal dn/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.ed25c35f2081.keytab.
datanode_1  | 2019-10-18 06:53:13,154 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_2  | 2019-10-18 06:53:18,235 INFO segmented.SegmentedRaftLogWorker: new 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/4cfc27b5-8884-4177-946c-f15af2a99f3b
datanode_3  | 2019-10-18 06:53:18,615 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2019-10-18 06:53:08,814 INFO ipc.Server: IPC Server listener on 9860: starting
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
kdc_1       | Generiting keytab
datanode_2  | 2019-10-18 06:53:18,236 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2019-10-18 06:53:13,154 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e at port 9858
datanode_3  | 2019-10-18 06:53:18,615 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2019-10-18 06:53:08,818 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 06:53:13,810 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-18 06:53:18,236 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2019-10-18 06:53:13,173 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start RPC server
datanode_3  | 2019-10-18 06:53:18,616 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1       | 2019-10-18 06:53:08,818 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
s3g_1       | 2019-10-18 07:00:11,694 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 06:53:13,811 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
kdc_1       | WARNING: no policy specified for dn/om@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 06:53:13,811 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
datanode_1  | 2019-10-18 06:53:13,393 INFO server.GrpcService: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2019-10-18 06:53:18,616 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 20191018T070011Z
scm_1       | 2019-10-18 06:53:08,819 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-10-18 06:53:18,237 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Principal "dn/om@EXAMPLE.COM" created.
om_1        | 2019-10-18 06:53:13,826 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_1  | 2019-10-18 06:53:15,928 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: addNew group-F3891471ADC2:[4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858] returns group-F3891471ADC2:java.util.concurrent.CompletableFuture@6cde4009[Not completed]
datanode_3  | 2019-10-18 06:53:18,617 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 20191018/us-west-1/s3/aws4_request
scm_1       | 2019-10-18 06:53:08,819 INFO ipc.Server: IPC Server listener on 9863: starting
datanode_2  | 2019-10-18 06:53:18,237 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:53:13,826 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_1  | 2019-10-18 06:53:15,943 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: new RaftServerImpl for group-F3891471ADC2:[4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2019-10-18 06:53:18,625 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: ConfigurationManager, init=-1: [9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
scm_1       | 2019-10-18 06:53:08,822 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_2  | 2019-10-18 06:53:18,238 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
datanode_1  | 2019-10-18 06:53:15,945 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2019-10-18 06:53:13,828 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_3  | 2019-10-18 06:53:18,625 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1       | 2019-10-18 07:00:11,699 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-18 06:53:08,822 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_2  | 2019-10-18 06:53:18,238 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
datanode_1  | 2019-10-18 06:53:15,945 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2019-10-18 06:53:14,204 INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
datanode_3  | 2019-10-18 06:53:18,630 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | 20191018T070011Z
scm_1       | 2019-10-18 06:53:08,824 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-10-18 06:53:18,239 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
kdc_1       | Generiting keytab
datanode_1  | 2019-10-18 06:53:15,945 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-10-18 06:53:18,632 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7fbeb4fb-b81e-4fd5-b009-f5c0c2437f07 does not exist. Creating ...
s3g_1       | 20191018/us-west-1/s3/aws4_request
scm_1       | 2019-10-18 06:53:08,824 INFO ipc.Server: IPC Server listener on 9861: starting
datanode_2  | 2019-10-18 06:53:18,239 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 06:53:15,946 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om_1        | 2019-10-18 06:53:14,206 [main] INFO       - Loaded 0 tokens
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:18,660 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7fbeb4fb-b81e-4fd5-b009-f5c0c2437f07/in_use.lock acquired by nodename 7@b59f5315e11c
datanode_2  | 2019-10-18 06:53:18,239 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2019-10-18 06:53:08,827 INFO server.SCMClientProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
kdc_1       | WARNING: no policy specified for dn/s3g@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-18 06:53:15,946 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2019-10-18 06:53:14,207 [main] INFO       - Loading token state into token manager.
datanode_3  | 2019-10-18 06:53:18,679 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7fbeb4fb-b81e-4fd5-b009-f5c0c2437f07 has been successfully formatted.
s3g_1       | 2019-10-18 07:00:11,700 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-18 06:53:18,248 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
kdc_1       | Principal "dn/s3g@EXAMPLE.COM" created.
scm_1       | 2019-10-18 06:53:08,828 INFO ipc.Server: IPC Server Responder: starting
datanode_1  | 2019-10-18 06:53:15,953 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: ConfigurationManager, init=-1: [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858], old=null, confs=<EMPTY_MAP>
om_1        | 2019-10-18 06:53:14,248 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2019-10-18 06:53:18,682 [pool-9-thread-1] INFO       - group-F5C0C2437F07: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
s3g_1       | 20191018T070011Z
scm_1       | 2019-10-18 06:53:08,828 INFO ipc.Server: IPC Server listener on 9961: starting
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-18 06:53:18,252 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2019-10-18 06:53:15,953 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2019-10-18 06:53:14,256 INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_3  | 2019-10-18 06:53:18,683 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
s3g_1       | 20191018/us-west-1/s3/aws4_request
scm_1       | 2019-10-18 06:53:08,831 INFO http.HttpServer2: Jetty bound to port 9876
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
datanode_2  | 2019-10-18 06:53:18,256 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2019-10-18 06:53:15,960 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2019-10-18 06:53:14,327 [main] INFO       - OzoneManager RPC server is listening at om/172.18.0.7:9862
datanode_3  | 2019-10-18 06:53:18,685 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
scm_1       | 2019-10-18 06:53:08,833 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-18 06:53:18,257 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2019-10-18 06:53:15,962 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/af52b6b0-4114-4e7c-99fb-f3891471adc2 does not exist. Creating ...
om_1        | 2019-10-18 06:53:14,410 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2019-10-18 06:53:18,689 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1       | 2019-10-18 07:00:11,706 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Generiting keytab
scm_1       | 2019-10-18 06:53:08,918 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-18 06:53:18,257 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-10-18 06:53:16,248 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/af52b6b0-4114-4e7c-99fb-f3891471adc2/in_use.lock acquired by nodename 7@713c90b40e6d
om_1        | 2019-10-18 06:53:14,457 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2019-10-18 06:53:18,689 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 20191018T070011Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:53:08,919 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:18,257 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2019-10-18 06:53:16,261 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/af52b6b0-4114-4e7c-99fb-f3891471adc2 has been successfully formatted.
om_1        | 2019-10-18 06:53:14,458 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:18,691 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-18 06:53:08,925 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@355c94be{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-10-18 06:53:18,288 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858], old=null
datanode_1  | 2019-10-18 06:53:16,265 [pool-9-thread-1] INFO       - group-F3891471ADC2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1        | 2019-10-18 06:53:14,488 [main] INFO       - Reading keypair and certificate from file system.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:18,694 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
scm_1       | 2019-10-18 06:53:08,926 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3166f664{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2019-10-18 06:53:18,289 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2019-10-18 06:53:16,266 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2019-10-18 06:53:14,500 [main] INFO       - Starting OM block token secret manager
s3g_1       | 2019-10-18 07:00:11,707 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:18,701 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:53:09,052 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:18,291 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
datanode_1  | 2019-10-18 06:53:16,269 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2019-10-18 06:53:14,501 [main] INFO       - Updating the current master key for generating tokens
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:18,739 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
scm_1       | 2019-10-18 06:53:09,059 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1bedc703{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-12044637410750214845.dir/webapp/,AVAILABLE}{/scm}
datanode_2  | 2019-10-18 06:53:18,295 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F15AF2A99F3B,id=05927fc9-2042-483a-98e5-6075d8118b6c
datanode_1  | 2019-10-18 06:53:16,276 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2019-10-18 06:53:14,502 [main] INFO       - Starting OM delegation token secret manager
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:18,743 INFO segmented.SegmentedRaftLogWorker: new 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7fbeb4fb-b81e-4fd5-b009-f5c0c2437f07
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
scm_1       | 2019-10-18 06:53:09,069 INFO server.AbstractConnector: Started ServerConnector@29bcf51d{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
datanode_1  | 2019-10-18 06:53:16,276 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2019-10-18 06:53:18,334 INFO impl.FollowerState: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B-FollowerState: change to CANDIDATE, lastRpcTime:44ms, electionTimeout:43ms
om_1        | 2019-10-18 06:53:14,502 [main] INFO       - Updating the current master key for generating tokens
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
datanode_3  | 2019-10-18 06:53:18,744 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
kdc_1       | Generiting keytab
scm_1       | 2019-10-18 06:53:09,069 INFO server.Server: Started @5274ms
datanode_1  | 2019-10-18 06:53:16,278 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-18 06:53:18,336 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown FollowerState
om_1        | 2019-10-18 06:53:14,503 [Thread[Thread-11,5,main]] INFO       - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
s3g_1       | 2019-10-18 07:00:11,713 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:18,744 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:53:09,083 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2019-10-18 06:53:16,281 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
datanode_2  | 2019-10-18 06:53:18,347 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2019-10-18 06:53:14,522 INFO ipc.Server: IPC Server Responder: starting
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:18,745 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-18 06:53:09,083 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2019-10-18 06:53:16,288 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2019-10-18 06:53:18,351 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start LeaderElection
om_1        | 2019-10-18 06:53:14,523 INFO ipc.Server: IPC Server listener on 9862: starting
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 06:53:18,745 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2019-10-18 06:53:09,086 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
datanode_1  | 2019-10-18 06:53:16,336 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | WARNING: no policy specified for s3g/713c90b40e6d@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-18 06:53:18,379 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B-LeaderElection1: begin an election at term 1 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858], old=null
om_1        | 2019-10-18 06:53:14,558 INFO hdfs.DFSUtil: Starting web server as: HTTP/om@EXAMPLE.COM
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-18 06:53:18,746 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
scm_1       | 2019-10-18 06:53:09,090 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:16,341 INFO segmented.SegmentedRaftLogWorker: new 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/af52b6b0-4114-4e7c-99fb-f3891471adc2
kdc_1       | Principal "s3g/713c90b40e6d@EXAMPLE.COM" created.
datanode_2  | 2019-10-18 06:53:18,381 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown LeaderElection
om_1        | 2019-10-18 06:53:14,558 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
s3g_1       | 2019-10-18 07:00:11,713 [qtp359368949-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
datanode_3  | 2019-10-18 06:53:18,746 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2019-10-18 06:53:09,104 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:16,341 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-18 06:53:18,382 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2019-10-18 06:53:14,661 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2019-10-18 07:00:11,715 [qtp359368949-27] ERROR      - Couldn't create RpcClient protocol exception: 
datanode_3  | 2019-10-18 06:53:18,747 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2019-10-18 06:53:09,107 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2019-10-18 06:53:16,342 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1       | Entry for principal s3g/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.713c90b40e6d.keytab.
datanode_2  | 2019-10-18 06:53:18,382 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: change Leader from null to 05927fc9-2042-483a-98e5-6075d8118b6c at term 1 for becomeLeader, leader elected after 208ms
om_1        | 2019-10-18 06:53:14,664 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 06:53:18,747 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2019-10-18 06:53:09,116 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:16,343 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Entry for principal s3g/713c90b40e6d@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.713c90b40e6d.keytab.
datanode_2  | 2019-10-18 06:53:18,387 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2019-10-18 06:53:14,670 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
s3g_1       | 20191018T070011Z
datanode_3  | 2019-10-18 06:53:18,747 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2019-10-18 06:53:09,117 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_1  | 2019-10-18 06:53:16,343 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Generiting keytab
datanode_2  | 2019-10-18 06:53:18,387 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 06:53:14,672 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
datanode_3  | 2019-10-18 06:53:18,756 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2019-10-18 06:53:09,123 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_1  | 2019-10-18 06:53:16,343 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 06:53:14,672 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2019-10-18 06:53:18,392 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3  | 2019-10-18 06:53:18,760 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2019-10-18 06:53:09,131 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_1  | 2019-10-18 06:53:16,344 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | WARNING: no policy specified for om/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 06:53:14,672 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2019-10-18 06:53:18,763 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2019-10-18 06:53:18,396 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2019-10-18 06:53:09,317 INFO server.SCMClientProtocolServer: Processing CSR for dn 713c90b40e6d, UUID: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
datanode_1  | 2019-10-18 06:53:16,345 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
kdc_1       | Principal "om/ed25c35f2081@EXAMPLE.COM" created.
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-18 06:53:14,691 INFO http.HttpServer2: Jetty bound to port 9874
datanode_3  | 2019-10-18 06:53:18,764 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2019-10-18 06:53:09,317 INFO server.SCMClientProtocolServer: Processing CSR for dn ed25c35f2081, UUID: 05927fc9-2042-483a-98e5-6075d8118b6c
datanode_2  | 2019-10-18 06:53:18,396 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1  | 2019-10-18 06:53:16,345 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2019-10-18 06:53:14,692 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3  | 2019-10-18 06:53:18,764 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2019-10-18 06:53:09,530 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:18,397 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
kdc_1       | Entry for principal om/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.ed25c35f2081.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_1  | 2019-10-18 06:53:16,345 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2019-10-18 06:53:14,723 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-10-18 06:53:18,765 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-10-18 06:53:18,411 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start LeaderState
scm_1       | 2019-10-18 06:53:09,545 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Entry for principal om/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.ed25c35f2081.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1  | 2019-10-18 06:53:16,354 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1        | 2019-10-18 06:53:14,725 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:18,794 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: start as a follower, conf=-1: [9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_2  | 2019-10-18 06:53:18,436 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-18 06:53:09,546 INFO server.SCMClientProtocolServer: Processing CSR for dn b59f5315e11c, UUID: 9b428cf8-0805-4b46-95f2-cb42dae54452
kdc_1       | Generiting keytab
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
datanode_1  | 2019-10-18 06:53:16,358 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2019-10-18 06:53:14,729 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@67f63d26{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2019-10-18 06:53:18,795 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-10-18 06:53:18,453 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858], old=null at 0
scm_1       | 2019-10-18 06:53:10,584 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
datanode_1  | 2019-10-18 06:53:16,364 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-10-18 06:53:14,730 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@679dd234{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-18 06:53:18,796 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start FollowerState
datanode_2  | 2019-10-18 06:53:18,569 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-F15AF2A99F3B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4cfc27b5-8884-4177-946c-f15af2a99f3b/current/log_inprogress_0
scm_1       | 2019-10-18 06:53:10,588 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_1  | 2019-10-18 06:53:16,365 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-10-18 06:53:14,836 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-10-18 06:53:18,802 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5C0C2437F07,id=9b428cf8-0805-4b46-95f2-cb42dae54452
datanode_2  | 2019-10-18 06:53:18,897 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: addNew group-949BC68E43B3:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-949BC68E43B3:java.util.concurrent.CompletableFuture@1b1a8291[Not completed]
scm_1       | 2019-10-18 06:53:10,591 INFO server.SCMClientProtocolServer: Processing CSR for om om, UUID: b737e5e1-e790-4e51-a5bc-6edeb4c8604d
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_1  | 2019-10-18 06:53:16,366 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2019-10-18 06:53:14,845 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@45292ec1{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-14713789019332891659.dir/webapp/,AVAILABLE}{/ozoneManager}
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
datanode_3  | 2019-10-18 06:53:18,915 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: addNew group-949BC68E43B3:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-949BC68E43B3:java.util.concurrent.CompletableFuture@6e706e6[Not completed]
scm_1       | 2019-10-18 06:53:13,006 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
datanode_2  | 2019-10-18 06:53:18,902 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c: new RaftServerImpl for group-949BC68E43B3:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2019-10-18 06:53:16,367 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-10-18 06:53:14,852 INFO server.AbstractConnector: Started ServerConnector@16d07cf3{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-18 06:53:18,919 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452: new RaftServerImpl for group-949BC68E43B3:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
scm_1       | 2019-10-18 06:53:13,020 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
datanode_2  | 2019-10-18 06:53:18,902 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2019-10-18 06:53:16,403 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: start as a follower, conf=-1: [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858], old=null
om_1        | 2019-10-18 06:53:14,852 INFO server.Server: Started @3979ms
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 06:53:18,919 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2019-10-18 06:53:13,042 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
datanode_2  | 2019-10-18 06:53:18,902 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2019-10-18 06:53:16,404 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-18 06:53:14,855 INFO impl.MetricsSinkAdapter: Sink prometheus started
kdc_1       | Oct 18 06:52:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381579, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:18,919 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2019-10-18 06:53:13,045 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
datanode_2  | 2019-10-18 06:53:18,903 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-10-18 06:53:16,406 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
om_1        | 2019-10-18 06:53:14,855 INFO impl.MetricsSystemImpl: Registered sink prometheus
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 06:53:18,919 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1       | 2019-10-18 06:53:13,097 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
datanode_2  | 2019-10-18 06:53:18,903 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2019-10-18 06:53:16,412 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F3891471ADC2,id=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
om_1        | 2019-10-18 06:53:14,865 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_3  | 2019-10-18 06:53:18,919 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
scm_1       | 2019-10-18 06:53:13,100 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:18,903 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-18 06:53:16,447 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2-FollowerState: change to CANDIDATE, lastRpcTime:41ms, electionTimeout:40ms
om_1        | 2019-10-18 06:53:34,172 INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:18,919 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
scm_1       | 2019-10-18 06:53:13,205 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:18,903 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-18 06:53:16,448 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
om_1        | 2019-10-18 06:53:34,191 INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 06:53:18,920 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
scm_1       | 2019-10-18 06:53:13,207 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 06:53:18,904 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-18 06:53:16,449 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2019-10-18 06:53:35,468 [IPC Server handler 3 on 9862] INFO       - created volume:vol-0-44773 for user:HTTP/scm@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:18,920 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2019-10-18 06:53:15,047 INFO net.NetworkTopology: Added a new node: /default-rack/4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
datanode_2  | 2019-10-18 06:53:18,905 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-18 06:53:16,454 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start LeaderElection
om_1        | 2019-10-18 06:53:35,500 [IPC Server handler 1 on 9862] INFO       - created volume:vol-1-48698 for user:HTTP/scm@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_3  | 2019-10-18 06:53:18,920 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2019-10-18 06:53:15,048 INFO node.SCMNodeManager: Registered Data node : 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938}
datanode_2  | 2019-10-18 06:53:18,905 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3 does not exist. Creating ...
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 06:53:35,516 [IPC Server handler 4 on 9862] INFO       - created volume:vol-2-36208 for user:HTTP/scm@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_1  | 2019-10-18 06:53:16,482 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2-LeaderElection1: begin an election at term 1 for -1: [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858], old=null
datanode_3  | 2019-10-18 06:53:18,920 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3 does not exist. Creating ...
scm_1       | 2019-10-18 06:53:15,052 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
datanode_2  | 2019-10-18 06:53:18,929 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/in_use.lock acquired by nodename 7@ed25c35f2081
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-18 06:53:35,529 [IPC Server handler 6 on 9862] INFO       - created volume:vol-3-18488 for user:HTTP/scm@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 2019-10-18 06:53:18,931 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/in_use.lock acquired by nodename 7@b59f5315e11c
datanode_1  | 2019-10-18 06:53:16,485 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown LeaderElection
scm_1       | 2019-10-18 06:53:15,053 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_2  | 2019-10-18 06:53:18,933 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3 has been successfully formatted.
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 06:53:35,541 [IPC Server handler 16 on 9862] INFO       - created volume:vol-4-00940 for user:HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
datanode_3  | 2019-10-18 06:53:18,937 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3 has been successfully formatted.
datanode_1  | 2019-10-18 06:53:16,486 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | 2019-10-18 06:53:15,053 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_2  | 2019-10-18 06:53:18,934 [pool-9-thread-1] INFO       - group-949BC68E43B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-18 06:53:47,751 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
datanode_3  | 2019-10-18 06:53:18,937 [pool-9-thread-1] INFO       - group-949BC68E43B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-18 06:53:16,486 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: change Leader from null to 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e at term 1 for becomeLeader, leader elected after 220ms
scm_1       | 2019-10-18 06:53:15,099 INFO net.NetworkTopology: Added a new node: /default-rack/05927fc9-2042-483a-98e5-6075d8118b6c
datanode_2  | 2019-10-18 06:53:18,934 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 06:53:47,764 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
datanode_3  | 2019-10-18 06:53:18,937 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1       | 2019-10-18 06:53:15,100 INFO node.SCMNodeManager: Registered Data node : 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537}
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-18 06:53:48,581 [IPC Server handler 18 on 9862] INFO       - created volume:12921-rpcwoport for user:testuser/scm@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:18,938 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
datanode_1  | 2019-10-18 06:53:16,492 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2019-10-18 06:53:15,202 INFO net.NetworkTopology: Added a new node: /default-rack/9b428cf8-0805-4b46-95f2-cb42dae54452
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 06:53:50,663 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:18,938 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2019-10-18 06:53:16,492 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
scm_1       | 2019-10-18 06:53:15,202 INFO node.SCMNodeManager: Registered Data node : 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347876642743}
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found inOct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:53:50,677 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 06:53:18,938 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-18 06:53:16,496 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
scm_1       | 2019-10-18 06:53:16,530 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: af52b6b0-4114-4e7c-99fb-f3891471adc2, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:53:53,605 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:18,938 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-10-18 06:53:18,361 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 4cfc27b5-8884-4177-946c-f15af2a99f3b, Nodes: 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_1  | 2019-10-18 06:53:16,500 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:53:53,617 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 06:53:18,938 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
datanode_1  | 2019-10-18 06:53:16,501 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 2019-10-18 06:53:18,860 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7fbeb4fb-b81e-4fd5-b009-f5c0c2437f07, Nodes: 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_2  | 2019-10-18 06:53:18,935 INFO segmented.SegmentedRaftLogWorker: new 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3
kdc_1       | Oct 18 06:52:59 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:53:56,352 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:18,938 INFO segmented.SegmentedRaftLogWorker: new 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_1  | 2019-10-18 06:53:16,502 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1       | 2019-10-18 06:53:18,988 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:53:56,364 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_1  | 2019-10-18 06:53:16,521 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start LeaderState
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 2019-10-18 06:53:34,598 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:53:58,891 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-18 06:53:34,602 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2019-10-18 06:53:58,900 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind Kerberos database
datanode_1  | 2019-10-18 06:53:16,545 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1        | 2019-10-18 06:54:01,625 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-18 06:53:16,559 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2: set configuration 0: [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858], old=null at 0
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-10-18 06:53:18,935 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
scm_1       | 2019-10-18 06:53:35,903 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:54:01,638 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-18 06:53:16,667 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-F3891471ADC2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/af52b6b0-4114-4e7c-99fb-f3891471adc2/current/log_inprogress_0
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-10-18 06:53:18,936 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2019-10-18 06:53:35,907 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-18 06:54:04,316 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-18 06:53:18,929 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: addNew group-949BC68E43B3:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-949BC68E43B3:java.util.concurrent.CompletableFuture@736ebccc[Not completed]
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2019-10-18 06:53:18,936 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2019-10-18 06:53:35,913 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2e675ef3-ea4f-4872-8ef8-4700f3dd96dd, Nodes: 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
om_1        | 2019-10-18 06:54:04,329 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-18 06:53:18,932 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: new RaftServerImpl for group-949BC68E43B3:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
datanode_3  | 2019-10-18 06:53:18,939 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2019-10-18 06:53:18,936 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2019-10-18 06:53:37,038 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:54:07,043 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-18 06:53:18,932 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
datanode_3  | 2019-10-18 06:53:18,940 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2019-10-18 06:53:18,936 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2019-10-18 06:53:37,042 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | 2019-10-18 06:54:07,058 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
datanode_1  | 2019-10-18 06:53:18,932 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2019-10-18 06:53:18,940 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2019-10-18 06:53:18,936 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2019-10-18 06:53:37,426 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:54:09,820 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
datanode_1  | 2019-10-18 06:53:18,932 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-10-18 06:53:18,940 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2019-10-18 06:53:18,936 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2019-10-18 06:53:37,431 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:54:09,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
datanode_1  | 2019-10-18 06:53:18,932 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2019-10-18 06:53:18,940 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2019-10-18 06:53:18,937 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2019-10-18 06:53:47,039 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:54:14,484 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
datanode_1  | 2019-10-18 06:53:18,933 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-18 06:53:18,941 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2019-10-18 06:53:18,937 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2019-10-18 06:53:47,042 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:54:14,495 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server [15](Notice): Request: kadm5_create_principal, testuser2/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
datanode_1  | 2019-10-18 06:53:18,933 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-18 06:53:18,941 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-10-18 06:53:18,937 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2019-10-18 06:53:47,203 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:54:19,154 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
datanode_1  | 2019-10-18 06:53:18,933 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-18 06:53:18,941 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2019-10-18 06:53:18,937 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1       | 2019-10-18 06:53:47,207 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:54:19,167 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
datanode_3  | 2019-10-18 06:53:18,941 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-10-18 06:53:18,942 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:54:22,146 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:53:47,785 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:18,933 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
datanode_3  | 2019-10-18 06:53:18,947 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_2  | 2019-10-18 06:53:18,942 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-18 06:54:22,158 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:53:47,788 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_1  | 2019-10-18 06:53:18,933 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3 does not exist. Creating ...
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
datanode_3  | 2019-10-18 06:53:18,948 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-10-18 06:53:18,942 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
om_1        | 2019-10-18 06:54:24,954 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:54:08,073 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:18,948 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/in_use.lock acquired by nodename 7@713c90b40e6d
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 06:53:18,948 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start FollowerState
datanode_2  | 2019-10-18 06:53:18,942 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-949BC68E43B3,id=05927fc9-2042-483a-98e5-6075d8118b6c
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-18 06:54:24,968 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:54:08,076 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 06:53:18,971 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3 has been successfully formatted.
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadminnot found in Kerberos database
datanode_2  | 2019-10-18 06:53:18,994 INFO impl.FollowerState: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:52ms, electionTimeout:52ms
om_1        | 2019-10-18 06:54:27,689 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
datanode_3  | 2019-10-18 06:53:18,948 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-949BC68E43B3,id=9b428cf8-0805-4b46-95f2-cb42dae54452
scm_1       | 2019-10-18 06:54:10,534 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:18,971 [pool-9-thread-1] INFO       - group-949BC68E43B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:18,995 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown FollowerState
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
datanode_3  | 2019-10-18 06:53:18,978 INFO impl.FollowerState: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:30ms, electionTimeout:30ms
om_1        | 2019-10-18 06:54:27,707 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:54:10,536 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_1  | 2019-10-18 06:53:18,972 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-18 06:53:18,995 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
datanode_3  | 2019-10-18 06:53:18,980 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown FollowerState
om_1        | 2019-10-18 06:54:30,330 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:54:17,041 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:18,972 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
datanode_3  | 2019-10-18 06:53:18,980 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2019-10-18 06:54:30,341 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:54:17,046 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 06:53:18,972 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
datanode_3  | 2019-10-18 06:53:18,984 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderElection
datanode_2  | 2019-10-18 06:53:18,995 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start LeaderElection
om_1        | 2019-10-18 06:54:32,873 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:54:17,213 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:18,972 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMP/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
datanode_3  | 2019-10-18 06:53:18,992 INFO impl.FollowerState: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07-FollowerState: change to CANDIDATE, lastRpcTime:196ms, electionTimeout:195ms
om_1        | 2019-10-18 06:54:32,885 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 06:53:19,001 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection2: begin an election at term 1 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
scm_1       | 2019-10-18 06:54:17,217 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 06:53:18,972 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
datanode_3  | 2019-10-18 06:53:18,993 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown FollowerState
om_1        | 2019-10-18 06:54:35,536 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,029 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection2: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3:t1, leader=null, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:18,972 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2019-10-18 06:54:41,984 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
datanode_3  | 2019-10-18 06:53:18,993 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2019-10-18 06:54:35,549 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 06:53:19,032 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection2: begin an election at term 2 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:18,973 INFO segmented.SegmentedRaftLogWorker: new 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3
scm_1       | 2019-10-18 06:54:41,987 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 06:53:18,993 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderElection
om_1        | 2019-10-18 06:54:38,190 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,117 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection2: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3:t2, leader=null, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1       | 2019-10-18 06:54:47,040 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 06:53:19,000 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07-LeaderElection2: begin an election at term 1 for -1: [9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:54:38,202 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 06:53:19,150 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection2: begin an election at term 3 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 2019-10-18 06:54:47,044 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,000 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection1: begin an election at term 1 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:54:38,855 [IPC Server handler 4 on 9862] INFO       - created volume:12921-rpcwoport2 for user:testuser/scm@EXAMPLE.COM
datanode_2  | 2019-10-18 06:53:19,223 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection2: Election PASSED; received 2 response(s) [05927fc9-2042-483a-98e5-6075d8118b6c<-4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#0:OK-t3, 05927fc9-2042-483a-98e5-6075d8118b6c<-9b428cf8-0805-4b46-95f2-cb42dae54452#0:FAIL-t3] and 0 exception(s); 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3:t3, leader=null, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-18 06:54:47,203 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:19,001 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown LeaderElection
datanode_2  | 2019-10-18 06:53:19,223 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown LeaderElection
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2019-10-18 06:54:47,207 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 06:53:19,002 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2019-10-18 06:54:40,827 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,224 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
scm_1       | 2019-10-18 06:55:11,985 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-18 06:53:19,002 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 1 for becomeLeader, leader elected after 319ms
om_1        | 2019-10-18 06:54:40,840 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 06:53:19,224 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from null to 05927fc9-2042-483a-98e5-6075d8118b6c at term 3 for becomeLeader, leader elected after 289ms
scm_1       | 2019-10-18 06:55:11,989 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | admin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,005 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2019-10-18 06:54:43,606 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:55:14,555 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,224 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2019-10-18 06:53:19,005 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2019-10-18 06:54:43,619 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:55:14,558 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-18 06:53:19,224 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-10-18 06:53:19,009 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2019-10-18 06:54:46,297 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:55:14,567 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
datanode_2  | 2019-10-18 06:53:19,225 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 06:53:18,973 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-10-18 06:53:19,011 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om_1        | 2019-10-18 06:54:46,308 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:55:14,567 INFO block.BlockManagerImpl: Deleting blocks conID: 4 locID: 102982067849724029 bcsId: 0
datanode_2  | 2019-10-18 06:53:19,225 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 06:53:18,974 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-18 06:53:19,012 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2019-10-18 06:54:48,941 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:55:17,040 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,225 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-18 06:53:18,974 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2019-10-18 06:53:19,012 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 2019-10-18 06:54:48,954 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:55:17,043 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 06:53:19,225 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
datanode_1  | 2019-10-18 06:53:18,974 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:54:51,437 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:19,022 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3:t1, leader=null, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
scm_1       | 2019-10-18 06:55:17,214 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,230 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
datanode_1  | 2019-10-18 06:53:18,974 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:54:51,448 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:55:17,218 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 06:53:19,231 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
datanode_1  | 2019-10-18 06:53:18,974 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2019-10-18 06:53:19,023 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderState
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:54:54,118 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:55:24,152 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,231 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
datanode_3  | 2019-10-18 06:53:19,031 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection1: begin an election at term 2 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:18,975 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:54:54,129 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:55:24,155 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 06:53:19,234 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2019-10-18 06:53:19,043 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
datanode_1  | 2019-10-18 06:53:18,978 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:54:56,684 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:55:47,039 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,235 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_3  | 2019-10-18 06:53:19,051 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07: set configuration 0: [9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:54:56,697 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-18 06:53:18,978 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2019-10-18 06:55:47,042 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 06:53:19,235 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-18 06:53:19,087 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3:t2, leader=null, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:54:59,431 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,239 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 2019-10-18 06:55:47,203 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:19,091 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection1: begin an election at term 3 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
datanode_1  | 2019-10-18 06:53:18,978 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:54:59,443 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 06:53:19,239 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-18 06:55:47,206 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
datanode_3  | 2019-10-18 06:53:19,193 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-F5C0C2437F07-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7fbeb4fb-b81e-4fd5-b009-f5c0c2437f07/current/log_inprogress_0
datanode_1  | 2019-10-18 06:53:18,979 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-949BC68E43B3,id=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
om_1        | 2019-10-18 06:55:02,248 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 06:53:19,239 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-18 06:55:54,152 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 06:53:19,212 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection1: Election REJECTED; received 2 response(s) [9b428cf8-0805-4b46-95f2-cb42dae54452<-05927fc9-2042-483a-98e5-6075d8118b6c#0:FAIL-t3, 9b428cf8-0805-4b46-95f2-cb42dae54452<-4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#0:FAIL-t3] and 0 exception(s); 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3:t3, leader=null, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 06:53:19,064 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:85ms, electionTimeout:85ms
om_1        | 2019-10-18 06:55:02,261 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_2  | 2019-10-18 06:53:19,239 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2019-10-18 06:55:54,155 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,214 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
datanode_1  | 2019-10-18 06:53:19,064 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
om_1        | 2019-10-18 06:55:04,987 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_2  | 2019-10-18 06:53:19,239 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-18 06:56:08,307 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:04,999 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
datanode_1  | 2019-10-18 06:53:19,064 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2019-10-18 06:53:19,214 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown LeaderElection
datanode_2  | 2019-10-18 06:53:19,239 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2019-10-18 06:56:08,308 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:55:05,649 [IPC Server handler 5 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /12921-rpcwoport2/bb1 failed, because acl already exist
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
datanode_1  | 2019-10-18 06:53:19,065 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start LeaderElection
datanode_3  | 2019-10-18 06:53:19,214 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start FollowerState
datanode_2  | 2019-10-18 06:53:19,243 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start LeaderState
scm_1       | 2019-10-18 06:56:09,673 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:55:07,747 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
datanode_1  | 2019-10-18 06:53:19,089 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-LeaderElection2: begin an election at term 1 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_3  | 2019-10-18 06:53:19,298 INFO impl.FollowerState: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:83ms, electionTimeout:83ms
datanode_2  | 2019-10-18 06:53:19,244 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-18 06:56:09,678 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:07,763 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
datanode_1  | 2019-10-18 06:53:19,127 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-LeaderElection2: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3:t1, leader=null, voted=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e, raftlog=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_3  | 2019-10-18 06:53:19,299 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown FollowerState
datanode_2  | 2019-10-18 06:53:19,245 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
scm_1       | 2019-10-18 06:56:09,980 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:10,333 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
datanode_1  | 2019-10-18 06:53:19,150 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-LeaderElection2: begin an election at term 2 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_3  | 2019-10-18 06:53:19,299 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode_2  | 2019-10-18 06:53:19,270 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0
scm_1       | 2019-10-18 06:56:09,985 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:55:10,346 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
datanode_1  | 2019-10-18 06:53:19,153 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from CANDIDATE to FOLLOWER at term 3 for recognizeCandidate:9b428cf8-0805-4b46-95f2-cb42dae54452
datanode_3  | 2019-10-18 06:53:19,299 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderElection
datanode_2  | 2019-10-18 06:53:19,313 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-   LEADER: Withhold vote from candidate 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e with term 2. State: leader=05927fc9-2042-483a-98e5-6075d8118b6c, term=3, lastRpcElapsed=null
scm_1       | 2019-10-18 06:56:17,039 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:55:13,080 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
datanode_1  | 2019-10-18 06:53:19,164 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown LeaderElection
datanode_3  | 2019-10-18 06:53:19,308 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection3: begin an election at term 4 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_2  | 2019-10-18 06:53:19,314 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-   LEADER: Withhold vote from candidate 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e with term 1. State: leader=05927fc9-2042-483a-98e5-6075d8118b6c, term=3, lastRpcElapsed=null
scm_1       | 2019-10-18 06:56:17,042 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:13,091 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
datanode_3  | 2019-10-18 06:53:19,332 INFO server.GrpcServerProtocolService: 9b428cf8-0805-4b46-95f2-cb42dae54452: Completed APPEND_ENTRIES, lastRequest: 05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#0-t3, previous=(t:0, i:0), leaderCommit=-1, initializing? false, entries: <empty>
datanode_2  | 2019-10-18 06:53:19,323 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from 05927fc9-2042-483a-98e5-6075d8118b6c to null at term 4 for updateCurrentTerm
scm_1       | 2019-10-18 06:56:24,152 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:15,676 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_1  | 2019-10-18 06:53:19,164 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
datanode_3  | 2019-10-18 06:53:19,356 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection3: Election PASSED; received 1 response(s) [9b428cf8-0805-4b46-95f2-cb42dae54452<-4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#0:OK-t4] and 0 exception(s); 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3:t4, leader=null, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_2  | 2019-10-18 06:53:19,323 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from    LEADER to FOLLOWER at term 4 for stepDown
scm_1       | 2019-10-18 06:56:24,155 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:55:15,689 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_1  | 2019-10-18 06:53:19,182 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:05927fc9-2042-483a-98e5-6075d8118b6c
datanode_2  | 2019-10-18 06:53:19,323 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown LeaderState
datanode_3  | 2019-10-18 06:53:19,356 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown LeaderElection
scm_1       | 2019-10-18 06:56:39,993 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:55:18,836 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
datanode_1  | 2019-10-18 06:53:19,182 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
datanode_2  | 2019-10-18 06:53:19,325 INFO impl.PendingRequests: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-PendingRequests: sendNotLeaderResponses
scm_1       | 2019-10-18 06:56:39,999 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 06:53:19,357 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
datanode_1  | 2019-10-18 06:53:19,183 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2019-10-18 06:53:19,327 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
scm_1       | 2019-10-18 06:56:47,037 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:55:18,848 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 06:53:19,357 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 4 for becomeLeader, leader elected after 419ms
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
datanode_1  | 2019-10-18 06:53:19,198 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
scm_1       | 2019-10-18 06:56:47,041 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 06:53:19,327 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-18 06:55:21,697 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 06:53:19,357 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
datanode_1  | 2019-10-18 06:53:19,217 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-LeaderElection2: Election REJECTED; received 0 response(s) [] and 0 exception(s); 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3:t3, leader=null, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
scm_1       | 2019-10-18 06:56:54,155 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 06:53:19,357 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
datanode_2  | 2019-10-18 06:53:19,328 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-18 06:55:21,708 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-18 06:53:19,324 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from null to 05927fc9-2042-483a-98e5-6075d8118b6c at term 3 for appendEntries, leader elected after 350ms
scm_1       | 2019-10-18 06:56:54,158 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,358 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
datanode_2  | 2019-10-18 06:53:19,334 INFO server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-AppendLogResponseHandler: follower responses appendEntries COMPLETED
om_1        | 2019-10-18 06:55:26,581 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:19,328 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from 05927fc9-2042-483a-98e5-6075d8118b6c to null at term 4 for updateCurrentTerm
scm_1       | 2019-10-18 06:56:58,921 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/713c90b40e6d@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,359 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_2  | 2019-10-18 06:53:19,339 INFO impl.FollowerInfo: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452: nextIndex: updateUnconditionally 0 -> 0
om_1        | 2019-10-18 06:55:26,595 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-18 06:53:19,329 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from  FOLLOWER to FOLLOWER at term 4 for recognizeCandidate:9b428cf8-0805-4b46-95f2-cb42dae54452
scm_1       | 2019-10-18 06:56:58,923 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 06:53:19,359 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
datanode_2  | 2019-10-18 06:53:19,353 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from  FOLLOWER to FOLLOWER at term 4 for recognizeCandidate:9b428cf8-0805-4b46-95f2-cb42dae54452
om_1        | 2019-10-18 06:55:29,412 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:19,329 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
scm_1       | 2019-10-18 06:57:00,423 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 06:53:19,359 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
datanode_2  | 2019-10-18 06:53:19,353 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown FollowerState
om_1        | 2019-10-18 06:55:29,426 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-18 06:53:19,329 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1       | 2019-10-18 06:57:00,599 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,364 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
datanode_2  | 2019-10-18 06:53:19,353 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
om_1        | 2019-10-18 06:55:32,040 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 06:53:19,329 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
scm_1       | 2019-10-18 06:57:00,879 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,365 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
datanode_2  | 2019-10-18 06:53:19,353 INFO impl.FollowerState: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
om_1        | 2019-10-18 06:55:32,053 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-18 06:53:19,358 INFO server.GrpcServerProtocolService: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: Completed APPEND_ENTRIES, lastRequest: 05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#0-t3, previous=(t:0, i:0), leaderCommit=-1, initializing? false, entries: <empty>
scm_1       | 2019-10-18 06:57:00,883 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 06:53:19,365 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
datanode_2  | 2019-10-18 06:53:19,361 INFO server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1  | 2019-10-18 06:53:19,433 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 4 for appendEntries, leader elected after 104ms
om_1        | 2019-10-18 06:55:34,768 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:57:09,984 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 06:53:19,368 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
datanode_2  | 2019-10-18 06:53:19,362 INFO impl.FollowerInfo: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: nextIndex: updateUnconditionally 0 -> 0
datanode_1  | 2019-10-18 06:53:19,443 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
om_1        | 2019-10-18 06:55:34,780 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:57:09,988 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 06:53:19,368 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
datanode_2  | 2019-10-18 06:53:19,434 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 4 for appendEntries, leader elected after 111ms
datanode_1  | 2019-10-18 06:53:19,444 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2019-10-18 06:55:37,493 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 06:57:14,596 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:19,368 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_2  | 2019-10-18 06:53:19,448 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
datanode_1  | 2019-10-18 06:53:19,495 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0
om_1        | 2019-10-18 06:55:37,506 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 06:57:14,599 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | 2019-10-18 06:53:19,372 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
datanode_2  | 2019-10-18 06:53:19,450 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Truncating segments toTruncate: null
datanode_1  | 2019-10-18 06:57:00,405 INFO client.DNCertificateClient: Getting certificate with certSerialId:11728348918507398.
om_1        | 2019-10-18 06:55:40,164 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:57:14,599 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
datanode_3  | 2019-10-18 06:53:19,373 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  |   toDelete: [(0, 0) isOpen? true, length=0, newEndIndex=-1], start index 0
datanode_1  | 2019-10-18 06:57:01,528 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
om_1        | 2019-10-18 06:55:40,176 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:57:14,600 INFO block.BlockManagerImpl: Deleting blocks conID: 6 locID: 102982075567964287 bcsId: 0
datanode_3  | 2019-10-18 06:53:19,373 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
datanode_1  | 2019-10-18 07:03:34,057 WARN server.GrpcServerProtocolService: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: installSnapshot onError, lastRequest: 9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#246-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_2  | 2019-10-18 06:53:19,450 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Starting segment from index:0
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:42,917 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:57:24,152 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:19,373 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
datanode_1  | Oct 18, 2019 7:03:34 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_2  | 2019-10-18 06:53:19,451 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Deleted log file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:55:42,929 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:57:24,154 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 06:53:19,373 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
datanode_1  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@3872e2c1
datanode_2  | 2019-10-18 06:53:19,452 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:55:45,589 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:57:30,883 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:19,373 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
datanode_1  | org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
datanode_2  | 2019-10-18 06:53:19,495 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
om_1        | 2019-10-18 06:55:45,601 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:57:30,886 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
datanode_2  | 2019-10-18 06:53:37,016 INFO client.DNCertificateClient: Getting certificate with certSerialId:11728348918507398.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
datanode_3  | 2019-10-18 06:53:19,377 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderState
scm_1       | 2019-10-18 06:57:39,979 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:55:46,347 [IPC Server handler 19 on 9862] INFO       - created volume:12921-rpcwport for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
datanode_2  | 2019-10-18 06:54:12,518 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
kdc_1       | Generiting keytab
datanode_3  | 2019-10-18 06:53:19,377 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-18 06:57:39,982 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:55:48,307 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
datanode_2  | 2019-10-18 06:55:24,695 WARN client.GrpcClientProtocolService: 1-OrderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:57:54,166 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:53:19,379 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
om_1        | 2019-10-18 06:55:48,319 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
datanode_2  | 2019-10-18 07:02:28,717 WARN client.GrpcClientProtocolService: 3-OrderedRequestStreamObserver3: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
kdc_1       | WARNING: no policy specified for om/s3g@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-18 06:57:54,169 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 06:53:19,426 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-18 06:55:50,922 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:03:34,110 WARN server.GrpcServerProtocolService: 05927fc9-2042-483a-98e5-6075d8118b6c: installSnapshot onError, lastRequest: 9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#246-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
kdc_1       | Principal "om/s3g@EXAMPLE.COM" created.
scm_1       | 2019-10-18 06:58:00,878 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 06:56:09,654 INFO client.DNCertificateClient: Getting certificate with certSerialId:11728348918507398.
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
datanode_2  | Oct 18, 2019 7:03:34 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
om_1        | 2019-10-18 06:55:50,933 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:58:00,881 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
datanode_3  | 2019-10-18 06:56:10,701 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
datanode_2  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@74d7ec36
om_1        | 2019-10-18 06:55:53,738 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
scm_1       | 2019-10-18 06:58:09,984 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 2019-10-18 06:58:33,578 WARN client.GrpcClientProtocolService: 1-OrderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
datanode_2  | org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
om_1        | 2019-10-18 06:55:53,751 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
scm_1       | 2019-10-18 06:58:09,988 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 07:03:29,750 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#244-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: size=1, first=(t:4, i:1), STATEMACHINELOGENTRY, client-0DA4D4A54789, cid=0
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
om_1        | 2019-10-18 06:55:56,477 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
scm_1       | 2019-10-18 06:58:14,611 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:03:29,750 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#244-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: size=1, first=(t:4, i:1), STATEMACHINELOGENTRY, client-0DA4D4A54789, cid=0
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
om_1        | 2019-10-18 06:55:56,491 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2019-10-18 06:58:14,613 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | 2019-10-18 07:03:32,250 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#245-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 2019-10-18 06:55:59,268 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:03:32,250 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#245-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
scm_1       | 2019-10-18 06:58:14,613 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-18 06:55:59,283 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:03:34,054 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
scm_1       | 2019-10-18 06:58:14,613 INFO block.BlockManagerImpl: Deleting blocks conID: 7 locID: 102982078885068928 bcsId: 0
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
datanode_1  | 
om_1        | 2019-10-18 06:56:01,974 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
scm_1       | 2019-10-18 06:58:15,062 INFO container.ReplicationManager: Starting Replication Monitor Thread.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
datanode_3  | Oct 18, 2019 7:03:34 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
datanode_1  | 2019-10-18 07:03:41,581 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:7536ms, electionTimeout:5127ms
om_1        | 2019-10-18 06:56:01,986 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
scm_1       | 2019-10-18 06:58:15,071 INFO container.ReplicationManager: Replication Monitor Thread took 7 milliseconds for processing 7 containers.
datanode_3  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable@6182b327
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 2019-10-18 07:03:41,581 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
om_1        | 2019-10-18 06:56:04,776 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | Oct 18, 2019 7:00:11 AM org.glassfish.jersey.internal.Errors logErrors
kdc_1       | Generiting keytab
scm_1       | 2019-10-18 06:58:24,153 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | java.lang.NullPointerException
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
om_1        | 2019-10-18 06:56:04,787 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
scm_1       | 2019-10-18 06:58:24,156 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:03:41,582 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onError(GrpcLogAppender.java:303)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 2019-10-18 06:56:07,601 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | MultiException stack 1 of 1
scm_1       | 2019-10-18 06:58:30,896 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for dn/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-18 07:03:41,582 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start LeaderElection
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 2019-10-18 06:56:07,615 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | javax.enterprise.inject.CreationException
scm_1       | 2019-10-18 06:58:30,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Principal "dn/b59f5315e11c@EXAMPLE.COM" created.
datanode_1  | 2019-10-18 07:03:41,584 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from 9b428cf8-0805-4b46-95f2-cb42dae54452 to null at term 4 for initElection
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-18 06:56:12,591 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm_1       | 2019-10-18 06:58:31,549 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:03:41,599 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-LeaderElection3: begin an election at term 5 for 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
datanode_2  | 
om_1        | 2019-10-18 06:56:12,604 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm_1       | 2019-10-18 06:58:31,551 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Entry for principal dn/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.b59f5315e11c.keytab.
datanode_1  | 2019-10-18 07:03:41,675 INFO impl.LeaderElection: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-LeaderElection3: Election PASSED; received 2 response(s) [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e<-05927fc9-2042-483a-98e5-6075d8118b6c#0:OK-t5, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e<-9b428cf8-0805-4b46-95f2-cb42dae54452#0:FAIL-t5] and 0 exception(s); 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3:t5, leader=null, voted=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e, raftlog=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLog:OPENED:c0,f1,i1, conf=0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_2  | 2019-10-18 07:03:41,631 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from 9b428cf8-0805-4b46-95f2-cb42dae54452 to null at term 5 for updateCurrentTerm
om_1        | 2019-10-18 06:56:16,854 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
scm_1       | 2019-10-18 06:58:32,989 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal dn/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.b59f5315e11c.keytab.
datanode_1  | 2019-10-18 07:03:41,675 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown LeaderElection
datanode_2  | 2019-10-18 07:03:41,632 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from  FOLLOWER to FOLLOWER at term 5 for recognizeCandidate:4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
om_1        | 2019-10-18 06:56:16,867 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
scm_1       | 2019-10-18 06:58:32,993 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Generiting keytab
datanode_1  | 2019-10-18 07:03:41,677 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
datanode_2  | 2019-10-18 07:03:41,632 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown FollowerState
om_1        | 2019-10-18 06:56:19,623 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
scm_1       | 2019-10-18 06:58:54,164 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:03:41,677 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from null to 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e at term 5 for becomeLeader, leader elected after 93ms
datanode_2  | 2019-10-18 07:03:41,632 INFO impl.FollowerState: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
om_1        | 2019-10-18 06:56:19,636 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
scm_1       | 2019-10-18 06:58:54,170 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for dn/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-18 07:03:41,677 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2019-10-18 07:03:41,633 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
om_1        | 2019-10-18 06:56:22,403 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
scm_1       | 2019-10-18 06:59:00,883 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "dn/d71a100b5ba6@EXAMPLE.COM" created.
datanode_1  | 2019-10-18 07:03:41,678 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2019-10-18 07:03:41,739 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from null to 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e at term 5 for appendEntries, leader elected after 108ms
om_1        | 2019-10-18 06:56:22,415 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
scm_1       | 2019-10-18 06:59:00,887 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:03:41,678 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2  | 2019-10-18 07:03:41,759 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: set configuration 2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 2
om_1        | 2019-10-18 06:56:25,121 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
scm_1       | 2019-10-18 06:59:02,990 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal dn/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.d71a100b5ba6.keytab.
datanode_1  | 2019-10-18 07:03:41,678 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_2  | 2019-10-18 07:03:41,760 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Rolling segment log-0_1 to index:1
om_1        | 2019-10-18 06:56:25,132 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
kdc_1       | Entry for principal dn/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.d71a100b5ba6.keytab.
datanode_1  | 2019-10-18 07:03:41,678 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2019-10-18 06:56:27,772 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:59:02,992 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:03:41,764 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0 to /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_0-1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
kdc_1       | Generiting keytab
om_1        | 2019-10-18 06:56:27,784 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 06:59:24,156 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:03:41,810 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_2
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:56:30,407 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 06:59:24,162 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:06:09,133 WARN server.GrpcServerProtocolService: 05927fc9-2042-483a-98e5-6075d8118b6c: installSnapshot onError, lastRequest: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#105-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-10-18 07:03:41,678 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:531)
kdc_1       | WARNING: no policy specified for scm/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 06:56:30,419 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | Oct 18, 2019 7:06:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_1  | 2019-10-18 07:03:41,689 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
kdc_1       | Principal "scm/ed25c35f2081@EXAMPLE.COM" created.
om_1        | 2019-10-18 06:56:33,135 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@6a5ea8c1
scm_1       | 2019-10-18 06:59:30,887 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:03:41,689 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
om_1        | 2019-10-18 06:56:33,148 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 06:59:30,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:03:41,690 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 06:56:35,851 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
kdc_1       | Entry for principal scm/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.ed25c35f2081.keytab.
scm_1       | 2019-10-18 06:59:32,989 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:03:41,693 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 06:56:35,861 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal scm/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.ed25c35f2081.keytab.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
scm_1       | 2019-10-18 06:59:32,995 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:03:41,693 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-18 06:56:36,541 [IPC Server handler 8 on 9862] INFO       - created volume:12921-rpcwoscheme for user:testuser/scm@EXAMPLE.COM
kdc_1       | Generiting keytab
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
scm_1       | 2019-10-18 06:59:54,158 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:03:41,693 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
datanode_3  | 
om_1        | 2019-10-18 06:56:38,580 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
scm_1       | 2019-10-18 06:59:54,161 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:03:41,699 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
datanode_3  | 2019-10-18 07:03:34,101 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
kdc_1       | WARNING: no policy specified for scm/om@EXAMPLE.COM; defaulting to no policy
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
scm_1       | 2019-10-18 07:00:00,890 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:03:41,699 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2019-10-18 06:56:38,595 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
datanode_3  | Oct 18, 2019 7:03:34 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
kdc_1       | Principal "scm/om@EXAMPLE.COM" created.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
scm_1       | 2019-10-18 07:00:00,894 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:03:41,699 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-18 06:56:41,428 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable@6d501491
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 2019-10-18 07:03:41,699 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2019-10-18 07:00:02,985 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-18 06:56:41,442 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | java.lang.NullPointerException
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 2019-10-18 07:03:41,699 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-18 07:00:02,989 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-18 06:56:44,328 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onError(GrpcLogAppender.java:303)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2019-10-18 07:03:41,699 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2019-10-18 07:00:03,704 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-18 06:56:44,340 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Generiting keytab
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2019-10-18 07:03:41,704 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start LeaderState
scm_1       | 2019-10-18 07:00:03,706 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-18 06:56:47,129 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2019-10-18 07:03:41,705 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: Rolling segment log-0_1 to index:1
scm_1       | 2019-10-18 07:00:24,162 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-18 06:56:47,142 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | WARNING: no policy specified for scm/s3g@EXAMPLE.COM; defaulting to no policy
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
datanode_2  | 
datanode_1  | 2019-10-18 07:03:41,708 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0 to /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_0-1
scm_1       | 2019-10-18 07:00:24,166 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-18 06:56:49,839 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
datanode_2  | 2019-10-18 07:06:15,271 INFO impl.FollowerState: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:6142ms, electionTimeout:5123ms
datanode_1  | 2019-10-18 07:03:41,709 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: set configuration 2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 2
kdc_1       | Principal "scm/s3g@EXAMPLE.COM" created.
scm_1       | 2019-10-18 07:00:27,274 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 06:56:49,849 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
datanode_2  | 2019-10-18 07:06:15,271 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown FollowerState
datanode_1  | 2019-10-18 07:03:41,751 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_2
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 07:00:27,276 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 06:56:52,653 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
datanode_2  | 2019-10-18 07:06:15,272 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode_1  | 2019-10-18 07:06:07,423 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#101-t5, previous=(t:5, i:52), leaderCommit=51, initializing? false, entries: size=1, first=(t:5, i:53), STATEMACHINELOGENTRY, client-7677D64DA6C3, cid=38
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
scm_1       | 2019-10-18 07:00:30,897 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 06:56:52,668 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
datanode_2  | 2019-10-18 07:06:15,272 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start LeaderElection
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
datanode_1  | 2019-10-18 07:06:07,424 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#102-t5, previous=(t:5, i:52), leaderCommit=51, initializing? false, entries: size=1, first=(t:5, i:53), STATEMACHINELOGENTRY, client-7677D64DA6C3, cid=38
scm_1       | 2019-10-18 07:00:30,903 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
datanode_2  | 2019-10-18 07:06:15,273 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e to null at term 5 for initElection
om_1        | 2019-10-18 06:56:55,522 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
datanode_1  | 2019-10-18 07:06:07,549 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#103-t5, previous=(t:5, i:53), leaderCommit=51, initializing? false, entries: size=1, first=(t:5, i:54), STATEMACHINELOGENTRY, client-11940D9C1DE7, cid=40
scm_1       | 2019-10-18 07:00:33,003 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
datanode_2  | 2019-10-18 07:06:15,479 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection3: begin an election at term 6 for 2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:56:55,534 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
datanode_1  | 2019-10-18 07:06:07,549 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#102-t5, previous=(t:5, i:53), leaderCommit=51, initializing? false, entries: size=1, first=(t:5, i:54), STATEMACHINELOGENTRY, client-11940D9C1DE7, cid=40
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 07:00:33,009 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
datanode_2  | 2019-10-18 07:06:15,594 INFO impl.LeaderElection: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-LeaderElection3: Election PASSED; received 2 response(s) [05927fc9-2042-483a-98e5-6075d8118b6c<-4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#0:OK-t6, 05927fc9-2042-483a-98e5-6075d8118b6c<-9b428cf8-0805-4b46-95f2-cb42dae54452#0:FAIL-t6] and 0 exception(s); 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3:t6, leader=null, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLog:OPENED:c52,f56,i56, conf=2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:56:58,232 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-18 07:06:08,295 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#104-t5, previous=(t:5, i:54), leaderCommit=52, initializing? false, entries: size=1, first=(t:5, i:55), METADATAENTRY(c52)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
scm_1       | 2019-10-18 07:00:51,400 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:06:15,594 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown LeaderElection
om_1        | 2019-10-18 06:56:58,243 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
datanode_1  | 2019-10-18 07:06:08,295 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#103-t5, previous=(t:5, i:54), leaderCommit=52, initializing? false, entries: size=1, first=(t:5, i:55), METADATAENTRY(c52)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
scm_1       | 2019-10-18 07:00:51,402 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-18 07:06:15,594 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: changes role from CANDIDATE to LEADER at term 6 for changeToLeader
om_1        | 2019-10-18 06:57:03,453 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
datanode_1  | 2019-10-18 07:06:08,306 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#104-t5, previous=(t:5, i:55), leaderCommit=52, initializing? false, entries: size=1, first=(t:5, i:56), STATEMACHINELOGENTRY, client-CB9B2A9B35D9, cid=37
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
scm_1       | 2019-10-18 07:00:52,662 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:06:15,594 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: change Leader from null to 05927fc9-2042-483a-98e5-6075d8118b6c at term 6 for becomeLeader, leader elected after 321ms
om_1        | 2019-10-18 06:57:03,467 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
datanode_1  | 2019-10-18 07:06:08,306 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#105-t5, previous=(t:5, i:55), leaderCommit=52, initializing? false, entries: size=1, first=(t:5, i:56), STATEMACHINELOGENTRY, client-CB9B2A9B35D9, cid=37
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
scm_1       | 2019-10-18 07:00:52,666 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:06:15,595 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2019-10-18 06:57:07,686 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381580, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:531)
datanode_1  | 2019-10-18 07:06:09,131 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
scm_1       | 2019-10-18 07:00:54,159 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:06:15,595 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2019-10-18 06:57:07,701 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | Oct 18, 2019 7:06:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
scm_1       | 2019-10-18 07:00:54,162 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:06:15,595 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2019-10-18 06:57:10,621 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable@3066b37b
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
scm_1       | 2019-10-18 07:01:00,265 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:10,633 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | java.lang.NullPointerException
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
scm_1       | 2019-10-18 07:01:00,268 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:57:13,376 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onError(GrpcLogAppender.java:303)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
scm_1       | 2019-10-18 07:01:18,406 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:13,387 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
scm_1       | 2019-10-18 07:01:18,408 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-18 06:57:16,050 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
scm_1       | 2019-10-18 07:01:19,580 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:16,063 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-18 07:03:34,751 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#246-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
scm_1       | 2019-10-18 07:01:19,588 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:57:18,871 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2019-10-18 07:03:34,751 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#246-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
scm_1       | 2019-10-18 07:01:24,168 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:18,883 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:06:15,596 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 07:03:37,251 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#247-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
scm_1       | 2019-10-18 07:01:24,175 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:57:21,680 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_3  | 2019-10-18 07:03:37,251 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#247-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
scm_1       | 2019-10-18 07:01:30,264 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:21,692 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:06:15,596 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-18 07:03:39,752 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#248-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
scm_1       | 2019-10-18 07:01:30,270 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:57:24,382 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:06:15,599 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2019-10-18 07:03:39,752 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#248-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
scm_1       | 2019-10-18 07:01:44,682 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:24,393 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:06:15,599 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
datanode_3  | 2019-10-18 07:03:41,628 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: change Leader from 9b428cf8-0805-4b46-95f2-cb42dae54452 to null at term 5 for updateCurrentTerm
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
scm_1       | 2019-10-18 07:01:44,684 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-18 06:57:30,716 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
datanode_3  | 2019-10-18 07:03:41,629 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from    LEADER to FOLLOWER at term 5 for recognizeCandidate:4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
scm_1       | 2019-10-18 07:01:49,572 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 07:03:41,629 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown LeaderState
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
datanode_2  | 2019-10-18 07:06:15,599 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:01:49,575 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:57:30,728 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:03:41,631 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
datanode_2  | 2019-10-18 07:06:15,599 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:01:54,154 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:03:41,631 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-18 06:57:31,542 [IPC Server handler 10 on 9862] INFO       - created volume:fstest61 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
datanode_2  | 2019-10-18 07:06:15,599 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:01:54,157 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 07:03:41,634 INFO impl.PendingRequests: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-PendingRequests: sendNotLeaderResponses
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-18 06:57:33,715 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:531)
datanode_2  | 2019-10-18 07:06:15,599 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:01:59,270 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:03:41,638 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start FollowerState
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-18 06:57:33,725 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 2019-10-18 07:06:15,602 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start LeaderState
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:01:59,271 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | 2019-10-18 07:03:41,739 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: change Leader from null to 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e at term 5 for appendEntries, leader elected after 111ms
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-18 06:57:34,468 [IPC Server handler 9 on 9862] INFO       - created volume:fstest261 for user:testuser/scm@EXAMPLE.COM
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 2019-10-18 07:06:15,602 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Rolling segment log-2_56 to index:56
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:02:00,264 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:03:41,760 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: set configuration 2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 2
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-18 06:57:36,585 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2019-10-18 07:06:15,603 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_2 to /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_2-56
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:02:00,267 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 07:03:41,761 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: Rolling segment log-0_1 to index:1
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-18 06:57:36,596 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:02:14,629 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
datanode_3  | 2019-10-18 07:03:41,764 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_0 to /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_0-1
datanode_2  | 2019-10-18 07:06:15,603 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: set configuration 57: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 57
om_1        | 2019-10-18 06:57:39,216 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:02:14,631 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
datanode_3  | 2019-10-18 07:03:41,810 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_2
om_1        | 2019-10-18 06:57:39,227 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 
datanode_2  | 2019-10-18 07:06:15,664 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_57
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:02:14,632 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-18 06:57:41,887 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:03:42,252 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#249-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
datanode_1  | 2019-10-18 07:06:09,135 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
datanode_2  | 2019-10-18 07:07:04,681 [pool-8-thread-24] INFO       - Operation: WriteChunk : Trace ID:  : Message: Block token verification failed. Fail to find any token (empty or null.) : Result: BLOCK_TOKEN_VERIFICATION_FAILED
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:02:14,632 INFO block.BlockManagerImpl: Deleting blocks conID: 9 locID: 102982094122057858 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-18 06:57:41,898 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:03:42,252 WARN server.GrpcLogAppender: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=9b428cf8-0805-4b46-95f2-cb42dae54452->05927fc9-2042-483a-98e5-6075d8118b6c#249-t4, previous=(t:4, i:1), leaderCommit=0, initializing? false, entries: <empty>
datanode_1  | Oct 18, 2019 7:06:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_2  | 2019-10-18 07:07:04,682 [pool-8-thread-24] ERROR      - group-949BC68E43B3: writeChunk writeStateMachineData failed: blockIdcontainerID: 15
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:02:14,632 INFO block.BlockManagerImpl: Deleting blocks conID: 10 locID: 102982094622556291 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-18 06:57:44,833 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:06:09,137 WARN server.GrpcServerProtocolService: 9b428cf8-0805-4b46-95f2-cb42dae54452: installSnapshot onError, lastRequest: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#106-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable@75fd7469
datanode_2  | localID: 102982118574653596
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:02:14,633 INFO block.BlockManagerImpl: Deleting blocks conID: 11 locID: 102982095890612356 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-18 06:57:44,850 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | java.lang.NullPointerException
datanode_3  | Oct 18, 2019 7:06:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_2  | blockCommitSequenceId: 0
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:02:18,881 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-18 06:57:47,397 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onError(GrpcLogAppender.java:303)
datanode_3  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@7bbbaf22
datanode_2  |  logIndex 65 chunkName 102982118574653596_chunk_1 Error message: Block token verification failed. Fail to find any token (empty or null.) Container Result: BLOCK_TOKEN_VERIFICATION_FAILED
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
scm_1       | 2019-10-18 07:02:18,918 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:57:47,412 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
datanode_3  | org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
datanode_2  | 2019-10-18 07:07:04,690 [05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker] ERROR      - pipeline Action CLOSE  on pipeline PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3.Reason : Block token verification failed. Fail to find any token (empty or null.)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2019-10-18 07:02:19,577 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:57:48,204 [IPC Server handler 3 on 9862] INFO       - created volume:fstest361 for user:testuser/scm@EXAMPLE.COM
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
datanode_2  | 2019-10-18 07:07:04,760 [05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker] ERROR      - pipeline Action CLOSE  on pipeline PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3.Reason : Log already failed at index 65 for task WriteLog:65: (t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
scm_1       | 2019-10-18 07:02:19,580 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:07,684 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#28-t6, previous=(t:6, i:64), leaderCommit=64, initializing? false, entries: size=1, first=(t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
om_1        | 2019-10-18 06:57:50,084 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
scm_1       | 2019-10-18 07:02:30,261 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
om_1        | 2019-10-18 06:57:50,096 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:00 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
scm_1       | 2019-10-18 07:02:30,264 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:07,684 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#28-t6, previous=(t:6, i:64), leaderCommit=64, initializing? false, entries: size=1, first=(t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
om_1        | 2019-10-18 06:57:52,940 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
scm_1       | 2019-10-18 07:02:48,882 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:07,776 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#29-t6, previous=(t:6, i:65), leaderCommit=64, initializing? false, entries: size=1, first=(t:6, i:66), STATEMACHINELOGENTRY, client-4C10A320D464, cid=48
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
om_1        | 2019-10-18 06:57:52,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
scm_1       | 2019-10-18 07:02:48,884 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:07,776 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#29-t6, previous=(t:6, i:65), leaderCommit=64, initializing? false, entries: size=1, first=(t:6, i:66), STATEMACHINELOGENTRY, client-4C10A320D464, cid=48
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
om_1        | 2019-10-18 06:57:55,750 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
scm_1       | 2019-10-18 07:02:49,586 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:10,277 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#30-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
om_1        | 2019-10-18 06:57:55,763 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-18 07:02:49,590 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:10,277 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#30-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
om_1        | 2019-10-18 06:57:58,492 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
scm_1       | 2019-10-18 07:03:00,266 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:12,778 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#31-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
om_1        | 2019-10-18 06:57:58,503 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-18 07:03:00,269 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:12,778 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#31-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 2019-10-18 06:58:01,114 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
scm_1       | 2019-10-18 07:03:15,073 INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 12 containers.
datanode_2  | 2019-10-18 07:07:15,279 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#32-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-18 06:58:01,126 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 07:03:15,550 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_2  | 2019-10-18 07:07:15,279 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#32-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 
om_1        | 2019-10-18 06:58:03,872 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-18 07:03:15,551 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_2  | 2019-10-18 07:07:17,780 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#33-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:06:15,293 INFO impl.FollowerState: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-FollowerState: change to CANDIDATE, lastRpcTime:5853ms, electionTimeout:5111ms
om_1        | 2019-10-18 06:58:03,884 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:03:18,882 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:17,780 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#33-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
datanode_3  | 2019-10-18 07:06:15,293 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown FollowerState
om_1        | 2019-10-18 06:58:06,423 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:531)
scm_1       | 2019-10-18 07:03:18,886 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:19,041 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: addNew group-670194CEC49D:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-670194CEC49D:java.util.concurrent.CompletableFuture@e307e0d[Not completed]
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:06:15,293 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
om_1        | 2019-10-18 06:58:06,434 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 07:03:19,580 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,045 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c: new RaftServerImpl for group-670194CEC49D:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 07:06:15,293 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderElection
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
om_1        | 2019-10-18 06:58:09,210 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 07:03:19,583 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:19,046 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 07:06:15,294 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: change Leader from 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e to null at term 5 for initElection
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 2019-10-18 06:58:09,224 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
scm_1       | 2019-10-18 07:03:25,201 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,046 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:06:15,479 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection4: begin an election at term 6 for 2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 2019-10-18 06:58:12,052 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
scm_1       | 2019-10-18 07:03:25,204 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-18 07:07:19,046 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:06:15,570 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-LeaderElection4: Election REJECTED; received 2 response(s) [9b428cf8-0805-4b46-95f2-cb42dae54452<-05927fc9-2042-483a-98e5-6075d8118b6c#0:FAIL-t6, 9b428cf8-0805-4b46-95f2-cb42dae54452<-4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#0:FAIL-t6] and 0 exception(s); 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3:t6, leader=null, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLog:OPENED:c52,f56,i56, conf=2: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
scm_1       | 2019-10-18 07:03:30,270 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 06:58:12,065 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:07:19,046 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 07:06:15,570 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: changes role from CANDIDATE to FOLLOWER at term 6 for DISCOVERED_A_NEW_TERM
datanode_1  | 
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2019-10-18 07:03:30,274 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 06:58:14,689 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,046 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-18 07:06:15,570 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown LeaderElection
datanode_1  | 2019-10-18 07:06:10,809 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#106-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-18 06:58:14,700 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:07:19,046 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 2019-10-18 07:03:34,043 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:06:15,570 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start FollowerState
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:06:10,811 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#105-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-18 06:58:15,339 [IPC Server handler 5 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /fstest361/bk1 failed, because acl already exist
scm_1       | 2019-10-18 07:03:34,045 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:06:15,623 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: change Leader from null to 05927fc9-2042-483a-98e5-6075d8118b6c at term 6 for appendEntries, leader elected after 328ms
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:06:13,310 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#107-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
datanode_2  | 2019-10-18 07:07:19,047 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2019-10-18 06:58:17,296 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 07:03:34,051 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-18 07:06:13,311 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#106-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:06:15,656 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: set configuration 57: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 57
om_1        | 2019-10-18 06:58:17,313 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
scm_1       | 2019-10-18 07:03:34,098 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 07:07:19,047 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2019-10-18 07:06:15,503 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e to null at term 6 for updateCurrentTerm
datanode_3  | 2019-10-18 07:06:15,656 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: Rolling segment log-2_56 to index:56
om_1        | 2019-10-18 06:58:20,057 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
scm_1       | 2019-10-18 07:04:04,049 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 07:07:19,047 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d does not exist. Creating ...
datanode_1  | 2019-10-18 07:06:15,504 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from    LEADER to FOLLOWER at term 6 for recognizeCandidate:9b428cf8-0805-4b46-95f2-cb42dae54452
om_1        | 2019-10-18 06:58:20,069 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:06:15,663 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_2 to /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_2-56
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
scm_1       | 2019-10-18 07:04:04,052 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 07:07:19,288 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d/in_use.lock acquired by nodename 7@ed25c35f2081
datanode_1  | 2019-10-18 07:06:15,504 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown LeaderState
om_1        | 2019-10-18 06:58:22,859 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:06:15,704 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_57
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
scm_1       | 2019-10-18 07:04:04,057 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 07:07:19,302 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d has been successfully formatted.
datanode_1  | 2019-10-18 07:06:15,506 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-18 06:58:22,873 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:04,714 [pool-8-thread-26] INFO       - Operation: WriteChunk : Trace ID:  : Message: Block token verification failed. Fail to find any token (empty or null.) : Result: BLOCK_TOKEN_VERIFICATION_FAILED
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
scm_1       | 2019-10-18 07:04:04,057 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 07:07:19,302 [pool-9-thread-1] INFO       - group-670194CEC49D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-18 07:06:15,506 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-18 06:58:25,464 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:04,714 [pool-8-thread-26] ERROR      - group-949BC68E43B3: writeChunk writeStateMachineData failed: blockIdcontainerID: 15
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:04:04,059 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,302 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-10-18 07:06:15,507 INFO impl.PendingRequests: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-PendingRequests: sendNotLeaderResponses
datanode_3  | localID: 102982118574653596
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-18 06:58:25,475 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:04:04,064 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2019-10-18 07:06:15,552 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-18 06:58:28,158 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_3  | blockCommitSequenceId: 0
scm_1       | 2019-10-18 07:04:25,468 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2019-10-18 07:06:15,568 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: changes role from  FOLLOWER to FOLLOWER at term 6 for recognizeCandidate:05927fc9-2042-483a-98e5-6075d8118b6c
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:58:28,172 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  |  logIndex 65 chunkName 102982118574653596_chunk_1 Error message: Block token verification failed. Fail to find any token (empty or null.) Container Result: BLOCK_TOKEN_VERIFICATION_FAILED
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-18 07:04:25,472 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_1  | 2019-10-18 07:06:15,568 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:58:30,823 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:04,725 [9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker] ERROR      - pipeline Action CLOSE  on pipeline PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3.Reason : Block token verification failed. Fail to find any token (empty or null.)
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-18 07:04:25,510 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:06:15,568 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:58:30,836 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:04,808 [9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker] ERROR      - pipeline Action CLOSE  on pipeline PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3.Reason : Log already failed at index 65 for task WriteLog:65: (t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2019-10-18 07:04:25,512 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_1  | 2019-10-18 07:06:15,568 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:58:35,427 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,053 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: addNew group-670194CEC49D:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-670194CEC49D:java.util.concurrent.CompletableFuture@19f34be3[Not completed]
datanode_2  | 2019-10-18 07:07:19,303 INFO segmented.SegmentedRaftLogWorker: new 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d
scm_1       | 2019-10-18 07:04:25,713 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:06:15,642 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: change Leader from null to 05927fc9-2042-483a-98e5-6075d8118b6c at term 6 for appendEntries, leader elected after 138ms
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:58:35,440 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:19,059 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452: new RaftServerImpl for group-670194CEC49D:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1       | 2019-10-18 07:04:25,714 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:06:15,656 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: set configuration 57: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 57
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:58:38,172 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,060 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 2019-10-18 07:04:25,716 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:06:15,656 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: Rolling segment log-2_56 to index:56
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:07:19,060 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2019-10-18 06:58:38,183 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-18 07:04:25,719 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:06:15,663 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_2 to /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_2-56
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 06:58:40,811 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,060 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1       | 2019-10-18 07:04:25,727 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2019-10-18 07:06:15,704 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/current/log_inprogress_57
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 06:58:40,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:19,060 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1       | 2019-10-18 07:04:25,730 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_1  | 2019-10-18 07:06:15,812 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#108-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:58:43,610 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,060 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2019-10-18 07:04:56,807 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_1  | 2019-10-18 07:06:15,812 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#107-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 06:58:43,622 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:19,060 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 2019-10-18 07:04:56,810 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_1  | 2019-10-18 07:06:18,312 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->9b428cf8-0805-4b46-95f2-cb42dae54452#109-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
om_1        | 2019-10-18 06:58:46,103 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 07:07:19,061 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-18 07:04:56,815 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_1  | 2019-10-18 07:06:18,313 WARN server.GrpcLogAppender: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3->05927fc9-2042-483a-98e5-6075d8118b6c-GrpcLogAppender: appendEntries Timeout, request=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e->05927fc9-2042-483a-98e5-6075d8118b6c#108-t5, previous=(t:5, i:56), leaderCommit=52, initializing? false, entries: <empty>
datanode_2  | 2019-10-18 07:07:19,303 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2019-10-18 06:58:46,117 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 07:07:19,061 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_1  | 2019-10-18 07:07:04,729 [pool-8-thread-51] INFO       - Operation: WriteChunk : Trace ID:  : Message: Block token verification failed. Fail to find any token (empty or null.) : Result: BLOCK_TOKEN_VERIFICATION_FAILED
om_1        | 2019-10-18 06:58:48,844 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-18 07:07:19,304 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2019-10-18 07:04:56,822 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:07:19,061 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d does not exist. Creating ...
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
datanode_1  | 2019-10-18 07:07:04,730 [grpc-default-executor-4] ERROR      - group-949BC68E43B3: writeChunk writeStateMachineData failed: blockIdcontainerID: 15
om_1        | 2019-10-18 06:58:48,857 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:07:19,304 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2019-10-18 07:04:56,828 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:07:19,300 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d/in_use.lock acquired by nodename 7@b59f5315e11c
datanode_1  | localID: 102982118574653596
om_1        | 2019-10-18 06:58:51,527 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 92 more
datanode_2  | 2019-10-18 07:07:19,304 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2019-10-18 07:04:56,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_1  | blockCommitSequenceId: 0
datanode_3  | 2019-10-18 07:07:19,305 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d has been successfully formatted.
om_1        | 2019-10-18 06:58:51,539 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-18 07:07:19,305 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2019-10-18 07:04:59,354 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  |  logIndex 65 chunkName 102982118574653596_chunk_1 Error message: Block token verification failed. Fail to find any token (empty or null.) Container Result: BLOCK_TOKEN_VERIFICATION_FAILED
datanode_3  | 2019-10-18 07:07:19,305 [pool-9-thread-1] INFO       - group-670194CEC49D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1        | 2019-10-18 06:58:54,250 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018T070011Z
datanode_2  | 2019-10-18 07:07:19,305 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2019-10-18 07:04:59,357 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:07:04,741 [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker] ERROR      - pipeline Action CLOSE  on pipeline PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3.Reason : Block token verification failed. Fail to find any token (empty or null.)
datanode_3  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
s3g_1       | 20191018/us-west-1/s3/aws4_request
datanode_2  | 2019-10-18 07:07:19,305 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2019-10-18 06:58:54,261 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 07:05:14,638 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:07:04,804 [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker] ERROR      - pipeline Action CLOSE  on pipeline PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3.Reason : Log already failed at index 65 for task WriteLog:65: (t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
datanode_3  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-10-18 07:07:19,305 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-10-18 06:58:57,042 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 07:05:14,638 INFO block.BlockManagerImpl: Deleting blocks conID: 13 locID: 102982110370726030 bcsId: 0
datanode_1  | 2019-10-18 07:07:19,041 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: addNew group-670194CEC49D:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] returns group-670194CEC49D:java.util.concurrent.CompletableFuture@21ffa449[Not completed]
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
datanode_2  | 2019-10-18 07:07:19,309 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:58:57,057 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-18 07:05:26,813 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:07:19,047 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: new RaftServerImpl for group-670194CEC49D:[05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858] with ContainerStateMachine:uninitialized
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2019-10-18 07:07:19,309 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-18 06:58:57,789 [IPC Server handler 17 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
scm_1       | 2019-10-18 07:05:26,814 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:07:19,048 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-10-18 07:07:19,309 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
om_1        | 2019-10-18 06:58:59,776 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 07:05:26,816 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 07:07:19,309 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-670194CEC49D,id=05927fc9-2042-483a-98e5-6075d8118b6c
om_1        | 2019-10-18 06:58:59,788 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-18 07:05:26,819 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-18 07:07:19,048 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | 2019-10-18 07:07:19,307 INFO segmented.SegmentedRaftLogWorker: new 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 07:07:19,373 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:9b428cf8-0805-4b46-95f2-cb42dae54452
om_1        | 2019-10-18 06:59:00,509 [IPC Server handler 12 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
scm_1       | 2019-10-18 07:05:26,826 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:07:19,048 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
datanode_2  | 2019-10-18 07:07:19,373 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown FollowerState
om_1        | 2019-10-18 06:59:02,567 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 07:05:26,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-18 07:07:19,048 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-18 06:59:02,580 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:07:19,374 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: start FollowerState
scm_1       | 2019-10-18 07:05:53,897 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2019-10-18 07:07:19,048 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 06:59:03,309 [IPC Server handler 6 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
datanode_2  | 2019-10-18 07:07:19,374 INFO impl.FollowerState: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1       | 2019-10-18 07:05:53,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:07:19,048 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D: ConfigurationManager, init=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null, confs=<EMPTY_MAP>
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 06:59:03,310 [IPC Server handler 6 on 9862] ERROR      - Add acl user:testuser2/scm@EXAMPLE.COM:xy[ACCESS] to volume fstest361 failed!
datanode_2  | 2019-10-18 07:07:19,430 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 1 for appendEntries, leader elected after 127ms
scm_1       | 2019-10-18 07:05:56,810 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-18 07:07:19,049 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | PERMISSION_DENIED org.apache.hadoop.ozone.om.exceptions.OMException: User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
datanode_2  | 2019-10-18 07:07:19,433 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
scm_1       | 2019-10-18 07:05:56,812 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-18 07:07:19,049 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1625)
scm_1       | 2019-10-18 07:05:56,819 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:07:19,049 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d does not exist. Creating ...
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:135)
datanode_2  | 2019-10-18 07:07:19,433 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-18 07:05:56,822 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-18 07:07:19,300 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d/in_use.lock acquired by nodename 7@713c90b40e6d
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.acl.OMVolumeAclRequest.validateAndUpdateCache(OMVolumeAclRequest.java:79)
datanode_2  | 2019-10-18 07:07:19,469 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-670194CEC49D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d/current/log_inprogress_0
scm_1       | 2019-10-18 07:05:56,828 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2019-10-18 07:07:19,305 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d has been successfully formatted.
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
datanode_2  | 2019-10-18 07:07:20,280 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#34-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
scm_1       | 2019-10-18 07:05:56,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-10-18 07:07:19,305 [pool-9-thread-1] INFO       - group-670194CEC49D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode_2  | 2019-10-18 07:07:20,280 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#34-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-18 07:06:14,649 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2019-10-18 07:07:19,305 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
datanode_2  | 2019-10-18 07:07:22,781 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#35-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:06:14,651 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:06:14,651 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
datanode_3  | 2019-10-18 07:07:19,308 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2019-10-18 07:07:22,781 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#35-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
datanode_3  | 2019-10-18 07:07:19,309 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_2  | 2019-10-18 07:07:25,282 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#36-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
scm_1       | 2019-10-18 07:06:14,651 INFO block.BlockManagerImpl: Deleting blocks conID: 15 locID: 102982113945190550 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
datanode_3  | 2019-10-18 07:07:19,309 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-18 07:06:14,652 INFO block.BlockManagerImpl: Deleting blocks conID: 13 locID: 102982114006466711 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
kdc_1       | Generiting keytab
datanode_3  | 2019-10-18 07:07:19,309 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 2019-10-18 07:06:26,816 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-18 07:07:19,309 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-10-18 07:07:25,282 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#36-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_1  | 2019-10-18 07:07:19,306 INFO segmented.SegmentedRaftLogWorker: new 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 2019-10-18 07:06:26,821 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for om/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
datanode_3  | 2019-10-18 07:07:19,314 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-18 07:07:27,783 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#37-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2019-10-18 07:06:26,823 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "om/b59f5315e11c@EXAMPLE.COM" created.
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
datanode_3  | 2019-10-18 07:07:19,314 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-10-18 07:07:27,783 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#37-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2019-10-18 07:06:26,828 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
datanode_3  | 2019-10-18 07:07:19,314 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start FollowerState
datanode_2  | 2019-10-18 07:07:27,839 [Command processor thread] ERROR      - Can't close container #13
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 2019-10-18 07:06:26,836 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal om/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.b59f5315e11c.keytab.
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
datanode_3  | 2019-10-18 07:07:19,315 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-670194CEC49D,id=9b428cf8-0805-4b46-95f2-cb42dae54452
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2019-10-18 07:06:26,840 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal om/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.b59f5315e11c.keytab.
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
s3g_1       | 	... 101 more
om_1        | 2019-10-18 06:59:05,415 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-18 07:06:56,825 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
om_1        | 2019-10-18 06:59:05,427 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
s3g_1       | 
datanode_3  | 2019-10-18 07:07:19,327 INFO impl.FollowerState: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-FollowerState: change to CANDIDATE, lastRpcTime:12ms, electionTimeout:12ms
scm_1       | 2019-10-18 07:06:56,829 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:07:19,306 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2019-10-18 06:59:08,261 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
s3g_1       | 
datanode_3  | 2019-10-18 07:07:19,327 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown FollowerState
scm_1       | 2019-10-18 07:06:56,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for om/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2019-10-18 06:59:08,271 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-18 07:00:11,731 WARN servlet.ServletHandler: 
datanode_3  | 2019-10-18 07:07:19,327 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
scm_1       | 2019-10-18 07:06:56,831 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "om/d71a100b5ba6@EXAMPLE.COM" created.
datanode_1  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2019-10-18 06:59:08,932 [IPC Server handler 3 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access volume
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
datanode_3  | 2019-10-18 07:07:19,327 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderElection
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
scm_1       | 2019-10-18 07:06:56,833 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2019-10-18 06:59:11,070 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 1. javax.enterprise.inject.CreationException
datanode_3  | 2019-10-18 07:07:19,349 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-LeaderElection5: begin an election at term 1 for -1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
scm_1       | 2019-10-18 07:06:56,834 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal om/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.d71a100b5ba6.keytab.
datanode_1  | 2019-10-18 07:07:19,307 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1        | 2019-10-18 06:59:11,085 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 2019-10-18 07:07:04,411 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,389 INFO impl.LeaderElection: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-LeaderElection5: Election PASSED; received 1 response(s) [9b428cf8-0805-4b46-95f2-cb42dae54452<-05927fc9-2042-483a-98e5-6075d8118b6c#0:OK-t1] and 0 exception(s); 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D:t1, leader=null, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
kdc_1       | Entry for principal om/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.d71a100b5ba6.keytab.
datanode_1  | 2019-10-18 07:07:19,307 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2019-10-18 06:59:13,699 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
scm_1       | 2019-10-18 07:07:04,413 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
datanode_3  | 2019-10-18 07:07:19,389 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown LeaderElection
kdc_1       | Generiting keytab
datanode_1  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-10-18 06:59:13,713 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2019-10-18 07:07:04,438 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2019-10-18 07:07:19,389 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:59:16,341 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
scm_1       | 2019-10-18 07:07:04,439 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-18 07:07:27,850 [Command processor thread] ERROR      - Can't close container #14
datanode_3  | 2019-10-18 07:07:19,389 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 1 for becomeLeader, leader elected after 83ms
kdc_1       | WARNING: no policy specified for HTTP/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 06:59:16,356 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
scm_1       | 2019-10-18 07:07:04,711 ERROR pipeline.PipelineActionHandler: Received pipeline action CLOSE for Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] from datanode 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537}. Reason : Block token verification failed. Fail to find any token (empty or null.)
datanode_3  | 2019-10-18 07:07:19,392 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
kdc_1       | Principal "HTTP/ed25c35f2081@EXAMPLE.COM" created.
datanode_1  | 2019-10-18 07:07:19,308 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-10-18 06:59:18,988 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_3  | 2019-10-18 07:07:19,392 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2019-10-18 07:07:04,712 INFO pipeline.SCMPipelineManager: destroying pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-18 07:07:19,312 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D: start as a follower, conf=-1: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null
om_1        | 2019-10-18 06:59:19,000 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
datanode_3  | 2019-10-18 07:07:19,392 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2019-10-18 07:07:04,717 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
kdc_1       | Entry for principal HTTP/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.ed25c35f2081.keytab.
datanode_1  | 2019-10-18 07:07:19,312 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-18 06:59:19,670 [IPC Server handler 17 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
scm_1       | 2019-10-18 07:07:04,720 INFO container.CloseContainerEventHandler: Close container Event triggered for container : #13
datanode_3  | 2019-10-18 07:07:19,392 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
kdc_1       | Entry for principal HTTP/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.ed25c35f2081.keytab.
datanode_1  | 2019-10-18 07:07:19,312 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
om_1        | 2019-10-18 06:59:21,817 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
scm_1       | 2019-10-18 07:07:04,726 INFO container.CloseContainerEventHandler: Close container Event triggered for container : #14
datanode_3  | 2019-10-18 07:07:19,392 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2019-10-18 07:07:19,312 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-670194CEC49D,id=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
om_1        | 2019-10-18 06:59:21,834 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-18 07:07:04,728 INFO container.CloseContainerEventHandler: Close container Event triggered for container : #15
datanode_3  | 2019-10-18 07:07:19,392 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-10-18 07:07:19,372 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:9b428cf8-0805-4b46-95f2-cb42dae54452
kdc_1       | Generiting keytab
om_1        | 2019-10-18 06:59:24,545 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
scm_1       | 2019-10-18 07:07:04,734 ERROR pipeline.PipelineActionHandler: Received pipeline action CLOSE for Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347876642743}. Reason : Block token verification failed. Fail to find any token (empty or null.)
datanode_3  | 2019-10-18 07:07:19,395 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2019-10-18 07:07:19,372 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:59:24,556 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-18 07:07:04,736 INFO pipeline.SCMPipelineManager: destroying pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
datanode_1  | 2019-10-18 07:07:19,372 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: start FollowerState
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 06:59:27,132 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2019-10-18 07:07:19,395 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
datanode_1  | 2019-10-18 07:07:19,372 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1       | 2019-10-18 07:07:04,747 ERROR pipeline.PipelineActionHandler: Received pipeline action CLOSE for Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938}. Reason : Block token verification failed. Fail to find any token (empty or null.)
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
om_1        | 2019-10-18 06:59:27,144 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-18 07:07:27,869 [Command processor thread] ERROR      - Can't close container #15
datanode_3  | 2019-10-18 07:07:19,395 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_1  | 2019-10-18 07:07:19,416 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D: change Leader from null to 9b428cf8-0805-4b46-95f2-cb42dae54452 at term 1 for appendEntries, leader elected after 110ms
scm_1       | 2019-10-18 07:07:04,747 INFO pipeline.SCMPipelineManager: destroying pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 06:59:29,740 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,395 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
datanode_1  | 2019-10-18 07:07:19,433 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
scm_1       | 2019-10-18 07:07:04,772 ERROR pipeline.PipelineActionHandler: Received pipeline action CLOSE for Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537}. Reason : Log already failed at index 65 for task WriteLog:65: (t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
om_1        | 2019-10-18 06:59:29,753 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:19,395 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_2  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
datanode_1  | 2019-10-18 07:07:19,433 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-18 07:07:04,772 INFO pipeline.SCMPipelineManager: destroying pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
om_1        | 2019-10-18 07:00:03,677 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:19,395 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
datanode_1  | 2019-10-18 07:07:19,469 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-670194CEC49D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d/current/log_inprogress_0
scm_1       | 2019-10-18 07:07:04,814 ERROR pipeline.PipelineActionHandler: Received pipeline action CLOSE for Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938}. Reason : Log already failed at index 65 for task WriteLog:65: (t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
kdc_1       | Generiting keytab
om_1        | 2019-10-18 07:00:03,690 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-18 07:07:19,398 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
datanode_1  | 2019-10-18 07:07:27,841 [Command processor thread] ERROR      - Can't close container #13
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
scm_1       | 2019-10-18 07:07:04,814 INFO pipeline.SCMPipelineManager: destroying pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-18 07:00:07,703 [Socket Reader #1 for port 9862] INFO       - 1fa697b722c56dbe84f36d107023bfd1989d81ba8d5899b6aa3f7efbef0172ca
datanode_3  | 2019-10-18 07:07:19,398 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
datanode_1  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
scm_1       | 2019-10-18 07:07:04,819 ERROR pipeline.PipelineActionHandler: Received pipeline action CLOSE for Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347876642743}. Reason : Log already failed at index 65 for task WriteLog:65: (t:6, i:65), STATEMACHINELOGENTRY, client-8F821EC1F64C, cid=45
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-18 07:00:07,707 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
datanode_3  | 2019-10-18 07:07:19,398 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
scm_1       | 2019-10-18 07:07:04,819 INFO pipeline.SCMPipelineManager: destroying pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
datanode_3  | 2019-10-18 07:07:19,398 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
scm_1       | 2019-10-18 07:07:19,324 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: bfed4f4d-8426-4472-9a25-670194cec49d, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
om_1        | 2019-10-18 07:00:07,723 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2019-10-18 07:07:19,398 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2019-10-18 07:07:27,854 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
datanode_3  | 2019-10-18 07:07:19,398 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2019-10-18 07:07:30,284 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#38-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 2019-10-18 07:00:08,914 [Socket Reader #1 for port 9862] INFO       - 1fa697b722c56dbe84f36d107023bfd1989d81ba8d5899b6aa3f7efbef0172ca
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
scm_1       | 2019-10-18 07:07:27,859 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
datanode_3  | 2019-10-18 07:07:19,400 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: start LeaderState
datanode_2  | 2019-10-18 07:07:30,284 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#38-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 2019-10-18 07:00:08,916 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
scm_1       | 2019-10-18 07:07:27,861 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
datanode_3  | 2019-10-18 07:07:19,400 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2019-10-18 07:07:32,785 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#39-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 2019-10-18 07:00:08,919 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
scm_1       | 2019-10-18 07:07:27,867 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
datanode_2  | 2019-10-18 07:07:32,785 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#39-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:07:19,402 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D: set configuration 0: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null at 0
om_1        | 2019-10-18 07:00:11,641 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
scm_1       | 2019-10-18 07:07:27,870 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for s3g/scm@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-18 07:07:35,290 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#40-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:07:19,442 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-670194CEC49D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bfed4f4d-8426-4472-9a25-670194cec49d/current/log_inprogress_0
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
scm_1       | 2019-10-18 07:07:27,875 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Principal "s3g/scm@EXAMPLE.COM" created.
datanode_2  | 2019-10-18 07:07:35,290 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#40-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:07:27,853 [Command processor thread] ERROR      - Can't close container #13
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
scm_1       | 2019-10-18 07:07:57,891 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-18 07:07:27,850 [Command processor thread] ERROR      - Can't close container #14
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-18 07:07:37,791 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#41-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
scm_1       | 2019-10-18 07:07:57,893 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
datanode_2  | 2019-10-18 07:07:37,791 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#41-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
scm_1       | 2019-10-18 07:07:57,896 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
datanode_2  | 2019-10-18 07:07:40,292 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#42-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
scm_1       | 2019-10-18 07:07:57,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
kdc_1       | Generiting keytab
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
datanode_2  | 2019-10-18 07:07:40,292 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#42-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
scm_1       | 2019-10-18 07:07:57,927 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
datanode_2  | 2019-10-18 07:07:42,793 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#43-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
scm_1       | 2019-10-18 07:07:57,930 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
kdc_1       | WARNING: no policy specified for scm/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
datanode_2  | 2019-10-18 07:07:42,793 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#43-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
kdc_1       | Principal "scm/b59f5315e11c@EXAMPLE.COM" created.
scm_1       | 2019-10-18 07:08:05,802 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-18 07:07:45,294 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#44-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
scm_1       | 2019-10-18 07:08:05,806 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Entry for principal scm/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.b59f5315e11c.keytab.
datanode_2  | 2019-10-18 07:07:45,294 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#44-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
scm_1       | 2019-10-18 07:08:05,834 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-18 07:07:27,869 [Command processor thread] ERROR      - Can't close container #14
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
datanode_1  | 2019-10-18 07:07:27,869 [Command processor thread] ERROR      - Can't close container #15
kdc_1       | Entry for principal scm/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.b59f5315e11c.keytab.
datanode_2  | 2019-10-18 07:07:47,795 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#45-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-10-18 07:08:05,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
s3g_1       | 1. javax.enterprise.inject.CreationException
datanode_1  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
kdc_1       | Generiting keytab
datanode_2  | 2019-10-18 07:07:47,795 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#45-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-18 07:08:10,926 INFO container.IncrementalContainerReportHandler: Moving container #13 to QUASI_CLOSED state, datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938} reported QUASI_CLOSED replica.
datanode_3  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
s3g_1       | 
datanode_1  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-18 07:07:50,295 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#46-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
scm_1       | 2019-10-18 07:08:10,963 INFO container.IncrementalContainerReportHandler: Moving container #14 to QUASI_CLOSED state, datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938} reported QUASI_CLOSED replica.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
kdc_1       | WARNING: no policy specified for scm/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-18 07:07:50,295 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#46-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
kdc_1       | Principal "scm/d71a100b5ba6@EXAMPLE.COM" created.
scm_1       | 2019-10-18 07:08:11,003 INFO container.IncrementalContainerReportHandler: Moving container #15 to QUASI_CLOSED state, datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938} reported QUASI_CLOSED replica.
datanode_2  | 2019-10-18 07:07:52,797 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#47-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 07:08:11,410 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] removed from db
datanode_2  | 2019-10-18 07:07:52,797 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#47-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
kdc_1       | Entry for principal scm/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.d71a100b5ba6.keytab.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 2019-10-18 07:08:11,486 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
datanode_2  | 2019-10-18 07:07:55,298 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#48-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Entry for principal scm/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.d71a100b5ba6.keytab.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
scm_1       | 2019-10-18 07:08:11,531 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
datanode_2  | 2019-10-18 07:07:55,298 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#48-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2019-10-18 07:07:57,798 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#49-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
scm_1       | 2019-10-18 07:08:11,583 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
kdc_1       | Generiting keytab
datanode_3  | 2019-10-18 07:07:27,902 [Command processor thread] ERROR      - Can't close container #15
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
datanode_1  | 2019-10-18 07:08:10,748 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: remove  FOLLOWER 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3:t6, leader=05927fc9-2042-483a-98e5-6075d8118b6c, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLog:OPENED:c64,f64,i66, conf=57: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null RUNNING
datanode_2  | 2019-10-18 07:07:57,798 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#49-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
scm_1       | 2019-10-18 07:08:11,584 ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
datanode_1  | 2019-10-18 07:08:10,751 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: shutdown
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
datanode_2  | 2019-10-18 07:08:00,299 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#50-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
kdc_1       | WARNING: no policy specified for testuser/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 not found
datanode_3  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:64)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
datanode_1  | 2019-10-18 07:08:10,751 INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-949BC68E43B3,id=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
datanode_2  | 2019-10-18 07:08:00,299 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#50-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
kdc_1       | Principal "testuser/ed25c35f2081@EXAMPLE.COM" created.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.XceiverServer.submitRequest(XceiverServer.java:68)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
datanode_1  | 2019-10-18 07:08:10,752 INFO impl.RoleInfo: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: shutdown FollowerState
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
datanode_2  | 2019-10-18 07:08:02,800 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#51-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:322)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:496)
datanode_1  | 2019-10-18 07:08:10,752 INFO impl.StateMachineUpdater: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater: set stopIndex = 64
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
datanode_2  | 2019-10-18 07:08:02,800 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#51-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:107)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:102)
datanode_1  | 2019-10-18 07:08:10,752 INFO impl.FollowerState: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
datanode_2  | 2019-10-18 07:08:05,301 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#52-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 2019-10-18 07:00:11,643 WARN ipc.Server: Auth failed for 172.18.0.6:49886:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:427)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 2019-10-18 07:08:10,755 [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Taking a snapshot at:(t:4, i:0) file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.4_0
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:413)
datanode_2  | 2019-10-18 07:08:05,301 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#52-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:432)
datanode_1  | 2019-10-18 07:08:10,829 [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Finished taking a snapshot at:(t:4, i:0) file:/data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.4_0 time:74
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:322)
datanode_2  | 2019-10-18 07:08:07,802 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#53-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2019-10-18 07:08:10,831 INFO impl.StateMachineUpdater: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater: Took a snapshot at index 0
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:68)
datanode_2  | 2019-10-18 07:08:07,802 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#53-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:08:11,023 INFO server.GrpcServerProtocolService: 9b428cf8-0805-4b46-95f2-cb42dae54452: Completed APPEND_ENTRIES, lastRequest: 05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#55-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_1  | 2019-10-18 07:08:10,833 INFO impl.StateMachineUpdater: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:00:11,658 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381581, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 2019-10-18 07:08:10,302 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#54-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:08:11,242 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: remove  FOLLOWER 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3:t6, leader=05927fc9-2042-483a-98e5-6075d8118b6c, voted=9b428cf8-0805-4b46-95f2-cb42dae54452, raftlog=9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLog:OPENED:c64,f64,i66, conf=57: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null RUNNING
datanode_1  | 2019-10-18 07:08:10,854 [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Taking a snapshot at:(t:4, i:0) file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.4_0
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 2019-10-18 07:08:10,302 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: appendEntries Timeout, request=05927fc9-2042-483a-98e5-6075d8118b6c->9b428cf8-0805-4b46-95f2-cb42dae54452#54-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
datanode_3  | 2019-10-18 07:08:11,245 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: shutdown
datanode_1  | 2019-10-18 07:08:10,868 [4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Finished taking a snapshot at:(t:4, i:0) file:/data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.4_0 time:14
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 2019-10-18 07:08:11,245 INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-949BC68E43B3,id=9b428cf8-0805-4b46-95f2-cb42dae54452
om_1        | 20191018/us-west-1/s3/aws4_request
datanode_1  | 2019-10-18 07:08:10,868 INFO impl.StateMachineUpdater: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater: Took a snapshot at index 0
datanode_2  | 2019-10-18 07:08:11,014 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: remove    LEADER 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3:t6, leader=05927fc9-2042-483a-98e5-6075d8118b6c, voted=05927fc9-2042-483a-98e5-6075d8118b6c, raftlog=05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLog:OPENED:c64,f64,i66, conf=57: [05927fc9-2042-483a-98e5-6075d8118b6c:172.18.0.10:9858, 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e:172.18.0.2:9858, 9b428cf8-0805-4b46-95f2-cb42dae54452:172.18.0.9:9858], old=null RUNNING
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2019-10-18 07:08:11,246 INFO impl.RoleInfo: 9b428cf8-0805-4b46-95f2-cb42dae54452: shutdown FollowerState
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
datanode_1  | 2019-10-18 07:08:10,869 INFO impl.StateMachineUpdater: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-StateMachineUpdater: snapshotIndex: updateIncreasingly 0 -> 0
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
datanode_2  | 2019-10-18 07:08:11,017 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: shutdown
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2019-10-18 07:08:10,869 INFO impl.RaftServerImpl: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3: closes. applyIndex: 64
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
datanode_3  | 2019-10-18 07:08:11,246 INFO impl.StateMachineUpdater: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater: set stopIndex = 64
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
datanode_2  | 2019-10-18 07:08:11,017 INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-949BC68E43B3,id=05927fc9-2042-483a-98e5-6075d8118b6c
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2019-10-18 07:08:10,875 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
datanode_3  | 2019-10-18 07:08:11,246 INFO impl.FollowerState: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
datanode_2  | 2019-10-18 07:08:11,017 INFO impl.RoleInfo: 05927fc9-2042-483a-98e5-6075d8118b6c: shutdown LeaderState
scm_1       | 2019-10-18 07:08:11,615 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 2019-10-18 07:08:10,876 INFO segmented.SegmentedRaftLogWorker: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e@group-949BC68E43B3-SegmentedRaftLogWorker close()
datanode_3  | 2019-10-18 07:08:11,247 [9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Taking a snapshot at:(t:6, i:63) file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.6_63
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
datanode_2  | 2019-10-18 07:08:11,018 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
scm_1       | 2019-10-18 07:08:11,652 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 2019-10-18 07:08:10,894 [grpc-default-executor-7] INFO       - Container 13 is synced with bcsId 59.
datanode_3  | 2019-10-18 07:08:11,262 [9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Finished taking a snapshot at:(t:6, i:63) file:/data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.6_63 time:15
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
datanode_2  | 2019-10-18 07:08:11,022 INFO impl.PendingRequests: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-PendingRequests: sendNotLeaderResponses
scm_1       | 2019-10-18 07:08:11,687 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 2019-10-18 07:08:10,895 [grpc-default-executor-7] INFO       - Container 13 is synced with bcsId 59.
datanode_3  | 2019-10-18 07:08:11,264 INFO impl.StateMachineUpdater: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater: Took a snapshot at index 63
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_2  | 2019-10-18 07:08:11,022 WARN server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:08:11,687 ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
datanode_1  | 2019-10-18 07:08:10,935 [grpc-default-executor-7] INFO       - Container 14 is synced with bcsId 63.
datanode_3  | 2019-10-18 07:08:11,264 INFO impl.StateMachineUpdater: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 63
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
datanode_2  | 2019-10-18 07:08:11,027 INFO server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452-AppendLogResponseHandler: follower responses appendEntries COMPLETED
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 not found
datanode_1  | 2019-10-18 07:08:10,935 [grpc-default-executor-7] INFO       - Container 14 is synced with bcsId 63.
datanode_3  | 2019-10-18 07:08:11,268 [9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Taking a snapshot at:(t:6, i:63) file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.6_63
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
datanode_2  | 2019-10-18 07:08:11,030 INFO server.GrpcLogAppender: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:132)
datanode_1  | 2019-10-18 07:08:10,971 [grpc-default-executor-7] INFO       - Container 15 is synced with bcsId 46.
datanode_3  | 2019-10-18 07:08:11,271 [9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Finished taking a snapshot at:(t:6, i:63) file:/data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.6_63 time:4
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
datanode_2  | 2019-10-18 07:08:11,036 INFO impl.FollowerInfo: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->9b428cf8-0805-4b46-95f2-cb42dae54452: nextIndex: updateUnconditionally 67 -> 65
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:322)
datanode_1  | 2019-10-18 07:08:10,971 [grpc-default-executor-7] INFO       - Container 15 is synced with bcsId 46.
datanode_3  | 2019-10-18 07:08:11,272 INFO impl.StateMachineUpdater: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater: Took a snapshot at index 63
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
datanode_2  | 2019-10-18 07:08:11,036 INFO impl.FollowerInfo: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: nextIndex: updateUnconditionally 67 -> 65
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:107)
datanode_3  | 2019-10-18 07:08:11,272 INFO impl.StateMachineUpdater: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-StateMachineUpdater: snapshotIndex: updateIncreasingly 63 -> 63
datanode_1  | 2019-10-18 07:08:11,023 INFO server.GrpcServerProtocolService: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: Completed APPEND_ENTRIES, lastRequest: 05927fc9-2042-483a-98e5-6075d8118b6c->4746d23f-e8ca-4bc6-bc17-e9dd8c69511e#55-t6, previous=(t:6, i:66), leaderCommit=64, initializing? false, entries: <empty>
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
datanode_2  | 2019-10-18 07:08:11,046 INFO impl.StateMachineUpdater: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater: set stopIndex = 64
s3g_1       | 	... 33 more
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:427)
datanode_1  | 2019-10-18 07:08:11,424 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: remove group-949BC68E43B3:null
datanode_3  | 2019-10-18 07:08:11,272 INFO impl.RaftServerImpl: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3: closes. applyIndex: 64
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
datanode_2  | 2019-10-18 07:08:11,048 [05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Taking a snapshot at:(t:5, i:52) file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.5_52
s3g_1       | Caused by: javax.enterprise.inject.CreationException
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:413)
datanode_1  | 2019-10-18 07:08:11,606 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: remove group-949BC68E43B3:null
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
datanode_2  | 2019-10-18 07:08:11,094 [05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Finished taking a snapshot at:(t:5, i:52) file:/data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.5_52 time:46
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 2019-10-18 07:08:11,275 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:322)
datanode_1  | 2019-10-18 07:08:11,716 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: remove group-949BC68E43B3:null
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
datanode_2  | 2019-10-18 07:08:11,096 INFO impl.StateMachineUpdater: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater: Took a snapshot at index 52
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 2019-10-18 07:08:11,276 INFO segmented.SegmentedRaftLogWorker: 9b428cf8-0805-4b46-95f2-cb42dae54452@group-949BC68E43B3-SegmentedRaftLogWorker close()
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:68)
datanode_1  | 2019-10-18 07:08:11,820 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: remove group-949BC68E43B3:null
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
datanode_2  | 2019-10-18 07:08:11,097 INFO impl.StateMachineUpdater: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 52
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 2019-10-18 07:08:11,301 [grpc-default-executor-8] INFO       - Container 13 is synced with bcsId 59.
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
datanode_1  | 2019-10-18 07:08:11,953 INFO impl.RaftServerProxy: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: remove group-949BC68E43B3:null
datanode_2  | 2019-10-18 07:08:11,106 [05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Taking a snapshot at:(t:5, i:52) file /data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.5_52
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-18 07:00:11,658 WARN ipc.Server: Auth failed for 172.18.0.6:49888:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-18 07:08:11,301 [grpc-default-executor-8] INFO       - Container 13 is synced with bcsId 59.
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 2019-10-18 07:08:43,378 [Command processor thread] INFO       - Container 13 is synced with bcsId 59.
datanode_2  | 2019-10-18 07:08:11,119 [05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater] INFO       - group-949BC68E43B3: Finished taking a snapshot at:(t:5, i:52) file:/data/metadata/ratis/330696bd-70f3-40b2-95d6-949bc68e43b3/sm/snapshot.5_52 time:13
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191018T070011Z
datanode_3  | 2019-10-18 07:08:11,327 [grpc-default-executor-8] INFO       - Container 14 is synced with bcsId 63.
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 2019-10-18 07:08:43,379 [Command processor thread] INFO       - Container 13 is synced with bcsId 59.
datanode_2  | 2019-10-18 07:08:11,119 INFO impl.StateMachineUpdater: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater: Took a snapshot at index 52
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191018/us-west-1/s3/aws4_request
datanode_3  | 2019-10-18 07:08:11,328 [grpc-default-executor-8] INFO       - Container 14 is synced with bcsId 63.
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2019-10-18 07:08:11,119 INFO impl.StateMachineUpdater: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-StateMachineUpdater: snapshotIndex: updateIncreasingly 52 -> 52
datanode_1  | 2019-10-18 07:08:43,414 [Command processor thread] INFO       - Container 13 is closed with bcsId 59.
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
datanode_3  | 2019-10-18 07:08:11,365 [grpc-default-executor-8] INFO       - Container 15 is synced with bcsId 46.
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2019-10-18 07:08:11,120 INFO impl.RaftServerImpl: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3: closes. applyIndex: 64
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 07:08:11,365 [grpc-default-executor-8] INFO       - Container 15 is synced with bcsId 46.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
datanode_1  | 2019-10-18 07:08:43,415 [Command processor thread] INFO       - Container 14 is synced with bcsId 63.
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2019-10-18 07:08:11,122 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-18 07:08:11,554 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: remove group-949BC68E43B3:null
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
datanode_2  | 2019-10-18 07:08:11,123 INFO segmented.SegmentedRaftLogWorker: 05927fc9-2042-483a-98e5-6075d8118b6c@group-949BC68E43B3-SegmentedRaftLogWorker close()
scm_1       | 2019-10-18 07:08:11,728 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 07:08:11,674 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: remove group-949BC68E43B3:null
datanode_1  | 2019-10-18 07:08:43,416 [Command processor thread] INFO       - Container 14 is synced with bcsId 63.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
datanode_2  | 2019-10-18 07:08:11,160 [grpc-default-executor-6] INFO       - Container 13 is synced with bcsId 59.
scm_1       | 2019-10-18 07:08:11,768 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-18 07:08:11,793 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: remove group-949BC68E43B3:null
datanode_1  | 2019-10-18 07:08:43,450 [Command processor thread] INFO       - Container 14 is closed with bcsId 63.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
datanode_2  | 2019-10-18 07:08:11,160 [grpc-default-executor-6] INFO       - Container 13 is synced with bcsId 59.
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 07:08:11,889 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: remove group-949BC68E43B3:null
datanode_1  | 2019-10-18 07:08:43,451 [Command processor thread] INFO       - Container 15 is synced with bcsId 46.
scm_1       | 2019-10-18 07:08:11,800 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
datanode_2  | 2019-10-18 07:08:11,186 [grpc-default-executor-6] INFO       - Container 14 is synced with bcsId 63.
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-18 07:08:12,005 INFO impl.RaftServerProxy: 9b428cf8-0805-4b46-95f2-cb42dae54452: remove group-949BC68E43B3:null
datanode_1  | 2019-10-18 07:08:43,451 [Command processor thread] INFO       - Container 15 is synced with bcsId 46.
scm_1       | 2019-10-18 07:08:11,800 ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
om_1        | 2019-10-18 07:00:11,663 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-18 07:08:11,187 [grpc-default-executor-6] INFO       - Container 14 is synced with bcsId 63.
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.2: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, dn/713c90b40e6d@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 2019-10-18 07:08:43,377 [Command processor thread] INFO       - Container 13 is synced with bcsId 59.
datanode_1  | 2019-10-18 07:08:43,468 [Command processor thread] INFO       - Container 15 is closed with bcsId 46.
om_1        | 20191018T070011Z
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 not found
datanode_2  | 2019-10-18 07:08:11,214 [grpc-default-executor-6] INFO       - Container 15 is synced with bcsId 46.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-18 07:08:43,378 [Command processor thread] INFO       - Container 13 is synced with bcsId 59.
datanode_1  | 2019-10-18 07:09:14,453 [Command processor thread] INFO       - Start to delete container blocks, TXIDs=[7(0),8(0),12(0)], numOfContainers=3, numOfBlocks=3
om_1        | 20191018/us-west-1/s3/aws4_request
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:132)
datanode_2  | 2019-10-18 07:08:11,214 [grpc-default-executor-6] INFO       - Container 15 is synced with bcsId 46.
kdc_1       | Oct 18 06:53:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
datanode_3  | 2019-10-18 07:08:43,414 [Command processor thread] INFO       - Container 13 is closed with bcsId 59.
datanode_1  | 2019-10-18 07:10:13,416 [BlockDeletingService#2] INFO       - Plan to choose 10 containers for block deletion, actually returns 3 valid containers.
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:322)
datanode_2  | 2019-10-18 07:08:11,497 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: remove group-949BC68E43B3:null
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
datanode_3  | 2019-10-18 07:08:43,415 [Command processor thread] INFO       - Container 14 is synced with bcsId 63.
datanode_1  | 2019-10-18 07:10:13,468 [BlockDeletingService#5] INFO       - Container: 15, deleted blocks: 1, task elapsed time: 48ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:107)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
datanode_2  | 2019-10-18 07:08:11,639 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: remove group-949BC68E43B3:null
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
datanode_3  | 2019-10-18 07:08:43,415 [Command processor thread] INFO       - Container 14 is synced with bcsId 63.
datanode_1  | 2019-10-18 07:10:13,468 [BlockDeletingService#9] INFO       - Container: 13, deleted blocks: 1, task elapsed time: 48ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:427)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
datanode_2  | 2019-10-18 07:08:11,759 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: remove group-949BC68E43B3:null
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
datanode_3  | 2019-10-18 07:08:43,450 [Command processor thread] INFO       - Container 14 is closed with bcsId 63.
datanode_1  | 2019-10-18 07:10:13,468 [BlockDeletingService#1] INFO       - Container: 14, deleted blocks: 1, task elapsed time: 48ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:413)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
datanode_2  | 2019-10-18 07:08:11,858 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: remove group-949BC68E43B3:null
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
datanode_3  | 2019-10-18 07:08:43,451 [Command processor thread] INFO       - Container 15 is synced with bcsId 46.
datanode_1  | 2019-10-18 07:10:14,473 [Command processor thread] INFO       - Start to delete container blocks, TXIDs=[9(0)], numOfContainers=1, numOfBlocks=1
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:322)
datanode_2  | 2019-10-18 07:08:11,979 INFO impl.RaftServerProxy: 05927fc9-2042-483a-98e5-6075d8118b6c: remove group-949BC68E43B3:null
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 07:08:43,451 [Command processor thread] INFO       - Container 15 is synced with bcsId 46.
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:68)
datanode_1  | 2019-10-18 07:11:13,470 [BlockDeletingService#2] INFO       - Plan to choose 10 containers for block deletion, actually returns 1 valid containers.
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
datanode_2  | 2019-10-18 07:08:43,378 [Command processor thread] INFO       - Container 13 is synced with bcsId 59.
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-18 07:08:43,468 [Command processor thread] INFO       - Container 15 is closed with bcsId 46.
datanode_1  | 2019-10-18 07:11:13,473 [BlockDeletingService#3] INFO       - Container: 13, deleted blocks: 1, task elapsed time: 2ms
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
datanode_2  | 2019-10-18 07:08:43,379 [Command processor thread] INFO       - Container 13 is synced with bcsId 59.
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:09:14,452 [Command processor thread] INFO       - Start to delete container blocks, TXIDs=[7(0),8(0),12(0)], numOfContainers=3, numOfBlocks=3
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
datanode_2  | 2019-10-18 07:08:43,414 [Command processor thread] INFO       - Container 13 is closed with bcsId 59.
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-18 07:10:13,592 [BlockDeletingService#2] INFO       - Plan to choose 10 containers for block deletion, actually returns 3 valid containers.
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
datanode_2  | 2019-10-18 07:08:43,415 [Command processor thread] INFO       - Container 14 is synced with bcsId 63.
kdc_1       | Oct 18 06:53:01 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-18 07:10:13,620 [BlockDeletingService#1] INFO       - Container: 14, deleted blocks: 1, task elapsed time: 26ms
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 07:08:43,415 [Command processor thread] INFO       - Container 14 is synced with bcsId 63.
datanode_3  | 2019-10-18 07:10:13,620 [BlockDeletingService#5] INFO       - Container: 15, deleted blocks: 1, task elapsed time: 26ms
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 07:08:43,450 [Command processor thread] INFO       - Container 14 is closed with bcsId 63.
datanode_3  | 2019-10-18 07:10:13,621 [BlockDeletingService#9] INFO       - Container: 13, deleted blocks: 1, task elapsed time: 26ms
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-18 07:08:43,451 [Command processor thread] INFO       - Container 15 is synced with bcsId 46.
datanode_3  | 2019-10-18 07:10:14,472 [Command processor thread] INFO       - Start to delete container blocks, TXIDs=[9(0)], numOfContainers=1, numOfBlocks=1
scm_1       | 2019-10-18 07:08:11,832 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-18 07:08:43,451 [Command processor thread] INFO       - Container 15 is synced with bcsId 46.
datanode_3  | 2019-10-18 07:11:13,623 [BlockDeletingService#2] INFO       - Plan to choose 10 containers for block deletion, actually returns 1 valid containers.
scm_1       | 2019-10-18 07:08:11,868 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-18 07:08:43,468 [Command processor thread] INFO       - Container 15 is closed with bcsId 46.
scm_1       | 2019-10-18 07:08:11,918 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
datanode_3  | 2019-10-18 07:11:13,626 [BlockDeletingService#3] INFO       - Container: 13, deleted blocks: 1, task elapsed time: 3ms
datanode_2  | 2019-10-18 07:09:14,452 [Command processor thread] INFO       - Start to delete container blocks, TXIDs=[7(0),8(0),12(0)], numOfContainers=3, numOfBlocks=3
scm_1       | 2019-10-18 07:08:11,918 ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
datanode_2  | 2019-10-18 07:10:13,481 [BlockDeletingService#2] INFO       - Plan to choose 10 containers for block deletion, actually returns 3 valid containers.
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 not found
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
datanode_2  | 2019-10-18 07:10:13,559 [BlockDeletingService#9] INFO       - Container: 13, deleted blocks: 1, task elapsed time: 74ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:132)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
datanode_2  | 2019-10-18 07:10:13,559 [BlockDeletingService#1] INFO       - Container: 14, deleted blocks: 1, task elapsed time: 74ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:322)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:107)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:427)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
datanode_2  | 2019-10-18 07:10:13,559 [BlockDeletingService#5] INFO       - Container: 15, deleted blocks: 1, task elapsed time: 74ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:413)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
datanode_2  | 2019-10-18 07:10:14,471 [Command processor thread] INFO       - Start to delete container blocks, TXIDs=[9(0)], numOfContainers=1, numOfBlocks=1
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:322)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
datanode_2  | 2019-10-18 07:11:13,561 [BlockDeletingService#2] INFO       - Plan to choose 10 containers for block deletion, actually returns 1 valid containers.
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:68)
om_1        | 2019-10-18 07:00:11,664 WARN ipc.Server: Auth failed for 172.18.0.6:49890:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
datanode_2  | 2019-10-18 07:11:13,565 [BlockDeletingService#3] INFO       - Container: 13, deleted blocks: 1, task elapsed time: 3ms
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 20191018/us-west-1/s3/aws4_request
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	... 60 more
om_1        | 2019-10-18 07:00:11,670 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:08:11,959 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-18 07:08:11,985 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-10-18 07:08:12,011 WARN pipeline.RatisPipelineUtils: Pipeline destroy failed for pipeline=PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 dn=9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 07:08:12,011 ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=330696bd-70f3-40b2-95d6-949bc68e43b3 not found
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:132)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:322)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	... 92 more
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:107)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:427)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:413)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:322)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:68)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 2019-10-18 07:00:11,670 WARN ipc.Server: Auth failed for 172.18.0.6:49892:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191018T070011Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-18 07:00:11,676 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 20191018T070011Z
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 20191018/us-west-1/s3/aws4_request
scm_1       | 2019-10-18 07:08:14,659 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 6 blocks
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-18 07:08:14,659 INFO block.BlockManagerImpl: Deleting blocks conID: 17 locID: 102982122611998879 bcsId: 0,conID: 16 locID: 102982122591748254 bcsId: 0,conID: 14 locID: 102982118568099995 bcsId: 0
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:08:14,660 INFO block.BlockManagerImpl: Deleting blocks conID: 18 locID: 102982123004887200 bcsId: 0
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 07:08:14,660 INFO block.BlockManagerImpl: Deleting blocks conID: 17 locID: 102982123004887202 bcsId: 0
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-18 07:08:14,661 INFO block.BlockManagerImpl: Deleting blocks conID: 16 locID: 102982123006263460 bcsId: 0
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:08:14,661 INFO block.BlockManagerImpl: Deleting blocks conID: 16 locID: 102982123004887201 bcsId: 0
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:08:14,661 INFO block.BlockManagerImpl: Deleting blocks conID: 18 locID: 102982123005935779 bcsId: 0
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
scm_1       | 2019-10-18 07:08:15,080 INFO container.ReplicationManager: Force closing container #13 with BCSID 59, which is in QUASI_CLOSED state.
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
scm_1       | 2019-10-18 07:08:15,082 INFO container.ReplicationManager: Sending close container command for container #13 to datanode 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537}.
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-10-18 07:08:15,082 INFO container.ReplicationManager: Sending close container command for container #13 to datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938}.
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-18 07:08:15,082 INFO container.ReplicationManager: Sending close container command for container #13 to datanode 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347876642743}.
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
scm_1       | 2019-10-18 07:08:15,082 INFO container.ReplicationManager: Force closing container #14 with BCSID 63, which is in QUASI_CLOSED state.
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
scm_1       | 2019-10-18 07:08:15,082 INFO container.ReplicationManager: Sending close container command for container #14 to datanode 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347876642743}.
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
scm_1       | 2019-10-18 07:08:15,082 INFO container.ReplicationManager: Sending close container command for container #14 to datanode 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537}.
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
scm_1       | 2019-10-18 07:08:15,083 INFO container.ReplicationManager: Sending close container command for container #14 to datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938}.
s3g_1       | 	... 101 more
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
scm_1       | 2019-10-18 07:08:15,083 INFO container.ReplicationManager: Force closing container #15 with BCSID 46, which is in QUASI_CLOSED state.
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 2019-10-18 07:00:11,734 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | 2019-10-18 07:08:15,083 INFO container.ReplicationManager: Sending close container command for container #15 to datanode 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537}.
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 1. javax.enterprise.inject.CreationException
scm_1       | 2019-10-18 07:08:15,083 INFO container.ReplicationManager: Sending close container command for container #15 to datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938}.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 
scm_1       | 2019-10-18 07:08:15,083 INFO container.ReplicationManager: Sending close container command for container #15 to datanode 9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347876642743}.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 07:08:15,083 INFO container.ReplicationManager: Replication Monitor Thread took 10 milliseconds for processing 18 containers.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 07:00:11,676 WARN ipc.Server: Auth failed for 172.18.0.6:49894:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-18 07:08:42,393 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-18 07:08:42,394 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-18 07:08:42,397 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-18 07:08:42,398 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
scm_1       | 2019-10-18 07:08:42,408 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal testuser/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.ed25c35f2081.keytab.
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-18 07:00:11,682 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-18 07:08:42,411 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal testuser/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.ed25c35f2081.keytab.
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
scm_1       | 2019-10-18 07:08:43,418 INFO container.IncrementalContainerReportHandler: Moving container #13 to CLOSED state, datanode 05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698451537} reported CLOSED replica.
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Generiting keytab
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
scm_1       | 2019-10-18 07:08:43,453 INFO container.IncrementalContainerReportHandler: Moving container #14 to CLOSED state, datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938} reported CLOSED replica.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
scm_1       | 2019-10-18 07:08:43,472 INFO container.IncrementalContainerReportHandler: Moving container #15 to CLOSED state, datanode 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11728347698448938} reported CLOSED replica.
kdc_1       | WARNING: no policy specified for testuser/om@EXAMPLE.COM; defaulting to no policy
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
scm_1       | 2019-10-18 07:08:43,574 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "testuser/om@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
scm_1       | 2019-10-18 07:08:43,576 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
scm_1       | 2019-10-18 07:09:09,146 INFO block.SCMBlockDeletingService: Totally added 9 delete blocks command for 3 datanodes, task elapsed time: 19ms
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
scm_1       | 2019-10-18 07:09:12,370 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
scm_1       | 2019-10-18 07:09:12,372 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-10-18 07:09:13,491 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-18 07:09:13,492 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
scm_1       | 2019-10-18 07:09:13,497 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
scm_1       | 2019-10-18 07:09:13,498 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
scm_1       | 2019-10-18 07:09:13,503 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
scm_1       | 2019-10-18 07:09:13,508 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for HTTP/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | 2019-10-18 07:09:13,514 INFO block.SCMBlockDeletingService: Block deletion txnID mismatch in datanode 9b428cf8-0805-4b46-95f2-cb42dae54452 for containerID 13. Datanode delete txnID: 0, SCM txnID: 7
kdc_1       | Principal "HTTP/b59f5315e11c@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
scm_1       | 2019-10-18 07:09:13,519 INFO block.SCMBlockDeletingService: Block deletion txnID mismatch in datanode 9b428cf8-0805-4b46-95f2-cb42dae54452 for containerID 14. Datanode delete txnID: 0, SCM txnID: 12
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
scm_1       | 2019-10-18 07:09:13,519 INFO block.SCMBlockDeletingService: Block deletion txnID mismatch in datanode 9b428cf8-0805-4b46-95f2-cb42dae54452 for containerID 15. Datanode delete txnID: 0, SCM txnID: 8
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Entry for principal HTTP/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.b59f5315e11c.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
scm_1       | 2019-10-18 07:09:14,665 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Entry for principal HTTP/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.b59f5315e11c.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
scm_1       | 2019-10-18 07:09:14,665 INFO block.BlockManagerImpl: Deleting blocks conID: 16 locID: 102982126952317101 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Generiting keytab
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
scm_1       | 2019-10-18 07:09:29,003 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-18 07:09:29,005 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 07:09:43,492 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-18 07:00:11,682 WARN ipc.Server: Auth failed for 172.18.0.6:49896:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for HTTP/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-18 07:09:43,492 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 20191018T070011Z
kdc_1       | Principal "HTTP/d71a100b5ba6@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-18 07:09:43,494 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
scm_1       | 2019-10-18 07:09:43,498 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Entry for principal HTTP/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.d71a100b5ba6.keytab.
scm_1       | 2019-10-18 07:09:43,501 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-18 07:00:11,687 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
scm_1       | 2019-10-18 07:09:43,505 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
scm_1       | 2019-10-18 07:09:53,081 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.d71a100b5ba6.keytab.
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2019-10-18 07:09:53,082 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Generiting keytab
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-18 07:10:09,147 INFO block.SCMBlockDeletingService: Totally added 3 delete blocks command for 3 datanodes, task elapsed time: 1ms
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	... 13 more
kdc_1       | WARNING: no policy specified for testuser2/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-18 07:10:13,496 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Principal "testuser2/ed25c35f2081@EXAMPLE.COM" created.
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
scm_1       | 2019-10-18 07:10:13,497 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 1. javax.enterprise.inject.CreationException
scm_1       | 2019-10-18 07:10:13,497 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Entry for principal testuser2/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.ed25c35f2081.keytab.
s3g_1       | 
scm_1       | 2019-10-18 07:10:13,499 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Entry for principal testuser2/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.ed25c35f2081.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
scm_1       | 2019-10-18 07:10:13,499 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
scm_1       | 2019-10-18 07:10:13,500 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
scm_1       | 2019-10-18 07:10:14,669 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 4 blocks
kdc_1       | WARNING: no policy specified for testuser2/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-10-18 07:10:14,669 INFO block.BlockManagerImpl: Deleting blocks conID: 16 locID: 102982129620287664 bcsId: 0
kdc_1       | Principal "testuser2/om@EXAMPLE.COM" created.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-18 07:10:14,669 INFO block.BlockManagerImpl: Deleting blocks conID: 17 locID: 102982129672782001 bcsId: 0
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
scm_1       | 2019-10-18 07:10:14,669 INFO block.BlockManagerImpl: Deleting blocks conID: 17 locID: 102982128042377390 bcsId: 0
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
scm_1       | 2019-10-18 07:10:14,670 INFO block.BlockManagerImpl: Deleting blocks conID: 18 locID: 102982128622960815 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
scm_1       | 2019-10-18 07:10:43,489 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
scm_1       | 2019-10-18 07:10:43,490 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
scm_1       | 2019-10-18 07:10:43,491 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
scm_1       | 2019-10-18 07:10:43,493 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | 2019-10-18 07:10:43,494 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
scm_1       | 2019-10-18 07:10:43,497 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
scm_1       | 2019-10-18 07:11:13,492 INFO ipc.Server: Auth successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
scm_1       | 2019-10-18 07:11:13,494 INFO ipc.Server: Auth successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:11:13,500 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/b59f5315e11c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-18 07:11:13,502 INFO ipc.Server: Auth successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
scm_1       | 2019-10-18 07:11:13,506 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/713c90b40e6d@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 07:00:11,687 WARN ipc.Server: Auth failed for 172.18.0.6:49898:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191018T070011Z
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
scm_1       | 2019-10-18 07:11:13,511 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/ed25c35f2081@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 20191018/us-west-1/s3/aws4_request
scm_1       | 2019-10-18 07:11:22,783 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
scm_1       | 2019-10-18 07:11:22,922 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
scm_1       | 2019-10-18 07:11:23,018 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:00:11,692 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-18 07:11:23,023 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 20191018T070011Z
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Caused by: javax.enterprise.inject.CreationException
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | WARNING: no policy specified for testuser2/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:53:02 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 07:00:11,693 WARN ipc.Server: Auth failed for 172.18.0.6:49900:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 07:00:11,698 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191018T070011Z
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-18 07:00:11,698 WARN ipc.Server: Auth failed for 172.18.0.6:49902:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-18 07:00:11,705 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	... 92 more
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | Principal "testuser2/s3g@EXAMPLE.COM" created.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | WARNING: no policy specified for testuser/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Principal "testuser/b59f5315e11c@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Entry for principal testuser/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.b59f5315e11c.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Entry for principal testuser/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.b59f5315e11c.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-18 07:00:11,706 WARN ipc.Server: Auth failed for 172.18.0.6:49904:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for testuser/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Principal "testuser/d71a100b5ba6@EXAMPLE.COM" created.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 20191018T070011Z
kdc_1       | Entry for principal testuser/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.d71a100b5ba6.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Entry for principal testuser/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.d71a100b5ba6.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Generiting keytab
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:00:11,712 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191018T070011Z
kdc_1       | WARNING: no policy specified for s3g/ed25c35f2081@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Principal "s3g/ed25c35f2081@EXAMPLE.COM" created.
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Entry for principal s3g/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.ed25c35f2081.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Entry for principal s3g/ed25c35f2081@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.ed25c35f2081.keytab.
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Generiting keytab
s3g_1       | 2019-10-18 07:00:11,945 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191018T070011Z
kdc_1       | WARNING: no policy specified for s3g/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Principal "s3g/om@EXAMPLE.COM" created.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-18 07:00:11,963 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:53:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381583, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 2019-10-18 07:00:11,963 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 20191018T070011Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 2019-10-18 07:00:11,969 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 2019-10-18 07:00:11,971 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 07:00:11,712 WARN ipc.Server: Auth failed for 172.18.0.6:49906:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-10-18 07:00:11,977 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-18 07:00:11,898 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191018T070011Z
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:03 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-18 07:00:11,977 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191018T070011Z
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-18 07:00:11,983 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191018T070011Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 2019-10-18 07:00:11,983 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-18 07:00:11,988 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 2019-10-18 07:00:11,988 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 07:00:11,944 WARN ipc.Server: Auth failed for 172.18.0.6:49910:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
om_1        | 20191018T070011Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-10-18 07:00:11,994 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:00:11,961 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/ed25c35f2081@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191018T070011Z
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-18 07:00:11,995 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191018T070011Z
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:04 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:04 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.4: ISSUE: authtime 1571381584, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
kdc_1       | Oct 18 06:53:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 2019-10-18 07:00:12,001 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191018T070011Z
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-18 07:00:12,001 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191018T070011Z
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 2019-10-18 07:00:12,007 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
s3g_1       | 20191018T070011Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 2019-10-18 07:00:12,008 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for testuser2/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191018T070011Z
kdc_1       | Principal "testuser2/b59f5315e11c@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Entry for principal testuser2/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.b59f5315e11c.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Entry for principal testuser2/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.b59f5315e11c.keytab.
om_1        | 2019-10-18 07:00:11,962 WARN ipc.Server: Auth failed for 172.18.0.6:49914:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
kdc_1       | Generiting keytab
om_1        | 20191018T070011Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-18 07:00:12,012 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | WARNING: no policy specified for testuser2/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
s3g_1       | 20191018T070011Z
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Principal "testuser2/d71a100b5ba6@EXAMPLE.COM" created.
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:00:11,968 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 20191018T070011Z
kdc_1       | Entry for principal testuser2/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.d71a100b5ba6.keytab.
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 2019-10-18 07:00:12,013 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser2/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.d71a100b5ba6.keytab.
s3g_1       | 20191018T070011Z
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Generiting keytab
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
kdc_1       | WARNING: no policy specified for s3g/b59f5315e11c@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 2019-10-18 07:00:12,017 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Principal "s3g/b59f5315e11c@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191018T070011Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Entry for principal s3g/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.b59f5315e11c.keytab.
s3g_1       | 2019-10-18 07:00:12,018 [qtp359368949-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Entry for principal s3g/b59f5315e11c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.b59f5315e11c.keytab.
s3g_1       | 2019-10-18 07:00:12,018 [qtp359368949-27] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Generiting keytab
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191018T070011Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | WARNING: no policy specified for s3g/d71a100b5ba6@EXAMPLE.COM; defaulting to no policy
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Principal "s3g/d71a100b5ba6@EXAMPLE.COM" created.
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Entry for principal s3g/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.d71a100b5ba6.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Entry for principal s3g/d71a100b5ba6@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.d71a100b5ba6.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-18 07:00:11,969 WARN ipc.Server: Auth failed for 172.18.0.6:49916:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-18 07:00:11,975 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:53:06 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.10: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, dn/ed25c35f2081@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 07:00:11,976 WARN ipc.Server: Auth failed for 172.18.0.6:49918:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 07:00:11,982 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/b59f5315e11c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/d71a100b5ba6@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:06 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:53:08 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.7: ISSUE: authtime 1571381588, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:53:08 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.9: ISSUE: authtime 1571381588, etypes {rep=18 tkt=18 ses=18}, dn/b59f5315e11c@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-18 07:00:11,982 WARN ipc.Server: Auth failed for 172.18.0.6:49920:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381588, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.7: ISSUE: authtime 1571381588, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1571381582, etypes {rep=18 tkt=18 ses=18}, dn/713c90b40e6d@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1571381586, etypes {rep=18 tkt=18 ses=18}, dn/ed25c35f2081@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-18 07:00:11,987 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:09 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381588, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1571381588, etypes {rep=18 tkt=18 ses=18}, dn/b59f5315e11c@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:11 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381591, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:53:11 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381591, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 18 06:53:12 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.7: ISSUE: authtime 1571381592, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Oct 18 06:53:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.7: ISSUE: authtime 1571381592, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Oct 18 06:53:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381594, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 18 06:53:14 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381594, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:53:16 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381596, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:53:16 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381596, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | WARNING: no policy specified for dn/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Principal "dn/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | WARNING: no policy specified for om/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Principal "om/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-18 07:00:11,987 WARN ipc.Server: Auth failed for 172.18.0.6:49922:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for scm/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 20191018T070011Z
kdc_1       | Principal "scm/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
om_1        | 2019-10-18 07:00:11,993 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Generiting keytab
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | WARNING: no policy specified for testuser/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Principal "testuser/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | WARNING: no policy specified for testuser2/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Principal "testuser2/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-18 07:00:11,994 WARN ipc.Server: Auth failed for 172.18.0.6:49924:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-18 07:00:11,999 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191018T070011Z
s3g_1       | Oct 18, 2019 7:00:12 AM org.glassfish.jersey.internal.Errors logErrors
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | MultiException stack 1 of 1
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | javax.enterprise.inject.CreationException
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-18 07:00:12,000 WARN ipc.Server: Auth failed for 172.18.0.6:49926:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191018T070011Z
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-18 07:00:12,005 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 20191018T070011Z
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-18 07:00:12,006 WARN ipc.Server: Auth failed for 172.18.0.6:49928:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191018T070011Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-18 07:00:12,012 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 20191018T070011Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | WARNING: no policy specified for s3g/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Principal "s3g/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:53:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1571381600, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 18 06:53:20 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 18 06:53:21 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Oct 18 06:53:21 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:53:21 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Oct 18 06:53:21 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 18 06:53:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381609, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:00:12,012 WARN ipc.Server: Auth failed for 172.18.0.6:49930:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 18 06:53:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381611, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-10-18 07:00:12,016 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 18 06:53:31 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381611, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 20191018T070011Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 18 06:53:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381611, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Oct 18 06:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Oct 18 06:53:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 18 06:53:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:53:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:53:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:53:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:54:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:54:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:54:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:54:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 06:54:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:54:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:54:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:54:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 18 06:54:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 18 06:54:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 18 06:54:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 18 06:54:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381625, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Oct 18 06:54:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Oct 18 06:54:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 18 06:54:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 18 06:54:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 18 06:54:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:12,017 WARN ipc.Server: Auth failed for 172.18.0.6:49932:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 18 06:54:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018T070011Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 18 06:54:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 18 06:54:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 06:54:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381676, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,833 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 06:54:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 18 06:54:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	... 92 more
kdc_1       | Oct 18 06:55:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:55:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 20191018T070011Z
kdc_1       | Oct 18 06:55:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:55:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:55:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:55:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Oct 18 06:55:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381697, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Oct 18 06:55:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:55:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:55:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 06:55:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:55:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:55:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:55:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 18 06:55:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 06:55:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381719, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 18 06:55:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 18 06:55:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 06:55:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 06:55:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 06:55:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:55:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:00:13,834 WARN ipc.Server: Auth failed for 172.18.0.6:49942:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:55:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 20191018T070013Z
kdc_1       | Oct 18 06:56:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:56:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 06:56:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 18 06:56:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,841 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 20191018T070013Z
kdc_1       | Oct 18 06:56:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 06:56:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 06:56:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	... 101 more
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 06:56:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 06:56:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 06:56:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:56:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381743, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2019-10-18 07:00:12,022 WARN servlet.ServletHandler: 
kdc_1       | Oct 18 06:56:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:56:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 
kdc_1       | Oct 18 06:56:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
kdc_1       | Oct 18 06:56:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | Oct 18 06:56:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Oct 18 06:56:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Oct 18 06:56:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 18 06:56:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 06:56:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 18 06:56:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 06:57:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 18 06:57:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 18 06:57:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 18 06:57:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Oct 18 06:57:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Oct 18 06:57:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | Oct 18 06:57:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 06:57:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381793, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-18 07:00:13,841 WARN ipc.Server: Auth failed for 172.18.0.6:49944:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 06:57:28 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 18 06:57:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Oct 18 06:57:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Oct 18 06:57:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,847 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 18 06:57:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Oct 18 06:57:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 18 06:57:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Oct 18 06:57:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Oct 18 06:57:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Oct 18 06:57:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 18 06:57:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 06:57:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:58:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:58:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:58:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 06:58:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 06:58:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 06:58:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 06:58:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 18 06:58:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 18 06:58:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 18 06:58:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 06:58:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 18 06:58:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Oct 18 06:58:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
kdc_1       | Oct 18 06:58:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
kdc_1       | Oct 18 06:58:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Oct 18 06:58:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 18 06:58:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,849 WARN ipc.Server: Auth failed for 172.18.0.6:49946:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 18 06:58:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 18 06:58:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 18 06:58:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381848, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 18 06:58:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381935, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 20191018T070013Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 18 06:58:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381935, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Oct 18 06:58:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381935, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,854 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Oct 18 06:59:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381935, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 18 06:59:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381943, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:59:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381943, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:59:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381946, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 18 06:59:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381946, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 18 06:59:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381946, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 18 06:59:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381946, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 18 06:59:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381946, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 18 06:59:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381946, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 06:59:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381959, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 06:59:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381959, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 06:59:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381959, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 18 06:59:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381965, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 18 06:59:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381965, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 18 06:59:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571381965, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 18 06:59:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571381970, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Oct 18 07:00:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	... 33 more
kdc_1       | Oct 18 07:00:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
kdc_1       | Oct 18 07:00:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Oct 18 07:00:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Oct 18 07:00:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Oct 18 07:00:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
kdc_1       | Oct 18 07:00:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 07:00:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 07:00:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 07:00:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 07:00:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 2019-10-18 07:00:13,855 WARN ipc.Server: Auth failed for 172.18.0.6:49948:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 07:00:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 18 07:00:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 18 07:01:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 18 07:01:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,861 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 07:01:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 18 07:01:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 18 07:01:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 18 07:01:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 07:01:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 07:01:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 07:01:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 07:01:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 18 07:01:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 07:01:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 07:01:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 07:01:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 07:01:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Oct 18 07:01:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 07:01:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 18 07:01:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 18 07:01:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 18 07:02:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Oct 18 07:02:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 18 07:02:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 18 07:02:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,861 WARN ipc.Server: Auth failed for 172.18.0.6:49950:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 18 07:02:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 20191018T070013Z
kdc_1       | Oct 18 07:02:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 07:02:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 07:02:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-18 07:00:13,867 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 07:02:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 20191018T070013Z
kdc_1       | Oct 18 07:02:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 07:02:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	... 60 more
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 07:03:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382193, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 07:03:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382193, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 07:03:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382199, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 18 07:03:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382199, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 18 07:04:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382270, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 18 07:04:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382270, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 18 07:04:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382277, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 18 07:04:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382277, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 07:04:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382285, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 18 07:04:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382285, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	... 92 more
kdc_1       | Oct 18 07:04:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382291, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 07:04:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382291, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 07:05:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382301, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 18 07:05:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382301, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 18 07:05:11 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382311, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 20191018T070011Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 07:05:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382311, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 18 07:05:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382319, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 07:05:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382319, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,867 WARN ipc.Server: Auth failed for 172.18.0.6:49952:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | Oct 18 07:05:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382329, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Oct 18 07:05:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382329, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Oct 18 07:05:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382336, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 18 07:05:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382336, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 18 07:05:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382342, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 18 07:05:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382342, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 07:05:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382348, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 18 07:05:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382348, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 07:05:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382358, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,873 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 07:06:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382358, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 18 07:08:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382489, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
kdc_1       | Oct 18 07:08:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382489, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 07:08:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382499, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 07:08:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382499, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 18 07:08:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382509, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 18 07:08:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382509, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Oct 18 07:08:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382517, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 18 07:08:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382517, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Oct 18 07:08:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382528, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
kdc_1       | Oct 18 07:08:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382528, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 18 07:08:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382534, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 18 07:08:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382534, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 18 07:09:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382540, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 18 07:09:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382540, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 18 07:09:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382546, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 18 07:09:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382546, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 18 07:09:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382555, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 18 07:09:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382555, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 18 07:09:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382563, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-10-18 07:00:12,024 WARN server.HttpChannel: //s3g:9878/bucket-test123
kdc_1       | Oct 18 07:09:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382563, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 18 07:09:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382572, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Oct 18 07:09:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382572, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 18 07:09:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382581, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Oct 18 07:09:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382581, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 18 07:09:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382587, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 18 07:09:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382587, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 18 07:09:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382597, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 18 07:09:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382597, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 2019-10-18 07:00:13,874 WARN ipc.Server: Auth failed for 172.18.0.6:49954:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 18 07:10:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382606, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 20191018T070013Z
kdc_1       | Oct 18 07:10:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382606, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Oct 18 07:10:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382612, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Oct 18 07:10:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382612, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-18 07:00:13,879 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 18 07:10:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382620, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191018T070013Z
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 18 07:10:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382620, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 18 07:10:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382625, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 18 07:10:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382625, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 18 07:10:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382631, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 18 07:10:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382631, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 18 07:10:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382637, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 18 07:10:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382637, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 18 07:10:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382644, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 18 07:10:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382644, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 18 07:10:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382651, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 18 07:10:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382651, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 18 07:10:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382659, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 18 07:11:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382659, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 18 07:11:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382666, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Oct 18 07:11:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382666, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Oct 18 07:11:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382673, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 18 07:11:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1571382673, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 18 07:11:18 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382678, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 18 07:11:18 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.6: ISSUE: authtime 1571382678, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 18 07:11:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1571382001, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:00:13,880 WARN ipc.Server: Auth failed for 172.18.0.6:49956:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 20191018T070013Z
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-18 07:00:13,885 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 20191018T070013Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	... 13 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-18 07:00:13,886 WARN ipc.Server: Auth failed for 172.18.0.6:49958:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018T070013Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:00:13,891 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 20191018T070013Z
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-18 07:00:13,892 WARN ipc.Server: Auth failed for 172.18.0.6:49960:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 20191018T070013Z
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-18 07:00:13,897 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 20191018T070013Z
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-18 07:00:13,897 WARN ipc.Server: Auth failed for 172.18.0.6:49962:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070013Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-18 07:00:18,406 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	... 60 more
om_1        | 2019-10-18 07:00:18,407 WARN ipc.Server: Auth failed for 172.18.0.6:49986:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 20191018T070017Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
om_1        | 20191018T070017Z
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	... 92 more
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191018T070011Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | e19387b2b668643c60141c20b62200dc3ef1025cbdcceff2e21f3f4ad15e0a7d, signature=fd3333aeada20555ff07fc565cfab7c8091a908373633576f98f4833bd7dba8a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:00:18,415 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 20191018T070017Z
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 2019-10-18 07:00:13,835 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:00:18,415 WARN ipc.Server: Auth failed for 172.18.0.6:49988:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-10-18 07:00:13,842 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070017Z
s3g_1       | 20191018T070013Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:00:18,421 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-10-18 07:00:13,843 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070017Z
s3g_1       | 20191018T070013Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 2019-10-18 07:00:13,849 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:13,850 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 2019-10-18 07:00:13,856 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 2019-10-18 07:00:13,856 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-10-18 07:00:13,862 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:00:18,421 WARN ipc.Server: Auth failed for 172.18.0.6:49990:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-10-18 07:00:13,862 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
om_1        | 20191018T070017Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-10-18 07:00:13,868 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:00:18,429 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
om_1        | 20191018T070017Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 2019-10-18 07:00:13,868 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:13,874 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 2019-10-18 07:00:13,875 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191018T070013Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 2019-10-18 07:00:13,881 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 2019-10-18 07:00:13,881 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 2019-10-18 07:00:13,887 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:00:18,430 WARN ipc.Server: Auth failed for 172.18.0.6:49992:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 20191018T070017Z
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 2019-10-18 07:00:13,887 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-18 07:00:18,437 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
om_1        | 20191018T070017Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 2019-10-18 07:00:13,892 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 2019-10-18 07:00:13,893 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 2019-10-18 07:00:13,898 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:13,898 [qtp359368949-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 2019-10-18 07:00:13,899 [qtp359368949-27] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-18 07:00:18,437 WARN ipc.Server: Auth failed for 172.18.0.6:49994:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 20191018T070017Z
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-18 07:00:18,442 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191018T070017Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-18 07:00:18,442 WARN ipc.Server: Auth failed for 172.18.0.6:49996:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070017Z
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:00:18,447 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 20191018T070017Z
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-10-18 07:00:18,449 WARN ipc.Server: Auth failed for 172.18.0.6:49998:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 20191018T070017Z
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:00:18,454 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070017Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-18 07:00:18,454 WARN ipc.Server: Auth failed for 172.18.0.6:50000:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 20191018T070017Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:00:18,458 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018T070017Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-18 07:00:18,459 WARN ipc.Server: Auth failed for 172.18.0.6:50002:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 20191018T070017Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-18 07:00:18,463 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 20191018T070017Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Oct 18, 2019 7:00:13 AM org.glassfish.jersey.internal.Errors logErrors
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | MultiException stack 1 of 1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-18 07:00:18,463 WARN ipc.Server: Auth failed for 172.18.0.6:50004:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 20191018T070017Z
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-18 07:00:18,468 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 20191018T070017Z
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-18 07:00:18,468 WARN ipc.Server: Auth failed for 172.18.0.6:50006:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 20191018T070017Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-18 07:00:23,252 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 20191018T070023Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-18 07:00:23,253 WARN ipc.Server: Auth failed for 172.18.0.6:50030:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 20191018T070023Z
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-18 07:00:23,261 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 20191018T070023Z
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-18 07:00:23,262 WARN ipc.Server: Auth failed for 172.18.0.6:50032:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 20191018T070023Z
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:00:23,269 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191018T070023Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	... 92 more
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191018T070013Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-18 07:00:23,270 WARN ipc.Server: Auth failed for 172.18.0.6:50034:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 20191018T070023Z
s3g_1       | 	... 101 more
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 
om_1        | 2019-10-18 07:00:23,277 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-10-18 07:00:13,905 WARN servlet.ServletHandler: 
om_1        | 20191018T070023Z
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-18 07:00:23,277 WARN ipc.Server: Auth failed for 172.18.0.6:50036:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 20191018T070023Z
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-10-18 07:00:23,283 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 20191018T070023Z
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-10-18 07:00:23,283 WARN ipc.Server: Auth failed for 172.18.0.6:50038:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 20191018T070023Z
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-18 07:00:23,290 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 20191018T070023Z
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-18 07:00:23,290 WARN ipc.Server: Auth failed for 172.18.0.6:50040:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 20191018T070023Z
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-18 07:00:23,297 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 20191018T070023Z
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	... 60 more
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-18 07:00:23,297 WARN ipc.Server: Auth failed for 172.18.0.6:50042:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 20191018T070023Z
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-18 07:00:23,305 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191018T070023Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	... 101 more
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 2019-10-18 07:00:13,908 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-18 07:00:23,305 WARN ipc.Server: Auth failed for 172.18.0.6:50044:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191018T070023Z
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 
om_1        | 2019-10-18 07:00:23,313 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 20191018T070023Z
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	... 13 more
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-18 07:00:23,314 WARN ipc.Server: Auth failed for 172.18.0.6:50046:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 20191018T070023Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:00:23,320 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191018T070023Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-18 07:00:23,321 WARN ipc.Server: Auth failed for 172.18.0.6:50048:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 20191018T070023Z
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	... 33 more
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 07:00:23,327 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191018T070023Z
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 20191018/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-18 07:00:23,327 WARN ipc.Server: Auth failed for 172.18.0.6:50050:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 20191018T070023Z
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 20191018/us-west-1/s3/aws4_request
om_1        | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-18 07:00:27,252 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:00:27,264 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:00:27,977 [IPC Server handler 1 on 9862] INFO       - created volume:fstest for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:00:29,967 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070013Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:00:29,982 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 7600f5b051c6bf325610627c3f0ba006b24e7a0b2e665174552b97afa6a1e2ce, signature=5e8b367c3f05f92eb465c1116b4a0b0740469897039839bdeeb08df32a8561c2, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:00:30,778 [IPC Server handler 16 on 9862] INFO       - created volume:fstest2 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-18 07:00:32,786 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-18 07:00:32,801 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-18 07:00:36,040 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-18 07:00:36,053 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-18 07:00:38,755 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:00:38,770 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-18 07:00:41,917 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:00:41,936 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:00:44,924 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-18 07:00:44,946 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:00:47,557 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-18 07:00:47,571 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-18 07:00:50,717 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:00:50,736 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:00:55,278 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:00:55,290 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:00:58,347 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:00:58,360 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-18 07:01:02,870 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-18 07:01:02,883 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-18 07:01:05,911 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-18 07:01:05,924 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 101 more
om_1        | 2019-10-18 07:01:08,903 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:01:08,918 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:11,742 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,407 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:01:11,756 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:01:14,737 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:01:14,750 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:01:17,699 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,416 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:01:17,718 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:01:22,111 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,416 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:01:22,122 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
om_1        | 2019-10-18 07:01:25,155 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,422 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:01:25,168 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:01:28,030 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:01:28,043 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:32,251 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:01:32,270 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:34,997 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,423 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:01:35,009 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | 2019-10-18 07:01:38,036 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,431 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:01:38,056 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:40,723 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:01:40,735 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:43,983 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:01:44,000 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:01:46,717 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:01:46,729 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:49,657 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,431 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:01:49,668 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:52,299 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:01:52,312 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:55,582 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:01:55,594 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:01:58,590 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:01:58,604 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:18,438 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:02:03,097 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:02:03,116 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:02:07,600 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,438 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:02:07,613 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:02:10,553 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:02:10,572 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 2019-10-18 07:02:13,550 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,443 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:02:13,568 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:02:16,662 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:18,443 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:02:16,681 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:02:21,821 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:02:21,839 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
om_1        | 2019-10-18 07:02:26,186 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-18 07:00:18,450 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:02:26,197 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:02:30,988 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:02:31,012 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:18,450 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:02:33,909 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018T070017Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:02:33,933 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
om_1        | 2019-10-18 07:02:37,094 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:02:37,112 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:02:41,323 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:02:41,335 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:02:41,832 [IPC Server handler 17 on 9862] ERROR      - Check access operation failed for volume:pqrs
s3g_1       | 2019-10-18 07:00:18,454 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume pqrs is not found
s3g_1       | 20191018T070017Z
om_1        | 	at org.apache.hadoop.ozone.om.VolumeManagerImpl.checkAccess(VolumeManagerImpl.java:685)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer.checkAccess(OzoneNativeAuthorizer.java:83)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1622)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1588)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getVolumeInfo(OzoneManager.java:1745)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.infoVolume(OzoneManagerRequestHandler.java:520)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:177)
s3g_1       | 2019-10-18 07:00:18,455 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:208)
s3g_1       | 20191018T070017Z
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:18,459 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 20191018T070017Z
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 2019-10-18 07:00:18,459 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 20191018T070017Z
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 2019-10-18 07:00:18,464 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 20191018T070017Z
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:03:15,524 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:03:15,538 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-18 07:00:18,464 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:03:18,902 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:03:18,904 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 2019-10-18 07:03:18,908 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-18 07:00:18,469 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:03:21,656 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:03:21,667 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:03:25,113 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:03:25,115 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-18 07:00:18,469 [qtp359368949-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 2019-10-18 07:03:25,118 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-18 07:00:18,469 [qtp359368949-27] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 2019-10-18 07:04:25,451 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:04:25,452 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:04:25,457 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:04:26,616 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:04:26,617 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:04:26,621 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:04:28,288 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:04:28,290 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:04:28,297 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-18 07:04:28,932 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-18 07:04:28,933 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-18 07:04:28,937 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:04:29,598 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:04:29,599 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:04:29,602 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:04:32,331 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:04:32,342 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-18 07:04:35,541 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-18 07:04:35,541 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:04:35,544 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:04:36,262 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-18 07:04:36,263 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:04:36,265 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:04:36,272 [IPC Server handler 11 on 9862] ERROR      - S3Bucket Creation Failed for userName: 2724f42bcd3225359401cb62da89c51d, s3BucketName bucket-57531, VolumeName s32724f42bcd3225359401cb62da89c51d
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-18 07:04:39,656 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-18 07:04:39,668 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-18 07:04:42,955 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-18 07:04:42,956 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-18 07:04:42,958 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:04:43,610 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:04:43,611 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:04:43,614 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:04:44,300 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:04:44,301 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:04:44,303 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:04:46,936 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:04:46,947 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-18 07:04:50,147 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-18 07:04:50,147 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-18 07:04:50,150 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-18 07:04:50,820 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-18 07:04:50,821 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-18 07:04:50,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-18 07:04:53,602 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:04:53,613 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:04:56,969 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:04:56,970 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-18 07:04:56,974 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-10-18 07:04:57,651 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-18 07:04:57,652 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-18 07:04:57,654 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-18 07:04:58,409 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 07:04:58,410 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:04:58,414 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 07:04:59,304 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:04:59,305 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-18 07:04:59,311 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-10-18 07:05:00,627 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-18 07:05:00,628 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-18 07:05:00,631 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-18 07:05:03,689 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:05:03,700 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:05:06,990 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:05:06,992 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-18 07:05:06,994 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-18 07:05:07,815 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-18 07:05:07,816 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-18 07:05:07,820 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 07:05:08,716 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:05:08,717 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-18 07:05:08,719 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-18 07:05:09,528 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-18 07:05:09,529 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-18 07:05:09,531 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-18 07:05:10,282 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:05:10,282 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-18 07:05:10,284 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-18 07:05:13,382 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:05:13,414 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-18 07:05:16,665 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-18 07:05:16,665 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-18 07:05:16,668 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-18 07:05:17,394 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-18 07:05:17,395 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-18 07:05:17,399 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-18 07:05:18,206 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-18 07:05:18,206 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-18 07:05:18,208 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-18 07:05:18,972 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-18 07:05:18,972 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:05:18,975 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:05:18,996 [IPC Server handler 16 on 9862] ERROR      - MultipartUpload: /s32724f42bcd3225359401cb62da89c51d/bucket-37397/multipartKey2Part number: 1size 6 is less than minimum part size 5242880
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:05:18,997 [IPC Server handler 16 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-37397key: multipartKey2
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-18 07:05:21,672 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-18 07:05:21,683 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-18 07:05:24,924 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-18 07:05:24,924 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-18 07:05:24,927 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:05:25,639 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-18 07:05:25,639 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-18 07:05:25,642 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-18 07:05:27,175 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-18 07:05:27,175 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-10-18 07:05:27,178 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-18 07:05:28,748 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:05:28,749 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-18 07:05:28,751 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-18 07:05:28,775 [IPC Server handler 1 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-37397key: multipartKey3
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:195)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | Oct 18, 2019 7:00:18 AM org.glassfish.jersey.internal.Errors logErrors
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 2019-10-18 07:05:31,364 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | MultiException stack 1 of 1
om_1        | 2019-10-18 07:05:31,379 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 2019-10-18 07:05:34,614 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-18 07:05:34,614 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-18 07:05:34,617 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-18 07:05:35,288 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:05:35,289 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:05:35,291 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-18 07:05:37,990 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-18 07:05:38,000 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-18 07:05:41,283 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-18 07:05:41,284 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 2019-10-18 07:05:41,287 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-10-18 07:05:41,302 [IPC Server handler 11 on 9862] ERROR      - Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-37397key: multipartKey5
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:116)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-18 07:05:44,007 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-18 07:05:44,019 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-18 07:05:47,226 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 07:05:47,227 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:05:47,229 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-18 07:05:47,244 [IPC Server handler 11 on 9862] ERROR      - ALLOCATE_KEY failed for Key: multipartKey in volume/bucket:s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:471)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:423)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:179)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-18 07:05:49,744 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:05:49,757 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-18 07:05:53,062 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-18 07:05:53,063 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-18 07:05:53,066 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-18 07:05:53,864 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:05:53,865 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:05:53,868 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-18 07:05:54,809 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-18 07:05:54,810 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-18 07:05:54,818 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-18 07:05:55,619 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-18 07:05:55,620 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-18 07:05:55,622 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-18 07:05:56,410 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:05:56,410 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:05:56,413 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-18 07:05:57,166 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-18 07:05:57,167 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-18 07:05:57,169 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-18 07:05:57,836 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-18 07:05:57,837 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-18 07:05:57,845 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-18 07:06:00,599 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-18 07:06:00,613 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-18 07:06:04,094 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:06:04,094 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:06:04,097 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:06:04,184 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:06:04,184 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-18 07:06:04,189 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:06:04,198 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-18 07:06:04,198 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-18 07:06:04,203 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-18 07:06:04,212 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-18 07:06:04,213 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-18 07:06:04,217 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-10-18 07:06:16,503 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:06:16,503 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-18 07:06:16,512 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-18 07:07:04,397 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-18 07:07:04,398 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:07:04,401 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-18 07:07:04,521 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-18 07:07:04,521 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-18 07:07:04,524 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-18 07:07:04,580 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:07:04,580 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-18 07:07:04,583 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-18 07:08:05,790 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:05,790 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:05,794 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-18 07:08:06,109 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 2019-10-18 07:08:06,110 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-18 07:08:06,112 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-18 07:08:06,530 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:06,530 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:06,533 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-18 07:08:07,370 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-18 07:08:07,371 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-18 07:08:07,373 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:08:07,444 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:08:07,444 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:08:07,445 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:08:07,445 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-18 07:08:07,446 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 92 more
om_1        | 2019-10-18 07:08:07,449 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:08:08,458 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:08:08,459 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:08:08,461 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-18 07:08:11,569 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:08:11,581 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:08:12,112 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:12,113 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-18 07:08:12,119 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-18 07:08:12,123 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-18 07:08:12,124 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-18 07:08:12,128 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:08:12,131 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:08:12,132 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-18 07:08:12,133 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-18 07:08:12,151 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-18 07:08:12,152 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-18 07:08:12,154 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:08:12,157 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-18 07:08:12,157 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:12,159 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:08:12,504 [IPC Server handler 11 on 9862] ERROR      - MultipartUpload Commit is failed for Key:mpyawscli in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 9b4ff034-fccf-4292-b3e1-1674272929ab-102982114614444192
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:156)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 2019-10-18 07:00:18,473 WARN servlet.ServletHandler: 
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-18 07:08:12,505 [IPC Server handler 9 on 9862] ERROR      - MultipartUpload Commit is failed for Key:mpyawscli in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 9b4ff034-fccf-4292-b3e1-1674272929ab-102982114614444192
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:156)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-18 07:08:12,506 [IPC Server handler 14 on 9862] ERROR      - MultipartUpload Commit is failed for Key:mpyawscli in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 9b4ff034-fccf-4292-b3e1-1674272929ab-102982114614444192
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:156)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 2019-10-18 07:08:12,508 [IPC Server handler 12 on 9862] ERROR      - MultipartUpload Commit is failed for Key:mpyawscli in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 9b4ff034-fccf-4292-b3e1-1674272929ab-102982114614444192
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:156)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-18 07:08:12,512 [IPC Server handler 13 on 9862] ERROR      - MultipartUpload Commit is failed for Key:mpyawscli in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-37397
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 9b4ff034-fccf-4292-b3e1-1674272929ab-102982114614444192
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:156)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	... 33 more
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-18 07:08:14,959 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-18 07:08:14,960 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-10-18 07:08:14,988 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-18 07:08:15,894 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-18 07:08:15,895 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-18 07:08:15,897 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-18 07:08:16,568 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:16,568 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:16,572 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:08:17,554 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:17,554 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-18 07:08:17,558 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:08:18,234 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:18,235 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:18,242 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 2019-10-18 07:08:20,924 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 2019-10-18 07:08:20,938 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:08:24,210 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-10-18 07:08:24,210 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-18 07:08:24,215 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-18 07:08:25,094 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 07:08:25,094 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:08:25,097 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 07:08:25,751 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-18 07:08:25,751 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-10-18 07:08:25,753 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-18 07:08:26,987 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-18 07:08:26,988 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-18 07:08:26,991 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-18 07:08:27,974 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-18 07:08:27,974 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-18 07:08:27,980 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-18 07:08:28,649 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:28,649 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:28,651 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-18 07:08:31,429 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 07:08:31,450 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:08:34,679 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 07:08:34,680 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-18 07:08:34,682 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-18 07:08:35,373 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-18 07:08:35,375 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-18 07:08:35,378 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-18 07:08:36,074 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-18 07:08:36,075 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-18 07:08:36,077 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-18 07:08:38,830 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-18 07:08:38,841 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-18 07:08:42,156 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:42,157 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:42,160 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 60 more
om_1        | 2019-10-18 07:08:42,835 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-18 07:08:42,835 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-18 07:08:42,838 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-18 07:08:43,546 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:08:43,547 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:08:43,549 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-18 07:08:44,334 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-18 07:08:44,334 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:08:44,337 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:08:44,986 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-18 07:08:44,986 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	... 92 more
om_1        | 2019-10-18 07:08:44,990 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:08:45,761 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:08:45,761 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:08:45,764 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-18 07:08:46,455 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-18 07:08:46,455 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-18 07:08:46,458 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-18 07:08:47,248 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:08:47,248 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-18 07:08:47,250 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:08:49,756 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:08:49,771 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:08:53,387 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:08:53,388 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-18 07:08:53,391 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-18 07:08:54,118 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-18 07:08:54,118 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:08:54,120 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-18 07:08:56,714 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-18 07:08:56,728 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:08:59,960 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:08:59,961 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:08:59,964 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:09:02,595 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-18 07:09:02,607 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-18 07:09:05,853 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-18 07:09:05,854 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-18 07:09:05,857 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 101 more
s3g_1       | 2019-10-18 07:00:18,474 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-18 07:09:08,526 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-18 07:09:08,536 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
om_1        | 2019-10-18 07:09:11,690 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:11,690 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 2019-10-18 07:09:11,693 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-18 07:09:12,341 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-18 07:09:12,342 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-18 07:09:12,344 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-18 07:09:13,203 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-18 07:09:13,204 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-18 07:09:13,206 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 2019-10-18 07:09:14,016 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:14,017 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-10-18 07:09:14,020 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:14,722 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:14,723 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:09:14,728 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:18,474 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-18 07:09:18,484 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-18 07:09:21,675 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-18 07:09:21,675 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-18 07:09:21,683 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:22,384 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:22,384 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 2019-10-18 07:09:22,387 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-18 07:09:23,071 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:23,072 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:09:23,075 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:25,753 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-18 07:09:25,767 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-18 07:09:28,960 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-18 07:09:28,960 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-18 07:09:28,963 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-18 07:09:29,761 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:09:29,762 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-18 07:09:29,768 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-18 07:09:30,492 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-18 07:09:30,493 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-18 07:09:30,501 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:31,174 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:31,175 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:09:31,178 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:31,895 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-18 07:09:31,895 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-18 07:09:31,898 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-10-18 07:09:34,679 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-18 07:09:34,690 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-18 07:09:37,849 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-18 07:09:37,850 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-18 07:09:37,852 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:09:38,583 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-18 07:09:38,584 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-18 07:09:38,587 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
om_1        | 2019-10-18 07:09:39,268 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 2019-10-18 07:09:39,268 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-18 07:09:39,271 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-18 07:09:39,957 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:39,958 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-18 07:09:39,961 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-18 07:09:40,678 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-18 07:09:40,678 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-18 07:09:40,681 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-18 07:09:43,359 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-18 07:09:43,370 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-18 07:09:46,570 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-18 07:09:46,570 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:09:46,573 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:09:49,168 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-18 07:09:49,179 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-18 07:09:52,432 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-18 07:09:52,432 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-18 07:09:52,434 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-18 07:09:53,053 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:09:53,053 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-18 07:09:53,056 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-18 07:09:53,867 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-18 07:09:53,867 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-18 07:09:53,870 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-18 07:09:54,607 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-18 07:09:54,607 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-18 07:09:54,609 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 33 more
om_1        | 2019-10-18 07:09:55,254 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-18 07:09:55,255 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-18 07:09:55,257 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-10-18 07:09:55,961 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-18 07:09:55,962 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-18 07:09:55,964 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-18 07:09:56,628 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-18 07:09:56,629 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:09:56,631 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-18 07:09:59,371 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-18 07:09:59,382 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:02,642 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 2019-10-18 07:10:02,643 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 2019-10-18 07:10:02,646 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-10-18 07:10:03,346 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:10:03,347 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-18 07:10:03,350 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-18 07:10:04,177 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-18 07:10:04,177 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-18 07:10:04,179 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 07:10:04,820 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-10-18 07:10:04,820 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-18 07:10:04,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:05,509 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-18 07:10:05,510 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-18 07:10:05,513 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-18 07:10:08,252 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:10:08,262 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:11,651 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-18 07:10:11,652 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-18 07:10:11,655 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-18 07:10:14,392 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-18 07:10:14,402 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-18 07:10:17,655 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-18 07:10:17,656 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-18 07:10:17,658 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-18 07:10:18,381 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-18 07:10:18,382 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-18 07:10:18,384 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-18 07:10:19,108 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-18 07:10:19,108 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-18 07:10:19,110 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 60 more
om_1        | 2019-10-18 07:10:21,815 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-18 07:10:21,828 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:25,059 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-18 07:10:25,060 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:10:25,063 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-18 07:10:27,665 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-18 07:10:27,678 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-18 07:10:30,786 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:10:30,787 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-18 07:10:30,789 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:33,461 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:10:33,472 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:36,790 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:10:36,791 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:10:36,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:10:39,636 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:10:39,648 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:10:42,980 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-18 07:10:42,980 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	... 92 more
om_1        | 2019-10-18 07:10:42,983 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:10:43,747 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:10:43,747 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:10:43,749 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018T070017Z
om_1        | 2019-10-18 07:10:46,541 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:10:46,554 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | b522e76779062f4d96f2137925245208070d8ae4ccb348c2dddb78fa195ee91e, signature=2d199eeb6169f348231cced50c616f3934426236c7898ca9e9bedc843337c3f0, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:10:49,715 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-18 07:10:49,716 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-18 07:10:49,719 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-18 07:10:50,427 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:10:50,428 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:10:50,430 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-18 07:10:53,170 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:10:53,182 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-18 07:10:57,838 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-18 07:10:57,838 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-18 07:10:57,846 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-18 07:10:58,497 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-18 07:10:58,498 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-18 07:10:58,501 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:11:01,221 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:11:01,232 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-18 07:11:04,828 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
om_1        | 2019-10-18 07:11:04,828 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-18 07:11:04,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-18 07:11:05,477 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-18 07:11:05,478 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:11:05,480 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-18 07:11:06,144 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-18 07:11:06,144 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-18 07:00:23,254 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
om_1        | 2019-10-18 07:11:06,146 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:11:08,857 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191018/us-west-1/s3/aws4_request
om_1        | 2019-10-18 07:11:08,870 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-18 07:11:12,918 [Socket Reader #1 for port 9862] INFO       - 83598f1ffb25a215148bda0b8867ad4a827f96d9c69c6c7729614fb9423d2afc
s3g_1       | 2019-10-18 07:00:23,263 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-18 07:11:12,918 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-18 07:11:12,921 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-18 07:11:15,545 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-18 07:11:15,556 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,263 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,271 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,271 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,278 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,278 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,284 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,285 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,291 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,292 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,298 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,299 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,307 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,307 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,315 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,315 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,322 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,322 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-18 07:00:23,328 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-18 07:00:23,329 [qtp359368949-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
s3g_1       | 2019-10-18 07:00:23,329 [qtp359368949-27] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Oct 18, 2019 7:00:23 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-10-18 07:00:23,334 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-18 07:00:23,336 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191018T070023Z
s3g_1       | 20191018/us-west-1/s3/aws4_request
s3g_1       | 30ec46d196ed519592094349aea239ee08d2ccce178ee3466515f3d7c5bb6a64, signature=4da9ff3478897cfee89329f1bca987e57dd8a27f96bf46083b02d6045a1b1778, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-18 07:03:18,927 [qtp359368949-30] INFO       - Location is /bucket-03493
s3g_1       | 2019-10-18 07:03:25,794 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2019-10-18 07:03:25,842 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2019-10-18 07:03:25,842 INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2019-10-18 07:03:25,844 WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2019-10-18 07:04:35,557 [qtp359368949-227] INFO       - Location is /bucket-57531
s3g_1       | 2019-10-18 07:04:36,278 [qtp359368949-226] INFO       - Location is /bucket-57531
s3g_1       | 2019-10-18 07:04:42,971 [qtp359368949-227] INFO       - Location is /bucket-13034
s3g_1       | 2019-10-18 07:04:44,354 [qtp359368949-227] ERROR      - Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:103)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:81)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:250)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-18 07:04:50,168 [qtp359368949-173] INFO       - Location is /bucket-62427
s3g_1       | 2019-10-18 07:04:56,991 [qtp359368949-173] INFO       - Location is /bucket-37397
s3g_1       | 2019-10-18 07:05:18,998 [qtp359368949-110] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-37397, key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-37397key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-18 07:05:28,776 [qtp359368949-173] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-37397, key: multipartKey3
s3g_1       | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-37397key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Oct 18, 2019 7:07:47 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=117, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:07:47 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=121, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:07:47 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=125, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:07:47 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=93, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:257)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:155)
s3g_1       | 	at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:144)
s3g_1       | 	at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:124)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:236)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:317)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:310)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:604)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:473)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:570)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:07:47 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=53, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:257)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:155)
s3g_1       | 	at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:144)
s3g_1       | 	at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:124)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:236)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:317)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:310)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:604)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:473)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:190)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2019-10-18 07:08:12,107 [qtp359368949-110] WARN       - Encountered exception java.io.IOException: Unexpected Storage Container Exception: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.ratis.protocol.GroupMismatchException: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: group-949BC68E43B3 not found. on the pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. The last committed block length is 0, uncommitted data length is 6291456 retry count 0
s3g_1       | 2019-10-18 07:08:12,114 [qtp359368949-111] WARN       - Encountered exception java.io.IOException: Unexpected Storage Container Exception: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.ratis.protocol.GroupMismatchException: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: group-949BC68E43B3 not found. on the pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. The last committed block length is 0, uncommitted data length is 8388608 retry count 0
s3g_1       | 2019-10-18 07:08:12,125 [qtp359368949-359] WARN       - Encountered exception java.io.IOException: Unexpected Storage Container Exception: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.ratis.protocol.GroupMismatchException: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: group-949BC68E43B3 not found. on the pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. The last committed block length is 0, uncommitted data length is 8388608 retry count 0
s3g_1       | 2019-10-18 07:08:12,142 [qtp359368949-173] WARN       - Encountered exception java.io.IOException: Unexpected Storage Container Exception: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.ratis.protocol.GroupMismatchException: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: group-949BC68E43B3 not found. on the pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. The last committed block length is 0, uncommitted data length is 8388608 retry count 0
s3g_1       | 2019-10-18 07:08:12,142 [qtp359368949-227] WARN       - Encountered exception java.io.IOException: Unexpected Storage Container Exception: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.ratis.protocol.GroupMismatchException: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e: group-949BC68E43B3 not found. on the pipeline Pipeline[ Id: 330696bd-70f3-40b2-95d6-949bc68e43b3, Nodes: 4746d23f-e8ca-4bc6-bc17-e9dd8c69511e{ip: 172.18.0.2, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}05927fc9-2042-483a-98e5-6075d8118b6c{ip: 172.18.0.10, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}9b428cf8-0805-4b46-95f2-cb42dae54452{ip: 172.18.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. The last committed block length is 0, uncommitted data length is 8388608 retry count 0
s3g_1       | 2019-10-18 07:08:42,172 [qtp359368949-111] INFO       - Location is /bucket-90039
s3g_1       | 2019-10-18 07:08:42,851 [qtp359368949-422] INFO       - Location is /destbucket-20913
s3g_1       | 2019-10-18 07:09:11,703 [qtp359368949-516] INFO       - Location is /bucket-32304
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=865, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=713, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=849, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=889, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=705, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=721, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=733, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=729, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=764, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=761, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=709, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=921, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:711)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:163)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=717, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=769, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=869, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=925, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:711)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:163)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=829, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=825, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=725, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=901, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=692, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=701, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=861, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=881, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=753, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=885, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=821, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=690, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=845, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=937, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:711)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:163)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor95.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=909, target=172.18.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=755, target=172.18.0.2:9858} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:61)
s3g_1       | 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:60)
s3g_1       | 	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:108)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
s3g_1       | 	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
s3g_1       | 	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=841, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=689, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 18, 2019 7:09:12 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=905, target=172.18.0.2:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2019-10-18 07:09:52,445 [qtp359368949-359] INFO       - Location is /bucket-01009
s3g_1       | 2019-10-18 07:10:02,659 [qtp359368949-173] INFO       - Location is /bucket-89750
s3g_1       | 2019-10-18 07:11:12,936 [qtp359368949-517] INFO       - Location is /bucket-16748
s3g_1       | 2019-10-18 07:11:18,483 [qtp359368949-419] ERROR      - Error: 
s3g_1       | java.lang.NullPointerException
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:78)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor18.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
