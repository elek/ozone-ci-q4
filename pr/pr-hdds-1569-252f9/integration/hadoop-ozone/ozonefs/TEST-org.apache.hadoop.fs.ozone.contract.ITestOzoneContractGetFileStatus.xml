<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="214.189" tests="18" errors="7" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.5.0-201fc85-SNAPSHOT/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.5.0-201fc85-SNAPSHOT/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.5.0-201fc85-SNAPSHOT/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.5.0-201fc85-SNAPSHOT/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.5.0-201fc85-SNAPSHOT/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.5.0-201fc85-SNAPSHOT/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.5.0-201fc85-SNAPSHOT/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/com/github/spotbugs/spotbugs/3.1.12/spotbugs-3.1.12.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/ow2/asm/asm-analysis/7.0/asm-analysis-7.0.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/7.0/asm-commons-7.0.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/7.0/asm-tree-7.0.jar:/home/user/.m2/repository/org/ow2/asm/asm-util/7.0/asm-util-7.0.jar:/home/user/.m2/repository/org/apache/bcel/bcel/6.3/bcel-6.3.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/org/dom4j/dom4j/2.1.1/dom4j-2.1.1.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter3175463345263246017.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-10-21T03-10-02_339-jvmRun1 surefire598402220236246853tmp surefire_904235630113644901190tmp"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.5.0-201fc85-SNAPSHOT/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.5.0-201fc85-SNAPSHOT/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.5.0-201fc85-SNAPSHOT/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.5.0-201fc85-SNAPSHOT/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.5.0-201fc85-SNAPSHOT/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.2.5/metrics-jvm-3.2.5.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-ganglia/3.2.5/metrics-ganglia-3.2.5.jar:/home/user/.m2/repository/info/ganglia/gmetric4j/gmetric4j/1.0.7/gmetric4j-1.0.7.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.5.0-201fc85-SNAPSHOT/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.5.0-201fc85-SNAPSHOT/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/com/github/spotbugs/spotbugs/3.1.12/spotbugs-3.1.12.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/ow2/asm/asm-analysis/7.0/asm-analysis-7.0.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/7.0/asm-commons-7.0.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/7.0/asm-tree-7.0.jar:/home/user/.m2/repository/org/ow2/asm/asm-util/7.0/asm-util-7.0.jar:/home/user/.m2/repository/org/apache/bcel/bcel/6.3/bcel-6.3.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/org/dom4j/dom4j/2.1.1/dom4j-2.1.1.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.9/jackson-jaxrs-json-provider-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.9/jackson-jaxrs-base-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre"/>
    <property name="surefire.excludesFile" value="/tools/ozone-bad-unit-tests"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter3175463345263246017.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/rt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_222-b10"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_222"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="java.vm.version" value="25.222-b10"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testListFilesEmptyDirectoryNonrecursive" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.403">
    <error message="Couldn&apos;t set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread" type="java.io.IOException"><![CDATA[java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 46 more
]]></error>
    <system-out><![CDATA[2019-10-21 05:00:35,867 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:35,959 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:35,963 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:35,990 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @859ms
2019-10-21 05:00:36,123 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-10-21 05:00:36,123 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-10-21 05:00:36,123 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-10-21 05:00:36,124 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-10-21 05:00:36,124 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-10-21 05:00:36,124 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-10-21 05:00:36,135 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-21 05:00:36,135 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-21 05:00:36,137 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-21 05:00:36,336 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@477b4cdf
2019-10-21 05:00:36,338 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-10-21 05:00:36,404 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-21 05:00:36,406 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-21 05:00:36,409 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-10-21 05:00:36,575 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-10-21 05:00:36,591 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:37,754 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(137)) - No pipeline exists in current db
2019-10-21 05:00:37,757 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:37,873 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-10-21 05:00:38,343 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-21 05:00:38,455 [Socket Reader #1 for port 37127] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37127
2019-10-21 05:00:38,482 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-21 05:00:38,484 [Socket Reader #1 for port 33530] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33530
2019-10-21 05:00:38,494 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-21 05:00:38,495 [Socket Reader #1 for port 43536] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43536
2019-10-21 05:00:38,521 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-10-21 05:00:38,643 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:38,661 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:38,672 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:38,675 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-10-21 05:00:38,676 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:38,676 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:38,709 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43536
2019-10-21 05:00:38,776 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-10-21 05:00:38,788 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-21 05:00:38,788 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-10-21 05:00:39,002 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:43536
2019-10-21 05:00:39,003 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-21 05:00:39,003 [IPC Server listener on 43536] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43536: starting
2019-10-21 05:00:39,005 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33530
2019-10-21 05:00:39,006 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:33530
2019-10-21 05:00:39,007 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-21 05:00:39,007 [IPC Server listener on 33530] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33530: starting
2019-10-21 05:00:39,009 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:37127
2019-10-21 05:00:39,010 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:37127
2019-10-21 05:00:39,011 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-21 05:00:39,011 [IPC Server listener on 37127] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37127: starting
2019-10-21 05:00:39,015 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35949
2019-10-21 05:00:39,016 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:39,048 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ba302e0{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:39,049 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c098bb3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:39,121 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70e659aa{/,file:///tmp/jetty-0.0.0.0-35949-scm-_-any-3959962001662295738.dir/webapp/,AVAILABLE}{/scm}
2019-10-21 05:00:39,126 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:35949}
2019-10-21 05:00:39,126 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3995ms
2019-10-21 05:00:39,128 [JUnit] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-10-21 05:00:39,128 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-10-21 05:00:39,130 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:35949
2019-10-21 05:00:39,136 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2102a4d5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-21 05:00:39,140 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:39,240 [JUnit] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-10-21 05:00:39,240 [JUnit] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-10-21 05:00:39,242 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:39,242 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:39,889 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-21 05:00:39,899 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: userTable
2019-10-21 05:00:39,900 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-10-21 05:00:39,900 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: volumeTable
2019-10-21 05:00:39,900 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-10-21 05:00:39,900 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: bucketTable
2019-10-21 05:00:39,901 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-10-21 05:00:39,901 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: keyTable
2019-10-21 05:00:39,901 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-10-21 05:00:39,901 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedTable
2019-10-21 05:00:39,902 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-10-21 05:00:39,902 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: openKeyTable
2019-10-21 05:00:39,902 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-10-21 05:00:39,902 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3Table
2019-10-21 05:00:39,902 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-10-21 05:00:39,903 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: multipartInfoTable
2019-10-21 05:00:39,903 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-10-21 05:00:39,903 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: dTokenTable
2019-10-21 05:00:39,903 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-10-21 05:00:39,904 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3SecretTable
2019-10-21 05:00:39,904 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-10-21 05:00:39,904 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: prefixTable
2019-10-21 05:00:39,904 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-10-21 05:00:39,904 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-21 05:00:39,905 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-21 05:00:39,905 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-21 05:00:40,270 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-21 05:00:40,271 [Socket Reader #1 for port 41423] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41423
2019-10-21 05:00:40,300 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1071)) - OzoneManager RPC server is listening at localhost/127.0.0.1:41423
2019-10-21 05:00:40,301 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-10-21 05:00:40,310 [IPC Server listener on 41423] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41423: starting
2019-10-21 05:00:40,310 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-21 05:00:40,315 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-10-21 05:00:40,319 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:40,320 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:40,323 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:40,326 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-10-21 05:00:40,326 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:40,326 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:40,329 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38704
2019-10-21 05:00:40,329 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:40,331 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bcec6a6{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:40,331 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4912d525{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:40,378 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@15fa55a6{/,file:///tmp/jetty-0.0.0.0-38704-ozoneManager-_-any-7804221658471405980.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-10-21 05:00:40,379 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f186450{HTTP/1.1,[http/1.1]}{0.0.0.0:38704}
2019-10-21 05:00:40,379 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5248ms
2019-10-21 05:00:40,379 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-21 05:00:40,381 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:38704
2019-10-21 05:00:40,643 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-21 05:00:40,711 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-252f9-3696506840 ip:192.168.157.255
2019-10-21 05:00:40,750 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-21 05:00:40,753 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/containers/hdds to VolumeSet
2019-10-21 05:00:40,757 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7e4d2287
2019-10-21 05:00:40,785 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7e4d2287
2019-10-21 05:00:40,958 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-21 05:00:41,046 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-21 05:00:41,054 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-21 05:00:41,056 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-21 05:00:41,058 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:41,059 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-21 05:00:41,060 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:00:41,254 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis] (custom)
2019-10-21 05:00:41,312 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-21 05:00:41,315 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:41,315 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:41,318 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:41,318 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-21 05:00:41,319 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:41,319 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:41,320 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39737
2019-10-21 05:00:41,320 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:41,323 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12fcc71f{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:41,323 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ed7821{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:41,354 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@62dbe64e{/,file:///tmp/jetty-0.0.0.0-39737-hddsDatanode-_-any-1755984774866177692.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-21 05:00:41,356 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6cff61fc{HTTP/1.1,[http/1.1]}{0.0.0.0:39737}
2019-10-21 05:00:41,356 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6225ms
2019-10-21 05:00:41,356 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-21 05:00:41,357 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39737
2019-10-21 05:00:41,359 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-21 05:00:41,362 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-252f9-3696506840 ip:192.168.157.255
2019-10-21 05:00:41,363 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42e564e1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-21 05:00:41,370 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-21 05:00:41,371 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/containers/hdds to VolumeSet
2019-10-21 05:00:41,372 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4b65d9f4
2019-10-21 05:00:41,372 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4b65d9f4
2019-10-21 05:00:41,398 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-21 05:00:41,398 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-21 05:00:41,399 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-21 05:00:41,399 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-21 05:00:41,399 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:41,399 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-21 05:00:41,400 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:00:41,400 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis] (custom)
2019-10-21 05:00:41,402 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-21 05:00:41,404 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:41,405 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:41,407 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:41,408 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-21 05:00:41,408 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:41,408 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:41,409 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43199
2019-10-21 05:00:41,409 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:41,413 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56da7487{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:41,414 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@328d044f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:41,443 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5484117b{/,file:///tmp/jetty-0.0.0.0-43199-hddsDatanode-_-any-2132859543611791906.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-21 05:00:41,444 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@37df14d1{HTTP/1.1,[http/1.1]}{0.0.0.0:43199}
2019-10-21 05:00:41,446 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6314ms
2019-10-21 05:00:41,446 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-21 05:00:41,447 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43199
2019-10-21 05:00:41,447 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-21 05:00:41,449 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@389c468a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-21 05:00:41,449 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-252f9-3696506840 ip:192.168.157.255
2019-10-21 05:00:41,457 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-21 05:00:41,457 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/containers/hdds to VolumeSet
2019-10-21 05:00:41,458 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@378cfecf
2019-10-21 05:00:41,458 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@378cfecf
2019-10-21 05:00:41,462 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/meta/datanode.id
2019-10-21 05:00:41,465 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/meta/datanode.id
2019-10-21 05:00:41,487 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-21 05:00:41,488 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-21 05:00:41,488 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-21 05:00:41,488 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-21 05:00:41,489 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:41,489 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-21 05:00:41,489 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:00:41,490 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis] (custom)
2019-10-21 05:00:41,493 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-21 05:00:41,495 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:41,496 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:41,498 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:41,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-21 05:00:41,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:41,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:41,500 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40831
2019-10-21 05:00:41,500 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:41,502 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1716e8c5{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:41,502 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4052c8c2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:41,532 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58f39564{/,file:///tmp/jetty-0.0.0.0-40831-hddsDatanode-_-any-3394064609313186780.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-21 05:00:41,533 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b948f3e{HTTP/1.1,[http/1.1]}{0.0.0.0:40831}
2019-10-21 05:00:41,534 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6403ms
2019-10-21 05:00:41,535 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-21 05:00:41,537 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40831
2019-10-21 05:00:41,538 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-21 05:00:41,540 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@34a154bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-21 05:00:41,540 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-252f9-3696506840 ip:192.168.157.255
2019-10-21 05:00:41,542 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/meta/datanode.id
2019-10-21 05:00:41,546 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-21 05:00:41,547 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/containers/hdds to VolumeSet
2019-10-21 05:00:41,547 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@68b9834c
2019-10-21 05:00:41,547 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@68b9834c
2019-10-21 05:00:41,566 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-21 05:00:41,566 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-21 05:00:41,567 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-21 05:00:41,567 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-21 05:00:41,567 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:41,567 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-21 05:00:41,567 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:00:41,568 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/ratis] (custom)
2019-10-21 05:00:41,570 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-21 05:00:41,571 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:41,572 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:41,573 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:41,574 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-21 05:00:41,574 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:41,574 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:41,575 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44715
2019-10-21 05:00:41,575 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:41,578 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53cf9c99{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:41,579 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@142213d5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:41,628 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@117d32e{/,file:///tmp/jetty-0.0.0.0-44715-hddsDatanode-_-any-3243034835893916458.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-21 05:00:41,630 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51d387d3{HTTP/1.1,[http/1.1]}{0.0.0.0:44715}
2019-10-21 05:00:41,630 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6499ms
2019-10-21 05:00:41,630 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-21 05:00:41,631 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44715
2019-10-21 05:00:41,632 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-21 05:00:41,635 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@454b415f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-21 05:00:41,636 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-252f9-3696506840 ip:192.168.157.255
2019-10-21 05:00:41,640 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/meta/datanode.id
2019-10-21 05:00:41,645 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-21 05:00:41,646 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/containers/hdds to VolumeSet
2019-10-21 05:00:41,646 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3d96fa9e
2019-10-21 05:00:41,647 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3d96fa9e
2019-10-21 05:00:41,675 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-21 05:00:41,676 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-21 05:00:41,676 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-21 05:00:41,676 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-21 05:00:41,676 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:41,677 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-21 05:00:41,677 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:00:41,678 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/ratis] (custom)
2019-10-21 05:00:41,680 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-21 05:00:41,682 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-21 05:00:41,683 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-21 05:00:41,685 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-21 05:00:41,686 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-21 05:00:41,686 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-21 05:00:41,687 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-21 05:00:41,688 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37798
2019-10-21 05:00:41,688 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-21 05:00:41,690 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ba46e63{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-10-21 05:00:41,690 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2dc3271b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-21 05:00:41,728 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6edf29c1{/,file:///tmp/jetty-0.0.0.0-37798-hddsDatanode-_-any-1609287058690309609.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-21 05:00:41,728 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79a04e5f{HTTP/1.1,[http/1.1]}{0.0.0.0:37798}
2019-10-21 05:00:41,729 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6598ms
2019-10-21 05:00:41,729 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-21 05:00:41,730 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37798
2019-10-21 05:00:41,732 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-10-21 05:00:41,733 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@51733aaf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-21 05:00:41,735 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/meta/datanode.id
2019-10-21 05:00:42,733 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-10-21 05:00:43,427 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-21 05:00:43,429 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-21 05:00:43,430 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 7d4ba912-917b-4f4e-a880-62fee1b9eb0e at port 0
2019-10-21 05:00:43,446 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start RPC server
2019-10-21 05:00:43,467 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-21 05:00:43,471 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-21 05:00:43,471 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis ea9103f6-20fd-4318-bf9c-fcf624e385d3 at port 0
2019-10-21 05:00:43,479 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start RPC server
2019-10-21 05:00:43,555 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-21 05:00:43,557 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-21 05:00:43,557 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c at port 0
2019-10-21 05:00:43,567 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start RPC server
2019-10-21 05:00:43,580 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: GrpcService started, listening on 0.0.0.0/0.0.0.0:46285
2019-10-21 05:00:43,580 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: GrpcService started, listening on 0.0.0.0/0.0.0.0:34640
2019-10-21 05:00:43,580 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: GrpcService started, listening on 0.0.0.0/0.0.0.0:44144
2019-10-21 05:00:43,581 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c is started using port 34640
2019-10-21 05:00:43,581 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 7d4ba912-917b-4f4e-a880-62fee1b9eb0e is started using port 46285
2019-10-21 05:00:43,581 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis ea9103f6-20fd-4318-bf9c-fcf624e385d3 is started using port 44144
2019-10-21 05:00:43,586 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc ea9103f6-20fd-4318-bf9c-fcf624e385d3 is started using port 37845
2019-10-21 05:00:43,586 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 7d4ba912-917b-4f4e-a880-62fee1b9eb0e is started using port 41243
2019-10-21 05:00:43,586 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c is started using port 40977
2019-10-21 05:00:43,652 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-21 05:00:43,654 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-21 05:00:43,654 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 7a92ee92-aaf5-44d8-9372-2212979166b2 at port 0
2019-10-21 05:00:43,660 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7a92ee92-aaf5-44d8-9372-2212979166b2: start RPC server
2019-10-21 05:00:43,663 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 7a92ee92-aaf5-44d8-9372-2212979166b2: GrpcService started, listening on 0.0.0.0/0.0.0.0:36899
2019-10-21 05:00:43,663 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 7a92ee92-aaf5-44d8-9372-2212979166b2 is started using port 36899
2019-10-21 05:00:43,664 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 7a92ee92-aaf5-44d8-9372-2212979166b2 is started using port 39923
2019-10-21 05:00:43,733 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-10-21 05:00:43,743 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-21 05:00:43,747 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-21 05:00:43,747 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis b29d5ac4-f099-47e5-b165-5a7ec59b9adb at port 0
2019-10-21 05:00:43,754 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb: start RPC server
2019-10-21 05:00:43,757 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb: GrpcService started, listening on 0.0.0.0/0.0.0.0:41557
2019-10-21 05:00:43,757 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis b29d5ac4-f099-47e5-b165-5a7ec59b9adb is started using port 41557
2019-10-21 05:00:43,759 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b29d5ac4-f099-47e5-b165-5a7ec59b9adb is started using port 35894
2019-10-21 05:00:44,734 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-10-21 05:00:45,392 [IPC Server handler 0 on 37127] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/7d4ba912-917b-4f4e-a880-62fee1b9eb0e
2019-10-21 05:00:45,393 [IPC Server handler 0 on 37127] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}
2019-10-21 05:00:45,396 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-10-21 05:00:45,396 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-10-21 05:00:45,396 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-10-21 05:00:45,452 [IPC Server handler 1 on 37127] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/ea9103f6-20fd-4318-bf9c-fcf624e385d3
2019-10-21 05:00:45,452 [IPC Server handler 1 on 37127] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}
2019-10-21 05:00:45,542 [IPC Server handler 3 on 37127] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c
2019-10-21 05:00:45,543 [IPC Server handler 3 on 37127] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}
2019-10-21 05:00:45,639 [IPC Server handler 4 on 37127] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/7a92ee92-aaf5-44d8-9372-2212979166b2
2019-10-21 05:00:45,639 [IPC Server handler 4 on 37127] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 7a92ee92-aaf5-44d8-9372-2212979166b2{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}
2019-10-21 05:00:45,745 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-10-21 05:00:45,750 [IPC Server handler 5 on 37127] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b29d5ac4-f099-47e5-b165-5a7ec59b9adb
2019-10-21 05:00:45,750 [IPC Server handler 5 on 37127] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : b29d5ac4-f099-47e5-b165-5a7ec59b9adb{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}
2019-10-21 05:00:45,892 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: addNew group-368AAEBBA61E:[7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-368AAEBBA61E:java.util.concurrent.CompletableFuture@dd6da42[Not completed]
2019-10-21 05:00:45,915 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: new RaftServerImpl for group-368AAEBBA61E:[7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:45,918 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:45,919 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:45,919 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:45,920 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:45,921 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:45,931 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-368AAEBBA61E: ConfigurationManager, init=-1: [7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:45,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis] (custom)
2019-10-21 05:00:45,938 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:45,940 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/da583af8-f857-4173-b4b3-368aaebba61e does not exist. Creating ...
2019-10-21 05:00:45,967 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/da583af8-f857-4173-b4b3-368aaebba61e/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,041 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/da583af8-f857-4173-b4b3-368aaebba61e has been successfully formatted.
2019-10-21 05:00:46,044 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-368AAEBBA61E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,045 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,047 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,057 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,057 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,061 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,064 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-10-21 05:00:46,071 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-10-21 05:00:46,112 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,119 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-368AAEBBA61E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/da583af8-f857-4173-b4b3-368aaebba61e
2019-10-21 05:00:46,120 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,120 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,122 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,122 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,122 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,123 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,124 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,124 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,124 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,138 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,142 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-368AAEBBA61E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,147 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,148 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,149 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,149 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,178 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-368AAEBBA61E: start as a follower, conf=-1: [7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:00:46,179 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-368AAEBBA61E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,181 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start FollowerState
2019-10-21 05:00:46,182 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-368AAEBBA61E,id=7d4ba912-917b-4f4e-a880-62fee1b9eb0e
2019-10-21 05:00:46,241 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: da583af8-f857-4173-b4b3-368aaebba61e, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-21 05:00:46,261 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: addNew group-388AA77EFED8:[bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640] returns group-388AA77EFED8:java.util.concurrent.CompletableFuture@2263bb74[Not completed]
2019-10-21 05:00:46,282 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: new RaftServerImpl for group-388AA77EFED8:[bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,284 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-388AA77EFED8: ConfigurationManager, init=-1: [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis] (custom)
2019-10-21 05:00:46,285 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,285 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/ea9aae8f-7362-4fee-a113-388aa77efed8 does not exist. Creating ...
2019-10-21 05:00:46,300 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/ea9aae8f-7362-4fee-a113-388aa77efed8/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,314 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/ea9aae8f-7362-4fee-a113-388aa77efed8 has been successfully formatted.
2019-10-21 05:00:46,315 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-388AA77EFED8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,322 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,322 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-388AA77EFED8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/ea9aae8f-7362-4fee-a113-388aa77efed8
2019-10-21 05:00:46,323 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,323 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,325 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,325 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-388AA77EFED8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,326 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,326 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,326 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,326 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,330 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-388AA77EFED8: start as a follower, conf=-1: [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640], old=null
2019-10-21 05:00:46,330 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-388AA77EFED8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,330 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start FollowerState
2019-10-21 05:00:46,332 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-388AA77EFED8,id=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c
2019-10-21 05:00:46,351 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ea9aae8f-7362-4fee-a113-388aa77efed8, Nodes: bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-21 05:00:46,369 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: addNew group-0E86144E0895:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144] returns group-0E86144E0895:java.util.concurrent.CompletableFuture@48c9ae65[Not completed]
2019-10-21 05:00:46,383 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: new RaftServerImpl for group-0E86144E0895:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,383 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,383 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,384 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-0E86144E0895: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis] (custom)
2019-10-21 05:00:46,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,385 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/b5bbaeff-3de3-478f-9f6a-0e86144e0895 does not exist. Creating ...
2019-10-21 05:00:46,399 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/b5bbaeff-3de3-478f-9f6a-0e86144e0895/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,424 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/b5bbaeff-3de3-478f-9f6a-0e86144e0895 has been successfully formatted.
2019-10-21 05:00:46,425 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-0E86144E0895: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,442 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-0E86144E0895-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/b5bbaeff-3de3-478f-9f6a-0e86144e0895
2019-10-21 05:00:46,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,443 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,443 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,443 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,443 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,443 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,443 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,444 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-0E86144E0895-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,444 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,444 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,444 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,444 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,448 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-0E86144E0895: start as a follower, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144], old=null
2019-10-21 05:00:46,448 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-0E86144E0895: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,448 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start FollowerState
2019-10-21 05:00:46,449 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0E86144E0895,id=ea9103f6-20fd-4318-bf9c-fcf624e385d3
2019-10-21 05:00:46,465 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b5bbaeff-3de3-478f-9f6a-0e86144e0895, Nodes: ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-21 05:00:46,479 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7a92ee92-aaf5-44d8-9372-2212979166b2: addNew group-C0927D7F4B73:[7a92ee92-aaf5-44d8-9372-2212979166b2:192.168.157.255:36899] returns group-C0927D7F4B73:java.util.concurrent.CompletableFuture@11771fd4[Not completed]
2019-10-21 05:00:46,480 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7a92ee92-aaf5-44d8-9372-2212979166b2: new RaftServerImpl for group-C0927D7F4B73:[7a92ee92-aaf5-44d8-9372-2212979166b2:192.168.157.255:36899] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,480 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7a92ee92-aaf5-44d8-9372-2212979166b2@group-C0927D7F4B73: ConfigurationManager, init=-1: [7a92ee92-aaf5-44d8-9372-2212979166b2:192.168.157.255:36899], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/ratis] (custom)
2019-10-21 05:00:46,481 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,482 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/ratis/bf77a8a8-1f64-4cb4-aca0-c0927d7f4b73 does not exist. Creating ...
2019-10-21 05:00:46,558 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/ratis/bf77a8a8-1f64-4cb4-aca0-c0927d7f4b73/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,615 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/ratis/bf77a8a8-1f64-4cb4-aca0-c0927d7f4b73 has been successfully formatted.
2019-10-21 05:00:46,615 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-C0927D7F4B73: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,616 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,616 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,616 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,616 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,616 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,619 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,619 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 7a92ee92-aaf5-44d8-9372-2212979166b2@group-C0927D7F4B73-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-3/data/ratis/bf77a8a8-1f64-4cb4-aca0-c0927d7f4b73
2019-10-21 05:00:46,619 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,620 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,621 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,621 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 7a92ee92-aaf5-44d8-9372-2212979166b2@group-C0927D7F4B73-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,621 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,622 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,622 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,622 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,624 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - 7a92ee92-aaf5-44d8-9372-2212979166b2@group-C0927D7F4B73: start as a follower, conf=-1: [7a92ee92-aaf5-44d8-9372-2212979166b2:192.168.157.255:36899], old=null
2019-10-21 05:00:46,625 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7a92ee92-aaf5-44d8-9372-2212979166b2@group-C0927D7F4B73: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,625 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7a92ee92-aaf5-44d8-9372-2212979166b2: start FollowerState
2019-10-21 05:00:46,625 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C0927D7F4B73,id=7a92ee92-aaf5-44d8-9372-2212979166b2
2019-10-21 05:00:46,636 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bf77a8a8-1f64-4cb4-aca0-c0927d7f4b73, Nodes: 7a92ee92-aaf5-44d8-9372-2212979166b2{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-21 05:00:46,654 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb: addNew group-332168732E62:[b29d5ac4-f099-47e5-b165-5a7ec59b9adb:192.168.157.255:41557] returns group-332168732E62:java.util.concurrent.CompletableFuture@654b0804[Not completed]
2019-10-21 05:00:46,656 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb: new RaftServerImpl for group-332168732E62:[b29d5ac4-f099-47e5-b165-5a7ec59b9adb:192.168.157.255:41557] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,656 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,656 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,657 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,657 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,657 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,657 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb@group-332168732E62: ConfigurationManager, init=-1: [b29d5ac4-f099-47e5-b165-5a7ec59b9adb:192.168.157.255:41557], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,657 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/ratis] (custom)
2019-10-21 05:00:46,657 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,658 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/ratis/b3bb12c9-a803-4e99-b575-332168732e62 does not exist. Creating ...
2019-10-21 05:00:46,671 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/ratis/b3bb12c9-a803-4e99-b575-332168732e62/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,684 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/ratis/b3bb12c9-a803-4e99-b575-332168732e62 has been successfully formatted.
2019-10-21 05:00:46,686 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-332168732E62: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,686 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,686 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,686 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,686 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,687 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new b29d5ac4-f099-47e5-b165-5a7ec59b9adb@group-332168732E62-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-4/data/ratis/b3bb12c9-a803-4e99-b575-332168732e62
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,690 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,691 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,691 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,691 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,691 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,691 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,692 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb@group-332168732E62-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,692 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,692 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,692 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,692 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,695 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb@group-332168732E62: start as a follower, conf=-1: [b29d5ac4-f099-47e5-b165-5a7ec59b9adb:192.168.157.255:41557], old=null
2019-10-21 05:00:46,695 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb@group-332168732E62: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,695 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b29d5ac4-f099-47e5-b165-5a7ec59b9adb: start FollowerState
2019-10-21 05:00:46,695 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-332168732E62,id=b29d5ac4-f099-47e5-b165-5a7ec59b9adb
2019-10-21 05:00:46,705 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b3bb12c9-a803-4e99-b575-332168732e62, Nodes: b29d5ac4-f099-47e5-b165-5a7ec59b9adb{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-21 05:00:46,707 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(205)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.pickNodesNeverUsed(RatisPipelineProvider.java:120)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:132)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:195)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-10-21 05:00:46,747 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-10-21 05:00:46,750 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: addNew group-4FD89D25A9D8:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-4FD89D25A9D8:java.util.concurrent.CompletableFuture@38bf1d54[Not completed]
2019-10-21 05:00:46,750 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: addNew group-4FD89D25A9D8:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-4FD89D25A9D8:java.util.concurrent.CompletableFuture@19fe82bb[Not completed]
2019-10-21 05:00:46,752 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: new RaftServerImpl for group-4FD89D25A9D8:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,753 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: new RaftServerImpl for group-4FD89D25A9D8:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis] (custom)
2019-10-21 05:00:46,754 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,754 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: addNew group-4FD89D25A9D8:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-4FD89D25A9D8:java.util.concurrent.CompletableFuture@5cb54aab[Not completed]
2019-10-21 05:00:46,754 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,754 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,754 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: new RaftServerImpl for group-4FD89D25A9D8:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:46,754 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,754 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8 does not exist. Creating ...
2019-10-21 05:00:46,754 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,754 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:46,755 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,755 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:46,755 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,755 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:46,755 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:46,755 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis] (custom)
2019-10-21 05:00:46,755 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:46,755 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:46,755 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,755 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis] (custom)
2019-10-21 05:00:46,756 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8 does not exist. Creating ...
2019-10-21 05:00:46,756 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:46,756 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8 does not exist. Creating ...
2019-10-21 05:00:46,833 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,833 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,833 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:46,956 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8 has been successfully formatted.
2019-10-21 05:00:46,956 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8 has been successfully formatted.
2019-10-21 05:00:46,956 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8 has been successfully formatted.
2019-10-21 05:00:46,958 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-4FD89D25A9D8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,958 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-4FD89D25A9D8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,958 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,958 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-4FD89D25A9D8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:46,959 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,958 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,959 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,959 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:46,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,959 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:46,961 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:46,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,961 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:46,961 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,961 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,962 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,963 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,963 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,963 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,963 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,961 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,964 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:46,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,964 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,964 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8
2019-10-21 05:00:46,970 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,973 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,972 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:46,973 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,973 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,973 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:46,973 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,974 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:46,974 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:46,974 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:46,974 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:46,975 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:46,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:46,975 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:46,975 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:46,975 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,976 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,976 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:46,976 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,976 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:46,976 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: start as a follower, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:00:46,976 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:46,976 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,976 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:46,977 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start FollowerState
2019-10-21 05:00:46,977 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:46,977 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4FD89D25A9D8,id=7d4ba912-917b-4f4e-a880-62fee1b9eb0e
2019-10-21 05:00:46,988 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: start as a follower, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:00:46,989 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,989 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start FollowerState
2019-10-21 05:00:46,989 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(181)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: start as a follower, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:00:46,989 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-21 05:00:46,989 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4FD89D25A9D8,id=ea9103f6-20fd-4318-bf9c-fcf624e385d3
2019-10-21 05:00:46,990 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start FollowerState
2019-10-21 05:00:46,990 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4FD89D25A9D8,id=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c
2019-10-21 05:00:47,011 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-10-21 05:00:47,026 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: addNew group-C1965988C799:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-C1965988C799:java.util.concurrent.CompletableFuture@39fcb297[Not completed]
2019-10-21 05:00:47,026 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: addNew group-C1965988C799:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-C1965988C799:java.util.concurrent.CompletableFuture@7982176f[Not completed]
2019-10-21 05:00:47,026 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: addNew group-C1965988C799:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-C1965988C799:java.util.concurrent.CompletableFuture@28e41633[Not completed]
2019-10-21 05:00:47,028 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: new RaftServerImpl for group-C1965988C799:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:47,028 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:47,028 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:47,028 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:47,028 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:47,029 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: new RaftServerImpl for group-C1965988C799:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:47,029 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-C1965988C799: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:47,029 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis] (custom)
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:47,029 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:47,029 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: new RaftServerImpl for group-C1965988C799:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:00:47,029 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/122744b2-db5c-432d-8002-c1965988c799 does not exist. Creating ...
2019-10-21 05:00:47,029 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:00:47,029 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-C1965988C799: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:47,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:00:47,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis] (custom)
2019-10-21 05:00:47,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:00:47,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:00:47,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:47,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:00:47,030 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/122744b2-db5c-432d-8002-c1965988c799 does not exist. Creating ...
2019-10-21 05:00:47,030 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-C1965988C799: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:00:47,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis] (custom)
2019-10-21 05:00:47,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:00:47,031 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/122744b2-db5c-432d-8002-c1965988c799 does not exist. Creating ...
2019-10-21 05:00:47,046 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/122744b2-db5c-432d-8002-c1965988c799/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:47,046 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/122744b2-db5c-432d-8002-c1965988c799/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:47,048 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/122744b2-db5c-432d-8002-c1965988c799/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:00:47,064 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/122744b2-db5c-432d-8002-c1965988c799 has been successfully formatted.
2019-10-21 05:00:47,065 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-C1965988C799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:47,065 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:47,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:47,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:47,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:47,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:47,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:47,067 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-C1965988C799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/122744b2-db5c-432d-8002-c1965988c799
2019-10-21 05:00:47,067 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/122744b2-db5c-432d-8002-c1965988c799 has been successfully formatted.
2019-10-21 05:00:47,067 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-C1965988C799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:47,067 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-C1965988C799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/122744b2-db5c-432d-8002-c1965988c799
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:47,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:47,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:47,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:47,070 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-C1965988C799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:47,071 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/122744b2-db5c-432d-8002-c1965988c799 has been successfully formatted.
2019-10-21 05:00:47,071 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-C1965988C799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:00:47,071 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:00:47,071 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:00:47,071 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:00:47,071 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-C1965988C799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/122744b2-db5c-432d-8002-c1965988c799
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:47,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:47,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:47,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:47,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:47,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:47,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:00:47,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:00:47,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:00:47,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:00:47,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:00:47,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:00:47,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:00:47,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:00:47,075 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:00:47,075 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:47,075 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:47,075 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:47,075 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:47,076 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:47,076 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-C1965988C799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:47,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-21 05:00:47,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-21 05:00:47,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-21 05:00:47,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-21 05:00:47,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:00:47,078 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-C1965988C799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:00:47,112 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 1 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,113 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 2 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,114 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 3 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,115 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 4 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,116 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 5 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,121 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 6 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,122 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 7 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,138 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 8 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,140 [Thread-224] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 9 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,142 [Thread-224] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-10-21 05:00:47,143 [Thread-224] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 43 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 46 more
2019-10-21 05:00:47,144 [Thread-224] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details null
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
]]></system-err>
  </testcase>
  <testcase name="testListStatusEmptyDirectory" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.043">
    <error message="Couldn&apos;t set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread" type="java.io.IOException"><![CDATA[java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
]]></error>
    <system-out><![CDATA[2019-10-21 05:00:47,171 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 1 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,176 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 2 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,178 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 3 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,180 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 4 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,181 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 5 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,191 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 6 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,192 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 7 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,193 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 8 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,195 [Thread-250] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 9 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,197 [Thread-250] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-10-21 05:00:47,198 [Thread-250] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 42 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
2019-10-21 05:00:47,202 [Thread-250] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details null
]]></system-out>
  </testcase>
  <testcase name="testListLocatedStatusFiltering" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.019">
    <error message="Couldn&apos;t set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread" type="java.io.IOException"><![CDATA[java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
]]></error>
    <system-out><![CDATA[2019-10-21 05:00:47,207 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 1 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,208 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 2 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,209 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 3 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,210 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 4 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,210 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 5 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,216 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 6 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,217 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 7 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,218 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 8 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,219 [Thread-262] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 9 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,220 [Thread-262] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-10-21 05:00:47,220 [Thread-262] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 42 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
2019-10-21 05:00:47,221 [Thread-262] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details null
]]></system-out>
  </testcase>
  <testcase name="testListStatusFilteredFile" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.017">
    <error message="Couldn&apos;t set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread" type="java.io.IOException"><![CDATA[java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
]]></error>
    <system-out><![CDATA[2019-10-21 05:00:47,226 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 1 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,227 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 2 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,227 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 3 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,232 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 4 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,233 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 5 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,234 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 6 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,235 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 7 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,236 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 8 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,236 [Thread-274] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 9 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,237 [Thread-274] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-10-21 05:00:47,237 [Thread-274] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 42 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
2019-10-21 05:00:47,238 [Thread-274] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details null
]]></system-out>
  </testcase>
  <testcase name="testListFilesEmptyDirectoryRecursive" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.013">
    <error message="Couldn&apos;t set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread" type="java.io.IOException"><![CDATA[java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
]]></error>
    <system-out><![CDATA[2019-10-21 05:00:47,243 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 1 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,244 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 2 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,245 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 3 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,245 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 4 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,246 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 5 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,247 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 6 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,248 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 7 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,248 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 8 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,249 [Thread-286] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 9 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,250 [Thread-286] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-10-21 05:00:47,250 [Thread-286] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 42 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
2019-10-21 05:00:47,251 [Thread-286] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details null
]]></system-out>
  </testcase>
  <testcase name="testListLocatedStatusFile" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.015">
    <error message="Couldn&apos;t set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread" type="java.io.IOException"><![CDATA[java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
]]></error>
    <system-out><![CDATA[2019-10-21 05:00:47,256 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 1 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,258 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 2 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,258 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 3 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,259 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 4 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,260 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 5 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,261 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 6 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,262 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 7 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,262 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 8 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,263 [Thread-298] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread, while invoking $Proxy40.submitRequest over nodeId=null,nodeAddress=localhost:41423 after 9 failover attempts. Trying to failover immediately.
2019-10-21 05:00:47,264 [Thread-298] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-10-21 05:00:47,264 [Thread-298] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.io.IOException: DestHost:destPort localhost:41423 , LocalHost:localPort pr-hdds-1569-252f9-3696506840/192.168.157.255:0. Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.getClient(MiniOzoneClusterImpl.java:212)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:51)
	at org.apache.hadoop.ozone.TestDataUtil.createVolumeAndBucket(TestDataUtil.java:93)
	at org.apache.hadoop.fs.ozone.contract.OzoneContract.getTestFileSystem(OzoneContract.java:83)
	at org.apache.hadoop.fs.contract.AbstractFSContractTestBase.setup(AbstractFSContractTestBase.java:181)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.setup(AbstractContractGetFileStatusTest.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:866)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 42 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:859)
	... 45 more
2019-10-21 05:00:47,266 [Thread-298] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details null
]]></system-out>
  </testcase>
  <testcase name="testGetFileStatusRoot" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.852"/>
  <testcase name="testListStatusFiltering" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="5.083"/>
  <testcase name="testListFilesNoDir" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.118"/>
  <testcase name="testListLocatedStatusEmptyDirectory" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.101"/>
  <testcase name="testListFilesFile" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.1"/>
  <testcase name="testComplexDirActions" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="180.003">
    <error message="test timed out after 180000 milliseconds" type="java.lang.Exception">java.lang.Exception: test timed out after 180000 milliseconds
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693)
	at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323)
	at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.waitOnFlushFutures(BlockOutputStream.java:518)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:481)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.fs.ozone.OzoneFSOutputStream.close(OzoneFSOutputStream.java:56)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:638)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createSubdirs(ContractTestUtils.java:1288)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createSubdirs(ContractTestUtils.java:1254)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.createTestTree(AbstractContractGetFileStatusTest.java:409)
	at org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testComplexDirActions(AbstractContractGetFileStatusTest.java:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-10-21 05:00:53,545 [Thread-355] INFO  rpc.RpcClient (RpcClient.java:createVolume(272)) - Creating Volume: volume46922, with user38153 as owner.
2019-10-21 05:00:53,547 [IPC Server handler 14 on 41423] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume46922 for user:user38153
2019-10-21 05:00:53,549 [Thread-355] INFO  rpc.RpcClient (RpcClient.java:createBucket(411)) - Creating Bucket: volume46922/bucket45143, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-10-21 05:00:53,599 [Thread-355] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket45143.volume46922 implemented by OzoneFileSystem{URI=o3fs://bucket45143.volume46922, workingDir=o3fs://bucket45143.volume46922/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 33 read ops, 0 large read ops, 9 write ops}
2019-10-21 05:00:53,636 [Thread-355] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-10-21 05:00:57,234 [Thread-348] INFO  impl.FollowerState (FollowerState.java:run(108)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-FollowerState: change to CANDIDATE, lastRpcTime:5105ms, electionTimeout:5104ms
2019-10-21 05:00:57,234 [Thread-348] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: shutdown FollowerState
2019-10-21 05:00:57,234 [Thread-348] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-10-21 05:00:57,235 [Thread-348] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start LeaderElection
2019-10-21 05:00:57,250 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9: begin an election at term 2 for -1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:00:57,256 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 2 for recognizeCandidate:bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c
2019-10-21 05:00:57,256 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 2 for recognizeCandidate:bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c
2019-10-21 05:00:57,256 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: shutdown LeaderElection
2019-10-21 05:00:57,256 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: shutdown LeaderElection
2019-10-21 05:00:57,256 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start FollowerState
2019-10-21 05:00:57,256 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start FollowerState
2019-10-21 05:00:57,322 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9: Election REJECTED; received 2 response(s) [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c<-ea9103f6-20fd-4318-bf9c-fcf624e385d3#0:FAIL-t2, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c<-7d4ba912-917b-4f4e-a880-62fee1b9eb0e#0:FAIL-t2] and 0 exception(s); bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8:t2, leader=null, voted=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c, raftlog=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:00:57,322 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-10-21 05:00:57,324 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: shutdown LeaderElection
2019-10-21 05:00:57,324 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start FollowerState
2019-10-21 05:01:02,168 [java.util.concurrent.ThreadPoolExecutor$Worker@b2e1158[State = -1, empty queue]] ERROR impl.OrderedAsync (TimeoutScheduler.java:lambda$onTimeout$5(176)) - Failed* to retry RaftClientRequest:client-957A03E81392->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8, cid=14, seq=1*, RW, cmdType: WriteChunk
traceID: "bd8aabccc7a88c14:bd8aabccc7a88c14:0:0"
containerID: 1
datanodeUuid: "7d4ba912-917b-4f4e-a880-62fee1b9eb0e"
writeChunk {
  blockID {
    containerID: 1
    localID: 102998609337253894
    blockCommitSequenceId: 0
  }
  chunkData {
    chunkName: "102998609337253894_chunk_1"
    offset: 0
    len: 512
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\211\341\244\213"
    }
  }
}
, data.size=512
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.ensurePrestart(ThreadPoolExecutor.java:1605)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:334)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.ratis.util.TimeoutScheduler.schedule(TimeoutScheduler.java:159)
	at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:133)
	at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:110)
	at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:176)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.onNext(GrpcClientProtocolClient.java:318)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:68)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-10-21 05:01:02,383 [Thread-370] INFO  impl.FollowerState (FollowerState.java:run(108)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-FollowerState: change to CANDIDATE, lastRpcTime:5126ms, electionTimeout:5126ms
2019-10-21 05:01:02,383 [Thread-370] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: shutdown FollowerState
2019-10-21 05:01:02,384 [Thread-370] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-10-21 05:01:02,384 [Thread-370] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start LeaderElection
2019-10-21 05:01:02,399 [Thread-369] INFO  impl.FollowerState (FollowerState.java:run(108)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-FollowerState: change to CANDIDATE, lastRpcTime:5142ms, electionTimeout:5142ms
2019-10-21 05:01:02,401 [Thread-369] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: shutdown FollowerState
2019-10-21 05:01:02,401 [Thread-369] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-10-21 05:01:02,401 [Thread-369] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start LeaderElection
2019-10-21 05:01:02,404 [Thread-371] INFO  impl.FollowerState (FollowerState.java:run(108)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-FollowerState: change to CANDIDATE, lastRpcTime:5080ms, electionTimeout:5079ms
2019-10-21 05:01:02,404 [Thread-371] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: shutdown FollowerState
2019-10-21 05:01:02,404 [Thread-371] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-10-21 05:01:02,405 [Thread-371] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start LeaderElection
2019-10-21 05:01:02,412 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10: begin an election at term 3 for -1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:02,412 [ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11: begin an election at term 3 for -1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:02,412 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12: begin an election at term 3 for -1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:02,434 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12: Election REJECTED; received 2 response(s) [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c<-ea9103f6-20fd-4318-bf9c-fcf624e385d3#0:FAIL-t3, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c<-7d4ba912-917b-4f4e-a880-62fee1b9eb0e#0:FAIL-t3] and 0 exception(s); bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8:t3, leader=null, voted=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c, raftlog=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:02,434 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
2019-10-21 05:01:02,434 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: shutdown LeaderElection
2019-10-21 05:01:02,434 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start FollowerState
2019-10-21 05:01:02,438 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10: Election REJECTED; received 2 response(s) [7d4ba912-917b-4f4e-a880-62fee1b9eb0e<-ea9103f6-20fd-4318-bf9c-fcf624e385d3#0:FAIL-t3, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e<-bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#0:FAIL-t3] and 0 exception(s); 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8:t3, leader=null, voted=7d4ba912-917b-4f4e-a880-62fee1b9eb0e, raftlog=7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:02,440 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
2019-10-21 05:01:02,440 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: shutdown LeaderElection
2019-10-21 05:01:02,440 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start FollowerState
2019-10-21 05:01:02,440 [ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11: Election REJECTED; received 2 response(s) [ea9103f6-20fd-4318-bf9c-fcf624e385d3<-bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#0:FAIL-t3, ea9103f6-20fd-4318-bf9c-fcf624e385d3<-7d4ba912-917b-4f4e-a880-62fee1b9eb0e#0:FAIL-t3] and 0 exception(s); ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8:t3, leader=null, voted=ea9103f6-20fd-4318-bf9c-fcf624e385d3, raftlog=ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:02,442 [ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
2019-10-21 05:01:02,443 [ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: shutdown LeaderElection
2019-10-21 05:01:02,443 [ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start FollowerState
2019-10-21 05:01:07,508 [Thread-391] INFO  impl.FollowerState (FollowerState.java:run(108)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-FollowerState: change to CANDIDATE, lastRpcTime:5073ms, electionTimeout:5071ms
2019-10-21 05:01:07,509 [Thread-391] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: shutdown FollowerState
2019-10-21 05:01:07,509 [Thread-391] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2019-10-21 05:01:07,510 [Thread-391] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start LeaderElection
2019-10-21 05:01:07,515 [Thread-392] INFO  impl.FollowerState (FollowerState.java:run(108)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-FollowerState: change to CANDIDATE, lastRpcTime:5074ms, electionTimeout:5073ms
2019-10-21 05:01:07,515 [Thread-392] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: shutdown FollowerState
2019-10-21 05:01:07,515 [Thread-392] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2019-10-21 05:01:07,515 [Thread-392] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start LeaderElection
2019-10-21 05:01:07,526 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13: begin an election at term 4 for -1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:07,526 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14: begin an election at term 4 for -1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:07,531 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: changes role from  FOLLOWER to FOLLOWER at term 4 for recognizeCandidate:7d4ba912-917b-4f4e-a880-62fee1b9eb0e
2019-10-21 05:01:07,532 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: shutdown FollowerState
2019-10-21 05:01:07,534 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: start FollowerState
2019-10-21 05:01:07,534 [Thread-393] INFO  impl.FollowerState (FollowerState.java:run(117)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-21 05:01:07,552 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14: Election PASSED; received 2 response(s) [7d4ba912-917b-4f4e-a880-62fee1b9eb0e<-ea9103f6-20fd-4318-bf9c-fcf624e385d3#0:OK-t4, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e<-bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#0:FAIL-t4] and 0 exception(s); 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8:t4, leader=null, voted=7d4ba912-917b-4f4e-a880-62fee1b9eb0e, raftlog=7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:07,552 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: shutdown LeaderElection
2019-10-21 05:01:07,554 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
2019-10-21 05:01:07,554 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: change Leader from null to 7d4ba912-917b-4f4e-a880-62fee1b9eb0e at term 4 for becomeLeader, leader elected after 20595ms
2019-10-21 05:01:07,554 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13: Election REJECTED; received 2 response(s) [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c<-ea9103f6-20fd-4318-bf9c-fcf624e385d3#0:FAIL-t4, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c<-7d4ba912-917b-4f4e-a880-62fee1b9eb0e#0:FAIL-t4] and 0 exception(s); bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8:t4, leader=null, voted=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c, raftlog=bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null
2019-10-21 05:01:07,555 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-21 05:01:07,555 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(170)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: changes role from CANDIDATE to FOLLOWER at term 4 for DISCOVERED_A_NEW_TERM
2019-10-21 05:01:07,557 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-21 05:01:07,557 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: shutdown LeaderElection
2019-10-21 05:01:07,557 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-21 05:01:07,557 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: start FollowerState
2019-10-21 05:01:07,557 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-21 05:01:07,558 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-21 05:01:07,558 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-21 05:01:07,566 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-21 05:01:07,566 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:01:07,567 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-21 05:01:07,571 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-21 05:01:07,571 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:01:07,571 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:01:07,572 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-21 05:01:07,573 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:01:07,573 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-21 05:01:07,573 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-21 05:01:07,573 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-21 05:01:07,573 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:01:07,575 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: start LeaderState
2019-10-21 05:01:07,575 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-21 05:01:07,576 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8: set configuration 0: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null at 0
2019-10-21 05:01:07,618 [7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(574)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8/current/log_inprogress_0
2019-10-21 05:01:07,625 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: change Leader from null to 7d4ba912-917b-4f4e-a880-62fee1b9eb0e at term 4 for appendEntries, leader elected after 20666ms
2019-10-21 05:01:07,625 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: change Leader from null to 7d4ba912-917b-4f4e-a880-62fee1b9eb0e at term 4 for appendEntries, leader elected after 20666ms
2019-10-21 05:01:07,651 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8: set configuration 0: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null at 0
2019-10-21 05:01:07,651 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8: set configuration 0: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null at 0
2019-10-21 05:01:07,652 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-21 05:01:07,652 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-21 05:01:07,688 [bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(574)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-4FD89D25A9D8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8/current/log_inprogress_0
2019-10-21 05:01:07,688 [ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(574)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-4FD89D25A9D8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/5fc34561-5c66-49ae-a9c5-4fd89d25a9d8/current/log_inprogress_0
2019-10-21 05:01:35,750 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#11-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:35,750 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#11-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:38,251 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#12-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:38,251 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#12-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:40,752 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#13-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:40,752 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#13-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:43,254 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#14-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:43,254 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#14-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:45,755 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#15-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:45,755 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#15-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:48,256 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#16-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:48,256 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#16-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:50,757 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#17-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:50,757 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#17-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:53,260 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#18-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:53,260 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#18-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:55,760 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#19-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:55,760 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#19-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:58,262 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#20-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:01:58,262 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#20-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:00,764 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#21-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:00,764 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#21-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:03,265 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#22-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:03,265 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#22-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:05,767 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#23-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:05,767 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#23-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:08,267 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#24-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:08,267 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#24-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:10,768 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#25-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:10,768 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#25-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:13,269 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#26-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:13,269 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#26-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:15,769 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#27-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:15,769 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#27-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:18,270 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#28-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:18,270 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#28-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:20,770 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#29-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:20,770 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#29-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:23,271 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#30-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:23,271 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#30-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:25,772 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#31-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:25,772 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#31-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:28,272 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#32-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:28,272 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#32-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:30,773 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#33-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:30,773 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#33-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:33,273 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#34-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:33,273 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#34-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:35,774 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#35-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:35,774 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#35-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:38,275 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#36-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:38,275 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#36-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:40,775 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#37-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:40,775 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#37-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:43,276 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#38-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:43,276 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#38-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:45,777 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#39-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:45,777 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#39-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:48,278 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#40-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:48,278 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#40-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:50,778 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#41-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:50,778 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#41-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:53,056 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(205)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.pickNodesNeverUsed(RatisPipelineProvider.java:120)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:132)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:195)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-10-21 05:02:53,071 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: addNew group-19DBC11D3729:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-19DBC11D3729:java.util.concurrent.CompletableFuture@625dea52[Not completed]
2019-10-21 05:02:53,072 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: addNew group-19DBC11D3729:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-19DBC11D3729:java.util.concurrent.CompletableFuture@60c9283d[Not completed]
2019-10-21 05:02:53,072 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: addNew group-19DBC11D3729:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] returns group-19DBC11D3729:java.util.concurrent.CompletableFuture@2600f025[Not completed]
2019-10-21 05:02:53,075 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3: new RaftServerImpl for group-19DBC11D3729:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:02:53,076 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:02:53,076 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:02:53,077 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:02:53,077 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:02:53,077 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e: new RaftServerImpl for group-19DBC11D3729:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:02:53,077 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:02:53,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:02:53,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:02:53,077 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-19DBC11D3729: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:02:53,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:02:53,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:02:53,077 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:02:53,078 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-19DBC11D3729: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:02:53,078 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis] (custom)
2019-10-21 05:02:53,078 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c: new RaftServerImpl for group-19DBC11D3729:[ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285] with ContainerStateMachine:uninitialized
2019-10-21 05:02:53,078 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis] (custom)
2019-10-21 05:02:53,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-21 05:02:53,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-21 05:02:53,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-10-21 05:02:53,078 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:02:53,078 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:02:53,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-21 05:02:53,078 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729 does not exist. Creating ...
2019-10-21 05:02:53,078 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729 does not exist. Creating ...
2019-10-21 05:02:53,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-21 05:02:53,079 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-19DBC11D3729: ConfigurationManager, init=-1: [ea9103f6-20fd-4318-bf9c-fcf624e385d3:192.168.157.255:44144, bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c:192.168.157.255:34640, 7d4ba912-917b-4f4e-a880-62fee1b9eb0e:192.168.157.255:46285], old=null, confs=<EMPTY_MAP>
2019-10-21 05:02:53,079 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis] (custom)
2019-10-21 05:02:53,079 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-21 05:02:53,079 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729 does not exist. Creating ...
2019-10-21 05:02:53,096 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:02:53,096 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:02:53,096 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729/in_use.lock acquired by nodename 402@pr-hdds-1569-252f9-3696506840
2019-10-21 05:02:53,100 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729 has been successfully formatted.
2019-10-21 05:02:53,100 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729 has been successfully formatted.
2019-10-21 05:02:53,100 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729 has been successfully formatted.
2019-10-21 05:02:53,100 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-19DBC11D3729: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:02:53,100 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-19DBC11D3729: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:02:53,100 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-19DBC11D3729: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-21 05:02:53,101 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:02:53,101 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:02:53,101 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:02:53,101 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-10-21 05:02:53,101 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:02:53,101 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-21 05:02:53,101 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:02:53,101 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:02:53,102 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:02:53,102 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:02:53,101 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-21 05:02:53,102 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:02:53,102 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:02:53,102 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-19DBC11D3729-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-2/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:02:53,103 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:02:53,104 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:02:53,104 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:02:53,104 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:02:53,104 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:02:53,105 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:02:53,105 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c@group-19DBC11D3729-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:02:53,102 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-19DBC11D3729-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-0/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729
2019-10-21 05:02:53,102 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-21 05:02:53,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:02:53,106 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:02:53,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:02:53,107 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:02:53,106 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-21 05:02:53,108 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-19DBC11D3729-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-b0cbf291-7f28-492a-8767-654aacb91b77/datanode-1/data/ratis/df1aa4af-e5d3-4261-af60-19dbc11d3729
2019-10-21 05:02:53,108 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-21 05:02:53,108 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-21 05:02:53,108 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-21 05:02:53,108 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-21 05:02:53,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-21 05:02:53,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-21 05:02:53,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-21 05:02:53,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-21 05:02:53,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-21 05:02:53,109 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:02:53,110 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - ea9103f6-20fd-4318-bf9c-fcf624e385d3@group-19DBC11D3729-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:02:53,108 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-21 05:02:53,110 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-19DBC11D3729-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-21 05:02:53,279 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#42-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:53,279 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#42-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:55,780 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#43-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:55,780 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#43-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:56,066 [RATISCREATEPIPELINE0] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(223)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1256812393@5b4a9027 for ea9103f6-20fd-4318-bf9c-fcf624e385d3
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998436001ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:184)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:219)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:213)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998436001ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-10-21 05:02:56,066 [RATISCREATEPIPELINE2] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(223)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1256812393@5b4a9027 for bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998479653ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:184)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:219)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998479653ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-10-21 05:02:56,066 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(223)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1256812393@5b4a9027 for 7d4ba912-917b-4f4e-a880-62fee1b9eb0e
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998172974ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:184)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:219)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998172974ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-10-21 05:02:56,069 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(205)) - Pipeline creation failed.
org.apache.hadoop.io.MultipleIOException: 3 exceptions [java.io.IOException: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1256812393@5b4a9027 for ea9103f6-20fd-4318-bf9c-fcf624e385d3, java.io.IOException: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1256812393@5b4a9027 for bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c, java.io.IOException: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1256812393@5b4a9027 for 7d4ba912-917b-4f4e-a880-62fee1b9eb0e]
	at org.apache.hadoop.io.MultipleIOException.createIOException(MultipleIOException.java:53)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.callRatisRpc(RatisPipelineProvider.java:239)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.initializePipeline(RatisPipelineProvider.java:182)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:195)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-10-21 05:02:58,281 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#44-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:02:58,281 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#44-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:00,781 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#45-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:00,781 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#45-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:03,282 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#46-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:03,282 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#46-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:05,782 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#47-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:05,782 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#47-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:08,283 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#48-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:08,283 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#48-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:10,784 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#49-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:10,784 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#49-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:13,284 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#50-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:13,284 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#50-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:15,785 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#51-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:15,785 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#51-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:18,285 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#52-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:18,285 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#52-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:20,786 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#53-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:20,786 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#53-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:23,287 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#54-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:23,287 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#54-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:25,787 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#55-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:25,787 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#55-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:28,288 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#56-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:28,288 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#56-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:30,316 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 120058ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 120060ms
2019-10-21 05:03:30,316 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 120058ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 120060ms
2019-10-21 05:03:30,380 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 120058ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 120060ms
2019-10-21 05:03:30,381 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-10-21 05:03:30,381 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-10-21 05:03:30,383 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(61)) - Close container Event triggered for container : #1
2019-10-21 05:03:30,387 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(61)) - Close container Event triggered for container : #2
2019-10-21 05:03:30,388 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(61)) - Close container Event triggered for container : #3
2019-10-21 05:03:30,788 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#57-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:30,788 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#57-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:31,464 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #1 does not exist in datanode. Container close failed.
2019-10-21 05:03:31,464 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #2 does not exist in datanode. Container close failed.
2019-10-21 05:03:31,464 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #3 does not exist in datanode. Container close failed.
2019-10-21 05:03:31,558 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #1 does not exist in datanode. Container close failed.
2019-10-21 05:03:31,560 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #2 does not exist in datanode. Container close failed.
2019-10-21 05:03:31,560 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #3 does not exist in datanode. Container close failed.
2019-10-21 05:03:32,789 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 122544ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 122544ms
2019-10-21 05:03:32,789 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 122544ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 122544ms
2019-10-21 05:03:33,289 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#58-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:33,289 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#58-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:33,376 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #1 does not exist in datanode. Container close failed.
2019-10-21 05:03:33,376 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #2 does not exist in datanode. Container close failed.
2019-10-21 05:03:33,376 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(84)) - Container #3 does not exist in datanode. Container close failed.
2019-10-21 05:03:33,378 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 122544ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 122544ms
2019-10-21 05:03:33,378 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:35,290 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 125045ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 125044ms
2019-10-21 05:03:35,290 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 125045ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 125044ms
2019-10-21 05:03:35,379 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 125045ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 125044ms
2019-10-21 05:03:35,379 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:35,789 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#59-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:35,789 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#59-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:37,792 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 127546ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 127546ms
2019-10-21 05:03:37,792 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 127546ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 127546ms
2019-10-21 05:03:38,290 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#60-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:38,290 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#60-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:38,378 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 127546ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 127546ms
2019-10-21 05:03:38,378 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:40,293 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 130047ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 130047ms
2019-10-21 05:03:40,293 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 130047ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 130047ms
2019-10-21 05:03:40,379 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 130047ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 130047ms
2019-10-21 05:03:40,379 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:40,791 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#61-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:40,791 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#61-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:42,794 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 132548ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 132548ms
2019-10-21 05:03:42,794 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 132549ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 132548ms
2019-10-21 05:03:43,293 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#62-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:43,293 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#62-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:43,379 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 132548ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 132548ms
2019-10-21 05:03:43,379 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:45,295 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 135049ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 135049ms
2019-10-21 05:03:45,296 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 135051ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 135050ms
2019-10-21 05:03:45,380 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 135049ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 135049ms
2019-10-21 05:03:45,380 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:45,794 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#63-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:45,795 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#63-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:47,796 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 137551ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 137550ms
2019-10-21 05:03:47,798 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 137552ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 137552ms
2019-10-21 05:03:48,295 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#64-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:48,296 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#64-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:48,380 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 137551ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 137550ms
2019-10-21 05:03:48,380 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:50,298 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 140052ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 140052ms
2019-10-21 05:03:50,300 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 140055ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 140054ms
2019-10-21 05:03:50,379 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 140052ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 140052ms
2019-10-21 05:03:50,379 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-10-21 05:03:50,796 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#65-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:50,798 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#65-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:52,799 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@2064f3a4] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 142553ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 142553ms
2019-10-21 05:03:52,802 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$557/744875818@78967e30] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(582)) - pipeline Action CLOSE  on pipeline PipelineID=5fc34561-5c66-49ae-a9c5-4fd89d25a9d8.Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 142556ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 142556ms
2019-10-21 05:03:53,298 [java.util.concurrent.ThreadPoolExecutor$Worker@61d3ff50[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c#66-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:53,300 [java.util.concurrent.ThreadPoolExecutor$Worker@3b15c9e2[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(200)) - 7d4ba912-917b-4f4e-a880-62fee1b9eb0e@group-4FD89D25A9D8->ea9103f6-20fd-4318-bf9c-fcf624e385d3-GrpcLogAppender: appendEntries Timeout, request=7d4ba912-917b-4f4e-a880-62fee1b9eb0e->ea9103f6-20fd-4318-bf9c-fcf624e385d3#66-t4, previous=(t:4, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-21 05:03:53,379 [EventQueue-PipelineActionsForPipelineActionHandler] ERROR pipeline.PipelineActionHandler (PipelineActionHandler.java:onMessage(60)) - Received pipeline action CLOSE for Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] from datanode 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}. Reason : 7d4ba912-917b-4f4e-a880-62fee1b9eb0e has not seen follower/s ea9103f6-20fd-4318-bf9c-fcf624e385d3 for 142553ms bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c for 142553ms
2019-10-21 05:03:53,379 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(354)) - destroying pipeline:Pipeline[ Id: 5fc34561-5c66-49ae-a9c5-4fd89d25a9d8, Nodes: 7d4ba912-917b-4f4e-a880-62fee1b9eb0e{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}bdcd399c-8b73-41dc-8cc1-b33ea43b9a3c{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}ea9103f6-20fd-4318-bf9c-fcf624e385d3{ip: 192.168.157.255, host: pr-hdds-1569-252f9-3696506840, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
]]></system-out>
    <system-err><![CDATA[Exception in thread "BlockDeletingService#0" java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:717)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1025)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
]]></system-err>
  </testcase>
  <testcase name="testListStatusFile" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.202"/>
  <testcase name="testListStatusNoDir" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.09"/>
  <testcase name="testListStatusFilteredNoDir" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.085"/>
  <testcase name="testListFilesFileRecursive" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.094"/>
  <testcase name="testLocatedStatusNoDir" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.089"/>
  <testcase name="testGetFileStatusNonexistentFile" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus" time="0.077"/>
</testsuite>