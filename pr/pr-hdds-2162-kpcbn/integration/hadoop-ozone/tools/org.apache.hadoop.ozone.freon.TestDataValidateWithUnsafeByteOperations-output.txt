2019-09-27 00:17:21,289 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:21,405 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:21,408 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:21,425 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @855ms
2019-09-27 00:17:21,527 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-27 00:17:21,527 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-27 00:17:21,528 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-27 00:17:21,528 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-27 00:17:21,528 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-27 00:17:21,528 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-27 00:17:21,540 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 00:17:21,540 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 00:17:21,541 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 00:17:21,817 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3e694b3f
2019-09-27 00:17:21,819 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-27 00:17:21,896 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 00:17:21,898 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 00:17:21,900 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-27 00:17:21,973 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-27 00:17:21,987 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:22,068 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-27 00:17:22,072 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:22,196 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-27 00:17:22,553 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:17:22,582 [Socket Reader #1 for port 43365] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43365
2019-09-27 00:17:22,758 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:17:22,759 [Socket Reader #1 for port 34509] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34509
2019-09-27 00:17:22,770 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:17:22,772 [Socket Reader #1 for port 41209] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41209
2019-09-27 00:17:22,802 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-27 00:17:22,968 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:22,986 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:22,997 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:23,000 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-27 00:17:23,001 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:23,001 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:23,033 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:41209
2019-09-27 00:17:23,098 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-27 00:17:23,116 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-27 00:17:23,116 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-27 00:17:23,344 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:41209
2019-09-27 00:17:23,344 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:17:23,345 [IPC Server listener on 41209] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41209: starting
2019-09-27 00:17:23,348 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34509
2019-09-27 00:17:23,349 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:34509
2019-09-27 00:17:23,350 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:17:23,350 [IPC Server listener on 34509] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34509: starting
2019-09-27 00:17:23,352 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:43365
2019-09-27 00:17:23,353 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:43365
2019-09-27 00:17:23,353 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:17:23,353 [IPC Server listener on 43365] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43365: starting
2019-09-27 00:17:23,357 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38738
2019-09-27 00:17:23,358 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:23,393 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:23,393 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:23,462 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70ab80e3{/,file:///tmp/jetty-0.0.0.0-38738-scm-_-any-3643028421529357503.dir/webapp/,AVAILABLE}{/scm}
2019-09-27 00:17:23,467 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@410954b{HTTP/1.1,[http/1.1]}{0.0.0.0:38738}
2019-09-27 00:17:23,467 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2897ms
2019-09-27 00:17:23,469 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-27 00:17:23,470 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-27 00:17:23,471 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:38738
2019-09-27 00:17:23,481 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@579d011c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:17:23,485 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:23,626 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-27 00:17:23,626 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-27 00:17:23,627 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:23,628 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:24,411 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:17:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-27 00:17:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-27 00:17:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-27 00:17:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-27 00:17:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-27 00:17:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-27 00:17:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-27 00:17:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-27 00:17:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-27 00:17:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-27 00:17:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-27 00:17:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-27 00:17:24,423 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-27 00:17:24,423 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-27 00:17:24,423 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-27 00:17:24,423 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-27 00:17:24,424 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-27 00:17:24,424 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-27 00:17:24,424 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-27 00:17:24,424 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-27 00:17:24,425 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-27 00:17:24,425 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-27 00:17:24,425 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 00:17:24,425 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 00:17:24,426 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 00:17:24,977 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:17:24,978 [Socket Reader #1 for port 39069] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39069
2019-09-27 00:17:25,024 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:39069
2019-09-27 00:17:25,025 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-27 00:17:25,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:17:25,027 [IPC Server listener on 39069] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39069: starting
2019-09-27 00:17:25,033 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-27 00:17:25,035 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:25,036 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:25,039 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:25,040 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-27 00:17:25,040 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:25,041 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:25,043 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45810
2019-09-27 00:17:25,044 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:25,046 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31ddd4a4{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:25,047 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b22b970{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:25,126 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@765df79d{/,file:///tmp/jetty-0.0.0.0-45810-ozoneManager-_-any-5374844029791649078.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-27 00:17:25,128 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@151335cb{HTTP/1.1,[http/1.1]}{0.0.0.0:45810}
2019-09-27 00:17:25,128 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4558ms
2019-09-27 00:17:25,129 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:17:25,130 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:45810
2019-09-27 00:17:25,507 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:17:25,561 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:17:25,604 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:17:25,606 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/containers/hdds to VolumeSet
2019-09-27 00:17:25,611 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-27 00:17:25,634 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-27 00:17:25,786 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:17:25,870 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:17:25,875 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:17:25,876 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:17:25,877 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:25,878 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:17:25,879 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:26,094 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis] (custom)
2019-09-27 00:17:26,153 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:17:26,156 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:26,157 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:26,160 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:26,162 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:17:26,162 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:26,162 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:26,164 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44746
2019-09-27 00:17:26,165 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:26,168 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:26,169 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:26,212 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d910b3{/,file:///tmp/jetty-0.0.0.0-44746-hddsDatanode-_-any-332798746736898187.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:17:26,214 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:44746}
2019-09-27 00:17:26,214 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5644ms
2019-09-27 00:17:26,215 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:17:26,216 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44746
2019-09-27 00:17:26,217 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:17:26,222 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:17:26,224 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@335542ef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:17:26,231 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:17:26,233 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/containers/hdds to VolumeSet
2019-09-27 00:17:26,233 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-27 00:17:26,235 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-27 00:17:26,258 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:17:26,259 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:17:26,259 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:17:26,259 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:17:26,260 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:26,260 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:17:26,261 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:26,261 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis] (custom)
2019-09-27 00:17:26,264 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:17:26,266 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:26,267 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:26,270 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:26,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:17:26,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:26,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:26,272 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46450
2019-09-27 00:17:26,273 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:26,277 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:26,278 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:26,324 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28da7d11{/,file:///tmp/jetty-0.0.0.0-46450-hddsDatanode-_-any-8270317798468319541.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:17:26,326 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:46450}
2019-09-27 00:17:26,327 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5756ms
2019-09-27 00:17:26,327 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:17:26,328 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46450
2019-09-27 00:17:26,329 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:17:26,333 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@275ba27e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:17:26,333 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:17:26,338 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/meta/datanode.id
2019-09-27 00:17:26,346 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:17:26,346 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/containers/hdds to VolumeSet
2019-09-27 00:17:26,347 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@40e37b06
2019-09-27 00:17:26,347 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/meta/datanode.id
2019-09-27 00:17:26,348 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@40e37b06
2019-09-27 00:17:26,371 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:17:26,372 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:17:26,372 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:17:26,372 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:17:26,373 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:26,373 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:17:26,373 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:26,374 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis] (custom)
2019-09-27 00:17:26,377 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:17:26,378 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:26,379 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:26,380 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:26,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:17:26,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:26,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:26,382 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38570
2019-09-27 00:17:26,382 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:26,384 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588f63c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:26,385 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1981d861{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:26,413 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@41eb94bc{/,file:///tmp/jetty-0.0.0.0-38570-hddsDatanode-_-any-7033437487117179555.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:17:26,413 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@378cfecf{HTTP/1.1,[http/1.1]}{0.0.0.0:38570}
2019-09-27 00:17:26,414 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5844ms
2019-09-27 00:17:26,414 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:17:26,416 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38570
2019-09-27 00:17:26,416 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:17:26,419 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:17:26,420 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3970232d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:17:26,423 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/meta/datanode.id
2019-09-27 00:17:26,430 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:17:26,430 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/containers/hdds to VolumeSet
2019-09-27 00:17:26,431 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-27 00:17:26,431 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-27 00:17:26,446 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:17:26,446 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:17:26,446 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:17:26,447 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:17:26,447 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:26,447 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:17:26,447 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:26,448 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis] (custom)
2019-09-27 00:17:26,449 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:17:26,451 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:26,451 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:26,453 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:26,453 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:17:26,453 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:26,453 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:26,454 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41673
2019-09-27 00:17:26,454 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:26,458 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:26,458 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:26,486 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dc3502b{/,file:///tmp/jetty-0.0.0.0-41673-hddsDatanode-_-any-3344035487868604911.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:17:26,487 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:41673}
2019-09-27 00:17:26,487 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5917ms
2019-09-27 00:17:26,488 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:17:26,489 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41673
2019-09-27 00:17:26,489 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:17:26,493 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c305fe0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:17:26,494 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:17:26,497 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/meta/datanode.id
2019-09-27 00:17:26,506 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:17:26,506 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/containers/hdds to VolumeSet
2019-09-27 00:17:26,507 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@250a500b
2019-09-27 00:17:26,508 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@250a500b
2019-09-27 00:17:26,526 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:17:26,526 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:17:26,526 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:17:26,527 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:17:26,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:26,528 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:17:26,528 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:26,529 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis] (custom)
2019-09-27 00:17:26,532 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:17:26,534 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:17:26,536 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:17:26,538 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:17:26,539 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:17:26,539 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:17:26,540 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:17:26,541 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43186
2019-09-27 00:17:26,541 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:17:26,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2630dbc4{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:17:26,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a1c3cb4{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:17:26,590 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@21505815{/,file:///tmp/jetty-0.0.0.0-43186-hddsDatanode-_-any-4365132853254437858.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:17:26,590 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e53339{HTTP/1.1,[http/1.1]}{0.0.0.0:43186}
2019-09-27 00:17:26,591 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6021ms
2019-09-27 00:17:26,592 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:17:26,592 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43186
2019-09-27 00:17:26,595 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:17:26,596 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38539304] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:17:26,600 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/meta/datanode.id
2019-09-27 00:17:27,595 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:17:28,288 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:17:28,292 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:17:28,292 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f at port 0
2019-09-27 00:17:28,324 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: start RPC server
2019-09-27 00:17:28,353 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:17:28,360 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:17:28,360 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78 at port 0
2019-09-27 00:17:28,374 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start RPC server
2019-09-27 00:17:28,440 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:17:28,441 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:17:28,442 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis da98b069-9f6e-4a69-a7c9-6291acdc1fbb at port 0
2019-09-27 00:17:28,450 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: start RPC server
2019-09-27 00:17:28,498 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: GrpcService started, listening on 0.0.0.0/0.0.0.0:36514
2019-09-27 00:17:28,498 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: GrpcService started, listening on 0.0.0.0/0.0.0.0:41573
2019-09-27 00:17:28,498 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: GrpcService started, listening on 0.0.0.0/0.0.0.0:35187
2019-09-27 00:17:28,499 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis da98b069-9f6e-4a69-a7c9-6291acdc1fbb is started using port 41573
2019-09-27 00:17:28,499 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78 is started using port 36514
2019-09-27 00:17:28,499 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f is started using port 35187
2019-09-27 00:17:28,507 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f is started using port 45059
2019-09-27 00:17:28,508 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc da98b069-9f6e-4a69-a7c9-6291acdc1fbb is started using port 35751
2019-09-27 00:17:28,507 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78 is started using port 45270
2019-09-27 00:17:28,512 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:17:28,514 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:17:28,516 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 53d26a16-5a67-474e-adf9-d44acce35b5f at port 0
2019-09-27 00:17:28,527 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start RPC server
2019-09-27 00:17:28,530 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: GrpcService started, listening on 0.0.0.0/0.0.0.0:36487
2019-09-27 00:17:28,531 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 53d26a16-5a67-474e-adf9-d44acce35b5f is started using port 36487
2019-09-27 00:17:28,534 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 53d26a16-5a67-474e-adf9-d44acce35b5f is started using port 33521
2019-09-27 00:17:28,596 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:17:28,623 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:17:28,631 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:17:28,631 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis f0921ff9-92b1-4e12-aada-0bc4b3386eaa at port 0
2019-09-27 00:17:28,644 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start RPC server
2019-09-27 00:17:28,648 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: GrpcService started, listening on 0.0.0.0/0.0.0.0:36798
2019-09-27 00:17:28,649 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis f0921ff9-92b1-4e12-aada-0bc4b3386eaa is started using port 36798
2019-09-27 00:17:28,652 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc f0921ff9-92b1-4e12-aada-0bc4b3386eaa is started using port 33300
2019-09-27 00:17:29,597 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:17:30,278 [IPC Server handler 14 on 43365] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f
2019-09-27 00:17:30,278 [IPC Server handler 14 on 43365] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:17:30,285 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-27 00:17:30,285 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-27 00:17:30,285 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-27 00:17:30,337 [IPC Server handler 7 on 43365] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/1d3a2991-ffc0-4d33-aec5-6dcc1711fd78
2019-09-27 00:17:30,338 [IPC Server handler 7 on 43365] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:17:30,425 [IPC Server handler 18 on 43365] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/da98b069-9f6e-4a69-a7c9-6291acdc1fbb
2019-09-27 00:17:30,426 [IPC Server handler 18 on 43365] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : da98b069-9f6e-4a69-a7c9-6291acdc1fbb{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:17:30,498 [IPC Server handler 17 on 43365] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:17:30,498 [IPC Server handler 17 on 43365] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 53d26a16-5a67-474e-adf9-d44acce35b5f{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:17:30,599 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-27 00:17:30,600 [IPC Server handler 14 on 43365] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f0921ff9-92b1-4e12-aada-0bc4b3386eaa
2019-09-27 00:17:30,600 [IPC Server handler 14 on 43365] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : f0921ff9-92b1-4e12-aada-0bc4b3386eaa{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:17:30,825 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: addNew group-1BD974C031C0:[e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:192.168.151.109:35187] returns group-1BD974C031C0:java.util.concurrent.CompletableFuture@59168ec5[Not completed]
2019-09-27 00:17:30,847 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: new RaftServerImpl for group-1BD974C031C0:[e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:192.168.151.109:35187] with ContainerStateMachine:uninitialized
2019-09-27 00:17:30,848 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:30,850 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:30,850 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:30,851 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:30,851 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:30,859 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: ConfigurationManager, init=-1: [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:192.168.151.109:35187], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:30,859 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis] (custom)
2019-09-27 00:17:30,866 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis/4140b4b6-4f37-4692-b645-1bd974c031c0 does not exist. Creating ...
2019-09-27 00:17:30,883 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis/4140b4b6-4f37-4692-b645-1bd974c031c0/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:30,887 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis/4140b4b6-4f37-4692-b645-1bd974c031c0 has been successfully formatted.
2019-09-27 00:17:30,890 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1BD974C031C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:30,890 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:30,892 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:30,897 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:30,897 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:30,900 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:30,904 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:30,910 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis/4140b4b6-4f37-4692-b645-1bd974c031c0
2019-09-27 00:17:30,911 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-27 00:17:30,917 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-27 00:17:30,947 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:30,947 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:30,950 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:30,951 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:30,951 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:30,952 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:30,953 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:30,953 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:30,953 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:30,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:30,968 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:30,972 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:30,973 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:30,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:30,974 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,000 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: start as a follower, conf=-1: [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:192.168.151.109:35187], old=null
2019-09-27 00:17:31,001 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,002 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: start FollowerState
2019-09-27 00:17:31,004 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1BD974C031C0,id=e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f
2019-09-27 00:17:31,074 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4140b4b6-4f37-4692-b645-1bd974c031c0, Nodes: e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:17:31,096 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: addNew group-1C3A3E8E0F45:[53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] returns group-1C3A3E8E0F45:java.util.concurrent.CompletableFuture@1b660a18[Not completed]
2019-09-27 00:17:31,139 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: new RaftServerImpl for group-1C3A3E8E0F45:[53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,140 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,141 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: ConfigurationManager, init=-1: [53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,141 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis] (custom)
2019-09-27 00:17:31,141 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/26d44f68-7053-4de4-9cfd-1c3a3e8e0f45 does not exist. Creating ...
2019-09-27 00:17:31,154 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/26d44f68-7053-4de4-9cfd-1c3a3e8e0f45/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,174 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/26d44f68-7053-4de4-9cfd-1c3a3e8e0f45 has been successfully formatted.
2019-09-27 00:17:31,176 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1C3A3E8E0F45: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,178 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,179 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,179 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/26d44f68-7053-4de4-9cfd-1c3a3e8e0f45
2019-09-27 00:17:31,185 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,185 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,186 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,186 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,186 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,186 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,186 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,187 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,187 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,187 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,188 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,188 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,193 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: start as a follower, conf=-1: [53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:31,193 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,193 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start FollowerState
2019-09-27 00:17:31,195 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C3A3E8E0F45,id=53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:17:31,213 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 26d44f68-7053-4de4-9cfd-1c3a3e8e0f45, Nodes: 53d26a16-5a67-474e-adf9-d44acce35b5f{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:17:31,231 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: addNew group-0CCE3748D473:[f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798] returns group-0CCE3748D473:java.util.concurrent.CompletableFuture@7e2e3d17[Not completed]
2019-09-27 00:17:31,253 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: new RaftServerImpl for group-0CCE3748D473:[f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,254 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,254 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,254 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,254 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,254 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,255 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: ConfigurationManager, init=-1: [f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,255 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis] (custom)
2019-09-27 00:17:31,255 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/e24a0df9-c1b4-4d2b-99f6-0cce3748d473 does not exist. Creating ...
2019-09-27 00:17:31,280 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/e24a0df9-c1b4-4d2b-99f6-0cce3748d473/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,293 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/e24a0df9-c1b4-4d2b-99f6-0cce3748d473 has been successfully formatted.
2019-09-27 00:17:31,293 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0CCE3748D473: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,294 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,294 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,294 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,294 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,294 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,295 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,295 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/e24a0df9-c1b4-4d2b-99f6-0cce3748d473
2019-09-27 00:17:31,330 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,330 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,330 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,331 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,331 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,331 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,331 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,331 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,331 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,332 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,332 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,332 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,333 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,333 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,333 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,338 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: start as a follower, conf=-1: [f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798], old=null
2019-09-27 00:17:31,338 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,338 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start FollowerState
2019-09-27 00:17:31,338 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0CCE3748D473,id=f0921ff9-92b1-4e12-aada-0bc4b3386eaa
2019-09-27 00:17:31,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e24a0df9-c1b4-4d2b-99f6-0cce3748d473, Nodes: f0921ff9-92b1-4e12-aada-0bc4b3386eaa{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:17:31,366 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: addNew group-E845166F496A:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514] returns group-E845166F496A:java.util.concurrent.CompletableFuture@812f46f[Not completed]
2019-09-27 00:17:31,367 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: new RaftServerImpl for group-E845166F496A:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,367 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,367 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,368 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,368 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,368 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,368 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: ConfigurationManager, init=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,368 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis] (custom)
2019-09-27 00:17:31,368 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/f0f4bdc7-cb76-4d46-8064-e845166f496a does not exist. Creating ...
2019-09-27 00:17:31,381 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/f0f4bdc7-cb76-4d46-8064-e845166f496a/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,393 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/f0f4bdc7-cb76-4d46-8064-e845166f496a has been successfully formatted.
2019-09-27 00:17:31,394 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E845166F496A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,395 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/f0f4bdc7-cb76-4d46-8064-e845166f496a
2019-09-27 00:17:31,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,400 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,400 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,400 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,400 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,400 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,404 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: start as a follower, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514], old=null
2019-09-27 00:17:31,404 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,404 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start FollowerState
2019-09-27 00:17:31,404 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E845166F496A,id=1d3a2991-ffc0-4d33-aec5-6dcc1711fd78
2019-09-27 00:17:31,415 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f0f4bdc7-cb76-4d46-8064-e845166f496a, Nodes: 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:17:31,442 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: addNew group-8A9910F96D8F:[da98b069-9f6e-4a69-a7c9-6291acdc1fbb:192.168.151.109:41573] returns group-8A9910F96D8F:java.util.concurrent.CompletableFuture@2c0b5439[Not completed]
2019-09-27 00:17:31,444 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: new RaftServerImpl for group-8A9910F96D8F:[da98b069-9f6e-4a69-a7c9-6291acdc1fbb:192.168.151.109:41573] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,445 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,445 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,445 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,445 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,445 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,445 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: ConfigurationManager, init=-1: [da98b069-9f6e-4a69-a7c9-6291acdc1fbb:192.168.151.109:41573], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,446 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis] (custom)
2019-09-27 00:17:31,446 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis/e3cb4ef8-1ae7-4362-b445-8a9910f96d8f does not exist. Creating ...
2019-09-27 00:17:31,468 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis/e3cb4ef8-1ae7-4362-b445-8a9910f96d8f/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,481 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis/e3cb4ef8-1ae7-4362-b445-8a9910f96d8f has been successfully formatted.
2019-09-27 00:17:31,481 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-8A9910F96D8F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,481 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,482 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis/e3cb4ef8-1ae7-4362-b445-8a9910f96d8f
2019-09-27 00:17:31,487 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,487 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,487 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,487 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,488 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,488 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,488 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,488 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,488 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,488 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,489 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,489 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,489 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,489 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,490 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,493 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: start as a follower, conf=-1: [da98b069-9f6e-4a69-a7c9-6291acdc1fbb:192.168.151.109:41573], old=null
2019-09-27 00:17:31,494 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,494 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: start FollowerState
2019-09-27 00:17:31,494 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8A9910F96D8F,id=da98b069-9f6e-4a69-a7c9-6291acdc1fbb
2019-09-27 00:17:31,508 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e3cb4ef8-1ae7-4362-b445-8a9910f96d8f, Nodes: da98b069-9f6e-4a69-a7c9-6291acdc1fbb{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:17:31,542 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: addNew group-F96EFF3B4AF8:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] returns group-F96EFF3B4AF8:java.util.concurrent.CompletableFuture@152a3f3d[Not completed]
2019-09-27 00:17:31,545 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: addNew group-F96EFF3B4AF8:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] returns group-F96EFF3B4AF8:java.util.concurrent.CompletableFuture@8cd21c6[Not completed]
2019-09-27 00:17:31,545 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: addNew group-F96EFF3B4AF8:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] returns group-F96EFF3B4AF8:java.util.concurrent.CompletableFuture@6993d88e[Not completed]
2019-09-27 00:17:31,545 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: new RaftServerImpl for group-F96EFF3B4AF8:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,545 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,546 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,546 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,546 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,546 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,546 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: ConfigurationManager, init=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,546 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis] (custom)
2019-09-27 00:17:31,547 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8 does not exist. Creating ...
2019-09-27 00:17:31,547 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: new RaftServerImpl for group-F96EFF3B4AF8:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,548 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,548 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,548 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,548 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,549 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,549 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: new RaftServerImpl for group-F96EFF3B4AF8:[1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487] with ContainerStateMachine:uninitialized
2019-09-27 00:17:31,549 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: ConfigurationManager, init=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,549 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:17:31,549 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis] (custom)
2019-09-27 00:17:31,549 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:17:31,550 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:17:31,550 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8 does not exist. Creating ...
2019-09-27 00:17:31,550 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:17:31,550 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:31,550 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: ConfigurationManager, init=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null, confs=<EMPTY_MAP>
2019-09-27 00:17:31,550 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis] (custom)
2019-09-27 00:17:31,551 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8 does not exist. Creating ...
2019-09-27 00:17:31,560 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,560 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,560 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8/in_use.lock acquired by nodename 20555@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:17:31,574 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8 has been successfully formatted.
2019-09-27 00:17:31,574 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8 has been successfully formatted.
2019-09-27 00:17:31,574 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8 has been successfully formatted.
2019-09-27 00:17:31,575 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F96EFF3B4AF8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,575 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F96EFF3B4AF8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,575 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F96EFF3B4AF8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:17:31,575 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,575 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:17:31,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,575 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,576 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:17:31,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,576 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,576 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:17:31,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,576 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,577 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8
2019-09-27 00:17:31,577 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:31,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,577 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,577 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,577 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,578 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:17:31,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,578 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8
2019-09-27 00:17:31,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,578 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8
2019-09-27 00:17:31,579 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,578 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,579 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,579 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:17:31,579 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,579 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,579 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,579 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:17:31,580 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,580 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,580 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:17:31,580 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,580 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:17:31,580 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,581 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,580 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:17:31,581 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,581 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:17:31,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,581 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,582 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,581 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:17:31,582 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:17:31,582 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,582 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:17:31,583 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:17:31,583 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,583 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:17:31,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,584 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:17:31,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,584 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:17:31,584 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:17:31,585 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:17:31,585 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: start as a follower, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:31,585 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,585 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start FollowerState
2019-09-27 00:17:31,585 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96EFF3B4AF8,id=1d3a2991-ffc0-4d33-aec5-6dcc1711fd78
2019-09-27 00:17:31,588 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: start as a follower, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:31,588 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,588 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start FollowerState
2019-09-27 00:17:31,589 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96EFF3B4AF8,id=f0921ff9-92b1-4e12-aada-0bc4b3386eaa
2019-09-27 00:17:31,603 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-27 00:17:31,603 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: start as a follower, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:31,606 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:17:31,606 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start FollowerState
2019-09-27 00:17:31,607 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96EFF3B4AF8,id=53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:17:31,615 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9ee1cab7-c5a5-4680-822c-f96eff3b4af8, Nodes: 53d26a16-5a67-474e-adf9-d44acce35b5f{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}f0921ff9-92b1-4e12-aada-0bc4b3386eaa{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}1d3a2991-ffc0-4d33-aec5-6dcc1711fd78{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-27 00:17:32,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:33,292 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-27 00:17:33,296 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-27 00:17:33,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:34,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:35,816 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:36,063 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:group-1BD974C031C0 changes to CANDIDATE, lastRpcTime:5061, electionTimeout:5060ms
2019-09-27 00:17:36,068 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: shutdown FollowerState
2019-09-27 00:17:36,068 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,076 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: start LeaderElection
2019-09-27 00:17:36,093 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1: begin an election at term 1 for -1: [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:192.168.151.109:35187], old=null
2019-09-27 00:17:36,095 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: shutdown LeaderElection
2019-09-27 00:17:36,096 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:17:36,096 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: change Leader from null to e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f at term 1 for becomeLeader, leader elected after 5206ms
2019-09-27 00:17:36,105 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:17:36,105 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:17:36,109 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:17:36,113 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:17:36,113 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:17:36,120 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:17:36,136 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: start LeaderState
2019-09-27 00:17:36,162 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:36,172 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: set configuration 0: [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f:192.168.151.109:35187], old=null at 0
2019-09-27 00:17:36,274 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 53d26a16-5a67-474e-adf9-d44acce35b5f:group-1C3A3E8E0F45 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5079ms
2019-09-27 00:17:36,276 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown FollowerState
2019-09-27 00:17:36,276 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,276 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start LeaderElection
2019-09-27 00:17:36,293 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2: begin an election at term 1 for -1: [53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,295 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown LeaderElection
2019-09-27 00:17:36,295 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:17:36,295 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: change Leader from null to 53d26a16-5a67-474e-adf9-d44acce35b5f at term 1 for becomeLeader, leader elected after 5117ms
2019-09-27 00:17:36,297 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:17:36,297 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:17:36,297 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:17:36,298 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:17:36,298 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:17:36,298 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:17:36,301 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start LeaderState
2019-09-27 00:17:36,302 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:36,303 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: set configuration 0: [53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null at 0
2019-09-27 00:17:36,399 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/ratis/4140b4b6-4f37-4692-b645-1bd974c031c0/current/log_inprogress_0
2019-09-27 00:17:36,401 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/26d44f68-7053-4de4-9cfd-1c3a3e8e0f45/current/log_inprogress_0
2019-09-27 00:17:36,445 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa:group-0CCE3748D473 changes to CANDIDATE, lastRpcTime:5106, electionTimeout:5106ms
2019-09-27 00:17:36,445 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown FollowerState
2019-09-27 00:17:36,445 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,445 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start LeaderElection
2019-09-27 00:17:36,470 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3: begin an election at term 1 for -1: [f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798], old=null
2019-09-27 00:17:36,470 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown LeaderElection
2019-09-27 00:17:36,470 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:17:36,470 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: change Leader from null to f0921ff9-92b1-4e12-aada-0bc4b3386eaa at term 1 for becomeLeader, leader elected after 5176ms
2019-09-27 00:17:36,472 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:17:36,472 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:17:36,472 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:17:36,473 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:17:36,473 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:17:36,473 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:17:36,477 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start LeaderState
2019-09-27 00:17:36,477 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:36,478 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: set configuration 0: [f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798], old=null at 0
2019-09-27 00:17:36,535 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:group-E845166F496A changes to CANDIDATE, lastRpcTime:5131, electionTimeout:5131ms
2019-09-27 00:17:36,536 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown FollowerState
2019-09-27 00:17:36,536 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,536 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start LeaderElection
2019-09-27 00:17:36,544 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/e24a0df9-c1b4-4d2b-99f6-0cce3748d473/current/log_inprogress_0
2019-09-27 00:17:36,546 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4: begin an election at term 1 for -1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514], old=null
2019-09-27 00:17:36,546 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown LeaderElection
2019-09-27 00:17:36,546 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:17:36,546 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: change Leader from null to 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78 at term 1 for becomeLeader, leader elected after 5152ms
2019-09-27 00:17:36,548 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:17:36,548 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:17:36,548 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:17:36,549 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:17:36,549 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:17:36,549 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:17:36,553 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start LeaderState
2019-09-27 00:17:36,553 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:36,553 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: set configuration 0: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514], old=null at 0
2019-09-27 00:17:36,593 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb:group-8A9910F96D8F changes to CANDIDATE, lastRpcTime:5098, electionTimeout:5086ms
2019-09-27 00:17:36,593 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa:group-F96EFF3B4AF8 changes to CANDIDATE, lastRpcTime:5004, electionTimeout:5004ms
2019-09-27 00:17:36,593 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: shutdown FollowerState
2019-09-27 00:17:36,593 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,594 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown FollowerState
2019-09-27 00:17:36,594 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: start LeaderElection
2019-09-27 00:17:36,594 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,596 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start LeaderElection
2019-09-27 00:17:36,603 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:group-F96EFF3B4AF8 changes to CANDIDATE, lastRpcTime:5017, electionTimeout:5017ms
2019-09-27 00:17:36,603 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown FollowerState
2019-09-27 00:17:36,603 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,604 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start LeaderElection
2019-09-27 00:17:36,618 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/f0f4bdc7-cb76-4d46-8064-e845166f496a/current/log_inprogress_0
2019-09-27 00:17:36,621 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5: begin an election at term 1 for -1: [da98b069-9f6e-4a69-a7c9-6291acdc1fbb:192.168.151.109:41573], old=null
2019-09-27 00:17:36,621 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: shutdown LeaderElection
2019-09-27 00:17:36,621 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:17:36,621 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: change Leader from null to da98b069-9f6e-4a69-a7c9-6291acdc1fbb at term 1 for becomeLeader, leader elected after 5140ms
2019-09-27 00:17:36,623 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:17:36,623 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:17:36,624 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:17:36,624 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:17:36,624 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:17:36,624 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:17:36,630 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: start LeaderState
2019-09-27 00:17:36,630 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:36,631 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: set configuration 0: [da98b069-9f6e-4a69-a7c9-6291acdc1fbb:192.168.151.109:41573], old=null at 0
2019-09-27 00:17:36,668 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6: begin an election at term 1 for -1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,668 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7: begin an election at term 1 for -1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,693 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/ratis/e3cb4ef8-1ae7-4362-b445-8a9910f96d8f/current/log_inprogress_0
2019-09-27 00:17:36,696 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - 53d26a16-5a67-474e-adf9-d44acce35b5f:group-F96EFF3B4AF8 changes to CANDIDATE, lastRpcTime:5090, electionTimeout:5089ms
2019-09-27 00:17:36,697 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown FollowerState
2019-09-27 00:17:36,697 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:17:36,697 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start LeaderElection
2019-09-27 00:17:36,709 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8: begin an election at term 1 for -1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,751 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7: Election REJECTED; received 2 response(s) [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78<-f0921ff9-92b1-4e12-aada-0bc4b3386eaa#0:FAIL-t1, 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78<-53d26a16-5a67-474e-adf9-d44acce35b5f#0:FAIL-t1] and 0 exception(s); 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:t1, leader=null, voted=1d3a2991-ffc0-4d33-aec5-6dcc1711fd78, raftlog=1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,753 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6: Election REJECTED; received 2 response(s) [f0921ff9-92b1-4e12-aada-0bc4b3386eaa<-1d3a2991-ffc0-4d33-aec5-6dcc1711fd78#0:FAIL-t1, f0921ff9-92b1-4e12-aada-0bc4b3386eaa<-53d26a16-5a67-474e-adf9-d44acce35b5f#0:FAIL-t1] and 0 exception(s); f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:t1, leader=null, voted=f0921ff9-92b1-4e12-aada-0bc4b3386eaa, raftlog=f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,759 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 00:17:36,760 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown LeaderElection
2019-09-27 00:17:36,762 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 00:17:36,764 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start FollowerState
2019-09-27 00:17:36,764 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown LeaderElection
2019-09-27 00:17:36,768 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start FollowerState
2019-09-27 00:17:36,775 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8: Election REJECTED; received 2 response(s) [53d26a16-5a67-474e-adf9-d44acce35b5f<-1d3a2991-ffc0-4d33-aec5-6dcc1711fd78#0:FAIL-t1, 53d26a16-5a67-474e-adf9-d44acce35b5f<-f0921ff9-92b1-4e12-aada-0bc4b3386eaa#0:FAIL-t1] and 0 exception(s); 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:t1, leader=null, voted=53d26a16-5a67-474e-adf9-d44acce35b5f, raftlog=53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:36,775 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 00:17:36,778 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown LeaderElection
2019-09-27 00:17:36,779 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start FollowerState
2019-09-27 00:17:36,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:37,820 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:38,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:39,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:40,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:41,781 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(106)) - 53d26a16-5a67-474e-adf9-d44acce35b5f:group-F96EFF3B4AF8 changes to CANDIDATE, lastRpcTime:5001, electionTimeout:5000ms
2019-09-27 00:17:41,781 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown FollowerState
2019-09-27 00:17:41,781 [Thread-256] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-27 00:17:41,782 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start LeaderElection
2019-09-27 00:17:41,797 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9: begin an election at term 2 for -1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:41,806 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:17:41,807 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown FollowerState
2019-09-27 00:17:41,807 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:17:41,807 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: start FollowerState
2019-09-27 00:17:41,807 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(115)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:17:41,807 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown FollowerState
2019-09-27 00:17:41,809 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: start FollowerState
2019-09-27 00:17:41,809 [Thread-255] INFO  impl.FollowerState (FollowerState.java:run(115)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:17:41,827 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:41,844 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9: Election PASSED; received 1 response(s) [53d26a16-5a67-474e-adf9-d44acce35b5f<-1d3a2991-ffc0-4d33-aec5-6dcc1711fd78#0:OK-t2] and 0 exception(s); 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:t2, leader=null, voted=53d26a16-5a67-474e-adf9-d44acce35b5f, raftlog=53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null
2019-09-27 00:17:41,844 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown LeaderElection
2019-09-27 00:17:41,846 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-27 00:17:41,847 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: change Leader from null to 53d26a16-5a67-474e-adf9-d44acce35b5f at term 2 for becomeLeader, leader elected after 10271ms
2019-09-27 00:17:41,847 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:17:41,847 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:17:41,847 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:17:41,847 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:17:41,848 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:17:41,848 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:17:41,854 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 00:17:41,855 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:41,855 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 00:17:41,860 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 00:17:41,861 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:41,861 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:41,862 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 00:17:41,863 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:17:41,863 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 00:17:41,863 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 00:17:41,863 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:17:41,863 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:17:41,867 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: start LeaderState
2019-09-27 00:17:41,867 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:41,868 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: set configuration 0: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null at 0
2019-09-27 00:17:41,927 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8/current/log_inprogress_0
2019-09-27 00:17:41,934 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: change Leader from null to 53d26a16-5a67-474e-adf9-d44acce35b5f at term 2 for appendEntries, leader elected after 10358ms
2019-09-27 00:17:41,934 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: change Leader from null to 53d26a16-5a67-474e-adf9-d44acce35b5f at term 2 for appendEntries, leader elected after 10358ms
2019-09-27 00:17:41,969 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: set configuration 0: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null at 0
2019-09-27 00:17:41,969 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: set configuration 0: [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78:192.168.151.109:36514, f0921ff9-92b1-4e12-aada-0bc4b3386eaa:192.168.151.109:36798, 53d26a16-5a67-474e-adf9-d44acce35b5f:192.168.151.109:36487], old=null at 0
2019-09-27 00:17:41,969 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:41,969 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:17:42,016 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8/current/log_inprogress_0
2019-09-27 00:17:42,016 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/ratis/9ee1cab7-c5a5-4680-822c-f96eff3b4af8/current/log_inprogress_0
2019-09-27 00:17:42,851 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:43,853 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:44,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:45,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:46,858 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:47,859 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:48,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:49,862 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:50,864 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:51,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:51,869 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:17:52,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:53,873 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:54,875 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:55,876 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:56,877 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:57,879 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:58,880 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:17:59,882 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:00,884 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:01,885 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:01,887 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:18:02,888 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:03,890 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:04,892 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:05,894 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:06,895 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:07,896 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:08,898 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:09,900 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:10,901 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:11,903 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:11,905 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:18:12,906 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:13,908 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:14,910 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:15,911 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:16,913 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:17,914 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:18,916 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:19,917 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:20,919 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:21,920 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:21,923 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:18:22,924 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:23,925 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:24,927 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:25,929 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:26,930 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:27,932 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:28,933 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:29,935 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:30,937 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:31,938 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:31,942 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:18:32,943 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:33,945 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:34,946 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:35,948 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:36,949 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:37,951 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:38,952 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:39,954 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:40,955 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:41,957 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:41,959 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:18:42,960 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:43,961 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:44,963 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:45,964 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:46,966 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:47,967 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:48,969 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:49,970 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:50,971 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:51,973 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:51,975 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:18:52,976 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:53,977 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:54,979 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:55,980 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:56,982 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:57,983 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:58,985 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:18:59,986 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:00,987 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:01,989 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:01,991 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:19:02,992 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:03,994 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:04,995 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:05,997 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:06,998 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:07,999 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:09,001 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:10,002 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:11,004 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:12,006 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:12,009 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:19:13,010 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:14,011 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:15,013 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:16,014 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:17,016 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:18,017 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:19,018 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:20,020 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:21,021 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:22,023 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:22,025 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:19:22,030 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-27 00:19:23,057 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:24,058 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:25,061 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:26,063 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:27,064 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:28,066 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:29,067 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:30,069 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:31,070 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:32,072 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:33,075 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:34,076 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:35,077 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:36,079 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:37,080 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:38,082 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:39,083 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:40,085 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:41,087 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:42,088 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:42,090 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:19:43,091 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:44,094 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:45,095 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:46,097 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:47,099 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:48,100 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:49,101 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:50,103 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:51,104 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:52,106 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:52,108 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:19:53,109 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:54,111 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:55,112 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:56,114 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:57,116 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:58,117 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:19:59,118 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:00,120 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:01,121 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:02,123 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:02,125 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:20:03,127 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:04,128 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:05,130 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:06,131 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:07,133 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:08,134 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:09,136 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:10,137 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:11,139 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:12,140 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:12,143 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:20:13,144 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:14,146 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:15,147 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:16,149 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:17,150 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:18,152 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:19,153 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:20,155 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:21,156 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:22,157 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:22,159 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:20:23,161 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:24,162 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:25,164 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:26,165 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:27,167 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:28,168 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:29,170 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:30,171 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:31,172 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:32,174 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:32,176 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:20:33,204 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:34,206 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:35,209 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:36,210 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:37,212 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:38,213 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:39,215 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:40,216 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:41,218 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:42,219 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:42,221 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:20:43,222 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:44,224 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:45,225 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:46,227 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:47,228 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:48,230 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:49,232 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:50,234 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:51,236 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:52,238 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:52,240 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:20:53,241 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:54,243 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:55,244 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:56,245 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:57,247 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:58,248 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:20:59,250 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:00,251 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:01,253 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:02,254 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:02,256 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:21:03,257 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:04,258 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:05,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:06,261 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:07,263 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:08,264 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:09,265 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:10,267 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:11,272 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:12,274 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:12,276 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:21:12,277 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-27 00:21:13,286 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:14,288 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:15,289 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:16,291 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:17,292 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:18,293 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:19,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:20,296 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:21,297 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:22,299 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:23,302 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:24,303 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:25,305 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:26,306 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:27,308 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:28,309 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:29,310 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:30,312 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:31,313 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:32,314 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:32,316 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:21:33,317 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:34,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:35,320 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:36,321 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:37,323 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:38,324 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:39,325 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:40,531 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:41,532 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:42,534 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:42,535 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:21:43,538 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:44,541 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:45,543 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:46,545 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:47,549 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:48,550 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:49,554 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:50,555 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:51,557 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:52,558 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:52,559 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:21:53,561 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:54,562 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:55,563 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:56,565 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:57,566 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:58,567 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:21:59,568 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:00,570 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:01,571 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:02,572 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:02,574 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:22:03,575 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:04,576 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:05,578 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:06,579 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:07,580 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:08,582 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:09,583 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:10,584 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:11,585 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:12,587 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:12,588 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:22:13,590 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:14,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:15,593 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:16,595 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:17,596 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:18,597 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:19,599 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:20,600 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:21,601 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:22,602 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:22,604 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:22:23,606 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:24,607 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:25,608 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:26,610 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:27,611 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:28,612 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:29,613 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:30,614 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:31,616 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:32,617 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:32,619 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:22:33,296 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-27 00:22:33,620 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:34,621 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:35,622 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:36,623 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:37,625 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:38,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:39,627 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:40,628 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:41,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:42,631 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:42,632 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:22:43,633 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:44,635 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:45,637 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:46,638 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:47,639 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:48,640 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:49,641 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:50,643 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:51,644 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:52,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:52,647 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:22:53,648 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:54,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:55,651 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:56,652 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:57,653 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:58,654 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:22:59,655 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:23:00,657 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:23:01,658 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:23:02,659 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:23:02,660 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:23:02,661 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.validateWriteTest(TestDataValidate.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-27 00:23:02,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-27 00:23:02,666 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-27 00:23:02,666 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-27 00:23:02,666 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39069
2019-09-27 00:23:02,675 [IPC Server listener on 39069] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39069
2019-09-27 00:23:02,677 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-27 00:23:02,683 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:23:02,685 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-27 00:23:02,718 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-27 00:23:02,726 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@765df79d{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-27 00:23:02,733 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@151335cb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:02,733 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b22b970{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:02,734 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31ddd4a4{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:02,739 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-27 00:23:03,558 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:23:03,593 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:23:07,742 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:23:07,742 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:23:07,744 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: close
2019-09-27 00:23:07,744 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: close
2019-09-27 00:23:07,747 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: shutdown
2019-09-27 00:23:07,747 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: shutdown
2019-09-27 00:23:07,747 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96EFF3B4AF8,id=1d3a2991-ffc0-4d33-aec5-6dcc1711fd78
2019-09-27 00:23:07,748 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8A9910F96D8F,id=da98b069-9f6e-4a69-a7c9-6291acdc1fbb
2019-09-27 00:23:07,748 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown FollowerState
2019-09-27 00:23:07,748 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: shutdown LeaderState
2019-09-27 00:23:07,749 [Thread-260] INFO  impl.FollowerState (FollowerState.java:run(115)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:23:07,749 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:07,754 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8: closes. applyIndex: 0
2019-09-27 00:23:07,754 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb-PendingRequests: sendNotLeaderResponses
2019-09-27 00:23:07,757 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:07,759 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:07,760 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-F96EFF3B4AF8-SegmentedRaftLogWorker close()
2019-09-27 00:23:07,762 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F: closes. applyIndex: 0
2019-09-27 00:23:07,765 [da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:07,765 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: shutdown
2019-09-27 00:23:07,767 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb@group-8A9910F96D8F-SegmentedRaftLogWorker close()
2019-09-27 00:23:07,768 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E845166F496A,id=1d3a2991-ffc0-4d33-aec5-6dcc1711fd78
2019-09-27 00:23:07,771 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown LeaderState
2019-09-27 00:23:07,771 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: shutdown server with port 41573 now
2019-09-27 00:23:07,772 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-PendingRequests: sendNotLeaderResponses
2019-09-27 00:23:07,774 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:07,781 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A: closes. applyIndex: 0
2019-09-27 00:23:07,783 [1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:07,785 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78@group-E845166F496A-SegmentedRaftLogWorker close()
2019-09-27 00:23:07,790 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - da98b069-9f6e-4a69-a7c9-6291acdc1fbb: shutdown server with port 41573 successfully
2019-09-27 00:23:07,790 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown server with port 36514 now
2019-09-27 00:23:07,799 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:23:07,806 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: shutdown server with port 36514 successfully
2019-09-27 00:23:07,806 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: installSnapshot onError, lastRequest: 53d26a16-5a67-474e-adf9-d44acce35b5f->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78#131-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-27 00:23:07,808 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-27 00:23:07,812 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: nextIndex: updateUnconditionally 1 -> 0
Sep 27, 2019 12:23:07 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@d95c0f3
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-27 00:23:07,825 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:23:07,843 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:23:07,849 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:23:07,850 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@41eb94bc{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:23:07,851 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@378cfecf{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:07,852 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:23:07,852 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1981d861{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:07,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588f63c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:07,857 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:23:07,859 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28da7d11{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:23:07,860 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:07,861 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:07,862 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:08,592 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:23:08,642 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:23:10,253 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 00:23:10,255 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 00:23:12,749 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 00:23:12,752 [grpc-default-executor-6] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 00:23:12,858 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:23:12,858 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: close
2019-09-27 00:23:12,859 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: shutdown
2019-09-27 00:23:12,859 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96EFF3B4AF8,id=f0921ff9-92b1-4e12-aada-0bc4b3386eaa
2019-09-27 00:23:12,860 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown FollowerState
2019-09-27 00:23:12,860 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:12,860 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(115)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:23:12,862 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8: closes. applyIndex: 0
2019-09-27 00:23:12,863 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:12,865 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:23:12,865 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-F96EFF3B4AF8-SegmentedRaftLogWorker close()
2019-09-27 00:23:12,865 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: close
2019-09-27 00:23:12,868 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: shutdown
2019-09-27 00:23:12,868 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: shutdown
2019-09-27 00:23:12,868 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0CCE3748D473,id=f0921ff9-92b1-4e12-aada-0bc4b3386eaa
2019-09-27 00:23:12,869 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown LeaderState
2019-09-27 00:23:12,869 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1BD974C031C0,id=e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f
2019-09-27 00:23:12,869 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa-PendingRequests: sendNotLeaderResponses
2019-09-27 00:23:12,870 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: shutdown LeaderState
2019-09-27 00:23:12,870 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:12,871 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473: closes. applyIndex: 0
2019-09-27 00:23:12,871 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f-PendingRequests: sendNotLeaderResponses
2019-09-27 00:23:12,871 [f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:12,872 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:12,874 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0: closes. applyIndex: 0
2019-09-27 00:23:12,874 [e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:12,875 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f@group-1BD974C031C0-SegmentedRaftLogWorker close()
2019-09-27 00:23:12,878 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa@group-0CCE3748D473-SegmentedRaftLogWorker close()
2019-09-27 00:23:12,878 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: shutdown server with port 35187 now
2019-09-27 00:23:12,881 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown server with port 36798 now
2019-09-27 00:23:12,882 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - e9f7e7b8-085c-42ee-8b74-6d61e51cdf5f: shutdown server with port 35187 successfully
2019-09-27 00:23:12,888 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: shutdown server with port 36798 successfully
2019-09-27 00:23:12,888 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-27 00:23:12,888 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - f0921ff9-92b1-4e12-aada-0bc4b3386eaa: installSnapshot onError, lastRequest: 53d26a16-5a67-474e-adf9-d44acce35b5f->f0921ff9-92b1-4e12-aada-0bc4b3386eaa#133-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-27 00:23:12,891 [grpc-default-executor-6] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa: nextIndex: updateUnconditionally 1 -> 0
Sep 27, 2019 12:23:12 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@572f8561
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-27 00:23:12,898 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:23:12,906 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:23:12,923 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:23:12,926 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:23:12,927 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:23:12,931 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:23:12,933 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@21505815{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:23:12,934 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d910b3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:23:12,935 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e53339{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:12,935 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:12,936 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a1c3cb4{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:12,937 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:12,937 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2630dbc4{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:12,938 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:13,580 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:23:15,253 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 00:23:15,254 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 00:23:15,255 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 00:23:15,256 [grpc-default-executor-7] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 00:23:17,757 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 00:23:17,758 [grpc-default-executor-7] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 00:23:17,760 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-27 00:23:17,761 [grpc-default-executor-6] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa: nextIndex: updateUnconditionally 0 -> 0
2019-09-27 00:23:17,940 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:23:17,942 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: close
2019-09-27 00:23:17,943 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: shutdown
2019-09-27 00:23:17,943 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96EFF3B4AF8,id=53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:23:17,944 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown LeaderState
2019-09-27 00:23:17,946 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 53d26a16-5a67-474e-adf9-d44acce35b5f-PendingRequests: sendNotLeaderResponses
2019-09-27 00:23:17,946 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$396/273520250@33a91394] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->f0921ff9-92b1-4e12-aada-0bc4b3386eaa-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 00:23:17,947 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:17,946 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$396/273520250@366cec82] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8->1d3a2991-ffc0-4d33-aec5-6dcc1711fd78-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 00:23:17,949 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8: closes. applyIndex: 0
2019-09-27 00:23:17,949 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:17,951 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-F96EFF3B4AF8-SegmentedRaftLogWorker close()
2019-09-27 00:23:17,953 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: shutdown
2019-09-27 00:23:17,953 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C3A3E8E0F45,id=53d26a16-5a67-474e-adf9-d44acce35b5f
2019-09-27 00:23:17,953 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown LeaderState
2019-09-27 00:23:17,954 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 53d26a16-5a67-474e-adf9-d44acce35b5f-PendingRequests: sendNotLeaderResponses
2019-09-27 00:23:17,954 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:23:17,955 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45: closes. applyIndex: 0
2019-09-27 00:23:17,955 [53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:23:17,957 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 53d26a16-5a67-474e-adf9-d44acce35b5f@group-1C3A3E8E0F45-SegmentedRaftLogWorker close()
2019-09-27 00:23:17,958 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown server with port 36487 now
2019-09-27 00:23:17,959 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 53d26a16-5a67-474e-adf9-d44acce35b5f: shutdown server with port 36487 successfully
2019-09-27 00:23:17,973 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-060db5b7-19d7-42a8-a0d5-ad015fadbbe1/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:23:17,998 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:23:18,002 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:23:18,004 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dc3502b{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:23:18,004 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:18,005 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:18,005 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:18,007 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-27 00:23:18,007 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-27 00:23:18,007 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-27 00:23:18,007 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-27 00:23:18,008 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-27 00:23:18,008 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-27 00:23:18,008 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43365
2019-09-27 00:23:18,011 [IPC Server listener on 43365] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43365
2019-09-27 00:23:18,011 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:23:18,083 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-27 00:23:18,083 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-27 00:23:18,083 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-27 00:23:18,083 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34509
2019-09-27 00:23:18,086 [IPC Server listener on 34509] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34509
2019-09-27 00:23:18,086 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-27 00:23:18,086 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:23:18,087 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-27 00:23:18,087 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41209
2019-09-27 00:23:18,089 [IPC Server listener on 41209] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41209
2019-09-27 00:23:18,089 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-27 00:23:18,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:23:18,091 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70ab80e3{/,null,UNAVAILABLE}{/scm}
2019-09-27 00:23:18,092 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@410954b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:23:18,093 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:23:18,093 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:23:18,094 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-27 00:23:18,095 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 00:23:18,095 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 00:23:18,096 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-27 00:23:18,104 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-27 00:23:18,113 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-27 00:23:18,113 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
