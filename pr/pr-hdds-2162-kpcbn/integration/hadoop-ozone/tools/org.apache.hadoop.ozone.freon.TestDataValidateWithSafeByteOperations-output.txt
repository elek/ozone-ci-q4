2019-09-27 00:24:03,400 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:03,484 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:03,486 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:03,500 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @794ms
2019-09-27 00:24:03,580 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-27 00:24:03,580 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-27 00:24:03,580 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-27 00:24:03,581 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-27 00:24:03,581 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-27 00:24:03,581 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-27 00:24:03,591 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 00:24:03,591 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 00:24:03,592 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 00:24:03,864 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3e694b3f
2019-09-27 00:24:03,866 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-27 00:24:03,940 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 00:24:03,943 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-27 00:24:03,945 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-27 00:24:04,020 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-27 00:24:04,034 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:04,107 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-27 00:24:04,110 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:04,224 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-27 00:24:04,597 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:24:04,626 [Socket Reader #1 for port 36430] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36430
2019-09-27 00:24:04,803 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:24:04,804 [Socket Reader #1 for port 39251] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39251
2019-09-27 00:24:04,816 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:24:04,817 [Socket Reader #1 for port 39572] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39572
2019-09-27 00:24:04,847 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-27 00:24:05,012 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:05,030 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:05,041 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:05,044 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-27 00:24:05,045 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:05,045 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:05,077 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39572
2019-09-27 00:24:05,133 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-27 00:24:05,148 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-27 00:24:05,148 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-27 00:24:05,403 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:39572
2019-09-27 00:24:05,404 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:24:05,404 [IPC Server listener on 39572] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39572: starting
2019-09-27 00:24:05,409 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39251
2019-09-27 00:24:05,410 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:39251
2019-09-27 00:24:05,411 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:24:05,411 [IPC Server listener on 39251] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39251: starting
2019-09-27 00:24:05,414 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:36430
2019-09-27 00:24:05,414 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:36430
2019-09-27 00:24:05,415 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:24:05,415 [IPC Server listener on 36430] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36430: starting
2019-09-27 00:24:05,421 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39609
2019-09-27 00:24:05,423 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:05,472 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:05,473 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:05,551 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9573b3b{/,file:///tmp/jetty-0.0.0.0-39609-scm-_-any-6833011503280997950.dir/webapp/,AVAILABLE}{/scm}
2019-09-27 00:24:05,556 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:39609}
2019-09-27 00:24:05,557 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2851ms
2019-09-27 00:24:05,559 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-27 00:24:05,559 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-27 00:24:05,560 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:39609
2019-09-27 00:24:05,569 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3670f00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:24:05,574 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:05,699 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-27 00:24:05,699 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-27 00:24:05,700 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:05,701 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:06,398 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:24:06,406 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-27 00:24:06,406 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-27 00:24:06,407 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-27 00:24:06,407 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-27 00:24:06,407 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-27 00:24:06,407 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-27 00:24:06,408 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-27 00:24:06,408 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-27 00:24:06,408 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-27 00:24:06,408 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-27 00:24:06,409 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-27 00:24:06,409 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-27 00:24:06,409 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-27 00:24:06,409 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-27 00:24:06,410 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-27 00:24:06,410 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-27 00:24:06,410 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-27 00:24:06,410 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-27 00:24:06,411 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-27 00:24:06,411 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-27 00:24:06,411 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-27 00:24:06,411 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-27 00:24:06,412 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 00:24:06,412 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 00:24:06,412 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 00:24:06,952 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:24:06,954 [Socket Reader #1 for port 37397] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37397
2019-09-27 00:24:06,984 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37397
2019-09-27 00:24:06,984 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-27 00:24:06,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:24:06,986 [IPC Server listener on 37397] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37397: starting
2019-09-27 00:24:06,992 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-27 00:24:06,996 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:06,997 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:07,002 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:07,005 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-27 00:24:07,005 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:07,006 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:07,010 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42994
2019-09-27 00:24:07,010 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:07,014 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:07,015 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:07,081 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@151335cb{/,file:///tmp/jetty-0.0.0.0-42994-ozoneManager-_-any-1396265858344737048.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-27 00:24:07,082 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:42994}
2019-09-27 00:24:07,083 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4377ms
2019-09-27 00:24:07,084 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:24:07,084 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:42994
2019-09-27 00:24:07,424 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:24:07,473 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:24:07,511 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:24:07,513 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/containers/hdds to VolumeSet
2019-09-27 00:24:07,517 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-27 00:24:07,539 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-27 00:24:07,652 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:24:07,720 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:24:07,735 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:24:07,738 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:24:07,740 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:07,741 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:24:07,743 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:07,970 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis] (custom)
2019-09-27 00:24:08,034 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:24:08,038 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:08,040 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:08,043 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:08,045 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:24:08,045 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:08,045 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:08,048 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46146
2019-09-27 00:24:08,048 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:08,051 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:08,052 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:08,097 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d910b3{/,file:///tmp/jetty-0.0.0.0-46146-hddsDatanode-_-any-6515464869873939994.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:24:08,098 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:46146}
2019-09-27 00:24:08,101 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5396ms
2019-09-27 00:24:08,102 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:24:08,104 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46146
2019-09-27 00:24:08,105 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:24:08,109 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:24:08,112 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@202a300d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:24:08,119 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:24:08,120 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/containers/hdds to VolumeSet
2019-09-27 00:24:08,120 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-27 00:24:08,122 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-27 00:24:08,140 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:24:08,140 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:24:08,140 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:24:08,141 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:24:08,141 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:08,141 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:24:08,141 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:08,142 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis] (custom)
2019-09-27 00:24:08,144 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:24:08,145 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:08,146 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:08,148 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:08,148 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:24:08,149 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:08,149 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:08,150 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36452
2019-09-27 00:24:08,150 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:08,156 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:08,156 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:08,185 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28da7d11{/,file:///tmp/jetty-0.0.0.0-36452-hddsDatanode-_-any-2334925392404068342.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:24:08,185 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:36452}
2019-09-27 00:24:08,186 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5480ms
2019-09-27 00:24:08,186 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:24:08,188 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36452
2019-09-27 00:24:08,188 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:24:08,191 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:24:08,192 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@750ccb37] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:24:08,199 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:24:08,201 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/containers/hdds to VolumeSet
2019-09-27 00:24:08,202 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@a098d76
2019-09-27 00:24:08,202 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@a098d76
2019-09-27 00:24:08,218 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:24:08,218 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:24:08,218 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:24:08,219 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:24:08,219 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:08,219 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:24:08,219 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:08,220 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis] (custom)
2019-09-27 00:24:08,222 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:24:08,223 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:08,224 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:08,225 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:08,226 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:24:08,226 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:08,226 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:08,227 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46587
2019-09-27 00:24:08,227 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:08,229 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ecec90d{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:08,230 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a6fa56e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:08,236 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/meta/datanode.id
2019-09-27 00:24:08,241 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/meta/datanode.id
2019-09-27 00:24:08,262 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f6917fb{/,file:///tmp/jetty-0.0.0.0-46587-hddsDatanode-_-any-1934283813261983899.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:24:08,263 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41eb94bc{HTTP/1.1,[http/1.1]}{0.0.0.0:46587}
2019-09-27 00:24:08,264 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5557ms
2019-09-27 00:24:08,264 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:24:08,265 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46587
2019-09-27 00:24:08,265 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:24:08,268 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:24:08,269 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26562ca0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:24:08,272 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/meta/datanode.id
2019-09-27 00:24:08,276 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:24:08,277 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/containers/hdds to VolumeSet
2019-09-27 00:24:08,277 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-27 00:24:08,277 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-27 00:24:08,292 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:24:08,292 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:24:08,292 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:24:08,293 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:24:08,293 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:08,293 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:24:08,293 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:08,294 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis] (custom)
2019-09-27 00:24:08,295 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:24:08,296 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:08,298 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:08,302 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:08,303 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:24:08,303 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:08,303 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:08,304 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33939
2019-09-27 00:24:08,304 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:08,307 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:08,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:08,335 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dc3502b{/,file:///tmp/jetty-0.0.0.0-33939-hddsDatanode-_-any-8459982156609680463.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:24:08,335 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:33939}
2019-09-27 00:24:08,336 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5630ms
2019-09-27 00:24:08,336 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:24:08,337 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33939
2019-09-27 00:24:08,337 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:24:08,340 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:24:08,341 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54ed0b1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:24:08,344 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/meta/datanode.id
2019-09-27 00:24:08,348 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:24:08,348 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/containers/hdds to VolumeSet
2019-09-27 00:24:08,348 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bd2af5b
2019-09-27 00:24:08,349 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bd2af5b
2019-09-27 00:24:08,363 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:24:08,363 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:24:08,363 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:24:08,364 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:24:08,364 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:08,364 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:24:08,364 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:08,365 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis] (custom)
2019-09-27 00:24:08,367 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:24:08,368 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:24:08,369 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:24:08,370 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:24:08,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:24:08,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:24:08,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:24:08,372 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41505
2019-09-27 00:24:08,372 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:24:08,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@934b52f{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:24:08,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ea4300e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:24:08,402 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cf0a747{/,file:///tmp/jetty-0.0.0.0-41505-hddsDatanode-_-any-4992142682794162509.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:24:08,402 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21505815{HTTP/1.1,[http/1.1]}{0.0.0.0:41505}
2019-09-27 00:24:08,403 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5697ms
2019-09-27 00:24:08,403 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:24:08,404 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41505
2019-09-27 00:24:08,406 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:24:08,408 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48acf707] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:24:08,411 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/meta/datanode.id
2019-09-27 00:24:09,406 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:24:10,181 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:24:10,184 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:24:10,185 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis f63b7671-9043-4785-b6df-4d4c4dad8523 at port 0
2019-09-27 00:24:10,219 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:24:10,229 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:24:10,229 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 68777b5e-7ffc-47f8-984e-f65c8c5f22a3 at port 0
2019-09-27 00:24:10,232 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - f63b7671-9043-4785-b6df-4d4c4dad8523: start RPC server
2019-09-27 00:24:10,244 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: start RPC server
2019-09-27 00:24:10,282 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:24:10,284 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:24:10,285 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 969490bd-5bb7-4982-8186-3b18f1181798 at port 0
2019-09-27 00:24:10,294 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 969490bd-5bb7-4982-8186-3b18f1181798: start RPC server
2019-09-27 00:24:10,348 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:24:10,351 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:24:10,351 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 53e979e6-fe08-4562-a1ec-2311618905b2 at port 0
2019-09-27 00:24:10,361 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 53e979e6-fe08-4562-a1ec-2311618905b2: start RPC server
2019-09-27 00:24:10,403 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - f63b7671-9043-4785-b6df-4d4c4dad8523: GrpcService started, listening on 0.0.0.0/0.0.0.0:35250
2019-09-27 00:24:10,403 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 969490bd-5bb7-4982-8186-3b18f1181798: GrpcService started, listening on 0.0.0.0/0.0.0.0:46426
2019-09-27 00:24:10,403 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: GrpcService started, listening on 0.0.0.0/0.0.0.0:32989
2019-09-27 00:24:10,403 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 53e979e6-fe08-4562-a1ec-2311618905b2: GrpcService started, listening on 0.0.0.0/0.0.0.0:36956
2019-09-27 00:24:10,405 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 68777b5e-7ffc-47f8-984e-f65c8c5f22a3 is started using port 32989
2019-09-27 00:24:10,405 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 969490bd-5bb7-4982-8186-3b18f1181798 is started using port 46426
2019-09-27 00:24:10,404 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis f63b7671-9043-4785-b6df-4d4c4dad8523 is started using port 35250
2019-09-27 00:24:10,405 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 53e979e6-fe08-4562-a1ec-2311618905b2 is started using port 36956
2019-09-27 00:24:10,415 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:24:10,417 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 68777b5e-7ffc-47f8-984e-f65c8c5f22a3 is started using port 45150
2019-09-27 00:24:10,417 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 53e979e6-fe08-4562-a1ec-2311618905b2 is started using port 39838
2019-09-27 00:24:10,416 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc f63b7671-9043-4785-b6df-4d4c4dad8523 is started using port 33891
2019-09-27 00:24:10,416 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 969490bd-5bb7-4982-8186-3b18f1181798 is started using port 43099
2019-09-27 00:24:10,431 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:24:10,436 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:24:10,437 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 1723d5c9-2014-4096-973a-a3d37dcf9d7b at port 0
2019-09-27 00:24:10,444 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: start RPC server
2019-09-27 00:24:10,447 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: GrpcService started, listening on 0.0.0.0/0.0.0.0:37968
2019-09-27 00:24:10,448 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 1723d5c9-2014-4096-973a-a3d37dcf9d7b is started using port 37968
2019-09-27 00:24:10,450 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 1723d5c9-2014-4096-973a-a3d37dcf9d7b is started using port 44237
2019-09-27 00:24:11,417 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-27 00:24:12,154 [IPC Server handler 0 on 36430] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f63b7671-9043-4785-b6df-4d4c4dad8523
2019-09-27 00:24:12,155 [IPC Server handler 0 on 36430] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : f63b7671-9043-4785-b6df-4d4c4dad8523{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:24:12,161 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-27 00:24:12,161 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-27 00:24:12,161 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-27 00:24:12,195 [IPC Server handler 1 on 36430] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/68777b5e-7ffc-47f8-984e-f65c8c5f22a3
2019-09-27 00:24:12,195 [IPC Server handler 1 on 36430] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 68777b5e-7ffc-47f8-984e-f65c8c5f22a3{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:24:12,272 [IPC Server handler 3 on 36430] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:24:12,272 [IPC Server handler 3 on 36430] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 969490bd-5bb7-4982-8186-3b18f1181798{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:24:12,344 [IPC Server handler 6 on 36430] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/53e979e6-fe08-4562-a1ec-2311618905b2
2019-09-27 00:24:12,344 [IPC Server handler 6 on 36430] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 53e979e6-fe08-4562-a1ec-2311618905b2{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:24:12,413 [IPC Server handler 5 on 36430] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/1723d5c9-2014-4096-973a-a3d37dcf9d7b
2019-09-27 00:24:12,413 [IPC Server handler 5 on 36430] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 1723d5c9-2014-4096-973a-a3d37dcf9d7b{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:24:12,418 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-27 00:24:12,727 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f63b7671-9043-4785-b6df-4d4c4dad8523: addNew group-DFB9A16A75FB:[f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250] returns group-DFB9A16A75FB:java.util.concurrent.CompletableFuture@31db6a69[Not completed]
2019-09-27 00:24:12,751 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f63b7671-9043-4785-b6df-4d4c4dad8523: new RaftServerImpl for group-DFB9A16A75FB:[f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250] with ContainerStateMachine:uninitialized
2019-09-27 00:24:12,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:12,755 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:12,755 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:12,756 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:12,757 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:12,767 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: ConfigurationManager, init=-1: [f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:12,767 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis] (custom)
2019-09-27 00:24:12,776 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/0781ba51-b090-4505-9d9d-dfb9a16a75fb does not exist. Creating ...
2019-09-27 00:24:12,795 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/0781ba51-b090-4505-9d9d-dfb9a16a75fb/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:12,810 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/0781ba51-b090-4505-9d9d-dfb9a16a75fb has been successfully formatted.
2019-09-27 00:24:12,813 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DFB9A16A75FB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:12,813 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:12,815 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:12,824 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:12,824 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:12,828 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:12,835 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:12,846 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/0781ba51-b090-4505-9d9d-dfb9a16a75fb
2019-09-27 00:24:12,848 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-27 00:24:12,857 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-27 00:24:12,898 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:12,899 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:12,904 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:12,904 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:12,905 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:12,905 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:12,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:12,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:12,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:12,919 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:12,923 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:12,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:12,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:12,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:12,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:12,957 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: start as a follower, conf=-1: [f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250], old=null
2019-09-27 00:24:12,958 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:12,959 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f63b7671-9043-4785-b6df-4d4c4dad8523: start FollowerState
2019-09-27 00:24:12,961 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFB9A16A75FB,id=f63b7671-9043-4785-b6df-4d4c4dad8523
2019-09-27 00:24:13,027 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0781ba51-b090-4505-9d9d-dfb9a16a75fb, Nodes: f63b7671-9043-4785-b6df-4d4c4dad8523{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:24:13,050 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969490bd-5bb7-4982-8186-3b18f1181798: addNew group-FA28CE8A802F:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426] returns group-FA28CE8A802F:java.util.concurrent.CompletableFuture@31963e2[Not completed]
2019-09-27 00:24:13,094 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 969490bd-5bb7-4982-8186-3b18f1181798: new RaftServerImpl for group-FA28CE8A802F:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,095 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,096 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,096 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,096 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,096 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,096 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: ConfigurationManager, init=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,097 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis] (custom)
2019-09-27 00:24:13,097 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/6081edfe-5db0-4a98-826f-fa28ce8a802f does not exist. Creating ...
2019-09-27 00:24:13,105 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/6081edfe-5db0-4a98-826f-fa28ce8a802f/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,131 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/6081edfe-5db0-4a98-826f-fa28ce8a802f has been successfully formatted.
2019-09-27 00:24:13,132 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FA28CE8A802F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,134 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,134 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,135 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,136 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/6081edfe-5db0-4a98-826f-fa28ce8a802f
2019-09-27 00:24:13,144 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,145 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,145 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,145 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,145 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,146 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,146 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,146 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,146 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,147 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,147 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,148 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,148 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,148 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,148 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,155 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: start as a follower, conf=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426], old=null
2019-09-27 00:24:13,155 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,155 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969490bd-5bb7-4982-8186-3b18f1181798: start FollowerState
2019-09-27 00:24:13,157 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FA28CE8A802F,id=969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:24:13,176 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6081edfe-5db0-4a98-826f-fa28ce8a802f, Nodes: 969490bd-5bb7-4982-8186-3b18f1181798{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:24:13,197 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: addNew group-ACF9F58AD083:[68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] returns group-ACF9F58AD083:java.util.concurrent.CompletableFuture@672983bf[Not completed]
2019-09-27 00:24:13,221 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: new RaftServerImpl for group-ACF9F58AD083:[68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,221 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,222 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,222 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,222 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: ConfigurationManager, init=-1: [68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,222 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis] (custom)
2019-09-27 00:24:13,223 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/28e29d02-a450-43fe-8f60-acf9f58ad083 does not exist. Creating ...
2019-09-27 00:24:13,236 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/28e29d02-a450-43fe-8f60-acf9f58ad083/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,249 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/28e29d02-a450-43fe-8f60-acf9f58ad083 has been successfully formatted.
2019-09-27 00:24:13,250 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-ACF9F58AD083: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,251 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,251 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/28e29d02-a450-43fe-8f60-acf9f58ad083
2019-09-27 00:24:13,291 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,291 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,293 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,293 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,293 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,294 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,300 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: start as a follower, conf=-1: [68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:13,300 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,300 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: start FollowerState
2019-09-27 00:24:13,301 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ACF9F58AD083,id=68777b5e-7ffc-47f8-984e-f65c8c5f22a3
2019-09-27 00:24:13,313 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 28e29d02-a450-43fe-8f60-acf9f58ad083, Nodes: 68777b5e-7ffc-47f8-984e-f65c8c5f22a3{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:24:13,333 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 53e979e6-fe08-4562-a1ec-2311618905b2: addNew group-C5EDE78D4444:[53e979e6-fe08-4562-a1ec-2311618905b2:192.168.151.109:36956] returns group-C5EDE78D4444:java.util.concurrent.CompletableFuture@24b3cda[Not completed]
2019-09-27 00:24:13,335 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 53e979e6-fe08-4562-a1ec-2311618905b2: new RaftServerImpl for group-C5EDE78D4444:[53e979e6-fe08-4562-a1ec-2311618905b2:192.168.151.109:36956] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,335 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,335 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,336 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,336 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,336 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,336 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: ConfigurationManager, init=-1: [53e979e6-fe08-4562-a1ec-2311618905b2:192.168.151.109:36956], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,336 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis] (custom)
2019-09-27 00:24:13,337 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis/b727a2a2-46e9-48c3-9de5-c5ede78d4444 does not exist. Creating ...
2019-09-27 00:24:13,349 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis/b727a2a2-46e9-48c3-9de5-c5ede78d4444/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,363 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis/b727a2a2-46e9-48c3-9de5-c5ede78d4444 has been successfully formatted.
2019-09-27 00:24:13,364 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C5EDE78D4444: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,364 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,364 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,364 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,364 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,364 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,365 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,365 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis/b727a2a2-46e9-48c3-9de5-c5ede78d4444
2019-09-27 00:24:13,369 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,369 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,369 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,369 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,369 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,370 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,370 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,370 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,370 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,371 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,371 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,371 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,372 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,372 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,372 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,376 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: start as a follower, conf=-1: [53e979e6-fe08-4562-a1ec-2311618905b2:192.168.151.109:36956], old=null
2019-09-27 00:24:13,376 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,376 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53e979e6-fe08-4562-a1ec-2311618905b2: start FollowerState
2019-09-27 00:24:13,378 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5EDE78D4444,id=53e979e6-fe08-4562-a1ec-2311618905b2
2019-09-27 00:24:13,387 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b727a2a2-46e9-48c3-9de5-c5ede78d4444, Nodes: 53e979e6-fe08-4562-a1ec-2311618905b2{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:24:13,409 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: addNew group-B055DA9F1AE2:[1723d5c9-2014-4096-973a-a3d37dcf9d7b:192.168.151.109:37968] returns group-B055DA9F1AE2:java.util.concurrent.CompletableFuture@28816afd[Not completed]
2019-09-27 00:24:13,413 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: new RaftServerImpl for group-B055DA9F1AE2:[1723d5c9-2014-4096-973a-a3d37dcf9d7b:192.168.151.109:37968] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,413 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,413 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,413 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,413 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,414 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,414 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: ConfigurationManager, init=-1: [1723d5c9-2014-4096-973a-a3d37dcf9d7b:192.168.151.109:37968], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,414 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis] (custom)
2019-09-27 00:24:13,414 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis/143e6ea8-6313-4c81-91b1-b055da9f1ae2 does not exist. Creating ...
2019-09-27 00:24:13,427 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis/143e6ea8-6313-4c81-91b1-b055da9f1ae2/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,440 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis/143e6ea8-6313-4c81-91b1-b055da9f1ae2 has been successfully formatted.
2019-09-27 00:24:13,441 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B055DA9F1AE2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,441 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,441 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,441 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,441 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,442 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,442 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,442 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis/143e6ea8-6313-4c81-91b1-b055da9f1ae2
2019-09-27 00:24:13,445 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,445 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,445 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,446 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,446 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,446 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,446 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,446 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,447 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,447 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,447 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,448 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,448 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,448 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,448 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,451 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: start as a follower, conf=-1: [1723d5c9-2014-4096-973a-a3d37dcf9d7b:192.168.151.109:37968], old=null
2019-09-27 00:24:13,451 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,452 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: start FollowerState
2019-09-27 00:24:13,452 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B055DA9F1AE2,id=1723d5c9-2014-4096-973a-a3d37dcf9d7b
2019-09-27 00:24:13,465 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 143e6ea8-6313-4c81-91b1-b055da9f1ae2, Nodes: 1723d5c9-2014-4096-973a-a3d37dcf9d7b{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:24:13,511 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f63b7671-9043-4785-b6df-4d4c4dad8523: addNew group-23347CE31B8D:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] returns group-23347CE31B8D:java.util.concurrent.CompletableFuture@64688c44[Not completed]
2019-09-27 00:24:13,513 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 969490bd-5bb7-4982-8186-3b18f1181798: addNew group-23347CE31B8D:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] returns group-23347CE31B8D:java.util.concurrent.CompletableFuture@5cdf1fc[Not completed]
2019-09-27 00:24:13,516 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f63b7671-9043-4785-b6df-4d4c4dad8523: new RaftServerImpl for group-23347CE31B8D:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,516 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,517 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: addNew group-23347CE31B8D:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] returns group-23347CE31B8D:java.util.concurrent.CompletableFuture@40cf6f21[Not completed]
2019-09-27 00:24:13,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,518 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: ConfigurationManager, init=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis] (custom)
2019-09-27 00:24:13,518 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 969490bd-5bb7-4982-8186-3b18f1181798: new RaftServerImpl for group-23347CE31B8D:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,518 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,519 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d does not exist. Creating ...
2019-09-27 00:24:13,519 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,519 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: new RaftServerImpl for group-23347CE31B8D:[969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989] with ContainerStateMachine:uninitialized
2019-09-27 00:24:13,519 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,519 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:24:13,519 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,519 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:24:13,520 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,520 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:24:13,520 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: ConfigurationManager, init=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,520 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:24:13,520 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:13,520 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis] (custom)
2019-09-27 00:24:13,520 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: ConfigurationManager, init=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null, confs=<EMPTY_MAP>
2019-09-27 00:24:13,521 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis] (custom)
2019-09-27 00:24:13,521 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d does not exist. Creating ...
2019-09-27 00:24:13,521 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d does not exist. Creating ...
2019-09-27 00:24:13,532 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,532 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,532 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d/in_use.lock acquired by nodename 23231@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:24:13,546 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d has been successfully formatted.
2019-09-27 00:24:13,546 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d has been successfully formatted.
2019-09-27 00:24:13,546 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d has been successfully formatted.
2019-09-27 00:24:13,546 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-23347CE31B8D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,547 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-23347CE31B8D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,547 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-23347CE31B8D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:24:13,547 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,547 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,547 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:24:13,548 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,548 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,548 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:24:13,549 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,548 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,549 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,549 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:24:13,549 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,549 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,550 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d
2019-09-27 00:24:13,549 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:13,550 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,550 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,550 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,551 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,550 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,551 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,551 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:24:13,551 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,551 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d
2019-09-27 00:24:13,552 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,551 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d
2019-09-27 00:24:13,552 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,552 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,552 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,552 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:24:13,553 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,552 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,553 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:24:13,553 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:24:13,553 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,554 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:24:13,554 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,554 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,555 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,555 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:24:13,555 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,555 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,555 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,555 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:24:13,556 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,556 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,556 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:24:13,557 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,556 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,557 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:24:13,557 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,557 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:24:13,557 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,558 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:24:13,558 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,558 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:24:13,558 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,558 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:24:13,558 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:24:13,559 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:24:13,559 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:24:13,561 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: start as a follower, conf=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:13,561 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,561 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: start FollowerState
2019-09-27 00:24:13,562 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-23347CE31B8D,id=68777b5e-7ffc-47f8-984e-f65c8c5f22a3
2019-09-27 00:24:13,563 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: start as a follower, conf=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:13,565 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: start as a follower, conf=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:13,565 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,566 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:24:13,566 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f63b7671-9043-4785-b6df-4d4c4dad8523: start FollowerState
2019-09-27 00:24:13,566 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969490bd-5bb7-4982-8186-3b18f1181798: start FollowerState
2019-09-27 00:24:13,566 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-23347CE31B8D,id=f63b7671-9043-4785-b6df-4d4c4dad8523
2019-09-27 00:24:13,568 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-23347CE31B8D,id=969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:24:13,590 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9e0115d8-e3ac-4c72-bc28-23347ce31b8d, Nodes: f63b7671-9043-4785-b6df-4d4c4dad8523{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}969490bd-5bb7-4982-8186-3b18f1181798{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}68777b5e-7ffc-47f8-984e-f65c8c5f22a3{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-27 00:24:13,674 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:14,676 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:15,319 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-27 00:24:15,323 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-27 00:24:15,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:16,679 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:17,680 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:18,002 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(106)) - f63b7671-9043-4785-b6df-4d4c4dad8523:group-DFB9A16A75FB changes to CANDIDATE, lastRpcTime:5043, electionTimeout:5042ms
2019-09-27 00:24:18,006 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown FollowerState
2019-09-27 00:24:18,006 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:24:18,014 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f63b7671-9043-4785-b6df-4d4c4dad8523: start LeaderElection
2019-09-27 00:24:18,032 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1: begin an election at term 1 for -1: [f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250], old=null
2019-09-27 00:24:18,035 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown LeaderElection
2019-09-27 00:24:18,036 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:24:18,036 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: change Leader from null to f63b7671-9043-4785-b6df-4d4c4dad8523 at term 1 for becomeLeader, leader elected after 5222ms
2019-09-27 00:24:18,046 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:24:18,046 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:24:18,050 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:24:18,053 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:24:18,053 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:24:18,054 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:24:18,068 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f63b7671-9043-4785-b6df-4d4c4dad8523: start LeaderState
2019-09-27 00:24:18,094 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,104 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: set configuration 0: [f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250], old=null at 0
2019-09-27 00:24:18,254 [Thread-214] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969490bd-5bb7-4982-8186-3b18f1181798:group-FA28CE8A802F changes to CANDIDATE, lastRpcTime:5098, electionTimeout:5097ms
2019-09-27 00:24:18,278 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown FollowerState
2019-09-27 00:24:18,279 [Thread-214] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:24:18,281 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969490bd-5bb7-4982-8186-3b18f1181798: start LeaderElection
2019-09-27 00:24:18,300 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/0781ba51-b090-4505-9d9d-dfb9a16a75fb/current/log_inprogress_0
2019-09-27 00:24:18,300 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2: begin an election at term 1 for -1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426], old=null
2019-09-27 00:24:18,301 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown LeaderElection
2019-09-27 00:24:18,302 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:24:18,302 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: change Leader from null to 969490bd-5bb7-4982-8186-3b18f1181798 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-27 00:24:18,304 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:24:18,304 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:24:18,304 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:24:18,305 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:24:18,305 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:24:18,305 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:24:18,309 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969490bd-5bb7-4982-8186-3b18f1181798: start LeaderState
2019-09-27 00:24:18,309 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,310 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: set configuration 0: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426], old=null at 0
2019-09-27 00:24:18,349 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(106)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:group-ACF9F58AD083 changes to CANDIDATE, lastRpcTime:5048, electionTimeout:5045ms
2019-09-27 00:24:18,349 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown FollowerState
2019-09-27 00:24:18,351 [Thread-217] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:24:18,351 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: start LeaderElection
2019-09-27 00:24:18,362 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/6081edfe-5db0-4a98-826f-fa28ce8a802f/current/log_inprogress_0
2019-09-27 00:24:18,362 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3: begin an election at term 1 for -1: [68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:18,362 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown LeaderElection
2019-09-27 00:24:18,362 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:24:18,362 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: change Leader from null to 68777b5e-7ffc-47f8-984e-f65c8c5f22a3 at term 1 for becomeLeader, leader elected after 5112ms
2019-09-27 00:24:18,364 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:24:18,364 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:24:18,365 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:24:18,365 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:24:18,365 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:24:18,365 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:24:18,369 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: start LeaderState
2019-09-27 00:24:18,369 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,370 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: set configuration 0: [68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null at 0
2019-09-27 00:24:18,424 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/28e29d02-a450-43fe-8f60-acf9f58ad083/current/log_inprogress_0
2019-09-27 00:24:18,527 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(106)) - 53e979e6-fe08-4562-a1ec-2311618905b2:group-C5EDE78D4444 changes to CANDIDATE, lastRpcTime:5151, electionTimeout:5149ms
2019-09-27 00:24:18,528 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53e979e6-fe08-4562-a1ec-2311618905b2: shutdown FollowerState
2019-09-27 00:24:18,528 [Thread-220] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:24:18,528 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53e979e6-fe08-4562-a1ec-2311618905b2: start LeaderElection
2019-09-27 00:24:18,544 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b:group-B055DA9F1AE2 changes to CANDIDATE, lastRpcTime:5092, electionTimeout:5092ms
2019-09-27 00:24:18,545 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: shutdown FollowerState
2019-09-27 00:24:18,545 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:24:18,545 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: start LeaderElection
2019-09-27 00:24:18,546 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4: begin an election at term 1 for -1: [53e979e6-fe08-4562-a1ec-2311618905b2:192.168.151.109:36956], old=null
2019-09-27 00:24:18,549 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 53e979e6-fe08-4562-a1ec-2311618905b2: shutdown LeaderElection
2019-09-27 00:24:18,549 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:24:18,549 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: change Leader from null to 53e979e6-fe08-4562-a1ec-2311618905b2 at term 1 for becomeLeader, leader elected after 5185ms
2019-09-27 00:24:18,551 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:24:18,551 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:24:18,552 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:24:18,552 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:24:18,552 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:24:18,552 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:24:18,556 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53e979e6-fe08-4562-a1ec-2311618905b2: start LeaderState
2019-09-27 00:24:18,557 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,557 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: set configuration 0: [53e979e6-fe08-4562-a1ec-2311618905b2:192.168.151.109:36956], old=null at 0
2019-09-27 00:24:18,599 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - 969490bd-5bb7-4982-8186-3b18f1181798:group-23347CE31B8D changes to CANDIDATE, lastRpcTime:5032, electionTimeout:5029ms
2019-09-27 00:24:18,600 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5: begin an election at term 1 for -1: [1723d5c9-2014-4096-973a-a3d37dcf9d7b:192.168.151.109:37968], old=null
2019-09-27 00:24:18,601 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown FollowerState
2019-09-27 00:24:18,601 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: shutdown LeaderElection
2019-09-27 00:24:18,601 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:24:18,601 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:24:18,601 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969490bd-5bb7-4982-8186-3b18f1181798: start LeaderElection
2019-09-27 00:24:18,601 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: change Leader from null to 1723d5c9-2014-4096-973a-a3d37dcf9d7b at term 1 for becomeLeader, leader elected after 5160ms
2019-09-27 00:24:18,603 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:24:18,605 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:24:18,607 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:24:18,607 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:24:18,607 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:24:18,607 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:24:18,611 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: start LeaderState
2019-09-27 00:24:18,611 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/ratis/b727a2a2-46e9-48c3-9de5-c5ede78d4444/current/log_inprogress_0
2019-09-27 00:24:18,612 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6: begin an election at term 1 for -1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:18,611 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,612 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: set configuration 0: [1723d5c9-2014-4096-973a-a3d37dcf9d7b:192.168.151.109:37968], old=null at 0
2019-09-27 00:24:18,678 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/ratis/143e6ea8-6313-4c81-91b1-b055da9f1ae2/current/log_inprogress_0
2019-09-27 00:24:18,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:18,690 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:24:18,690 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:24:18,690 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown FollowerState
2019-09-27 00:24:18,690 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown FollowerState
2019-09-27 00:24:18,691 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: start FollowerState
2019-09-27 00:24:18,691 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f63b7671-9043-4785-b6df-4d4c4dad8523: start FollowerState
2019-09-27 00:24:18,691 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(115)) - f63b7671-9043-4785-b6df-4d4c4dad8523: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:24:18,691 [Thread-228] INFO  impl.FollowerState (FollowerState.java:run(115)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:24:18,727 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6: Election PASSED; received 1 response(s) [969490bd-5bb7-4982-8186-3b18f1181798<-68777b5e-7ffc-47f8-984e-f65c8c5f22a3#0:OK-t1] and 0 exception(s); 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:t1, leader=null, voted=969490bd-5bb7-4982-8186-3b18f1181798, raftlog=969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null
2019-09-27 00:24:18,727 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown LeaderElection
2019-09-27 00:24:18,728 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:24:18,729 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: change Leader from null to 969490bd-5bb7-4982-8186-3b18f1181798 at term 1 for becomeLeader, leader elected after 5182ms
2019-09-27 00:24:18,731 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:24:18,731 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:24:18,731 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:24:18,732 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:24:18,732 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:24:18,732 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:24:18,738 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 00:24:18,739 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:18,740 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 00:24:18,745 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 00:24:18,752 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:18,752 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:18,754 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 00:24:18,754 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:24:18,754 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 00:24:18,754 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 00:24:18,755 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:24:18,755 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:24:18,759 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 969490bd-5bb7-4982-8186-3b18f1181798: start LeaderState
2019-09-27 00:24:18,760 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,761 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: set configuration 0: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null at 0
2019-09-27 00:24:18,815 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d/current/log_inprogress_0
2019-09-27 00:24:18,841 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: change Leader from null to 969490bd-5bb7-4982-8186-3b18f1181798 at term 1 for appendEntries, leader elected after 5292ms
2019-09-27 00:24:18,841 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: change Leader from null to 969490bd-5bb7-4982-8186-3b18f1181798 at term 1 for appendEntries, leader elected after 5294ms
2019-09-27 00:24:18,882 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: set configuration 0: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null at 0
2019-09-27 00:24:18,882 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: set configuration 0: [969490bd-5bb7-4982-8186-3b18f1181798:192.168.151.109:46426, f63b7671-9043-4785-b6df-4d4c4dad8523:192.168.151.109:35250, 68777b5e-7ffc-47f8-984e-f65c8c5f22a3:192.168.151.109:32989], old=null at 0
2019-09-27 00:24:18,883 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,883 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:24:18,927 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d/current/log_inprogress_0
2019-09-27 00:24:18,927 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/ratis/9e0115d8-e3ac-4c72-bc28-23347ce31b8d/current/log_inprogress_0
2019-09-27 00:24:19,686 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:20,688 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:21,689 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:22,691 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:23,698 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:24,700 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:25,701 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:26,703 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:27,704 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:28,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:29,707 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:30,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:31,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:32,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:32,715 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:24:33,717 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:34,719 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:35,720 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:36,722 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:37,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:38,725 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:39,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:40,728 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:41,730 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:42,736 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:42,738 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:24:43,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:44,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:45,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:46,744 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:47,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:48,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:49,749 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:50,750 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:51,752 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:52,753 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:52,756 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:24:53,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:54,759 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:55,760 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:56,761 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:57,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:58,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:24:59,766 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:00,767 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:01,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:02,770 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:02,772 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:25:03,774 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:04,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:05,777 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:06,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:07,780 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:08,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:09,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:10,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:11,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:12,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:12,791 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:25:13,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:14,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:15,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:16,798 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:17,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:18,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:19,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:20,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:21,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:22,807 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:22,809 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:25:23,810 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:24,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:25,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:26,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:27,816 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:28,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:29,819 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:30,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:31,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:32,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:32,826 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:25:33,826 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:34,828 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:35,829 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:36,831 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:37,833 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:38,834 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:39,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:40,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:41,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:42,841 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:42,846 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:25:43,847 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:44,849 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:45,850 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:46,852 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:47,853 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:48,855 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:49,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:50,858 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:51,859 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:52,860 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:52,862 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:25:53,864 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:54,865 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:55,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:56,868 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:57,869 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:58,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:25:59,872 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:00,874 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:01,875 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:02,877 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:02,878 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:26:02,882 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-27 00:26:03,909 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:04,911 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:05,913 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:06,915 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:07,916 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:08,918 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:09,919 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:10,921 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:11,923 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:12,924 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:13,927 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:14,929 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:15,930 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:16,932 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:17,933 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:18,935 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:19,936 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:20,938 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:21,939 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:22,941 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:22,942 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:26:23,944 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:24,945 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:25,947 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:26,948 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:27,950 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:28,951 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:29,953 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:30,954 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:31,955 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:32,957 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:32,959 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:26:33,960 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:34,962 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:35,963 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:36,964 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:37,966 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:38,967 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:39,969 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:40,970 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:41,971 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:42,973 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:42,974 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:26:43,977 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:44,978 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:45,979 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:46,981 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:47,982 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:48,984 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:49,985 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:50,987 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:51,988 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:52,989 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:52,992 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:26:53,993 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:54,995 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:55,996 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:56,997 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:57,999 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:26:59,000 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:00,002 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:01,003 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:02,005 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:03,006 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:03,008 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:27:04,009 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:05,010 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:06,012 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:07,014 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:08,015 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:09,017 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:10,018 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:11,019 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:12,021 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:13,022 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:13,024 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:27:14,039 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:15,042 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:16,044 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:17,047 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:18,050 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:19,051 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:20,052 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:21,054 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:22,055 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:23,057 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:23,059 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:27:24,060 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:25,062 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:26,063 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:27,066 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:28,067 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:29,070 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:30,073 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:31,075 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:32,079 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:33,081 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:33,083 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:27:34,084 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:35,085 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:36,087 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:37,089 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:38,091 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:39,092 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:40,094 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:41,096 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:42,098 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:43,099 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:43,101 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:27:44,103 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:45,104 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:46,105 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:47,107 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:48,108 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:49,110 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:50,111 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:51,113 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:52,114 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:53,116 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:53,118 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:27:53,118 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-27 00:27:54,128 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:55,129 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:56,131 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:57,132 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:58,133 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:27:59,134 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:00,136 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:01,137 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:02,139 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:03,140 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:04,143 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:05,145 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:06,146 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:07,148 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:08,149 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:09,150 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:10,152 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:11,153 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:12,154 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:13,155 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:13,157 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:28:14,158 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:15,159 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:16,160 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:17,162 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:18,163 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:19,164 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:20,165 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:21,167 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:22,168 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:23,169 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:23,171 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:28:24,172 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:25,173 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:26,174 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:27,176 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:28,177 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:29,178 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:30,180 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:31,181 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:32,182 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:33,183 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:33,185 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:28:34,186 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:35,187 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:36,189 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:37,190 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:38,191 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:39,193 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:40,194 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:41,195 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:42,196 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:43,197 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:43,199 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:28:44,200 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:45,201 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:46,202 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:47,204 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:48,205 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:49,206 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:50,207 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:51,209 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:52,210 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:53,211 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:53,213 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:28:54,214 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:55,215 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:56,216 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:57,218 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:58,219 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:28:59,221 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:00,222 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:01,223 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:02,224 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:03,226 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:03,227 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:29:04,228 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:05,230 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:06,231 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:07,232 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:08,233 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:09,235 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:10,236 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:11,237 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:12,245 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:13,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:13,248 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:29:14,249 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:15,250 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:15,324 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-27 00:29:16,251 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:17,252 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:18,253 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:19,255 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:20,256 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:21,257 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:22,258 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:23,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:23,261 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:29:24,262 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:25,265 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:26,266 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:27,269 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:28,272 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:29,273 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:30,275 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:31,276 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:32,278 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:33,279 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:33,281 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:29:34,282 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:35,283 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:36,285 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:37,287 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:38,288 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:39,289 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:40,291 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:41,292 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:42,293 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:43,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:29:43,296 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:29:43,296 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.validateWriteTest(TestDataValidate.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-27 00:29:43,300 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-27 00:29:43,301 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-27 00:29:43,301 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-27 00:29:43,301 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37397
2019-09-27 00:29:43,306 [IPC Server listener on 37397] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37397
2019-09-27 00:29:43,312 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-27 00:29:43,316 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:29:43,323 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-27 00:29:43,337 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-27 00:29:43,354 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@151335cb{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-27 00:29:43,360 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:43,361 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:43,361 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:43,367 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-27 00:29:44,245 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:29:44,323 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:29:48,371 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:29:48,371 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:29:48,372 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: close
2019-09-27 00:29:48,372 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 969490bd-5bb7-4982-8186-3b18f1181798: close
2019-09-27 00:29:48,375 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: shutdown
2019-09-27 00:29:48,375 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: shutdown
2019-09-27 00:29:48,376 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23347CE31B8D,id=68777b5e-7ffc-47f8-984e-f65c8c5f22a3
2019-09-27 00:29:48,376 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FA28CE8A802F,id=969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:29:48,377 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown FollowerState
2019-09-27 00:29:48,377 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown LeaderState
2019-09-27 00:29:48,377 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(115)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:29:48,377 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:48,383 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969490bd-5bb7-4982-8186-3b18f1181798-PendingRequests: sendNotLeaderResponses
2019-09-27 00:29:48,383 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D: closes. applyIndex: 0
2019-09-27 00:29:48,385 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:48,389 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:48,389 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F: closes. applyIndex: 0
2019-09-27 00:29:48,391 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-23347CE31B8D-SegmentedRaftLogWorker close()
2019-09-27 00:29:48,391 [969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:48,395 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-FA28CE8A802F-SegmentedRaftLogWorker close()
2019-09-27 00:29:48,396 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: shutdown
2019-09-27 00:29:48,399 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: shutdown
2019-09-27 00:29:48,400 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ACF9F58AD083,id=68777b5e-7ffc-47f8-984e-f65c8c5f22a3
2019-09-27 00:29:48,400 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23347CE31B8D,id=969490bd-5bb7-4982-8186-3b18f1181798
2019-09-27 00:29:48,400 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown LeaderState
2019-09-27 00:29:48,401 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown LeaderState
2019-09-27 00:29:48,401 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3-PendingRequests: sendNotLeaderResponses
2019-09-27 00:29:48,406 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$381/496620594@3e754c1a] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D->f63b7671-9043-4785-b6df-4d4c4dad8523-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 00:29:48,405 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 969490bd-5bb7-4982-8186-3b18f1181798-PendingRequests: sendNotLeaderResponses
2019-09-27 00:29:48,407 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:48,411 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083: closes. applyIndex: 0
2019-09-27 00:29:48,406 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$381/496620594@36ca1b48] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D->68777b5e-7ffc-47f8-984e-f65c8c5f22a3-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 00:29:48,413 [68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:48,409 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:48,416 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3@group-ACF9F58AD083-SegmentedRaftLogWorker close()
2019-09-27 00:29:48,416 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D: closes. applyIndex: 0
2019-09-27 00:29:48,420 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - f63b7671-9043-4785-b6df-4d4c4dad8523: Completed APPEND_ENTRIES, lastRequest: 969490bd-5bb7-4982-8186-3b18f1181798->f63b7671-9043-4785-b6df-4d4c4dad8523#132-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 00:29:48,420 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: Completed APPEND_ENTRIES, lastRequest: 969490bd-5bb7-4982-8186-3b18f1181798->68777b5e-7ffc-47f8-984e-f65c8c5f22a3#132-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 00:29:48,422 [969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:48,422 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown server with port 32989 now
2019-09-27 00:29:48,424 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D-SegmentedRaftLogWorker close()
2019-09-27 00:29:48,428 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown server with port 46426 now
2019-09-27 00:29:48,428 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D->68777b5e-7ffc-47f8-984e-f65c8c5f22a3-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-27 00:29:48,428 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D->f63b7671-9043-4785-b6df-4d4c4dad8523-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-27 00:29:48,432 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 969490bd-5bb7-4982-8186-3b18f1181798: shutdown server with port 46426 successfully
2019-09-27 00:29:48,435 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D->f63b7671-9043-4785-b6df-4d4c4dad8523: nextIndex: updateUnconditionally 1 -> 0
2019-09-27 00:29:48,437 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 68777b5e-7ffc-47f8-984e-f65c8c5f22a3: shutdown server with port 32989 successfully
2019-09-27 00:29:48,435 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 969490bd-5bb7-4982-8186-3b18f1181798@group-23347CE31B8D->68777b5e-7ffc-47f8-984e-f65c8c5f22a3: nextIndex: updateUnconditionally 1 -> 0
2019-09-27 00:29:48,440 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:29:48,452 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:29:48,477 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:29:48,482 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:29:48,483 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f6917fb{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:29:48,484 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41eb94bc{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:48,485 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a6fa56e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:48,485 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ecec90d{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:48,494 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:29:48,499 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:29:48,503 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28da7d11{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:29:48,504 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:48,505 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:48,507 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:49,163 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:29:49,451 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:29:53,487 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:29:53,489 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: close
2019-09-27 00:29:53,490 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: shutdown
2019-09-27 00:29:53,491 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B055DA9F1AE2,id=1723d5c9-2014-4096-973a-a3d37dcf9d7b
2019-09-27 00:29:53,491 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: shutdown LeaderState
2019-09-27 00:29:53,492 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b-PendingRequests: sendNotLeaderResponses
2019-09-27 00:29:53,492 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:53,495 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2: closes. applyIndex: 0
2019-09-27 00:29:53,496 [1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:53,497 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b@group-B055DA9F1AE2-SegmentedRaftLogWorker close()
2019-09-27 00:29:53,500 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: shutdown server with port 37968 now
2019-09-27 00:29:53,502 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 1723d5c9-2014-4096-973a-a3d37dcf9d7b: shutdown server with port 37968 successfully
2019-09-27 00:29:53,508 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:29:53,509 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - f63b7671-9043-4785-b6df-4d4c4dad8523: close
2019-09-27 00:29:53,510 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: shutdown
2019-09-27 00:29:53,510 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFB9A16A75FB,id=f63b7671-9043-4785-b6df-4d4c4dad8523
2019-09-27 00:29:53,511 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown LeaderState
2019-09-27 00:29:53,512 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - f63b7671-9043-4785-b6df-4d4c4dad8523-PendingRequests: sendNotLeaderResponses
2019-09-27 00:29:53,512 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:53,515 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB: closes. applyIndex: 0
2019-09-27 00:29:53,516 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:53,519 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-DFB9A16A75FB-SegmentedRaftLogWorker close()
2019-09-27 00:29:53,523 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: shutdown
2019-09-27 00:29:53,523 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23347CE31B8D,id=f63b7671-9043-4785-b6df-4d4c4dad8523
2019-09-27 00:29:53,524 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown FollowerState
2019-09-27 00:29:53,525 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:53,527 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(115)) - f63b7671-9043-4785-b6df-4d4c4dad8523: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:29:53,531 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D: closes. applyIndex: 0
2019-09-27 00:29:53,531 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:29:53,531 [f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:53,532 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f63b7671-9043-4785-b6df-4d4c4dad8523@group-23347CE31B8D-SegmentedRaftLogWorker close()
2019-09-27 00:29:53,535 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown server with port 35250 now
2019-09-27 00:29:53,535 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - f63b7671-9043-4785-b6df-4d4c4dad8523: shutdown server with port 35250 successfully
2019-09-27 00:29:53,537 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:29:53,555 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:29:53,559 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:29:53,560 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cf0a747{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:29:53,561 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21505815{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:53,561 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ea4300e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:53,562 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@934b52f{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:53,564 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:29:53,567 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:29:53,570 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d910b3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:29:53,570 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:53,571 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:53,572 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:54,397 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:29:58,564 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:29:58,564 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 53e979e6-fe08-4562-a1ec-2311618905b2: close
2019-09-27 00:29:58,565 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: shutdown
2019-09-27 00:29:58,565 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5EDE78D4444,id=53e979e6-fe08-4562-a1ec-2311618905b2
2019-09-27 00:29:58,566 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 53e979e6-fe08-4562-a1ec-2311618905b2: shutdown LeaderState
2019-09-27 00:29:58,566 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 53e979e6-fe08-4562-a1ec-2311618905b2-PendingRequests: sendNotLeaderResponses
2019-09-27 00:29:58,567 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:29:58,568 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444: closes. applyIndex: 0
2019-09-27 00:29:58,569 [53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:29:58,570 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 53e979e6-fe08-4562-a1ec-2311618905b2@group-C5EDE78D4444-SegmentedRaftLogWorker close()
2019-09-27 00:29:58,572 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 53e979e6-fe08-4562-a1ec-2311618905b2: shutdown server with port 36956 now
2019-09-27 00:29:58,573 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 53e979e6-fe08-4562-a1ec-2311618905b2: shutdown server with port 36956 successfully
2019-09-27 00:29:58,584 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-3609cbf9-11e5-4e21-937e-bd24f83bdf83/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:29:58,601 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:29:58,604 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:29:58,605 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dc3502b{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:29:58,606 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:58,607 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:58,607 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:58,609 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-27 00:29:58,609 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-27 00:29:58,609 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-27 00:29:58,609 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-27 00:29:58,609 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-27 00:29:58,610 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-27 00:29:58,610 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36430
2019-09-27 00:29:58,611 [IPC Server listener on 36430] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36430
2019-09-27 00:29:58,612 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:29:58,656 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-27 00:29:58,657 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-27 00:29:58,657 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-27 00:29:58,657 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39251
2019-09-27 00:29:58,660 [IPC Server listener on 39251] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39251
2019-09-27 00:29:58,660 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-27 00:29:58,661 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-27 00:29:58,661 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:29:58,661 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39572
2019-09-27 00:29:58,664 [IPC Server listener on 39572] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39572
2019-09-27 00:29:58,664 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-27 00:29:58,664 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:29:58,665 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9573b3b{/,null,UNAVAILABLE}{/scm}
2019-09-27 00:29:58,666 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:29:58,666 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:29:58,667 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:29:58,668 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-27 00:29:58,668 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 00:29:58,669 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 00:29:58,670 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-27 00:29:58,676 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-27 00:29:58,684 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-27 00:29:58,685 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
