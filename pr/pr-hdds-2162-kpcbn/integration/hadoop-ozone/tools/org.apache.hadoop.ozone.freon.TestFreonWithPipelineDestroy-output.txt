2019-09-27 00:03:39,759 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:39,861 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:39,864 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:39,881 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @891ms
2019-09-27 00:03:40,014 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-27 00:03:40,015 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-27 00:03:40,015 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-27 00:03:40,015 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-27 00:03:40,016 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-27 00:03:40,016 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-27 00:03:40,030 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 00:03:40,031 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 00:03:40,032 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 00:03:40,296 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@65fb9ffc
2019-09-27 00:03:40,298 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-27 00:03:40,371 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-27 00:03:40,445 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-27 00:03:40,459 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:40,532 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-27 00:03:40,536 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:40,682 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-27 00:03:41,103 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:03:41,131 [Socket Reader #1 for port 35025] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35025
2019-09-27 00:03:41,303 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:03:41,304 [Socket Reader #1 for port 43922] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43922
2019-09-27 00:03:41,316 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:03:41,317 [Socket Reader #1 for port 44822] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44822
2019-09-27 00:03:41,347 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-27 00:03:41,531 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:03:41,548 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:03:41,559 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:03:41,561 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-27 00:03:41,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:03:41,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:03:41,590 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:44822
2019-09-27 00:03:41,641 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-27 00:03:41,653 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-27 00:03:41,654 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-27 00:03:41,866 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:44822
2019-09-27 00:03:41,867 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:03:41,867 [IPC Server listener on 44822] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44822: starting
2019-09-27 00:03:41,870 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:43922
2019-09-27 00:03:41,871 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:43922
2019-09-27 00:03:41,872 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:03:41,872 [IPC Server listener on 43922] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43922: starting
2019-09-27 00:03:41,875 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:35025
2019-09-27 00:03:41,875 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:35025
2019-09-27 00:03:41,875 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:03:41,875 [IPC Server listener on 35025] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35025: starting
2019-09-27 00:03:41,880 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45462
2019-09-27 00:03:41,881 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:03:41,916 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:03:41,917 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:03:41,987 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9573b3b{/,file:///tmp/jetty-0.0.0.0-45462-scm-_-any-5732947407812932335.dir/webapp/,AVAILABLE}{/scm}
2019-09-27 00:03:41,992 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:45462}
2019-09-27 00:03:41,992 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3002ms
2019-09-27 00:03:41,994 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-27 00:03:41,995 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-27 00:03:41,996 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:45462
2019-09-27 00:03:42,003 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3670f00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:03:42,005 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:42,137 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-27 00:03:42,137 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-27 00:03:42,139 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:42,139 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:42,886 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-27 00:03:42,894 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-27 00:03:42,894 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-27 00:03:42,894 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-27 00:03:42,895 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-27 00:03:42,895 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-27 00:03:42,895 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-27 00:03:42,895 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-27 00:03:42,895 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-27 00:03:42,896 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-27 00:03:42,896 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-27 00:03:42,896 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-27 00:03:42,896 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-27 00:03:42,897 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-27 00:03:42,897 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-27 00:03:42,897 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-27 00:03:42,897 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-27 00:03:42,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-27 00:03:42,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-27 00:03:42,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-27 00:03:42,898 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-27 00:03:42,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-27 00:03:42,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-27 00:03:42,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-27 00:03:42,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-27 00:03:42,899 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-27 00:03:43,463 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-27 00:03:43,464 [Socket Reader #1 for port 42465] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42465
2019-09-27 00:03:43,490 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:42465
2019-09-27 00:03:43,490 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-27 00:03:43,492 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-27 00:03:43,492 [IPC Server listener on 42465] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42465: starting
2019-09-27 00:03:43,497 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-27 00:03:43,499 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:03:43,500 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:03:43,503 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:03:43,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-27 00:03:43,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:03:43,505 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:03:43,507 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34602
2019-09-27 00:03:43,507 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:03:43,509 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:03:43,510 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:03:43,566 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@151335cb{/,file:///tmp/jetty-0.0.0.0-34602-ozoneManager-_-any-1911952135706706884.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-27 00:03:43,567 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:34602}
2019-09-27 00:03:43,567 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4577ms
2019-09-27 00:03:43,568 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:03:43,569 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:34602
2019-09-27 00:03:43,907 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:03:43,970 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:03:44,008 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:03:44,010 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/containers/hdds to VolumeSet
2019-09-27 00:03:44,014 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@889d9e8
2019-09-27 00:03:44,033 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@889d9e8
2019-09-27 00:03:44,148 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:03:44,218 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:03:44,223 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:03:44,224 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:03:44,226 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:44,227 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:03:44,227 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:03:44,390 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis] (custom)
2019-09-27 00:03:44,433 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:03:44,439 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:03:44,440 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:03:44,443 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:03:44,444 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:03:44,445 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:03:44,445 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:03:44,448 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43045
2019-09-27 00:03:44,448 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:03:44,451 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cdb2d95{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:03:44,452 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:03:44,495 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26cb5207{/,file:///tmp/jetty-0.0.0.0-43045-hddsDatanode-_-any-4169350950787599790.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:03:44,497 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15400fff{HTTP/1.1,[http/1.1]}{0.0.0.0:43045}
2019-09-27 00:03:44,498 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5508ms
2019-09-27 00:03:44,499 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:03:44,500 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43045
2019-09-27 00:03:44,501 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:03:44,505 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:03:44,508 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4acef680] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:03:44,514 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:03:44,515 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/containers/hdds to VolumeSet
2019-09-27 00:03:44,516 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bbf841e
2019-09-27 00:03:44,516 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bbf841e
2019-09-27 00:03:44,536 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:03:44,536 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:03:44,536 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:03:44,537 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:03:44,537 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:44,537 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:03:44,538 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:03:44,538 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis] (custom)
2019-09-27 00:03:44,540 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:03:44,542 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:03:44,543 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:03:44,546 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:03:44,546 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:03:44,547 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:03:44,547 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:03:44,548 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39256
2019-09-27 00:03:44,548 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:03:44,552 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a92be4f{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:03:44,553 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@337bbfdf{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:03:44,588 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44536de4{/,file:///tmp/jetty-0.0.0.0-39256-hddsDatanode-_-any-6914454937542644779.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:03:44,589 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5fcfde70{HTTP/1.1,[http/1.1]}{0.0.0.0:39256}
2019-09-27 00:03:44,589 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5599ms
2019-09-27 00:03:44,590 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:03:44,591 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39256
2019-09-27 00:03:44,591 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-27 00:03:44,594 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-27 00:03:44,594 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73fc0f17] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:03:44,602 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-27 00:03:44,603 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/containers/hdds to VolumeSet
2019-09-27 00:03:44,603 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5a6d30e2
2019-09-27 00:03:44,603 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5a6d30e2
2019-09-27 00:03:44,617 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-27 00:03:44,617 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-27 00:03:44,618 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-27 00:03:44,618 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-27 00:03:44,618 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:44,618 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-27 00:03:44,619 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:03:44,619 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis] (custom)
2019-09-27 00:03:44,619 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/meta/datanode.id
2019-09-27 00:03:44,623 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-27 00:03:44,623 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/meta/datanode.id
2019-09-27 00:03:44,624 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-27 00:03:44,625 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-27 00:03:44,626 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-27 00:03:44,627 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-27 00:03:44,627 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-27 00:03:44,627 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-27 00:03:44,628 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36556
2019-09-27 00:03:44,628 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-27 00:03:44,630 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e642b88{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-27 00:03:44,630 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ecec90d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-27 00:03:44,659 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36480b2d{/,file:///tmp/jetty-0.0.0.0-36556-hddsDatanode-_-any-6698989473125040906.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-27 00:03:44,659 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27d33393{HTTP/1.1,[http/1.1]}{0.0.0.0:36556}
2019-09-27 00:03:44,660 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5669ms
2019-09-27 00:03:44,660 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-27 00:03:44,662 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36556
2019-09-27 00:03:44,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 00:03:44,665 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e7878d6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-27 00:03:44,668 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/meta/datanode.id
2019-09-27 00:03:45,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 00:03:46,575 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:03:46,578 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:03:46,578 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis cf6167b6-64af-40a0-a21e-d855bda6bfa8 at port 0
2019-09-27 00:03:46,607 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start RPC server
2019-09-27 00:03:46,614 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:03:46,620 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:03:46,620 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 62d906d8-2945-434b-94b9-a699aef24408 at port 0
2019-09-27 00:03:46,631 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 62d906d8-2945-434b-94b9-a699aef24408: start RPC server
2019-09-27 00:03:46,667 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 00:03:46,682 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-27 00:03:46,684 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-27 00:03:46,684 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 317d6895-aec9-4781-8050-9fe2df94d215 at port 0
2019-09-27 00:03:46,694 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 317d6895-aec9-4781-8050-9fe2df94d215: start RPC server
2019-09-27 00:03:46,763 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: GrpcService started, listening on 0.0.0.0/0.0.0.0:46335
2019-09-27 00:03:46,763 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 317d6895-aec9-4781-8050-9fe2df94d215: GrpcService started, listening on 0.0.0.0/0.0.0.0:41302
2019-09-27 00:03:46,763 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 62d906d8-2945-434b-94b9-a699aef24408: GrpcService started, listening on 0.0.0.0/0.0.0.0:36091
2019-09-27 00:03:46,764 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 317d6895-aec9-4781-8050-9fe2df94d215 is started using port 41302
2019-09-27 00:03:46,763 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis cf6167b6-64af-40a0-a21e-d855bda6bfa8 is started using port 46335
2019-09-27 00:03:46,764 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 62d906d8-2945-434b-94b9-a699aef24408 is started using port 36091
2019-09-27 00:03:46,771 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 62d906d8-2945-434b-94b9-a699aef24408 is started using port 43250
2019-09-27 00:03:46,772 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 317d6895-aec9-4781-8050-9fe2df94d215 is started using port 41968
2019-09-27 00:03:46,771 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc cf6167b6-64af-40a0-a21e-d855bda6bfa8 is started using port 42297
2019-09-27 00:03:47,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-27 00:03:48,559 [IPC Server handler 0 on 35025] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cf6167b6-64af-40a0-a21e-d855bda6bfa8
2019-09-27 00:03:48,559 [IPC Server handler 0 on 35025] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : cf6167b6-64af-40a0-a21e-d855bda6bfa8{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:03:48,565 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-27 00:03:48,565 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-27 00:03:48,566 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-27 00:03:48,599 [IPC Server handler 1 on 35025] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/62d906d8-2945-434b-94b9-a699aef24408
2019-09-27 00:03:48,599 [IPC Server handler 1 on 35025] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 62d906d8-2945-434b-94b9-a699aef24408{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:03:48,668 [IPC Server handler 3 on 35025] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/317d6895-aec9-4781-8050-9fe2df94d215
2019-09-27 00:03:48,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-27 00:03:48,672 [IPC Server handler 3 on 35025] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 317d6895-aec9-4781-8050-9fe2df94d215{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-27 00:03:49,113 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: addNew group-4AE8FF0876E7:[cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] returns group-4AE8FF0876E7:java.util.concurrent.CompletableFuture@65c9dd7a[Not completed]
2019-09-27 00:03:49,135 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: new RaftServerImpl for group-4AE8FF0876E7:[cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] with ContainerStateMachine:uninitialized
2019-09-27 00:03:49,138 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:03:49,140 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:03:49,140 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:03:49,141 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:03:49,142 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:49,153 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: ConfigurationManager, init=-1: [cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null, confs=<EMPTY_MAP>
2019-09-27 00:03:49,153 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis] (custom)
2019-09-27 00:03:49,163 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/9f09d97b-ede2-4a23-8943-4ae8ff0876e7 does not exist. Creating ...
2019-09-27 00:03:49,192 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/9f09d97b-ede2-4a23-8943-4ae8ff0876e7/in_use.lock acquired by nodename 17635@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:03:49,209 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/9f09d97b-ede2-4a23-8943-4ae8ff0876e7 has been successfully formatted.
2019-09-27 00:03:49,213 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4AE8FF0876E7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:03:49,213 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:03:49,216 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:03:49,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:03:49,224 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:49,227 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,233 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:03:49,240 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/9f09d97b-ede2-4a23-8943-4ae8ff0876e7
2019-09-27 00:03:49,242 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-27 00:03:49,250 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-27 00:03:49,282 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:03:49,282 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:03:49,285 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,286 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:03:49,286 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:03:49,287 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:03:49,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:03:49,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:03:49,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:03:49,298 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:03:49,302 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:03:49,306 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:03:49,307 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:03:49,308 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:03:49,308 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:03:49,333 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: start as a follower, conf=-1: [cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:49,334 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:03:49,335 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start FollowerState
2019-09-27 00:03:49,337 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4AE8FF0876E7,id=cf6167b6-64af-40a0-a21e-d855bda6bfa8
2019-09-27 00:03:49,399 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9f09d97b-ede2-4a23-8943-4ae8ff0876e7, Nodes: cf6167b6-64af-40a0-a21e-d855bda6bfa8{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:03:49,420 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 317d6895-aec9-4781-8050-9fe2df94d215: addNew group-2F02C96A7C15:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302] returns group-2F02C96A7C15:java.util.concurrent.CompletableFuture@48604b56[Not completed]
2019-09-27 00:03:49,455 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 317d6895-aec9-4781-8050-9fe2df94d215: new RaftServerImpl for group-2F02C96A7C15:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302] with ContainerStateMachine:uninitialized
2019-09-27 00:03:49,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:03:49,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:03:49,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:03:49,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:03:49,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:49,458 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: ConfigurationManager, init=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302], old=null, confs=<EMPTY_MAP>
2019-09-27 00:03:49,458 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis] (custom)
2019-09-27 00:03:49,458 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/4930504f-0822-4b9b-b6d7-2f02c96a7c15 does not exist. Creating ...
2019-09-27 00:03:49,504 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/4930504f-0822-4b9b-b6d7-2f02c96a7c15/in_use.lock acquired by nodename 17635@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:03:49,518 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/4930504f-0822-4b9b-b6d7-2f02c96a7c15 has been successfully formatted.
2019-09-27 00:03:49,519 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-2F02C96A7C15: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:03:49,520 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:03:49,520 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:03:49,521 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:03:49,521 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:49,521 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,521 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:03:49,521 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/4930504f-0822-4b9b-b6d7-2f02c96a7c15
2019-09-27 00:03:49,526 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:03:49,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:03:49,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:03:49,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:03:49,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:03:49,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:03:49,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:03:49,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:03:49,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:03:49,528 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:03:49,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:03:49,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:03:49,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:03:49,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:03:49,533 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: start as a follower, conf=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302], old=null
2019-09-27 00:03:49,533 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:03:49,534 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 317d6895-aec9-4781-8050-9fe2df94d215: start FollowerState
2019-09-27 00:03:49,535 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2F02C96A7C15,id=317d6895-aec9-4781-8050-9fe2df94d215
2019-09-27 00:03:49,547 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4930504f-0822-4b9b-b6d7-2f02c96a7c15, Nodes: 317d6895-aec9-4781-8050-9fe2df94d215{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:03:49,566 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62d906d8-2945-434b-94b9-a699aef24408: addNew group-E87C51FBCFA9:[62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091] returns group-E87C51FBCFA9:java.util.concurrent.CompletableFuture@678a9cfc[Not completed]
2019-09-27 00:03:49,580 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62d906d8-2945-434b-94b9-a699aef24408: new RaftServerImpl for group-E87C51FBCFA9:[62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091] with ContainerStateMachine:uninitialized
2019-09-27 00:03:49,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:03:49,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:03:49,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:03:49,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:03:49,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:49,581 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: ConfigurationManager, init=-1: [62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091], old=null, confs=<EMPTY_MAP>
2019-09-27 00:03:49,582 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis] (custom)
2019-09-27 00:03:49,582 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/14c24874-53a2-4d10-a131-e87c51fbcfa9 does not exist. Creating ...
2019-09-27 00:03:49,596 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/14c24874-53a2-4d10-a131-e87c51fbcfa9/in_use.lock acquired by nodename 17635@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:03:49,609 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/14c24874-53a2-4d10-a131-e87c51fbcfa9 has been successfully formatted.
2019-09-27 00:03:49,610 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E87C51FBCFA9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:03:49,610 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:03:49,610 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:03:49,610 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:03:49,610 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:49,610 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,611 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:03:49,611 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/14c24874-53a2-4d10-a131-e87c51fbcfa9
2019-09-27 00:03:49,639 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:03:49,639 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:03:49,639 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,639 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:03:49,639 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:03:49,639 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:03:49,640 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:03:49,640 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:03:49,640 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:03:49,640 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:03:49,641 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:03:49,641 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:03:49,641 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:03:49,641 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:03:49,641 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:03:49,645 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: start as a follower, conf=-1: [62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091], old=null
2019-09-27 00:03:49,645 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:03:49,646 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62d906d8-2945-434b-94b9-a699aef24408: start FollowerState
2019-09-27 00:03:49,646 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E87C51FBCFA9,id=62d906d8-2945-434b-94b9-a699aef24408
2019-09-27 00:03:49,657 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 14c24874-53a2-4d10-a131-e87c51fbcfa9, Nodes: 62d906d8-2945-434b-94b9-a699aef24408{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-27 00:03:49,696 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 62d906d8-2945-434b-94b9-a699aef24408: addNew group-4E389FF86993:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] returns group-4E389FF86993:java.util.concurrent.CompletableFuture@29dd5454[Not completed]
2019-09-27 00:03:49,697 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 317d6895-aec9-4781-8050-9fe2df94d215: addNew group-4E389FF86993:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] returns group-4E389FF86993:java.util.concurrent.CompletableFuture@7d747ef6[Not completed]
2019-09-27 00:03:49,697 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: addNew group-4E389FF86993:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] returns group-4E389FF86993:java.util.concurrent.CompletableFuture@6cdfdf0b[Not completed]
2019-09-27 00:03:49,698 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 62d906d8-2945-434b-94b9-a699aef24408: new RaftServerImpl for group-4E389FF86993:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] with ContainerStateMachine:uninitialized
2019-09-27 00:03:49,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:03:49,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:03:49,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:03:49,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:03:49,699 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: new RaftServerImpl for group-4E389FF86993:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] with ContainerStateMachine:uninitialized
2019-09-27 00:03:49,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:49,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:03:49,700 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: ConfigurationManager, init=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null, confs=<EMPTY_MAP>
2019-09-27 00:03:49,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:03:49,700 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis] (custom)
2019-09-27 00:03:49,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:03:49,700 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 317d6895-aec9-4781-8050-9fe2df94d215: new RaftServerImpl for group-4E389FF86993:[317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335] with ContainerStateMachine:uninitialized
2019-09-27 00:03:49,700 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:03:49,701 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-27 00:03:49,701 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993 does not exist. Creating ...
2019-09-27 00:03:49,701 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-27 00:03:49,701 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:49,701 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-27 00:03:49,701 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: ConfigurationManager, init=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null, confs=<EMPTY_MAP>
2019-09-27 00:03:49,702 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-27 00:03:49,702 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis] (custom)
2019-09-27 00:03:49,702 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:49,702 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993 does not exist. Creating ...
2019-09-27 00:03:49,702 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: ConfigurationManager, init=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null, confs=<EMPTY_MAP>
2019-09-27 00:03:49,702 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis] (custom)
2019-09-27 00:03:49,703 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993 does not exist. Creating ...
2019-09-27 00:03:49,727 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993/in_use.lock acquired by nodename 17635@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:03:49,727 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993/in_use.lock acquired by nodename 17635@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:03:49,727 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993/in_use.lock acquired by nodename 17635@pr-hdds-2162-kpcbn-4093309294
2019-09-27 00:03:49,747 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993 has been successfully formatted.
2019-09-27 00:03:49,747 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993 has been successfully formatted.
2019-09-27 00:03:49,747 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993 has been successfully formatted.
2019-09-27 00:03:49,747 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4E389FF86993: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:03:49,748 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4E389FF86993: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:03:49,748 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:03:49,748 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4E389FF86993: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-27 00:03:49,748 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:03:49,748 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:03:49,749 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:03:49,749 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-27 00:03:49,749 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:49,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:03:49,749 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,749 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-27 00:03:49,750 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:03:49,749 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:03:49,750 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993
2019-09-27 00:03:49,750 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-27 00:03:49,750 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:03:49,750 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:49,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:03:49,750 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:49,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,751 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,751 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:03:49,751 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,752 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:03:49,752 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:03:49,752 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:03:49,752 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-27 00:03:49,752 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:03:49,752 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993
2019-09-27 00:03:49,753 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:03:49,753 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993
2019-09-27 00:03:49,753 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:03:49,753 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:03:49,754 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:03:49,753 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-27 00:03:49,754 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:03:49,754 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:03:49,754 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-27 00:03:49,754 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,755 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-27 00:03:49,755 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:03:49,755 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:03:49,756 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:03:49,755 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-27 00:03:49,756 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:03:49,756 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:03:49,756 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:03:49,756 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-27 00:03:49,757 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:03:49,757 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:03:49,757 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:03:49,757 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-27 00:03:49,758 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:03:49,757 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:03:49,758 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-27 00:03:49,758 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:03:49,758 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-27 00:03:49,759 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-27 00:03:49,759 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:03:49,759 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-27 00:03:49,759 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:03:49,759 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:03:49,759 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-27 00:03:49,760 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:03:49,760 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-27 00:03:49,760 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-27 00:03:49,760 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-27 00:03:49,761 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-27 00:03:49,766 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: start as a follower, conf=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:49,767 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:03:49,767 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62d906d8-2945-434b-94b9-a699aef24408: start FollowerState
2019-09-27 00:03:49,767 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E389FF86993,id=62d906d8-2945-434b-94b9-a699aef24408
2019-09-27 00:03:49,768 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: start as a follower, conf=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:49,769 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:03:49,769 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: start as a follower, conf=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:49,770 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 317d6895-aec9-4781-8050-9fe2df94d215: start FollowerState
2019-09-27 00:03:49,770 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-27 00:03:49,772 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start FollowerState
2019-09-27 00:03:49,772 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E389FF86993,id=317d6895-aec9-4781-8050-9fe2df94d215
2019-09-27 00:03:49,773 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E389FF86993,id=cf6167b6-64af-40a0-a21e-d855bda6bfa8
2019-09-27 00:03:49,798 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3446d91d-6ae8-4b3d-b1ca-4e389ff86993, Nodes: 317d6895-aec9-4781-8050-9fe2df94d215{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}62d906d8-2945-434b-94b9-a699aef24408{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}cf6167b6-64af-40a0-a21e-d855bda6bfa8{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-27 00:03:49,923 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:50,925 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:51,573 [Thread-178] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-27 00:03:51,577 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-27 00:03:51,926 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:52,928 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:53,930 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:54,480 [Thread-181] INFO  impl.FollowerState (FollowerState.java:run(106)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8:group-4AE8FF0876E7 changes to CANDIDATE, lastRpcTime:5145, electionTimeout:5144ms
2019-09-27 00:03:54,484 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown FollowerState
2019-09-27 00:03:54,484 [Thread-181] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:03:54,492 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start LeaderElection
2019-09-27 00:03:54,509 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1: begin an election at term 1 for -1: [cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:54,511 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown LeaderElection
2019-09-27 00:03:54,512 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:03:54,514 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: change Leader from null to cf6167b6-64af-40a0-a21e-d855bda6bfa8 at term 1 for becomeLeader, leader elected after 5300ms
2019-09-27 00:03:54,522 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:03:54,523 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:03:54,526 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:03:54,530 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:03:54,530 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:03:54,532 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:03:54,551 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start LeaderState
2019-09-27 00:03:54,562 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(106)) - 317d6895-aec9-4781-8050-9fe2df94d215:group-2F02C96A7C15 changes to CANDIDATE, lastRpcTime:5028, electionTimeout:5027ms
2019-09-27 00:03:54,564 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown FollowerState
2019-09-27 00:03:54,564 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:03:54,564 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 317d6895-aec9-4781-8050-9fe2df94d215: start LeaderElection
2019-09-27 00:03:54,583 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:03:54,592 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2: begin an election at term 1 for -1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302], old=null
2019-09-27 00:03:54,593 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown LeaderElection
2019-09-27 00:03:54,594 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:03:54,594 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: change Leader from null to 317d6895-aec9-4781-8050-9fe2df94d215 at term 1 for becomeLeader, leader elected after 5073ms
2019-09-27 00:03:54,594 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:03:54,594 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:03:54,595 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:03:54,595 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:03:54,595 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:03:54,595 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:03:54,597 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: set configuration 0: [cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null at 0
2019-09-27 00:03:54,610 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 317d6895-aec9-4781-8050-9fe2df94d215: start LeaderState
2019-09-27 00:03:54,610 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:03:54,611 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: set configuration 0: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302], old=null at 0
2019-09-27 00:03:54,802 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/4930504f-0822-4b9b-b6d7-2f02c96a7c15/current/log_inprogress_0
2019-09-27 00:03:54,802 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/9f09d97b-ede2-4a23-8943-4ae8ff0876e7/current/log_inprogress_0
2019-09-27 00:03:54,817 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(106)) - 62d906d8-2945-434b-94b9-a699aef24408:group-E87C51FBCFA9 changes to CANDIDATE, lastRpcTime:5171, electionTimeout:5171ms
2019-09-27 00:03:54,817 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown FollowerState
2019-09-27 00:03:54,818 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:03:54,818 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62d906d8-2945-434b-94b9-a699aef24408: start LeaderElection
2019-09-27 00:03:54,829 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3: begin an election at term 1 for -1: [62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091], old=null
2019-09-27 00:03:54,829 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown LeaderElection
2019-09-27 00:03:54,830 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:03:54,830 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: change Leader from null to 62d906d8-2945-434b-94b9-a699aef24408 at term 1 for becomeLeader, leader elected after 5220ms
2019-09-27 00:03:54,830 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:03:54,830 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:03:54,830 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:03:54,831 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:03:54,831 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:03:54,831 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:03:54,836 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62d906d8-2945-434b-94b9-a699aef24408: start LeaderState
2019-09-27 00:03:54,836 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:03:54,837 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: set configuration 0: [62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091], old=null at 0
2019-09-27 00:03:54,871 [Thread-195] INFO  impl.FollowerState (FollowerState.java:run(106)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8:group-4E389FF86993 changes to CANDIDATE, lastRpcTime:5098, electionTimeout:5079ms
2019-09-27 00:03:54,871 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown FollowerState
2019-09-27 00:03:54,871 [Thread-195] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:03:54,872 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start LeaderElection
2019-09-27 00:03:54,874 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(106)) - 317d6895-aec9-4781-8050-9fe2df94d215:group-4E389FF86993 changes to CANDIDATE, lastRpcTime:5104, electionTimeout:5102ms
2019-09-27 00:03:54,875 [Thread-194] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown FollowerState
2019-09-27 00:03:54,875 [Thread-194] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-27 00:03:54,875 [Thread-194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 317d6895-aec9-4781-8050-9fe2df94d215: start LeaderElection
2019-09-27 00:03:54,884 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/14c24874-53a2-4d10-a131-e87c51fbcfa9/current/log_inprogress_0
2019-09-27 00:03:54,884 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4: begin an election at term 1 for -1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:54,884 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5: begin an election at term 1 for -1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:54,930 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:cf6167b6-64af-40a0-a21e-d855bda6bfa8
2019-09-27 00:03:54,931 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown FollowerState
2019-09-27 00:03:54,931 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 62d906d8-2945-434b-94b9-a699aef24408: start FollowerState
2019-09-27 00:03:54,931 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(115)) - 62d906d8-2945-434b-94b9-a699aef24408: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:03:54,933 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:54,968 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4: Election PASSED; received 2 response(s) [cf6167b6-64af-40a0-a21e-d855bda6bfa8<-317d6895-aec9-4781-8050-9fe2df94d215#0:FAIL-t1, cf6167b6-64af-40a0-a21e-d855bda6bfa8<-62d906d8-2945-434b-94b9-a699aef24408#0:OK-t1] and 0 exception(s); cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:t1, leader=null, voted=cf6167b6-64af-40a0-a21e-d855bda6bfa8, raftlog=cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:54,968 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5: Election REJECTED; received 2 response(s) [317d6895-aec9-4781-8050-9fe2df94d215<-62d906d8-2945-434b-94b9-a699aef24408#0:FAIL-t1, 317d6895-aec9-4781-8050-9fe2df94d215<-cf6167b6-64af-40a0-a21e-d855bda6bfa8#0:FAIL-t1] and 0 exception(s); 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:t1, leader=null, voted=317d6895-aec9-4781-8050-9fe2df94d215, raftlog=317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null
2019-09-27 00:03:54,968 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown LeaderElection
2019-09-27 00:03:54,971 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-27 00:03:54,972 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-27 00:03:54,974 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown LeaderElection
2019-09-27 00:03:54,975 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: change Leader from null to cf6167b6-64af-40a0-a21e-d855bda6bfa8 at term 1 for becomeLeader, leader elected after 5226ms
2019-09-27 00:03:54,975 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 317d6895-aec9-4781-8050-9fe2df94d215: start FollowerState
2019-09-27 00:03:54,975 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-27 00:03:54,975 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-27 00:03:54,977 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-27 00:03:54,977 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-27 00:03:54,977 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-27 00:03:54,977 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-27 00:03:54,984 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 00:03:54,985 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:54,985 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 00:03:54,990 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 00:03:54,991 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:03:54,991 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:54,993 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-27 00:03:54,993 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-27 00:03:54,993 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-27 00:03:54,994 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-27 00:03:54,994 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-27 00:03:54,994 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-27 00:03:54,998 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: start LeaderState
2019-09-27 00:03:54,998 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:03:54,999 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: set configuration 0: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null at 0
2019-09-27 00:03:55,052 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993/current/log_inprogress_0
2019-09-27 00:03:55,071 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: change Leader from null to cf6167b6-64af-40a0-a21e-d855bda6bfa8 at term 1 for appendEntries, leader elected after 5322ms
2019-09-27 00:03:55,071 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: change Leader from null to cf6167b6-64af-40a0-a21e-d855bda6bfa8 at term 1 for appendEntries, leader elected after 5322ms
2019-09-27 00:03:55,106 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: set configuration 0: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null at 0
2019-09-27 00:03:55,106 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: set configuration 0: [317d6895-aec9-4781-8050-9fe2df94d215:192.168.151.109:41302, 62d906d8-2945-434b-94b9-a699aef24408:192.168.151.109:36091, cf6167b6-64af-40a0-a21e-d855bda6bfa8:192.168.151.109:46335], old=null at 0
2019-09-27 00:03:55,107 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:03:55,107 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-27 00:03:55,160 [62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993/current/log_inprogress_0
2019-09-27 00:03:55,160 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/ratis/3446d91d-6ae8-4b3d-b1ca-4e389ff86993/current/log_inprogress_0
2019-09-27 00:03:55,936 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:56,938 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:57,939 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:58,941 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:03:59,948 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:00,949 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:01,951 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:02,953 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:03,954 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:04,956 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:05,958 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:06,959 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:07,961 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:08,962 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:08,964 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-27 00:04:09,966 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:10,967 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:11,969 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:12,970 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:13,972 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:14,974 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:15,975 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:16,977 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:17,979 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:18,980 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:18,982 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-27 00:04:19,983 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:20,985 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:21,987 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:22,988 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:23,990 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:24,991 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:25,993 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:26,994 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:27,996 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:28,997 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:28,999 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-27 00:04:30,001 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:31,002 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:32,004 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:33,005 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:34,007 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:35,009 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:36,010 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:37,012 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:38,013 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:39,015 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:39,017 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-27 00:04:40,018 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:41,020 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:42,021 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:43,023 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:44,024 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:45,026 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:46,027 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:47,029 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:48,030 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:49,032 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:49,034 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-27 00:04:50,035 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:51,037 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:52,038 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:53,040 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:54,041 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:55,043 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:56,044 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:57,046 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:58,048 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:59,050 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:04:59,052 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-27 00:05:00,053 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:01,055 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:02,056 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:03,058 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:04,059 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:05,061 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:06,062 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:07,064 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:08,065 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:09,067 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:09,069 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-27 00:05:10,070 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:11,072 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:12,073 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:13,075 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:14,076 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:15,078 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:16,080 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:17,081 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:18,083 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:19,084 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:19,086 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-27 00:05:20,087 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:21,089 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:22,091 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:23,092 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:24,093 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:25,095 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:26,096 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:27,098 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:28,099 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:29,101 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:29,102 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-27 00:05:30,103 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:31,105 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:32,106 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:33,108 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:34,109 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:35,111 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:36,112 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:37,114 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:38,115 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:39,116 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-27 00:05:39,118 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-27 00:05:39,121 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestFreonWithPipelineDestroy.startFreon(TestFreonWithPipelineDestroy.java:87)
	at org.apache.hadoop.ozone.freon.TestFreonWithPipelineDestroy.testRestart(TestFreonWithPipelineDestroy.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 57 more
2019-09-27 00:05:39,139 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-27 00:05:39,139 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-27 00:05:39,140 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-27 00:05:39,140 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42465
2019-09-27 00:05:39,154 [IPC Server listener on 42465] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42465
2019-09-27 00:05:39,157 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-27 00:05:39,158 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:05:39,168 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-27 00:05:39,171 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-27 00:05:39,176 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@151335cb{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-27 00:05:39,181 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:05:39,181 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:05:39,182 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:05:39,188 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-27 00:05:39,608 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:05:39,616 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:05:44,192 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:05:44,192 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:05:44,194 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: close
2019-09-27 00:05:44,194 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 62d906d8-2945-434b-94b9-a699aef24408: close
2019-09-27 00:05:44,197 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: shutdown
2019-09-27 00:05:44,197 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: shutdown
2019-09-27 00:05:44,197 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E389FF86993,id=62d906d8-2945-434b-94b9-a699aef24408
2019-09-27 00:05:44,198 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown FollowerState
2019-09-27 00:05:44,197 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4AE8FF0876E7,id=cf6167b6-64af-40a0-a21e-d855bda6bfa8
2019-09-27 00:05:44,198 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(115)) - 62d906d8-2945-434b-94b9-a699aef24408: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:05:44,198 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:05:44,198 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown LeaderState
2019-09-27 00:05:44,202 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993: closes. applyIndex: 0
2019-09-27 00:05:44,203 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8-PendingRequests: sendNotLeaderResponses
2019-09-27 00:05:44,205 [62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:05:44,206 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:05:44,208 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 62d906d8-2945-434b-94b9-a699aef24408@group-4E389FF86993-SegmentedRaftLogWorker close()
2019-09-27 00:05:44,210 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7: closes. applyIndex: 0
2019-09-27 00:05:44,212 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:05:44,212 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: shutdown
2019-09-27 00:05:44,214 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E87C51FBCFA9,id=62d906d8-2945-434b-94b9-a699aef24408
2019-09-27 00:05:44,214 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown LeaderState
2019-09-27 00:05:44,215 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 62d906d8-2945-434b-94b9-a699aef24408-PendingRequests: sendNotLeaderResponses
2019-09-27 00:05:44,216 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:05:44,217 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9: closes. applyIndex: 0
2019-09-27 00:05:44,218 [62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:05:44,218 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4AE8FF0876E7-SegmentedRaftLogWorker close()
2019-09-27 00:05:44,219 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 62d906d8-2945-434b-94b9-a699aef24408@group-E87C51FBCFA9-SegmentedRaftLogWorker close()
2019-09-27 00:05:44,221 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: shutdown
2019-09-27 00:05:44,223 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E389FF86993,id=cf6167b6-64af-40a0-a21e-d855bda6bfa8
2019-09-27 00:05:44,223 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown LeaderState
2019-09-27 00:05:44,223 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown server with port 36091 now
2019-09-27 00:05:44,225 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$395/1699175846@3a3222cb] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993->317d6895-aec9-4781-8050-9fe2df94d215-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 00:05:44,225 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$395/1699175846@667cfc44] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993->62d906d8-2945-434b-94b9-a699aef24408-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-27 00:05:44,225 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8-PendingRequests: sendNotLeaderResponses
2019-09-27 00:05:44,227 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:05:44,230 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993: closes. applyIndex: 0
2019-09-27 00:05:44,231 [cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:05:44,232 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993-SegmentedRaftLogWorker close()
2019-09-27 00:05:44,234 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown server with port 46335 now
2019-09-27 00:05:44,235 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 317d6895-aec9-4781-8050-9fe2df94d215: Completed APPEND_ENTRIES, lastRequest: cf6167b6-64af-40a0-a21e-d855bda6bfa8->317d6895-aec9-4781-8050-9fe2df94d215#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 00:05:44,235 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 62d906d8-2945-434b-94b9-a699aef24408: Completed APPEND_ENTRIES, lastRequest: cf6167b6-64af-40a0-a21e-d855bda6bfa8->62d906d8-2945-434b-94b9-a699aef24408#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-27 00:05:44,238 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8: shutdown server with port 46335 successfully
2019-09-27 00:05:44,242 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993->317d6895-aec9-4781-8050-9fe2df94d215-GrpcLogAppender is stopped
2019-09-27 00:05:44,243 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 62d906d8-2945-434b-94b9-a699aef24408: shutdown server with port 36091 successfully
2019-09-27 00:05:44,245 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:05:44,246 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - cf6167b6-64af-40a0-a21e-d855bda6bfa8@group-4E389FF86993->62d906d8-2945-434b-94b9-a699aef24408-GrpcLogAppender is stopped
2019-09-27 00:05:44,252 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:05:44,272 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:05:44,273 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:05:44,276 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:05:44,277 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:05:44,280 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44536de4{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:05:44,280 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@26cb5207{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:05:44,281 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5fcfde70{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:05:44,281 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15400fff{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:05:44,281 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@337bbfdf{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:05:44,282 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:05:44,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a92be4f{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:05:44,283 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cdb2d95{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:05:44,690 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-27 00:05:49,287 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-27 00:05:49,289 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 317d6895-aec9-4781-8050-9fe2df94d215: close
2019-09-27 00:05:49,290 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: shutdown
2019-09-27 00:05:49,290 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: shutdown
2019-09-27 00:05:49,291 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E389FF86993,id=317d6895-aec9-4781-8050-9fe2df94d215
2019-09-27 00:05:49,291 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2F02C96A7C15,id=317d6895-aec9-4781-8050-9fe2df94d215
2019-09-27 00:05:49,291 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown FollowerState
2019-09-27 00:05:49,291 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown LeaderState
2019-09-27 00:05:49,292 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:05:49,292 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 317d6895-aec9-4781-8050-9fe2df94d215-PendingRequests: sendNotLeaderResponses
2019-09-27 00:05:49,292 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(115)) - 317d6895-aec9-4781-8050-9fe2df94d215: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-27 00:05:49,294 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993: closes. applyIndex: 0
2019-09-27 00:05:49,295 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-StateMachineUpdater: set stopIndex = 0
2019-09-27 00:05:49,296 [317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:05:49,296 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15: closes. applyIndex: 0
2019-09-27 00:05:49,297 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-4E389FF86993-SegmentedRaftLogWorker close()
2019-09-27 00:05:49,297 [317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-27 00:05:49,300 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 317d6895-aec9-4781-8050-9fe2df94d215@group-2F02C96A7C15-SegmentedRaftLogWorker close()
2019-09-27 00:05:49,302 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown server with port 41302 now
2019-09-27 00:05:49,304 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 317d6895-aec9-4781-8050-9fe2df94d215: shutdown server with port 41302 successfully
2019-09-27 00:05:49,318 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-1d26b45b-4de4-4460-b3e4-00538417abe6/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-27 00:05:49,338 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-27 00:05:49,341 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-27 00:05:49,343 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36480b2d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-27 00:05:49,344 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27d33393{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:05:49,344 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ecec90d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:05:49,345 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e642b88{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:05:49,345 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-27 00:05:49,346 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-27 00:05:49,346 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-27 00:05:49,346 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-27 00:05:49,346 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-27 00:05:49,347 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-27 00:05:49,347 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35025
2019-09-27 00:05:49,348 [IPC Server listener on 35025] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35025
2019-09-27 00:05:49,348 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:05:49,408 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-27 00:05:49,409 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-27 00:05:49,409 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-27 00:05:49,409 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43922
2019-09-27 00:05:49,410 [IPC Server listener on 43922] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43922
2019-09-27 00:05:49,410 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-27 00:05:49,410 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-27 00:05:49,411 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44822
2019-09-27 00:05:49,411 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:05:49,412 [IPC Server listener on 44822] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44822
2019-09-27 00:05:49,412 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-27 00:05:49,414 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-27 00:05:49,414 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9573b3b{/,null,UNAVAILABLE}{/scm}
2019-09-27 00:05:49,415 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-27 00:05:49,416 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-27 00:05:49,416 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-27 00:05:49,417 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-27 00:05:49,417 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 00:05:49,417 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-27 00:05:49,418 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-27 00:05:49,424 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-27 00:05:49,430 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-27 00:05:49,430 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
