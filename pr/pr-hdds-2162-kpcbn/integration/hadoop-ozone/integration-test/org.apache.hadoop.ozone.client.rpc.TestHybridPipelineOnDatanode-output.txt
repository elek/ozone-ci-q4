2019-09-26 20:26:42,839 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:42,940 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:42,943 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:42,961 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @899ms
2019-09-26 20:26:43,051 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 20:26:43,051 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 20:26:43,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 20:26:43,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 20:26:43,052 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 20:26:43,053 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 20:26:43,062 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 20:26:43,062 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 20:26:43,063 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 20:26:43,269 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@a1153bc
2019-09-26 20:26:43,271 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 20:26:43,348 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 20:26:43,351 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 20:26:43,354 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 20:26:43,437 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 20:26:43,452 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:43,510 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 20:26:43,512 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:43,619 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 20:26:43,983 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:26:44,011 [Socket Reader #1 for port 36315] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36315
2019-09-26 20:26:44,172 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:26:44,173 [Socket Reader #1 for port 45922] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45922
2019-09-26 20:26:44,185 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:26:44,186 [Socket Reader #1 for port 43828] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43828
2019-09-26 20:26:44,214 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 20:26:44,359 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:26:44,367 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:26:44,374 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:26:44,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 20:26:44,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:26:44,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:26:44,406 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43828
2019-09-26 20:26:44,472 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 20:26:44,485 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 20:26:44,485 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 20:26:44,734 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:43828
2019-09-26 20:26:44,735 [IPC Server listener on 43828] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43828: starting
2019-09-26 20:26:44,735 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:26:44,738 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45922
2019-09-26 20:26:44,740 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45922
2019-09-26 20:26:44,740 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:26:44,740 [IPC Server listener on 45922] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45922: starting
2019-09-26 20:26:44,742 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:36315
2019-09-26 20:26:44,743 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:36315
2019-09-26 20:26:44,743 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:26:44,743 [IPC Server listener on 36315] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36315: starting
2019-09-26 20:26:44,747 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42372
2019-09-26 20:26:44,749 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:26:44,794 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@732f29af{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:26:44,795 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6622fc65{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 20:26:44,829 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7555b920{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-26 20:26:44,835 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6db66836{HTTP/1.1,[http/1.1]}{0.0.0.0:42372}
2019-09-26 20:26:44,835 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2773ms
2019-09-26 20:26:44,837 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 20:26:44,837 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 20:26:44,839 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:42372
2019-09-26 20:26:44,847 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78461bc4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:26:44,851 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:44,976 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-26 20:26:44,977 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 20:26:44,978 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:44,979 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:45,738 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:26:45,746 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 20:26:45,746 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 20:26:45,747 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 20:26:45,747 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 20:26:45,747 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 20:26:45,747 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 20:26:45,747 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 20:26:45,748 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 20:26:45,748 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 20:26:45,748 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 20:26:45,748 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 20:26:45,749 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 20:26:45,749 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 20:26:45,749 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 20:26:45,749 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 20:26:45,750 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 20:26:45,750 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 20:26:45,750 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 20:26:45,750 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 20:26:45,750 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 20:26:45,751 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 20:26:45,751 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 20:26:45,751 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 20:26:45,752 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 20:26:45,752 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 20:26:46,329 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:26:46,330 [Socket Reader #1 for port 36207] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36207
2019-09-26 20:26:46,350 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:36207
2019-09-26 20:26:46,350 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 20:26:46,351 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:26:46,352 [IPC Server listener on 36207] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36207: starting
2019-09-26 20:26:46,357 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 20:26:46,359 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:26:46,360 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:26:46,363 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:26:46,364 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 20:26:46,364 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:26:46,364 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:26:46,367 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42155
2019-09-26 20:26:46,368 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:26:46,370 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67dba613{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:26:46,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cf8edcf{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 20:26:46,377 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22d1886d{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-26 20:26:46,379 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7df60067{HTTP/1.1,[http/1.1]}{0.0.0.0:42155}
2019-09-26 20:26:46,380 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4318ms
2019-09-26 20:26:46,380 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:26:46,381 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:42155
2019-09-26 20:26:46,712 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:26:46,763 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:26:46,795 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:26:46,797 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 20:26:46,799 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5136207f
2019-09-26 20:26:46,816 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5136207f
2019-09-26 20:26:46,920 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:26:46,985 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:26:46,994 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:26:46,996 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:26:46,998 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:46,999 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:26:47,001 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:26:47,210 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis] (custom)
2019-09-26 20:26:47,262 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:26:47,265 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:26:47,266 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:26:47,269 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:26:47,270 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:26:47,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:26:47,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:26:47,273 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46393
2019-09-26 20:26:47,273 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:26:47,278 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@558756be{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:26:47,279 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d1dcdff{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:26:47,329 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@352c44a8{/,file:///tmp/jetty-0.0.0.0-46393-hddsDatanode-_-any-4780106643192228499.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:26:47,329 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7aac8884{HTTP/1.1,[http/1.1]}{0.0.0.0:46393}
2019-09-26 20:26:47,330 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5269ms
2019-09-26 20:26:47,331 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:26:47,332 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46393
2019-09-26 20:26:47,333 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:26:47,337 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:26:47,340 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@705e562f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:26:47,346 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:26:47,347 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 20:26:47,347 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@117525fe
2019-09-26 20:26:47,348 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@117525fe
2019-09-26 20:26:47,364 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:26:47,365 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:26:47,365 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:26:47,365 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:26:47,365 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:47,366 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:26:47,366 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:26:47,367 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis] (custom)
2019-09-26 20:26:47,368 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:26:47,369 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:26:47,370 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:26:47,372 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:26:47,372 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:26:47,373 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:26:47,373 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:26:47,374 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36768
2019-09-26 20:26:47,374 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:26:47,378 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77774571{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:26:47,379 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cd64ee8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:26:47,408 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e519ad3{/,file:///tmp/jetty-0.0.0.0-36768-hddsDatanode-_-any-1161570344737274081.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:26:47,409 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bc44ce8{HTTP/1.1,[http/1.1]}{0.0.0.0:36768}
2019-09-26 20:26:47,410 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5348ms
2019-09-26 20:26:47,410 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:26:47,411 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36768
2019-09-26 20:26:47,412 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:26:47,414 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:26:47,415 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d985705] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:26:47,423 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:26:47,423 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 20:26:47,424 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6e0c6a7a
2019-09-26 20:26:47,424 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6e0c6a7a
2019-09-26 20:26:47,438 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:26:47,438 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:26:47,438 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:26:47,438 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:26:47,439 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:47,439 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:26:47,439 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:26:47,440 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis] (custom)
2019-09-26 20:26:47,441 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:26:47,443 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:26:47,443 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:26:47,446 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:26:47,447 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:26:47,447 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:26:47,447 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:26:47,449 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46535
2019-09-26 20:26:47,449 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:26:47,452 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5fcfde70{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:26:47,454 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28da7d11{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:26:47,460 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/meta/datanode.id
2019-09-26 20:26:47,464 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/meta/datanode.id
2019-09-26 20:26:47,502 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@296e281a{/,file:///tmp/jetty-0.0.0.0-46535-hddsDatanode-_-any-5221277714579707120.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:26:47,504 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59cda16e{HTTP/1.1,[http/1.1]}{0.0.0.0:46535}
2019-09-26 20:26:47,504 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5442ms
2019-09-26 20:26:47,505 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:26:47,506 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46535
2019-09-26 20:26:47,509 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:26:47,510 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3a847a4a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:26:47,512 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/meta/datanode.id
2019-09-26 20:26:48,509 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:26:49,394 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:26:49,396 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:26:49,396 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b56b6312-0b85-468b-92a8-80020e892d33 at port 0
2019-09-26 20:26:49,414 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b56b6312-0b85-468b-92a8-80020e892d33: start RPC server
2019-09-26 20:26:49,433 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:26:49,438 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:26:49,438 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 7b661031-646e-43a9-913b-69a84112d16d at port 0
2019-09-26 20:26:49,447 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7b661031-646e-43a9-913b-69a84112d16d: start RPC server
2019-09-26 20:26:49,510 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:26:49,525 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:26:49,526 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:26:49,527 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 945233cc-2bc9-439b-ab63-d113bab7cbd4 at port 0
2019-09-26 20:26:49,537 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: start RPC server
2019-09-26 20:26:49,553 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: GrpcService started, listening on 0.0.0.0/0.0.0.0:35971
2019-09-26 20:26:49,553 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 7b661031-646e-43a9-913b-69a84112d16d: GrpcService started, listening on 0.0.0.0/0.0.0.0:37748
2019-09-26 20:26:49,553 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b56b6312-0b85-468b-92a8-80020e892d33: GrpcService started, listening on 0.0.0.0/0.0.0.0:33327
2019-09-26 20:26:49,555 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 7b661031-646e-43a9-913b-69a84112d16d is started using port 37748
2019-09-26 20:26:49,554 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 945233cc-2bc9-439b-ab63-d113bab7cbd4 is started using port 35971
2019-09-26 20:26:49,555 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b56b6312-0b85-468b-92a8-80020e892d33 is started using port 33327
2019-09-26 20:26:49,561 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 945233cc-2bc9-439b-ab63-d113bab7cbd4 is started using port 35146
2019-09-26 20:26:49,562 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 7b661031-646e-43a9-913b-69a84112d16d is started using port 45908
2019-09-26 20:26:49,561 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b56b6312-0b85-468b-92a8-80020e892d33 is started using port 42071
2019-09-26 20:26:50,511 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:26:51,383 [IPC Server handler 1 on 36315] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b56b6312-0b85-468b-92a8-80020e892d33
2019-09-26 20:26:51,384 [IPC Server handler 1 on 36315] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b56b6312-0b85-468b-92a8-80020e892d33{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:26:51,388 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 20:26:51,388 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 20:26:51,388 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 20:26:51,418 [IPC Server handler 2 on 36315] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:26:51,418 [IPC Server handler 2 on 36315] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 7b661031-646e-43a9-913b-69a84112d16d{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:26:51,512 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-26 20:26:51,513 [IPC Server handler 3 on 36315] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/945233cc-2bc9-439b-ab63-d113bab7cbd4
2019-09-26 20:26:51,513 [IPC Server handler 3 on 36315] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 945233cc-2bc9-439b-ab63-d113bab7cbd4{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:26:51,889 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b56b6312-0b85-468b-92a8-80020e892d33: addNew group-0CD6E90C5995:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327] returns group-0CD6E90C5995:java.util.concurrent.CompletableFuture@60fbb728[Not completed]
2019-09-26 20:26:51,908 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b56b6312-0b85-468b-92a8-80020e892d33: new RaftServerImpl for group-0CD6E90C5995:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327] with ContainerStateMachine:uninitialized
2019-09-26 20:26:51,911 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:26:51,912 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:26:51,912 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:26:51,913 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:26:51,914 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:51,923 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: ConfigurationManager, init=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327], old=null, confs=<EMPTY_MAP>
2019-09-26 20:26:51,924 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis] (custom)
2019-09-26 20:26:51,932 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/f043df63-edc7-4e67-96d7-0cd6e90c5995 does not exist. Creating ...
2019-09-26 20:26:51,949 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/f043df63-edc7-4e67-96d7-0cd6e90c5995/in_use.lock acquired by nodename 591@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:26:51,965 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/f043df63-edc7-4e67-96d7-0cd6e90c5995 has been successfully formatted.
2019-09-26 20:26:51,968 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0CD6E90C5995: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:26:51,968 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:26:51,970 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:26:51,976 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:26:51,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:51,979 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:51,984 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:26:51,989 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/f043df63-edc7-4e67-96d7-0cd6e90c5995
2019-09-26 20:26:51,991 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 20:26:51,997 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 20:26:52,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:26:52,024 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:26:52,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,028 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:26:52,028 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:26:52,029 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:26:52,029 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:26:52,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:26:52,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:26:52,037 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:26:52,041 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:26:52,045 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:26:52,046 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:26:52,046 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:26:52,047 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:26:52,071 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: start as a follower, conf=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327], old=null
2019-09-26 20:26:52,072 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:26:52,073 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b56b6312-0b85-468b-92a8-80020e892d33: start FollowerState
2019-09-26 20:26:52,074 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0CD6E90C5995,id=b56b6312-0b85-468b-92a8-80020e892d33
2019-09-26 20:26:52,137 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f043df63-edc7-4e67-96d7-0cd6e90c5995, Nodes: b56b6312-0b85-468b-92a8-80020e892d33{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:26:52,160 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7b661031-646e-43a9-913b-69a84112d16d: addNew group-403CD43DD07C:[7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] returns group-403CD43DD07C:java.util.concurrent.CompletableFuture@11704022[Not completed]
2019-09-26 20:26:52,192 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7b661031-646e-43a9-913b-69a84112d16d: new RaftServerImpl for group-403CD43DD07C:[7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] with ContainerStateMachine:uninitialized
2019-09-26 20:26:52,193 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:26:52,194 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:26:52,194 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:26:52,194 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:26:52,194 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:52,194 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: ConfigurationManager, init=-1: [7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null, confs=<EMPTY_MAP>
2019-09-26 20:26:52,195 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis] (custom)
2019-09-26 20:26:52,195 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/6a843abb-2616-45af-9ecf-403cd43dd07c does not exist. Creating ...
2019-09-26 20:26:52,209 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/6a843abb-2616-45af-9ecf-403cd43dd07c/in_use.lock acquired by nodename 591@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:26:52,229 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/6a843abb-2616-45af-9ecf-403cd43dd07c has been successfully formatted.
2019-09-26 20:26:52,230 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-403CD43DD07C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:26:52,231 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:26:52,231 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:26:52,232 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:26:52,232 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:52,232 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,232 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:26:52,232 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/6a843abb-2616-45af-9ecf-403cd43dd07c
2019-09-26 20:26:52,239 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:26:52,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:26:52,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:26:52,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:26:52,240 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:26:52,241 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:26:52,241 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:26:52,241 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:26:52,241 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:26:52,242 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:26:52,242 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:26:52,242 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:26:52,243 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:26:52,243 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:26:52,248 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: start as a follower, conf=-1: [7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:52,248 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:26:52,248 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7b661031-646e-43a9-913b-69a84112d16d: start FollowerState
2019-09-26 20:26:52,250 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-403CD43DD07C,id=7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:26:52,264 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6a843abb-2616-45af-9ecf-403cd43dd07c, Nodes: 7b661031-646e-43a9-913b-69a84112d16d{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:26:52,283 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: addNew group-195898F058E6:[945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971] returns group-195898F058E6:java.util.concurrent.CompletableFuture@479f27e5[Not completed]
2019-09-26 20:26:52,300 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: new RaftServerImpl for group-195898F058E6:[945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971] with ContainerStateMachine:uninitialized
2019-09-26 20:26:52,301 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:26:52,302 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:26:52,302 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:26:52,302 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:26:52,302 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:52,302 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: ConfigurationManager, init=-1: [945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971], old=null, confs=<EMPTY_MAP>
2019-09-26 20:26:52,303 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis] (custom)
2019-09-26 20:26:52,303 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/25f73b5b-4f3e-4088-aeb3-195898f058e6 does not exist. Creating ...
2019-09-26 20:26:52,317 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/25f73b5b-4f3e-4088-aeb3-195898f058e6/in_use.lock acquired by nodename 591@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:26:52,330 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/25f73b5b-4f3e-4088-aeb3-195898f058e6 has been successfully formatted.
2019-09-26 20:26:52,331 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-195898F058E6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:26:52,331 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:26:52,331 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:26:52,331 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:26:52,332 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:52,332 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,332 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:26:52,332 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/25f73b5b-4f3e-4088-aeb3-195898f058e6
2019-09-26 20:26:52,362 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:26:52,362 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:26:52,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:26:52,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:26:52,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:26:52,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:26:52,364 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:26:52,364 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:26:52,364 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:26:52,365 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:26:52,365 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:26:52,365 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:26:52,365 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:26:52,366 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:26:52,371 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: start as a follower, conf=-1: [945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971], old=null
2019-09-26 20:26:52,371 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:26:52,371 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: start FollowerState
2019-09-26 20:26:52,371 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-195898F058E6,id=945233cc-2bc9-439b-ab63-d113bab7cbd4
2019-09-26 20:26:52,382 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 25f73b5b-4f3e-4088-aeb3-195898f058e6, Nodes: 945233cc-2bc9-439b-ab63-d113bab7cbd4{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:26:52,416 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b56b6312-0b85-468b-92a8-80020e892d33: addNew group-F6CFD5E15282:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] returns group-F6CFD5E15282:java.util.concurrent.CompletableFuture@3b02c373[Not completed]
2019-09-26 20:26:52,419 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7b661031-646e-43a9-913b-69a84112d16d: addNew group-F6CFD5E15282:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] returns group-F6CFD5E15282:java.util.concurrent.CompletableFuture@7a3fc948[Not completed]
2019-09-26 20:26:52,421 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b56b6312-0b85-468b-92a8-80020e892d33: new RaftServerImpl for group-F6CFD5E15282:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] with ContainerStateMachine:uninitialized
2019-09-26 20:26:52,422 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:26:52,423 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:26:52,423 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:26:52,423 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:26:52,423 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:52,423 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: addNew group-F6CFD5E15282:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] returns group-F6CFD5E15282:java.util.concurrent.CompletableFuture@663bad47[Not completed]
2019-09-26 20:26:52,423 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: ConfigurationManager, init=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null, confs=<EMPTY_MAP>
2019-09-26 20:26:52,424 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7b661031-646e-43a9-913b-69a84112d16d: new RaftServerImpl for group-F6CFD5E15282:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] with ContainerStateMachine:uninitialized
2019-09-26 20:26:52,424 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis] (custom)
2019-09-26 20:26:52,424 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:26:52,424 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:26:52,424 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282 does not exist. Creating ...
2019-09-26 20:26:52,424 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:26:52,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:26:52,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:52,425 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: ConfigurationManager, init=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null, confs=<EMPTY_MAP>
2019-09-26 20:26:52,425 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: new RaftServerImpl for group-F6CFD5E15282:[b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748] with ContainerStateMachine:uninitialized
2019-09-26 20:26:52,425 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis] (custom)
2019-09-26 20:26:52,425 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:26:52,426 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:26:52,426 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282 does not exist. Creating ...
2019-09-26 20:26:52,426 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:26:52,426 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:26:52,426 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:52,427 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: ConfigurationManager, init=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null, confs=<EMPTY_MAP>
2019-09-26 20:26:52,427 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis] (custom)
2019-09-26 20:26:52,427 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282 does not exist. Creating ...
2019-09-26 20:26:52,438 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282/in_use.lock acquired by nodename 591@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:26:52,438 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282/in_use.lock acquired by nodename 591@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:26:52,438 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282/in_use.lock acquired by nodename 591@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:26:52,452 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282 has been successfully formatted.
2019-09-26 20:26:52,452 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282 has been successfully formatted.
2019-09-26 20:26:52,452 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282 has been successfully formatted.
2019-09-26 20:26:52,453 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F6CFD5E15282: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:26:52,453 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F6CFD5E15282: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:26:52,453 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:26:52,453 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:26:52,453 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F6CFD5E15282: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:26:52,453 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:26:52,453 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:26:52,454 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:26:52,454 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:26:52,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:26:52,454 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:52,454 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:26:52,454 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:52,455 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:26:52,455 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,455 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,455 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:26:52,455 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:52,455 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282
2019-09-26 20:26:52,455 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:26:52,456 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:26:52,455 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,456 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:26:52,456 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282
2019-09-26 20:26:52,456 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,456 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:26:52,456 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:26:52,457 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:26:52,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:26:52,457 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,457 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282
2019-09-26 20:26:52,457 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:26:52,457 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:26:52,458 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:26:52,457 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:26:52,458 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:26:52,458 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:26:52,458 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:26:52,458 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:26:52,458 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:26:52,458 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:26:52,459 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:26:52,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:26:52,459 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:26:52,459 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:26:52,459 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:26:52,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:26:52,460 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:26:52,459 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:26:52,460 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:26:52,460 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:26:52,460 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:26:52,460 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:26:52,460 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:26:52,461 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:26:52,461 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:26:52,461 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:26:52,461 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:26:52,461 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:26:52,461 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:26:52,461 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:26:52,462 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:26:52,462 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:26:52,462 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:26:52,462 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:26:52,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:26:52,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:26:52,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:26:52,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:26:52,465 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: start as a follower, conf=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:52,466 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:26:52,466 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7b661031-646e-43a9-913b-69a84112d16d: start FollowerState
2019-09-26 20:26:52,466 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6CFD5E15282,id=7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:26:52,470 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: start as a follower, conf=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:52,471 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:26:52,472 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: start FollowerState
2019-09-26 20:26:52,473 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: start as a follower, conf=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:52,473 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6CFD5E15282,id=945233cc-2bc9-439b-ab63-d113bab7cbd4
2019-09-26 20:26:52,474 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:26:52,474 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b56b6312-0b85-468b-92a8-80020e892d33: start FollowerState
2019-09-26 20:26:52,476 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6CFD5E15282,id=b56b6312-0b85-468b-92a8-80020e892d33
2019-09-26 20:26:52,492 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 39108eb5-b51d-43cc-8513-f6cfd5e15282, Nodes: b56b6312-0b85-468b-92a8-80020e892d33{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}7b661031-646e-43a9-913b-69a84112d16d{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}945233cc-2bc9-439b-ab63-d113bab7cbd4{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-26 20:26:52,512 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-26 20:26:53,694 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:26:54,393 [Thread-178] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-26 20:26:54,395 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-26 20:26:54,695 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:26:55,696 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:26:56,697 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:26:57,163 [Thread-180] INFO  impl.FollowerState (FollowerState.java:run(106)) - b56b6312-0b85-468b-92a8-80020e892d33:group-0CD6E90C5995 changes to CANDIDATE, lastRpcTime:5089, electionTimeout:5089ms
2019-09-26 20:26:57,165 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown FollowerState
2019-09-26 20:26:57,165 [Thread-180] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:26:57,170 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b56b6312-0b85-468b-92a8-80020e892d33: start LeaderElection
2019-09-26 20:26:57,188 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1: begin an election at term 1 for -1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327], old=null
2019-09-26 20:26:57,190 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown LeaderElection
2019-09-26 20:26:57,190 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:26:57,191 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: change Leader from null to b56b6312-0b85-468b-92a8-80020e892d33 at term 1 for becomeLeader, leader elected after 5222ms
2019-09-26 20:26:57,198 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:26:57,198 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:26:57,201 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:26:57,204 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:26:57,204 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:26:57,205 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:26:57,220 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b56b6312-0b85-468b-92a8-80020e892d33: start LeaderState
2019-09-26 20:26:57,243 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:26:57,253 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: set configuration 0: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327], old=null at 0
2019-09-26 20:26:57,363 [Thread-183] INFO  impl.FollowerState (FollowerState.java:run(106)) - 7b661031-646e-43a9-913b-69a84112d16d:group-403CD43DD07C changes to CANDIDATE, lastRpcTime:5115, electionTimeout:5113ms
2019-09-26 20:26:57,365 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown FollowerState
2019-09-26 20:26:57,366 [Thread-183] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:26:57,366 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7b661031-646e-43a9-913b-69a84112d16d: start LeaderElection
2019-09-26 20:26:57,381 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2: begin an election at term 1 for -1: [7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:57,382 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown LeaderElection
2019-09-26 20:26:57,383 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:26:57,383 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: change Leader from null to 7b661031-646e-43a9-913b-69a84112d16d at term 1 for becomeLeader, leader elected after 5151ms
2019-09-26 20:26:57,383 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:26:57,383 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:26:57,383 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:26:57,384 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:26:57,384 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:26:57,384 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:26:57,390 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7b661031-646e-43a9-913b-69a84112d16d: start LeaderState
2019-09-26 20:26:57,390 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:26:57,391 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: set configuration 0: [7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null at 0
2019-09-26 20:26:57,487 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/6a843abb-2616-45af-9ecf-403cd43dd07c/current/log_inprogress_0
2019-09-26 20:26:57,487 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/f043df63-edc7-4e67-96d7-0cd6e90c5995/current/log_inprogress_0
2019-09-26 20:26:57,560 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4:group-195898F058E6 changes to CANDIDATE, lastRpcTime:5188, electionTimeout:5188ms
2019-09-26 20:26:57,560 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown FollowerState
2019-09-26 20:26:57,560 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:26:57,560 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: start LeaderElection
2019-09-26 20:26:57,563 [Thread-191] INFO  impl.FollowerState (FollowerState.java:run(106)) - 7b661031-646e-43a9-913b-69a84112d16d:group-F6CFD5E15282 changes to CANDIDATE, lastRpcTime:5097, electionTimeout:5097ms
2019-09-26 20:26:57,564 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown FollowerState
2019-09-26 20:26:57,564 [Thread-191] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:26:57,564 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7b661031-646e-43a9-913b-69a84112d16d: start LeaderElection
2019-09-26 20:26:57,577 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3: begin an election at term 1 for -1: [945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971], old=null
2019-09-26 20:26:57,577 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4: begin an election at term 1 for -1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:57,577 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown LeaderElection
2019-09-26 20:26:57,577 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:26:57,577 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: change Leader from null to 945233cc-2bc9-439b-ab63-d113bab7cbd4 at term 1 for becomeLeader, leader elected after 5246ms
2019-09-26 20:26:57,578 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:26:57,578 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:26:57,578 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:26:57,578 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:26:57,578 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:26:57,579 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:26:57,582 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: start LeaderState
2019-09-26 20:26:57,583 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:26:57,583 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: set configuration 0: [945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971], old=null at 0
2019-09-26 20:26:57,629 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/25f73b5b-4f3e-4088-aeb3-195898f058e6/current/log_inprogress_0
2019-09-26 20:26:57,650 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:26:57,650 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:26:57,651 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown FollowerState
2019-09-26 20:26:57,651 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown FollowerState
2019-09-26 20:26:57,651 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(115)) - b56b6312-0b85-468b-92a8-80020e892d33: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:26:57,651 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b56b6312-0b85-468b-92a8-80020e892d33: start FollowerState
2019-09-26 20:26:57,651 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: start FollowerState
2019-09-26 20:26:57,651 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(115)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:26:57,690 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4: Election PASSED; received 1 response(s) [7b661031-646e-43a9-913b-69a84112d16d<-b56b6312-0b85-468b-92a8-80020e892d33#0:OK-t1] and 0 exception(s); 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:t1, leader=null, voted=7b661031-646e-43a9-913b-69a84112d16d, raftlog=7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null
2019-09-26 20:26:57,691 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown LeaderElection
2019-09-26 20:26:57,693 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:26:57,693 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: change Leader from null to 7b661031-646e-43a9-913b-69a84112d16d at term 1 for becomeLeader, leader elected after 5239ms
2019-09-26 20:26:57,693 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:26:57,695 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:26:57,696 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:26:57,696 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:26:57,696 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:26:57,696 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:26:57,698 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:26:57,703 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 20:26:57,704 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:57,704 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 20:26:57,708 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 20:26:57,709 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:26:57,710 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:57,711 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 20:26:57,711 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:26:57,711 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 20:26:57,712 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 20:26:57,712 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:26:57,712 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:26:57,716 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7b661031-646e-43a9-913b-69a84112d16d: start LeaderState
2019-09-26 20:26:57,717 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:26:57,718 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: set configuration 0: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null at 0
2019-09-26 20:26:57,755 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282/current/log_inprogress_0
2019-09-26 20:26:57,763 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: change Leader from null to 7b661031-646e-43a9-913b-69a84112d16d at term 1 for appendEntries, leader elected after 5309ms
2019-09-26 20:26:57,764 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: change Leader from null to 7b661031-646e-43a9-913b-69a84112d16d at term 1 for appendEntries, leader elected after 5311ms
2019-09-26 20:26:57,789 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: set configuration 0: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null at 0
2019-09-26 20:26:57,789 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: set configuration 0: [b56b6312-0b85-468b-92a8-80020e892d33:192.168.151.109:33327, 945233cc-2bc9-439b-ab63-d113bab7cbd4:192.168.151.109:35971, 7b661031-646e-43a9-913b-69a84112d16d:192.168.151.109:37748], old=null at 0
2019-09-26 20:26:57,789 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:26:57,789 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:26:57,829 [b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282/current/log_inprogress_0
2019-09-26 20:26:57,829 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/ratis/39108eb5-b51d-43cc-8513-f6cfd5e15282/current/log_inprogress_0
2019-09-26 20:26:58,700 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:26:59,701 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:00,703 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:01,704 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:02,705 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:03,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:04,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:05,711 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:06,713 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:07,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:08,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:09,716 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:10,717 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:11,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:12,719 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:12,721 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 20:27:13,722 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:14,723 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:15,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:16,725 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:17,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:18,728 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:19,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:20,730 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:21,731 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:22,732 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:22,734 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 20:27:23,735 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:24,736 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:25,737 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:26,738 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:27,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:28,740 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:29,742 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:30,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:31,744 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:32,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:32,747 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 20:27:33,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:34,749 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:35,750 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:36,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:37,752 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:38,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:39,755 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:40,756 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:41,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:42,758 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:42,760 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 20:27:43,761 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:44,762 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:45,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:46,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:47,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:48,766 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:49,767 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:50,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:51,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:52,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:52,772 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 20:27:53,774 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:54,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:55,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:56,777 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:57,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:58,780 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:27:59,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:00,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:01,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:02,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:02,786 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 20:28:03,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:04,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:05,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:06,791 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:07,793 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:08,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:09,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:10,797 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:11,798 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:12,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:12,801 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 20:28:13,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:14,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:15,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:16,807 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:17,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:18,809 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:19,811 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:20,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:21,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:22,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:22,817 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 20:28:23,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:24,819 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:25,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:26,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:27,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:28,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:29,827 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:30,828 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:31,829 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:32,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:32,832 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 20:28:33,833 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:34,834 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:35,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:36,837 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:37,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:38,840 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:39,841 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:40,842 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:41,843 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:42,844 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:28:42,846 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 20:28:42,850 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestHybridPipelineOnDatanode.init(TestHybridPipelineOnDatanode.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-26 20:28:42,854 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 20:28:42,855 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 20:28:42,855 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 20:28:42,855 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36207
2019-09-26 20:28:42,877 [IPC Server listener on 36207] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36207
2019-09-26 20:28:42,878 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 20:28:42,879 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:28:42,879 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 20:28:42,883 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 20:28:42,888 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22d1886d{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 20:28:42,895 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7df60067{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:28:42,896 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cf8edcf{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 20:28:42,896 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67dba613{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:28:42,901 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 20:28:43,350 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:28:43,423 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:28:47,904 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:28:47,904 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:28:47,905 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - b56b6312-0b85-468b-92a8-80020e892d33: close
2019-09-26 20:28:47,905 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 7b661031-646e-43a9-913b-69a84112d16d: close
2019-09-26 20:28:47,907 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: shutdown
2019-09-26 20:28:47,907 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: shutdown
2019-09-26 20:28:47,908 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0CD6E90C5995,id=b56b6312-0b85-468b-92a8-80020e892d33
2019-09-26 20:28:47,908 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-403CD43DD07C,id=7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:28:47,909 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown LeaderState
2019-09-26 20:28:47,908 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown LeaderState
2019-09-26 20:28:47,910 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b56b6312-0b85-468b-92a8-80020e892d33-PendingRequests: sendNotLeaderResponses
2019-09-26 20:28:47,910 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 7b661031-646e-43a9-913b-69a84112d16d-PendingRequests: sendNotLeaderResponses
2019-09-26 20:28:47,913 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:28:47,913 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:28:47,916 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C: closes. applyIndex: 0
2019-09-26 20:28:47,916 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995: closes. applyIndex: 0
2019-09-26 20:28:47,918 [7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:28:47,918 [b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:28:47,920 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 7b661031-646e-43a9-913b-69a84112d16d@group-403CD43DD07C-SegmentedRaftLogWorker close()
2019-09-26 20:28:47,920 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b56b6312-0b85-468b-92a8-80020e892d33@group-0CD6E90C5995-SegmentedRaftLogWorker close()
2019-09-26 20:28:47,923 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: shutdown
2019-09-26 20:28:47,924 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: shutdown
2019-09-26 20:28:47,924 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6CFD5E15282,id=7b661031-646e-43a9-913b-69a84112d16d
2019-09-26 20:28:47,924 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6CFD5E15282,id=b56b6312-0b85-468b-92a8-80020e892d33
2019-09-26 20:28:47,925 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown LeaderState
2019-09-26 20:28:47,925 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown FollowerState
2019-09-26 20:28:47,927 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 7b661031-646e-43a9-913b-69a84112d16d-PendingRequests: sendNotLeaderResponses
2019-09-26 20:28:47,927 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$396/1404385058@5f3c68c6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282->b56b6312-0b85-468b-92a8-80020e892d33-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 20:28:47,928 [Thread-208] INFO  impl.FollowerState (FollowerState.java:run(115)) - b56b6312-0b85-468b-92a8-80020e892d33: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:28:47,927 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:28:47,927 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$396/1404385058@5afd1e36] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282->945233cc-2bc9-439b-ab63-d113bab7cbd4-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 20:28:47,931 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282: closes. applyIndex: 0
2019-09-26 20:28:47,928 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:28:47,932 [b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:28:47,932 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282: closes. applyIndex: 0
2019-09-26 20:28:47,933 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b56b6312-0b85-468b-92a8-80020e892d33@group-F6CFD5E15282-SegmentedRaftLogWorker close()
2019-09-26 20:28:47,933 [7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:28:47,937 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown server with port 33327 now
2019-09-26 20:28:47,937 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: Completed APPEND_ENTRIES, lastRequest: 7b661031-646e-43a9-913b-69a84112d16d->945233cc-2bc9-439b-ab63-d113bab7cbd4#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 20:28:47,937 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - b56b6312-0b85-468b-92a8-80020e892d33: Completed APPEND_ENTRIES, lastRequest: 7b661031-646e-43a9-913b-69a84112d16d->b56b6312-0b85-468b-92a8-80020e892d33#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 20:28:47,938 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282-SegmentedRaftLogWorker close()
2019-09-26 20:28:47,941 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown server with port 37748 now
2019-09-26 20:28:47,941 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282->b56b6312-0b85-468b-92a8-80020e892d33-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 20:28:47,941 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282->945233cc-2bc9-439b-ab63-d113bab7cbd4-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 20:28:47,944 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 7b661031-646e-43a9-913b-69a84112d16d: shutdown server with port 37748 successfully
2019-09-26 20:28:47,946 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - b56b6312-0b85-468b-92a8-80020e892d33: shutdown server with port 33327 successfully
2019-09-26 20:28:47,946 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282->b56b6312-0b85-468b-92a8-80020e892d33: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 20:28:47,946 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 7b661031-646e-43a9-913b-69a84112d16d@group-F6CFD5E15282->945233cc-2bc9-439b-ab63-d113bab7cbd4: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 20:28:47,949 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:28:47,954 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:28:47,970 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:28:47,971 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:28:47,973 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:28:47,975 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:28:47,977 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@352c44a8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:28:47,977 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e519ad3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:28:47,977 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7aac8884{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:28:47,978 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bc44ce8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:28:47,978 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d1dcdff{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:28:47,978 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cd64ee8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:28:47,979 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@558756be{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:28:47,979 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77774571{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:28:48,522 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:28:52,981 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:28:52,982 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: close
2019-09-26 20:28:52,982 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: shutdown
2019-09-26 20:28:52,983 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-195898F058E6,id=945233cc-2bc9-439b-ab63-d113bab7cbd4
2019-09-26 20:28:52,983 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown LeaderState
2019-09-26 20:28:52,984 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4-PendingRequests: sendNotLeaderResponses
2019-09-26 20:28:52,984 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:28:52,986 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6: closes. applyIndex: 0
2019-09-26 20:28:52,987 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:28:52,988 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-195898F058E6-SegmentedRaftLogWorker close()
2019-09-26 20:28:52,990 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: shutdown
2019-09-26 20:28:52,990 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6CFD5E15282,id=945233cc-2bc9-439b-ab63-d113bab7cbd4
2019-09-26 20:28:52,990 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown FollowerState
2019-09-26 20:28:52,990 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:28:52,990 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(115)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:28:52,992 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282: closes. applyIndex: 0
2019-09-26 20:28:52,993 [945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:28:52,993 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4@group-F6CFD5E15282-SegmentedRaftLogWorker close()
2019-09-26 20:28:52,995 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown server with port 35971 now
2019-09-26 20:28:52,995 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 945233cc-2bc9-439b-ab63-d113bab7cbd4: shutdown server with port 35971 successfully
2019-09-26 20:28:53,007 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e699df1d-2e45-4047-850a-4d440f1c7da7/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:28:53,022 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:28:53,025 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:28:53,027 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@296e281a{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:28:53,028 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59cda16e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:28:53,029 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28da7d11{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:28:53,030 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5fcfde70{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:28:53,031 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 20:28:53,031 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 20:28:53,031 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-26 20:28:53,031 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 20:28:53,032 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 20:28:53,032 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 20:28:53,032 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36315
2019-09-26 20:28:53,033 [IPC Server listener on 36315] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36315
2019-09-26 20:28:53,034 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:28:53,104 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 20:28:53,104 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 20:28:53,105 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 20:28:53,105 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45922
2019-09-26 20:28:53,107 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 20:28:53,107 [IPC Server listener on 45922] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45922
2019-09-26 20:28:53,107 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 20:28:53,107 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:28:53,107 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43828
2019-09-26 20:28:53,109 [IPC Server listener on 43828] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43828
2019-09-26 20:28:53,109 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 20:28:53,109 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:28:53,111 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7555b920{/,null,UNAVAILABLE}{/scm}
2019-09-26 20:28:53,111 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6db66836{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:28:53,112 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6622fc65{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 20:28:53,112 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@732f29af{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:28:53,113 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 20:28:53,113 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 20:28:53,114 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 20:28:53,114 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 20:28:53,207 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-26 20:28:53,214 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 20:28:53,214 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
