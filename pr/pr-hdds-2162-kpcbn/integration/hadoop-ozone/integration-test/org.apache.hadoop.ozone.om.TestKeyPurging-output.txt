2019-09-26 19:29:51,775 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:51,875 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:51,878 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:51,895 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @896ms
2019-09-26 19:29:52,017 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 19:29:52,018 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 19:29:52,018 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 19:29:52,019 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 19:29:52,019 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 19:29:52,019 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 19:29:52,036 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 19:29:52,037 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 19:29:52,038 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 19:29:52,331 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5e0e82ae
2019-09-26 19:29:52,333 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 19:29:52,403 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 19:29:52,405 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 19:29:52,407 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 19:29:52,478 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 19:29:52,491 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:52,561 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 19:29:52,563 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:52,711 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 19:29:53,044 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 19:29:53,071 [Socket Reader #1 for port 46516] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46516
2019-09-26 19:29:53,216 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 19:29:53,217 [Socket Reader #1 for port 44011] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44011
2019-09-26 19:29:53,231 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 19:29:53,232 [Socket Reader #1 for port 43888] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43888
2019-09-26 19:29:53,258 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 19:29:53,414 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 19:29:53,428 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 19:29:53,440 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 19:29:53,444 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 19:29:53,445 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 19:29:53,445 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 19:29:53,484 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43888
2019-09-26 19:29:53,546 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 19:29:53,559 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 19:29:53,559 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 19:29:53,784 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:43888
2019-09-26 19:29:53,785 [IPC Server listener on 43888] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43888: starting
2019-09-26 19:29:53,785 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 19:29:53,788 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:44011
2019-09-26 19:29:53,789 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:44011
2019-09-26 19:29:53,790 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 19:29:53,790 [IPC Server listener on 44011] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44011: starting
2019-09-26 19:29:53,792 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:46516
2019-09-26 19:29:53,792 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:46516
2019-09-26 19:29:53,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 19:29:53,793 [IPC Server listener on 46516] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46516: starting
2019-09-26 19:29:53,797 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37821
2019-09-26 19:29:53,798 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 19:29:53,857 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49872d67{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 19:29:53,858 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b2a01d4{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 19:29:53,898 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@59a67c3a{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-26 19:29:53,904 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3d6300e8{HTTP/1.1,[http/1.1]}{0.0.0.0:37821}
2019-09-26 19:29:53,905 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2906ms
2019-09-26 19:29:53,907 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 19:29:53,907 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 19:29:53,908 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:37821
2019-09-26 19:29:53,914 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@60094a13] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 19:29:53,917 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:54,023 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-26 19:29:54,023 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 19:29:54,025 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:54,026 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:54,817 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 19:29:54,826 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 19:29:54,826 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 19:29:54,826 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 19:29:54,826 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 19:29:54,827 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 19:29:54,827 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 19:29:54,827 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 19:29:54,827 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 19:29:54,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 19:29:54,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 19:29:54,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 19:29:54,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 19:29:54,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 19:29:54,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 19:29:54,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 19:29:54,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 19:29:54,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 19:29:54,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 19:29:54,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 19:29:54,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 19:29:54,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 19:29:54,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 19:29:54,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 19:29:54,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 19:29:54,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 19:29:55,267 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3256)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-26 19:29:55,307 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-26 19:29:55,346 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: omServiceIdDefault and Raft Peers: localhost:9872
2019-09-26 19:29:55,490 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3256)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-26 19:29:55,508 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 19:29:55,585 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 19:29:55,590 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9872 (custom)
2019-09-26 19:29:55,591 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-26 19:29:55,592 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 19:29:55,593 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3256)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-26 19:29:55,593 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 19:29:55,596 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 19:29:55,696 [KeyDeletingService#1] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3256)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-26 19:29:55,750 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis] (custom)
2019-09-26 19:29:55,756 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: addNew group-C5BA1605619E:[7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:localhost:9872] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@39c1fe0b[Not completed]
2019-09-26 19:29:55,758 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1215)) - OzoneManager Ratis server initialized at port 9872
2019-09-26 19:29:55,760 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-26 19:29:55,760 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-26 19:29:55,773 [pool-22-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: new RaftServerImpl for group-C5BA1605619E:[7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:localhost:9872] with OzoneManagerStateMachine:uninitialized
2019-09-26 19:29:55,776 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-26 19:29:55,776 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-26 19:29:55,776 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 19:29:55,776 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 19:29:55,777 [Socket Reader #1 for port 39043] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39043
2019-09-26 19:29:55,778 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 19:29:55,779 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 19:29:55,788 [pool-22-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: ConfigurationManager, init=-1: [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:localhost:9872], old=null, confs=<EMPTY_MAP>
2019-09-26 19:29:55,789 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis] (custom)
2019-09-26 19:29:55,800 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:39043
2019-09-26 19:29:55,800 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 19:29:55,801 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9 at port 9872
2019-09-26 19:29:55,804 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2019-09-26 19:29:55,834 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 25385@pr-hdds-2162-kpcbn-4093309294
2019-09-26 19:29:55,851 [pool-22-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2019-09-26 19:29:55,855 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 19:29:55,859 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 19:29:55,867 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 19:29:55,867 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 19:29:55,869 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-26 19:29:55,874 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 19:29:55,880 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2019-09-26 19:29:55,882 [pool-22-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 19:29:55,888 [pool-22-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 19:29:55,918 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-26 19:29:55,918 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-26 19:29:55,922 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-26 19:29:55,922 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 19:29:55,923 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-26 19:29:55,923 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 19:29:55,925 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 19:29:55,925 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 19:29:55,925 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 19:29:55,934 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-26 19:29:55,939 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 19:29:55,945 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 19:29:55,946 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-26 19:29:55,947 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = -1 (default)
2019-09-26 19:29:55,947 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 19:29:55,981 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: start as a follower, conf=-1: [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:localhost:9872], old=null
2019-09-26 19:29:55,983 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 19:29:55,985 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: start FollowerState
2019-09-26 19:29:55,987 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=7283a5c6-feb1-4e38-b5f1-c5072fb88fd9
2019-09-26 19:29:55,988 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: start RPC server
2019-09-26 19:29:56,002 [KeyDeletingService#0] ERROR ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:updateServerRole(598)) - Failed to retrieve RaftPeerRole. Setting cached role to UNRECOGNIZED and resetting leader info.
java.io.IOException: java.lang.NullPointerException
	at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54)
	at org.apache.ratis.server.impl.RaftServerImpl.waitForReply(RaftServerImpl.java:648)
	at org.apache.ratis.server.impl.RaftServerProxy.getGroupInfo(RaftServerProxy.java:424)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer.getGroupInfo(OzoneManagerRatisServer.java:621)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer.updateServerRole(OzoneManagerRatisServer.java:573)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer.isLeader(OzoneManagerRatisServer.java:548)
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3256)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.ratis.proto.RaftProtos$RoleInfoProto$Builder.setRole(RaftProtos.java:38013)
	at org.apache.ratis.server.impl.RaftServerImpl.getRoleInfoProto(RaftServerImpl.java:374)
	at org.apache.ratis.server.impl.RaftServerImpl.getGroupInfo(RaftServerImpl.java:366)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$getGroupInfoAsync$14(RaftServerProxy.java:430)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	... 1 more
2019-09-26 19:29:56,092 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
2019-09-26 19:29:56,104 [IPC Server listener on 39043] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39043: starting
2019-09-26 19:29:56,104 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 19:29:56,112 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 19:29:56,114 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 19:29:56,115 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 19:29:56,119 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 19:29:56,120 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 19:29:56,120 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 19:29:56,121 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 19:29:56,124 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39182
2019-09-26 19:29:56,124 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 19:29:56,127 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e8e0dec{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 19:29:56,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75fa1be3{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 19:29:56,136 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2b9f74d0{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-26 19:29:56,137 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65c86db8{HTTP/1.1,[http/1.1]}{0.0.0.0:39182}
2019-09-26 19:29:56,138 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5140ms
2019-09-26 19:29:56,138 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 19:29:56,139 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:39182
2019-09-26 19:29:56,286 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 19:29:56,334 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 19:29:56,365 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 19:29:56,367 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 19:29:56,370 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ed7821
2019-09-26 19:29:56,386 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ed7821
2019-09-26 19:29:56,438 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 19:29:56,438 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 19:29:56,439 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 19:29:56,439 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 19:29:56,439 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 19:29:56,439 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 19:29:56,440 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 19:29:56,441 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis] (custom)
2019-09-26 19:29:56,494 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 19:29:56,496 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 19:29:56,497 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 19:29:56,499 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 19:29:56,499 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 19:29:56,500 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 19:29:56,500 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 19:29:56,501 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33383
2019-09-26 19:29:56,501 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 19:29:56,508 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4bd51d3e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 19:29:56,509 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b74b35{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 19:29:56,541 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12704e15{/,file:///tmp/jetty-0.0.0.0-33383-hddsDatanode-_-any-1758102970496076516.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 19:29:56,543 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@512575e9{HTTP/1.1,[http/1.1]}{0.0.0.0:33383}
2019-09-26 19:29:56,543 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5545ms
2019-09-26 19:29:56,544 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 19:29:56,545 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33383
2019-09-26 19:29:56,548 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-26 19:29:56,551 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@522ad6e2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 19:29:56,658 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/meta/datanode.id
2019-09-26 19:29:57,092 [Thread-96] INFO  impl.FollowerState (FollowerState.java:run(106)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:group-C5BA1605619E changes to CANDIDATE, lastRpcTime:1107, electionTimeout:1106ms
2019-09-26 19:29:57,095 [Thread-96] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: shutdown FollowerState
2019-09-26 19:29:57,096 [Thread-96] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 19:29:57,100 [Thread-96] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: start LeaderElection
2019-09-26 19:29:57,115 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1: begin an election at term 1 for -1: [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:localhost:9872], old=null
2019-09-26 19:29:57,117 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: shutdown LeaderElection
2019-09-26 19:29:57,118 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 19:29:57,119 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: change Leader from null to 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9 at term 1 for becomeLeader, leader elected after 1263ms
2019-09-26 19:29:57,128 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 19:29:57,128 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 19:29:57,132 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 19:29:57,135 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 19:29:57,135 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 19:29:57,137 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 19:29:57,177 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: start LeaderState
2019-09-26 19:29:57,203 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 19:29:57,227 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: set configuration 0: [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9:localhost:9872], old=null at 0
2019-09-26 19:29:57,384 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2019-09-26 19:29:57,548 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-26 19:29:58,549 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-26 19:29:58,614 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 19:29:58,617 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 19:29:58,617 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis aa0868fd-2958-4343-a25b-5d04c4dd6ef0 at port 0
2019-09-26 19:29:58,624 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: start RPC server
2019-09-26 19:29:58,629 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: GrpcService started, listening on 0.0.0.0/0.0.0.0:44607
2019-09-26 19:29:58,630 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis aa0868fd-2958-4343-a25b-5d04c4dd6ef0 is started using port 44607
2019-09-26 19:29:58,633 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc aa0868fd-2958-4343-a25b-5d04c4dd6ef0 is started using port 33334
2019-09-26 19:29:59,549 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-26 19:30:00,550 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-26 19:30:00,591 [IPC Server handler 1 on 46516] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/aa0868fd-2958-4343-a25b-5d04c4dd6ef0
2019-09-26 19:30:00,592 [IPC Server handler 1 on 46516] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : aa0868fd-2958-4343-a25b-5d04c4dd6ef0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 19:30:00,597 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 19:30:00,597 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 19:30:00,600 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 19:30:01,077 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: addNew group-76CBE5C4DCA3:[aa0868fd-2958-4343-a25b-5d04c4dd6ef0:192.168.151.109:44607] returns group-76CBE5C4DCA3:java.util.concurrent.CompletableFuture@2e7c63b[Not completed]
2019-09-26 19:30:01,090 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: new RaftServerImpl for group-76CBE5C4DCA3:[aa0868fd-2958-4343-a25b-5d04c4dd6ef0:192.168.151.109:44607] with ContainerStateMachine:uninitialized
2019-09-26 19:30:01,091 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 19:30:01,091 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 19:30:01,091 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 19:30:01,092 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 19:30:01,092 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 19:30:01,092 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: ConfigurationManager, init=-1: [aa0868fd-2958-4343-a25b-5d04c4dd6ef0:192.168.151.109:44607], old=null, confs=<EMPTY_MAP>
2019-09-26 19:30:01,093 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis] (custom)
2019-09-26 19:30:01,093 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis/b8c35162-5d62-4bf4-b0fb-76cbe5c4dca3 does not exist. Creating ...
2019-09-26 19:30:01,097 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis/b8c35162-5d62-4bf4-b0fb-76cbe5c4dca3/in_use.lock acquired by nodename 25385@pr-hdds-2162-kpcbn-4093309294
2019-09-26 19:30:01,103 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis/b8c35162-5d62-4bf4-b0fb-76cbe5c4dca3 has been successfully formatted.
2019-09-26 19:30:01,104 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-76CBE5C4DCA3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 19:30:01,104 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 19:30:01,105 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 19:30:01,105 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 19:30:01,105 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 19:30:01,105 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 19:30:01,105 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 19:30:01,106 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis/b8c35162-5d62-4bf4-b0fb-76cbe5c4dca3
2019-09-26 19:30:01,131 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 19:30:01,131 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 19:30:01,132 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 19:30:01,132 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 19:30:01,132 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 19:30:01,132 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 19:30:01,132 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 19:30:01,133 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 19:30:01,133 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 19:30:01,133 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 19:30:01,134 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 19:30:01,134 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 19:30:01,134 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 19:30:01,134 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 19:30:01,135 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 19:30:01,141 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: start as a follower, conf=-1: [aa0868fd-2958-4343-a25b-5d04c4dd6ef0:192.168.151.109:44607], old=null
2019-09-26 19:30:01,142 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 19:30:01,142 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: start FollowerState
2019-09-26 19:30:01,142 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-76CBE5C4DCA3,id=aa0868fd-2958-4343-a25b-5d04c4dd6ef0
2019-09-26 19:30:01,197 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b8c35162-5d62-4bf4-b0fb-76cbe5c4dca3, Nodes: aa0868fd-2958-4343-a25b-5d04c4dd6ef0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 19:30:01,551 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-09-26 19:30:02,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:03,617 [Thread-173] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-26 19:30:03,620 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 2 milliseconds for processing 0 containers.
2019-09-26 19:30:03,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:04,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:05,766 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:06,229 [Thread-175] INFO  impl.FollowerState (FollowerState.java:run(106)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0:group-76CBE5C4DCA3 changes to CANDIDATE, lastRpcTime:5087, electionTimeout:5087ms
2019-09-26 19:30:06,231 [Thread-175] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: shutdown FollowerState
2019-09-26 19:30:06,231 [Thread-175] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 19:30:06,231 [Thread-175] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: start LeaderElection
2019-09-26 19:30:06,255 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2: begin an election at term 1 for -1: [aa0868fd-2958-4343-a25b-5d04c4dd6ef0:192.168.151.109:44607], old=null
2019-09-26 19:30:06,256 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: shutdown LeaderElection
2019-09-26 19:30:06,256 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 19:30:06,257 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: change Leader from null to aa0868fd-2958-4343-a25b-5d04c4dd6ef0 at term 1 for becomeLeader, leader elected after 5152ms
2019-09-26 19:30:06,257 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 19:30:06,257 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 19:30:06,257 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 19:30:06,258 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 19:30:06,258 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 19:30:06,258 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 19:30:06,263 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: start LeaderState
2019-09-26 19:30:06,264 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 19:30:06,264 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: set configuration 0: [aa0868fd-2958-4343-a25b-5d04c4dd6ef0:192.168.151.109:44607], old=null at 0
2019-09-26 19:30:06,319 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/ratis/b8c35162-5d62-4bf4-b0fb-76cbe5c4dca3/current/log_inprogress_0
2019-09-26 19:30:06,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:07,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:08,770 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:09,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:10,772 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:11,774 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:12,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:13,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:14,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:15,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:16,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:17,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:18,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:19,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:20,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:21,791 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:21,792 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 19:30:22,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:23,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:24,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:25,798 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:26,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:27,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:28,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:29,803 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:30,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:31,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:31,808 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 19:30:32,809 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:33,811 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:34,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:35,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:36,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:37,816 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:38,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:39,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:40,819 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:41,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:41,823 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 19:30:42,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:43,827 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:44,829 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:45,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:46,832 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:47,833 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:48,835 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:49,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:50,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:51,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:51,841 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 19:30:52,842 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:53,843 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:54,845 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:55,846 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:56,848 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:57,849 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:58,850 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:30:59,852 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:00,853 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:01,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:01,855 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 19:31:02,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:03,858 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:04,859 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:05,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:06,862 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:07,863 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:08,864 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:09,865 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:10,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:11,867 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:11,869 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 19:31:12,870 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:13,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:14,872 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:15,873 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:16,875 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:17,876 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:18,878 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:19,879 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:20,879 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:21,881 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:21,882 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 19:31:22,884 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:23,885 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:24,886 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:25,887 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:26,888 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:27,890 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:28,891 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:29,892 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:30,893 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:31,895 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:31,896 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 19:31:32,897 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:33,898 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:34,899 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:35,900 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:36,902 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:37,903 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:38,904 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:39,906 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:40,907 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:41,908 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:41,910 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 19:31:42,911 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:43,912 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:44,913 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:45,914 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:46,916 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:47,917 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:48,918 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:49,919 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:50,920 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:51,921 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 19:31:51,923 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 19:31:51,925 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:203)
	at org.apache.hadoop.ozone.om.TestKeyPurging.setup(TestKeyPurging.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 53 more
2019-09-26 19:31:51,927 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 19:31:51,928 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 19:31:51,928 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 19:31:51,928 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39043
2019-09-26 19:31:51,938 [IPC Server listener on 39043] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39043
2019-09-26 19:31:51,942 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 19:31:51,944 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: close
2019-09-26 19:31:51,947 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: shutdown
2019-09-26 19:31:51,947 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=7283a5c6-feb1-4e38-b5f1-c5072fb88fd9
2019-09-26 19:31:51,948 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: shutdown LeaderState
2019-09-26 19:31:51,949 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9-PendingRequests: sendNotLeaderResponses
2019-09-26 19:31:51,953 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 0
2019-09-26 19:31:51,953 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-26 19:31:51,963 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex -1
2019-09-26 19:31:51,963 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-26 19:31:51,964 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex -1
2019-09-26 19:31:51,965 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E: closes. applyIndex: 0
2019-09-26 19:31:51,967 [7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 19:31:51,969 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9@group-C5BA1605619E-SegmentedRaftLogWorker close()
2019-09-26 19:31:51,971 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: shutdown server with port 9872 now
2019-09-26 19:31:51,974 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 7283a5c6-feb1-4e38-b5f1-c5072fb88fd9: shutdown server with port 9872 successfully
2019-09-26 19:31:51,974 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 19:31:51,975 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 19:31:51,976 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 19:31:51,981 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2b9f74d0{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 19:31:51,987 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65c86db8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 19:31:51,988 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75fa1be3{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 19:31:51,988 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e8e0dec{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 19:31:51,993 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 19:31:52,016 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 19:31:56,561 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 19:31:56,562 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: close
2019-09-26 19:31:56,563 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: shutdown
2019-09-26 19:31:56,564 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-76CBE5C4DCA3,id=aa0868fd-2958-4343-a25b-5d04c4dd6ef0
2019-09-26 19:31:56,564 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: shutdown LeaderState
2019-09-26 19:31:56,564 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0-PendingRequests: sendNotLeaderResponses
2019-09-26 19:31:56,565 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-StateMachineUpdater: set stopIndex = 0
2019-09-26 19:31:56,566 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3: closes. applyIndex: 0
2019-09-26 19:31:56,567 [aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 19:31:56,568 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0@group-76CBE5C4DCA3-SegmentedRaftLogWorker close()
2019-09-26 19:31:56,570 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: shutdown server with port 44607 now
2019-09-26 19:31:56,572 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - aa0868fd-2958-4343-a25b-5d04c4dd6ef0: shutdown server with port 44607 successfully
2019-09-26 19:31:56,587 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e565222b-9b0b-435f-80a2-6256c03641f8/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 19:31:56,607 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 19:31:56,609 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 19:31:56,611 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12704e15{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 19:31:56,611 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@512575e9{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 19:31:56,612 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b74b35{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 19:31:56,612 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4bd51d3e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 19:31:56,613 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 19:31:56,613 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 19:31:56,613 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-26 19:31:56,614 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 19:31:56,614 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 19:31:56,614 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 19:31:56,614 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46516
2019-09-26 19:31:56,615 [IPC Server listener on 46516] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46516
2019-09-26 19:31:56,616 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 19:31:56,677 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 19:31:56,678 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 19:31:56,678 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 19:31:56,678 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44011
2019-09-26 19:31:56,681 [IPC Server listener on 44011] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44011
2019-09-26 19:31:56,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 19:31:56,681 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 19:31:56,681 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 19:31:56,681 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43888
2019-09-26 19:31:56,683 [IPC Server listener on 43888] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43888
2019-09-26 19:31:56,683 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 19:31:56,683 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 19:31:56,685 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@59a67c3a{/,null,UNAVAILABLE}{/scm}
2019-09-26 19:31:56,685 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3d6300e8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 19:31:56,686 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b2a01d4{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 19:31:56,686 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49872d67{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 19:31:56,687 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 19:31:56,687 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 19:31:56,688 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 19:31:56,688 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 19:31:56,694 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-09-26 19:31:56,696 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 19:31:56,697 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
