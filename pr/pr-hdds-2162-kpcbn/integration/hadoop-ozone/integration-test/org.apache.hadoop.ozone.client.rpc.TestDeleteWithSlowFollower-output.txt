2019-09-26 20:12:49,582 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:49,689 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:49,692 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:49,711 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @868ms
2019-09-26 20:12:49,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 20:12:49,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 20:12:49,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 20:12:49,833 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 20:12:49,833 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 20:12:49,833 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 20:12:49,851 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 20:12:49,851 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 20:12:49,853 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 20:12:50,137 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@55141def
2019-09-26 20:12:50,139 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 20:12:50,211 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 20:12:50,213 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 20:12:50,215 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 20:12:50,287 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 20:12:50,302 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:50,360 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 20:12:50,362 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:50,479 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 20:12:50,826 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:12:50,853 [Socket Reader #1 for port 41439] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41439
2019-09-26 20:12:51,005 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:12:51,006 [Socket Reader #1 for port 42591] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42591
2019-09-26 20:12:51,019 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:12:51,020 [Socket Reader #1 for port 43296] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43296
2019-09-26 20:12:51,041 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 20:12:51,177 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:12:51,184 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:12:51,192 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:12:51,194 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 20:12:51,195 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:12:51,195 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:12:51,223 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43296
2019-09-26 20:12:51,285 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 20:12:51,297 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 20:12:51,297 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 20:12:51,531 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:43296
2019-09-26 20:12:51,532 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:12:51,532 [IPC Server listener on 43296] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43296: starting
2019-09-26 20:12:51,535 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42591
2019-09-26 20:12:51,537 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:42591
2019-09-26 20:12:51,537 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:12:51,537 [IPC Server listener on 42591] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42591: starting
2019-09-26 20:12:51,540 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41439
2019-09-26 20:12:51,540 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:41439
2019-09-26 20:12:51,540 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:12:51,540 [IPC Server listener on 41439] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41439: starting
2019-09-26 20:12:51,545 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33858
2019-09-26 20:12:51,546 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:12:51,586 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:12:51,587 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 20:12:51,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5398edd0{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-26 20:12:51,629 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:33858}
2019-09-26 20:12:51,630 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2787ms
2019-09-26 20:12:51,632 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 20:12:51,632 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 20:12:51,634 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:33858
2019-09-26 20:12:51,641 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1095f122] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:12:51,646 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:51,765 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-26 20:12:51,765 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 20:12:51,767 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:51,767 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:52,530 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:12:52,538 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 20:12:52,538 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 20:12:52,539 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 20:12:52,539 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 20:12:52,539 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 20:12:52,539 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 20:12:52,540 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 20:12:52,540 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 20:12:52,540 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 20:12:52,541 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 20:12:52,541 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 20:12:52,541 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 20:12:52,541 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 20:12:52,542 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 20:12:52,542 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 20:12:52,542 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 20:12:52,542 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 20:12:52,543 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 20:12:52,543 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 20:12:52,543 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 20:12:52,543 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 20:12:52,544 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 20:12:52,544 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 20:12:52,544 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 20:12:52,544 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 20:12:53,157 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:12:53,159 [Socket Reader #1 for port 41603] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41603
2019-09-26 20:12:53,195 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:41603
2019-09-26 20:12:53,196 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 20:12:53,198 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:12:53,198 [IPC Server listener on 41603] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41603: starting
2019-09-26 20:12:53,205 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 20:12:53,207 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:12:53,208 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:12:53,211 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:12:53,212 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 20:12:53,213 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:12:53,213 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:12:53,216 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41669
2019-09-26 20:12:53,216 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:12:53,219 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:12:53,220 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 20:12:53,226 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@529cfee5{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-26 20:12:53,227 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:41669}
2019-09-26 20:12:53,229 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4386ms
2019-09-26 20:12:53,229 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:12:53,230 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:41669
2019-09-26 20:12:53,597 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:12:53,651 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:12:53,690 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:12:53,692 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 20:12:53,695 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-26 20:12:53,715 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-26 20:12:53,824 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:12:53,892 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:12:53,897 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:12:53,898 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:12:53,899 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:53,900 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:12:53,901 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:12:54,072 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis] (custom)
2019-09-26 20:12:54,127 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:12:54,129 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:12:54,130 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:12:54,133 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:12:54,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:12:54,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:12:54,135 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:12:54,136 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43226
2019-09-26 20:12:54,136 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:12:54,139 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:12:54,140 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:12:54,183 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7aac8884{/,file:///tmp/jetty-0.0.0.0-43226-hddsDatanode-_-any-783231930223082071.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:12:54,184 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:43226}
2019-09-26 20:12:54,185 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5342ms
2019-09-26 20:12:54,185 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:12:54,186 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43226
2019-09-26 20:12:54,187 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:12:54,190 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:12:54,192 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fcc5ef4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:12:54,199 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:12:54,199 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 20:12:54,200 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@117525fe
2019-09-26 20:12:54,200 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@117525fe
2019-09-26 20:12:54,220 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:12:54,220 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:12:54,221 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:12:54,221 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:12:54,221 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:54,222 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:12:54,222 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:12:54,223 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis] (custom)
2019-09-26 20:12:54,225 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:12:54,227 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:12:54,228 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:12:54,230 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:12:54,230 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:12:54,231 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:12:54,231 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:12:54,232 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43261
2019-09-26 20:12:54,232 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:12:54,235 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77774571{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:12:54,236 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cd64ee8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:12:54,268 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e519ad3{/,file:///tmp/jetty-0.0.0.0-43261-hddsDatanode-_-any-4285417367080557351.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:12:54,270 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bc44ce8{HTTP/1.1,[http/1.1]}{0.0.0.0:43261}
2019-09-26 20:12:54,270 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5427ms
2019-09-26 20:12:54,271 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:12:54,272 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43261
2019-09-26 20:12:54,272 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:12:54,275 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@11018e79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:12:54,275 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:12:54,283 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:12:54,284 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 20:12:54,284 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-26 20:12:54,284 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-26 20:12:54,297 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:12:54,298 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:12:54,298 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:12:54,298 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:12:54,298 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:54,298 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:12:54,299 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:12:54,299 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis] (custom)
2019-09-26 20:12:54,301 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:12:54,302 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:12:54,303 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:12:54,304 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:12:54,305 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:12:54,305 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:12:54,305 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:12:54,306 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43407
2019-09-26 20:12:54,306 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:12:54,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:12:54,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:12:54,320 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/meta/datanode.id
2019-09-26 20:12:54,324 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/meta/datanode.id
2019-09-26 20:12:54,341 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5dd903be{/,file:///tmp/jetty-0.0.0.0-43407-hddsDatanode-_-any-3389904893340521907.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:12:54,342 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:43407}
2019-09-26 20:12:54,342 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5499ms
2019-09-26 20:12:54,343 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:12:54,343 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43407
2019-09-26 20:12:54,345 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:12:54,346 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a877f84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:12:54,348 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/meta/datanode.id
2019-09-26 20:12:55,345 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:12:56,260 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:12:56,263 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:12:56,263 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 at port 0
2019-09-26 20:12:56,291 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start RPC server
2019-09-26 20:12:56,295 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:12:56,301 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:12:56,301 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis f6965e03-a7de-48a1-a4fe-2910b6888944 at port 0
2019-09-26 20:12:56,311 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - f6965e03-a7de-48a1-a4fe-2910b6888944: start RPC server
2019-09-26 20:12:56,346 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:12:56,361 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:12:56,363 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:12:56,363 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 8ce5d084-8e1d-4410-9ede-27b1c8ae4966 at port 0
2019-09-26 20:12:56,370 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: start RPC server
2019-09-26 20:12:56,439 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: GrpcService started, listening on 0.0.0.0/0.0.0.0:36717
2019-09-26 20:12:56,439 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: GrpcService started, listening on 0.0.0.0/0.0.0.0:40462
2019-09-26 20:12:56,439 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - f6965e03-a7de-48a1-a4fe-2910b6888944: GrpcService started, listening on 0.0.0.0/0.0.0.0:36066
2019-09-26 20:12:56,440 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 is started using port 40462
2019-09-26 20:12:56,440 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 8ce5d084-8e1d-4410-9ede-27b1c8ae4966 is started using port 36717
2019-09-26 20:12:56,440 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis f6965e03-a7de-48a1-a4fe-2910b6888944 is started using port 36066
2019-09-26 20:12:56,446 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc f6965e03-a7de-48a1-a4fe-2910b6888944 is started using port 38065
2019-09-26 20:12:56,446 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 8ce5d084-8e1d-4410-9ede-27b1c8ae4966 is started using port 45651
2019-09-26 20:12:56,446 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 is started using port 40543
2019-09-26 20:12:57,346 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:12:58,230 [IPC Server handler 0 on 41439] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:12:58,230 [IPC Server handler 0 on 41439] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 9a95b9fa-dff8-42b6-9903-a5daabde5ab3{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:12:58,235 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 20:12:58,236 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 20:12:58,236 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 20:12:58,278 [IPC Server handler 1 on 41439] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f6965e03-a7de-48a1-a4fe-2910b6888944
2019-09-26 20:12:58,278 [IPC Server handler 1 on 41439] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : f6965e03-a7de-48a1-a4fe-2910b6888944{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:12:58,347 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-26 20:12:58,349 [IPC Server handler 2 on 41439] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/8ce5d084-8e1d-4410-9ede-27b1c8ae4966
2019-09-26 20:12:58,349 [IPC Server handler 2 on 41439] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 8ce5d084-8e1d-4410-9ede-27b1c8ae4966{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:12:58,773 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: addNew group-6A300CA2834F:[9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462] returns group-6A300CA2834F:java.util.concurrent.CompletableFuture@3d091b5c[Not completed]
2019-09-26 20:12:58,790 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: new RaftServerImpl for group-6A300CA2834F:[9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462] with ContainerStateMachine:uninitialized
2019-09-26 20:12:58,793 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:12:58,794 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:12:58,794 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 20:12:58,795 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:12:58,796 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:12:58,805 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: ConfigurationManager, init=-1: [9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462], old=null, confs=<EMPTY_MAP>
2019-09-26 20:12:58,805 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis] (custom)
2019-09-26 20:12:58,813 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/5ea41c3c-76ce-49d6-93c9-6a300ca2834f does not exist. Creating ...
2019-09-26 20:12:58,829 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/5ea41c3c-76ce-49d6-93c9-6a300ca2834f/in_use.lock acquired by nodename 25347@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:12:58,844 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/5ea41c3c-76ce-49d6-93c9-6a300ca2834f has been successfully formatted.
2019-09-26 20:12:58,847 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6A300CA2834F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:12:58,847 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 20:12:58,849 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:12:58,854 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:12:58,855 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:58,857 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:58,861 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:12:58,866 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/5ea41c3c-76ce-49d6-93c9-6a300ca2834f
2019-09-26 20:12:58,867 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 20:12:58,874 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 20:12:58,900 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:12:58,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:12:58,904 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:58,904 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:12:58,905 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:12:58,905 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:12:58,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:12:58,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:12:58,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:12:58,915 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:12:58,919 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:12:58,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:12:58,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:12:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:12:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:12:58,968 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: start as a follower, conf=-1: [9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462], old=null
2019-09-26 20:12:58,969 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:12:58,971 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start FollowerState
2019-09-26 20:12:58,973 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A300CA2834F,id=9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:12:59,037 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5ea41c3c-76ce-49d6-93c9-6a300ca2834f, Nodes: 9a95b9fa-dff8-42b6-9903-a5daabde5ab3{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:12:59,059 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f6965e03-a7de-48a1-a4fe-2910b6888944: addNew group-13C459E5A7F7:[f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] returns group-13C459E5A7F7:java.util.concurrent.CompletableFuture@47cb058[Not completed]
2019-09-26 20:12:59,097 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f6965e03-a7de-48a1-a4fe-2910b6888944: new RaftServerImpl for group-13C459E5A7F7:[f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] with ContainerStateMachine:uninitialized
2019-09-26 20:12:59,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:12:59,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:12:59,100 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 20:12:59,100 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:12:59,100 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:12:59,100 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: ConfigurationManager, init=-1: [f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null, confs=<EMPTY_MAP>
2019-09-26 20:12:59,100 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis] (custom)
2019-09-26 20:12:59,101 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/bab8df74-13fe-41af-9975-13c459e5a7f7 does not exist. Creating ...
2019-09-26 20:12:59,136 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/bab8df74-13fe-41af-9975-13c459e5a7f7/in_use.lock acquired by nodename 25347@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:12:59,150 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/bab8df74-13fe-41af-9975-13c459e5a7f7 has been successfully formatted.
2019-09-26 20:12:59,152 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-13C459E5A7F7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:12:59,153 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 20:12:59,153 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:12:59,153 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:12:59,154 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:59,154 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,154 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:12:59,154 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/bab8df74-13fe-41af-9975-13c459e5a7f7
2019-09-26 20:12:59,161 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:12:59,162 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:12:59,162 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,162 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:12:59,162 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:12:59,162 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:12:59,163 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:12:59,163 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:12:59,163 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:12:59,163 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:12:59,164 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:12:59,164 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:12:59,164 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:12:59,165 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:12:59,165 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:12:59,170 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: start as a follower, conf=-1: [f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:12:59,170 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:12:59,170 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f6965e03-a7de-48a1-a4fe-2910b6888944: start FollowerState
2019-09-26 20:12:59,172 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13C459E5A7F7,id=f6965e03-a7de-48a1-a4fe-2910b6888944
2019-09-26 20:12:59,185 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bab8df74-13fe-41af-9975-13c459e5a7f7, Nodes: f6965e03-a7de-48a1-a4fe-2910b6888944{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:12:59,204 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: addNew group-0B31E870CE92:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717] returns group-0B31E870CE92:java.util.concurrent.CompletableFuture@3e467fa[Not completed]
2019-09-26 20:12:59,223 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: new RaftServerImpl for group-0B31E870CE92:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717] with ContainerStateMachine:uninitialized
2019-09-26 20:12:59,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:12:59,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:12:59,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 20:12:59,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:12:59,224 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:12:59,225 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: ConfigurationManager, init=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717], old=null, confs=<EMPTY_MAP>
2019-09-26 20:12:59,225 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis] (custom)
2019-09-26 20:12:59,225 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/7efda3a4-bbda-43d6-9e98-0b31e870ce92 does not exist. Creating ...
2019-09-26 20:12:59,248 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/7efda3a4-bbda-43d6-9e98-0b31e870ce92/in_use.lock acquired by nodename 25347@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:12:59,261 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/7efda3a4-bbda-43d6-9e98-0b31e870ce92 has been successfully formatted.
2019-09-26 20:12:59,261 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-0B31E870CE92: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:12:59,261 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 20:12:59,262 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:12:59,262 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:12:59,262 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:59,262 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,262 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:12:59,263 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/7efda3a4-bbda-43d6-9e98-0b31e870ce92
2019-09-26 20:12:59,287 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:12:59,287 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:12:59,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:12:59,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:12:59,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:12:59,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:12:59,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:12:59,289 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:12:59,289 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:12:59,289 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:12:59,290 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:12:59,290 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:12:59,290 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:12:59,290 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:12:59,294 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: start as a follower, conf=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717], old=null
2019-09-26 20:12:59,294 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:12:59,294 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: start FollowerState
2019-09-26 20:12:59,294 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B31E870CE92,id=8ce5d084-8e1d-4410-9ede-27b1c8ae4966
2019-09-26 20:12:59,304 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7efda3a4-bbda-43d6-9e98-0b31e870ce92, Nodes: 8ce5d084-8e1d-4410-9ede-27b1c8ae4966{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:12:59,332 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: addNew group-430E0D5E4BE0:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] returns group-430E0D5E4BE0:java.util.concurrent.CompletableFuture@27dbe818[Not completed]
2019-09-26 20:12:59,332 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: addNew group-430E0D5E4BE0:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] returns group-430E0D5E4BE0:java.util.concurrent.CompletableFuture@3ae64099[Not completed]
2019-09-26 20:12:59,332 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f6965e03-a7de-48a1-a4fe-2910b6888944: addNew group-430E0D5E4BE0:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] returns group-430E0D5E4BE0:java.util.concurrent.CompletableFuture@4418621b[Not completed]
2019-09-26 20:12:59,334 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: new RaftServerImpl for group-430E0D5E4BE0:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] with ContainerStateMachine:uninitialized
2019-09-26 20:12:59,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:12:59,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:12:59,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 20:12:59,334 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:12:59,335 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:12:59,335 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f6965e03-a7de-48a1-a4fe-2910b6888944: new RaftServerImpl for group-430E0D5E4BE0:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] with ContainerStateMachine:uninitialized
2019-09-26 20:12:59,335 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: ConfigurationManager, init=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null, confs=<EMPTY_MAP>
2019-09-26 20:12:59,335 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:12:59,335 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis] (custom)
2019-09-26 20:12:59,335 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:12:59,335 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 20:12:59,335 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:12:59,336 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: new RaftServerImpl for group-430E0D5E4BE0:[8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066] with ContainerStateMachine:uninitialized
2019-09-26 20:12:59,336 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:12:59,336 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0 does not exist. Creating ...
2019-09-26 20:12:59,336 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: ConfigurationManager, init=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null, confs=<EMPTY_MAP>
2019-09-26 20:12:59,336 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:12:59,336 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis] (custom)
2019-09-26 20:12:59,336 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:12:59,336 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-26 20:12:59,337 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0 does not exist. Creating ...
2019-09-26 20:12:59,337 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:12:59,337 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:12:59,337 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: ConfigurationManager, init=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null, confs=<EMPTY_MAP>
2019-09-26 20:12:59,337 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis] (custom)
2019-09-26 20:12:59,337 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0 does not exist. Creating ...
2019-09-26 20:12:59,348 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-26 20:12:59,361 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0/in_use.lock acquired by nodename 25347@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:12:59,361 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0/in_use.lock acquired by nodename 25347@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:12:59,361 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0/in_use.lock acquired by nodename 25347@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:12:59,387 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0 has been successfully formatted.
2019-09-26 20:12:59,387 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0 has been successfully formatted.
2019-09-26 20:12:59,387 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0 has been successfully formatted.
2019-09-26 20:12:59,387 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-430E0D5E4BE0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:12:59,388 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-430E0D5E4BE0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:12:59,388 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 20:12:59,388 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-430E0D5E4BE0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:12:59,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 20:12:59,388 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:12:59,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:12:59,388 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-26 20:12:59,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:12:59,388 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:12:59,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:59,389 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:12:59,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,389 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:59,390 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:12:59,390 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:12:59,390 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0
2019-09-26 20:12:59,390 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,390 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:12:59,390 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:12:59,391 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,390 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:12:59,391 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:12:59,391 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0
2019-09-26 20:12:59,391 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0
2019-09-26 20:12:59,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:12:59,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:12:59,391 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:12:59,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:12:59,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:12:59,393 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:12:59,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:12:59,393 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:12:59,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:12:59,393 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:12:59,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:12:59,394 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:12:59,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:12:59,394 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:12:59,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:12:59,394 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:12:59,394 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:12:59,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:12:59,395 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:12:59,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:12:59,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:12:59,395 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:12:59,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:12:59,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:12:59,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:12:59,396 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:12:59,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:12:59,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:12:59,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:12:59,397 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:12:59,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:12:59,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:12:59,397 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:12:59,397 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:12:59,397 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:12:59,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:12:59,397 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:12:59,398 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:12:59,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:12:59,398 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:12:59,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:12:59,398 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:12:59,404 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: start as a follower, conf=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:12:59,404 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:12:59,404 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: start as a follower, conf=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:12:59,404 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: start as a follower, conf=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:12:59,404 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: start FollowerState
2019-09-26 20:12:59,404 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:12:59,404 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:12:59,404 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f6965e03-a7de-48a1-a4fe-2910b6888944: start FollowerState
2019-09-26 20:12:59,404 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-430E0D5E4BE0,id=8ce5d084-8e1d-4410-9ede-27b1c8ae4966
2019-09-26 20:12:59,404 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start FollowerState
2019-09-26 20:12:59,405 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-430E0D5E4BE0,id=f6965e03-a7de-48a1-a4fe-2910b6888944
2019-09-26 20:12:59,405 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-430E0D5E4BE0,id=9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:12:59,421 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 296ea32f-459d-4d2c-9117-430e0d5e4be0, Nodes: 9a95b9fa-dff8-42b6-9903-a5daabde5ab3{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}f6965e03-a7de-48a1-a4fe-2910b6888944{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}8ce5d084-8e1d-4410-9ede-27b1c8ae4966{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-26 20:13:00,549 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:01,242 [Thread-181] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-26 20:13:01,245 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-26 20:13:01,550 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:02,557 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:03,559 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:04,084 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:group-6A300CA2834F changes to CANDIDATE, lastRpcTime:5114, electionTimeout:5113ms
2019-09-26 20:13:04,087 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown FollowerState
2019-09-26 20:13:04,088 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:13:04,095 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start LeaderElection
2019-09-26 20:13:04,113 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1: begin an election at term 1 for -1: [9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462], old=null
2019-09-26 20:13:04,115 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown LeaderElection
2019-09-26 20:13:04,115 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:13:04,115 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: change Leader from null to 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 at term 1 for becomeLeader, leader elected after 5268ms
2019-09-26 20:13:04,122 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:13:04,123 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:13:04,126 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:13:04,129 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:13:04,129 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:13:04,130 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:13:04,145 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start LeaderState
2019-09-26 20:13:04,169 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:13:04,183 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: set configuration 0: [9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462], old=null at 0
2019-09-26 20:13:04,227 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(106)) - f6965e03-a7de-48a1-a4fe-2910b6888944:group-13C459E5A7F7 changes to CANDIDATE, lastRpcTime:5056, electionTimeout:5055ms
2019-09-26 20:13:04,230 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown FollowerState
2019-09-26 20:13:04,230 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:13:04,231 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f6965e03-a7de-48a1-a4fe-2910b6888944: start LeaderElection
2019-09-26 20:13:04,247 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2: begin an election at term 1 for -1: [f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:13:04,247 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown LeaderElection
2019-09-26 20:13:04,248 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:13:04,248 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: change Leader from null to f6965e03-a7de-48a1-a4fe-2910b6888944 at term 1 for becomeLeader, leader elected after 5094ms
2019-09-26 20:13:04,248 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:13:04,248 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:13:04,249 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:13:04,249 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:13:04,249 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:13:04,250 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:13:04,257 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f6965e03-a7de-48a1-a4fe-2910b6888944: start LeaderState
2019-09-26 20:13:04,257 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:13:04,258 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: set configuration 0: [f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null at 0
2019-09-26 20:13:04,313 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966:group-0B31E870CE92 changes to CANDIDATE, lastRpcTime:5019, electionTimeout:5019ms
2019-09-26 20:13:04,314 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown FollowerState
2019-09-26 20:13:04,314 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:13:04,314 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: start LeaderElection
2019-09-26 20:13:04,331 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3: begin an election at term 1 for -1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717], old=null
2019-09-26 20:13:04,332 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown LeaderElection
2019-09-26 20:13:04,332 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:13:04,332 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: change Leader from null to 8ce5d084-8e1d-4410-9ede-27b1c8ae4966 at term 1 for becomeLeader, leader elected after 5070ms
2019-09-26 20:13:04,332 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:13:04,333 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:13:04,333 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:13:04,333 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:13:04,333 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:13:04,333 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:13:04,337 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: start LeaderState
2019-09-26 20:13:04,338 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:13:04,338 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: set configuration 0: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717], old=null at 0
2019-09-26 20:13:04,401 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/bab8df74-13fe-41af-9975-13c459e5a7f7/current/log_inprogress_0
2019-09-26 20:13:04,401 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/7efda3a4-bbda-43d6-9e98-0b31e870ce92/current/log_inprogress_0
2019-09-26 20:13:04,401 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/5ea41c3c-76ce-49d6-93c9-6a300ca2834f/current/log_inprogress_0
2019-09-26 20:13:04,488 [Thread-199] INFO  impl.FollowerState (FollowerState.java:run(106)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:group-430E0D5E4BE0 changes to CANDIDATE, lastRpcTime:5083, electionTimeout:5083ms
2019-09-26 20:13:04,488 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown FollowerState
2019-09-26 20:13:04,489 [Thread-199] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:13:04,489 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start LeaderElection
2019-09-26 20:13:04,514 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4: begin an election at term 1 for -1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:13:04,558 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:13:04,558 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:13:04,559 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown FollowerState
2019-09-26 20:13:04,559 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown FollowerState
2019-09-26 20:13:04,559 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: start FollowerState
2019-09-26 20:13:04,559 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f6965e03-a7de-48a1-a4fe-2910b6888944: start FollowerState
2019-09-26 20:13:04,559 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(115)) - f6965e03-a7de-48a1-a4fe-2910b6888944: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:13:04,559 [Thread-197] INFO  impl.FollowerState (FollowerState.java:run(115)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:13:04,561 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:04,593 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4: Election PASSED; received 1 response(s) [9a95b9fa-dff8-42b6-9903-a5daabde5ab3<-f6965e03-a7de-48a1-a4fe-2910b6888944#0:OK-t1] and 0 exception(s); 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:t1, leader=null, voted=9a95b9fa-dff8-42b6-9903-a5daabde5ab3, raftlog=9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null
2019-09-26 20:13:04,593 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown LeaderElection
2019-09-26 20:13:04,593 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:13:04,594 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: change Leader from null to 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 at term 1 for becomeLeader, leader elected after 5206ms
2019-09-26 20:13:04,595 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:13:04,595 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:13:04,596 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:13:04,596 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:13:04,596 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:13:04,596 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:13:04,601 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 20:13:04,601 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:13:04,602 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 20:13:04,605 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 20:13:04,609 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:13:04,609 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:13:04,610 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 20:13:04,610 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:13:04,611 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 20:13:04,611 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 20:13:04,611 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:13:04,611 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:13:04,614 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: start LeaderState
2019-09-26 20:13:04,615 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:13:04,615 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: set configuration 0: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null at 0
2019-09-26 20:13:04,666 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: change Leader from null to 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 at term 1 for appendEntries, leader elected after 5277ms
2019-09-26 20:13:04,667 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0/current/log_inprogress_0
2019-09-26 20:13:04,666 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: change Leader from null to 9a95b9fa-dff8-42b6-9903-a5daabde5ab3 at term 1 for appendEntries, leader elected after 5278ms
2019-09-26 20:13:04,692 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: set configuration 0: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null at 0
2019-09-26 20:13:04,692 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: set configuration 0: [8ce5d084-8e1d-4410-9ede-27b1c8ae4966:192.168.151.109:36717, 9a95b9fa-dff8-42b6-9903-a5daabde5ab3:192.168.151.109:40462, f6965e03-a7de-48a1-a4fe-2910b6888944:192.168.151.109:36066], old=null at 0
2019-09-26 20:13:04,692 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:13:04,692 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:13:04,732 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0/current/log_inprogress_0
2019-09-26 20:13:04,732 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/ratis/296ea32f-459d-4d2c-9117-430e0d5e4be0/current/log_inprogress_0
2019-09-26 20:13:05,563 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:06,565 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:07,566 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:08,567 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:09,569 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:10,575 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:11,576 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:12,577 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:13,579 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:14,580 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:15,581 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:16,583 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:17,584 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:18,585 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:19,586 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:19,588 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 20:13:20,589 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:21,590 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:22,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:23,593 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:24,594 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:25,595 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:26,596 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:27,598 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:28,599 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:29,601 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:29,602 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 20:13:30,603 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:31,605 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:32,606 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:33,608 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:34,609 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:35,610 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:36,611 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:37,613 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:38,614 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:39,615 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:39,617 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 20:13:40,618 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:41,619 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:42,621 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:43,622 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:44,623 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:45,624 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:46,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:47,627 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:48,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:49,630 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:49,632 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 20:13:50,632 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:51,634 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:52,635 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:53,637 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:54,638 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:55,639 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:56,640 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:57,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:58,643 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:59,644 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:13:59,645 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 20:14:00,646 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:01,647 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:02,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:03,650 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:04,651 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:05,653 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:06,654 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:07,655 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:08,656 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:09,658 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:09,659 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 20:14:10,660 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:11,661 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:12,663 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:13,664 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:14,665 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:15,666 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:16,668 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:17,670 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:18,671 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:19,673 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:19,674 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 20:14:20,675 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:21,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:22,678 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:23,679 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:24,681 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:25,682 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:26,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:27,685 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:28,686 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:29,688 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:29,689 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 20:14:30,690 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:31,691 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:32,692 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:33,694 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:34,695 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:35,699 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:36,700 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:37,702 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:38,703 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:39,704 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:39,706 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 20:14:40,707 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:41,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:42,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:43,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:44,713 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:45,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:46,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:47,717 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:48,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:49,720 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:14:49,722 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 20:14:49,725 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.init(TestDeleteWithSlowFollower.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-26 20:14:49,730 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 20:14:49,730 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 20:14:49,731 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 20:14:49,731 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41603
2019-09-26 20:14:49,741 [IPC Server listener on 41603] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41603
2019-09-26 20:14:49,743 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 20:14:49,744 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:14:49,749 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 20:14:49,756 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 20:14:49,760 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@529cfee5{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 20:14:49,766 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:14:49,766 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 20:14:49,767 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:14:49,771 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 20:14:49,855 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:14:49,855 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:14:54,774 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:14:54,774 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:14:54,776 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - f6965e03-a7de-48a1-a4fe-2910b6888944: close
2019-09-26 20:14:54,776 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: close
2019-09-26 20:14:54,779 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: shutdown
2019-09-26 20:14:54,779 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: shutdown
2019-09-26 20:14:54,780 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-430E0D5E4BE0,id=f6965e03-a7de-48a1-a4fe-2910b6888944
2019-09-26 20:14:54,780 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A300CA2834F,id=9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:14:54,780 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown FollowerState
2019-09-26 20:14:54,781 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown LeaderState
2019-09-26 20:14:54,781 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(115)) - f6965e03-a7de-48a1-a4fe-2910b6888944: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:14:54,781 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:14:54,785 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0: closes. applyIndex: 0
2019-09-26 20:14:54,785 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3-PendingRequests: sendNotLeaderResponses
2019-09-26 20:14:54,788 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:14:54,791 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F: closes. applyIndex: 0
2019-09-26 20:14:54,791 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:14:54,791 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:14:54,794 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-430E0D5E4BE0-SegmentedRaftLogWorker close()
2019-09-26 20:14:54,794 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-6A300CA2834F-SegmentedRaftLogWorker close()
2019-09-26 20:14:54,798 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: shutdown
2019-09-26 20:14:54,798 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: shutdown
2019-09-26 20:14:54,798 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-13C459E5A7F7,id=f6965e03-a7de-48a1-a4fe-2910b6888944
2019-09-26 20:14:54,798 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-430E0D5E4BE0,id=9a95b9fa-dff8-42b6-9903-a5daabde5ab3
2019-09-26 20:14:54,799 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown LeaderState
2019-09-26 20:14:54,799 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown LeaderState
2019-09-26 20:14:54,800 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - f6965e03-a7de-48a1-a4fe-2910b6888944-PendingRequests: sendNotLeaderResponses
2019-09-26 20:14:54,804 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$415/1009635981@2e15bdc4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0->8ce5d084-8e1d-4410-9ede-27b1c8ae4966-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 20:14:54,804 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$415/1009635981@78f8fb2a] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0->f6965e03-a7de-48a1-a4fe-2910b6888944-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 20:14:54,803 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3-PendingRequests: sendNotLeaderResponses
2019-09-26 20:14:54,805 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:14:54,807 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:14:54,810 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0: closes. applyIndex: 0
2019-09-26 20:14:54,807 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7: closes. applyIndex: 0
2019-09-26 20:14:54,811 [9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:14:54,811 [f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:14:54,813 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0-SegmentedRaftLogWorker close()
2019-09-26 20:14:54,814 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f6965e03-a7de-48a1-a4fe-2910b6888944@group-13C459E5A7F7-SegmentedRaftLogWorker close()
2019-09-26 20:14:54,819 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown server with port 36066 now
2019-09-26 20:14:54,819 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - f6965e03-a7de-48a1-a4fe-2910b6888944: Completed APPEND_ENTRIES, lastRequest: 9a95b9fa-dff8-42b6-9903-a5daabde5ab3->f6965e03-a7de-48a1-a4fe-2910b6888944#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 20:14:54,819 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: Completed APPEND_ENTRIES, lastRequest: 9a95b9fa-dff8-42b6-9903-a5daabde5ab3->8ce5d084-8e1d-4410-9ede-27b1c8ae4966#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 20:14:54,819 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown server with port 40462 now
2019-09-26 20:14:54,827 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3: shutdown server with port 40462 successfully
2019-09-26 20:14:54,827 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0->f6965e03-a7de-48a1-a4fe-2910b6888944-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 20:14:54,827 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0->8ce5d084-8e1d-4410-9ede-27b1c8ae4966-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 20:14:54,830 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - f6965e03-a7de-48a1-a4fe-2910b6888944: shutdown server with port 36066 successfully
2019-09-26 20:14:54,834 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0->8ce5d084-8e1d-4410-9ede-27b1c8ae4966: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 20:14:54,835 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 9a95b9fa-dff8-42b6-9903-a5daabde5ab3@group-430E0D5E4BE0->f6965e03-a7de-48a1-a4fe-2910b6888944: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 20:14:54,838 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:14:54,838 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:14:54,864 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:14:54,870 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:14:54,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e519ad3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:14:54,872 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:14:54,873 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bc44ce8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:14:54,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cd64ee8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:14:54,874 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77774571{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:14:54,877 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:14:54,879 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7aac8884{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:14:54,880 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:14:54,881 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:14:54,882 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:14:54,965 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:14:59,878 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:14:59,879 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: close
2019-09-26 20:14:59,879 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: shutdown
2019-09-26 20:14:59,879 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: shutdown
2019-09-26 20:14:59,880 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-430E0D5E4BE0,id=8ce5d084-8e1d-4410-9ede-27b1c8ae4966
2019-09-26 20:14:59,880 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown FollowerState
2019-09-26 20:14:59,880 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B31E870CE92,id=8ce5d084-8e1d-4410-9ede-27b1c8ae4966
2019-09-26 20:14:59,880 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(115)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:14:59,880 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:14:59,880 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown LeaderState
2019-09-26 20:14:59,883 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0: closes. applyIndex: 0
2019-09-26 20:14:59,883 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966-PendingRequests: sendNotLeaderResponses
2019-09-26 20:14:59,884 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:14:59,884 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:14:59,885 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-430E0D5E4BE0-SegmentedRaftLogWorker close()
2019-09-26 20:14:59,885 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92: closes. applyIndex: 0
2019-09-26 20:14:59,887 [8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:14:59,888 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966@group-0B31E870CE92-SegmentedRaftLogWorker close()
2019-09-26 20:14:59,890 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown server with port 36717 now
2019-09-26 20:14:59,891 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 8ce5d084-8e1d-4410-9ede-27b1c8ae4966: shutdown server with port 36717 successfully
2019-09-26 20:14:59,895 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a0a1f82c-fdae-4bbd-b48c-95f90cc61ad3/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:14:59,918 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:14:59,920 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:14:59,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5dd903be{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:14:59,922 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:14:59,923 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:14:59,923 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:14:59,924 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 20:14:59,924 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 20:14:59,924 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-26 20:14:59,924 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 20:14:59,924 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 20:14:59,924 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 20:14:59,925 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41439
2019-09-26 20:14:59,926 [IPC Server listener on 41439] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41439
2019-09-26 20:14:59,927 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:14:59,982 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 20:14:59,982 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 20:14:59,983 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 20:14:59,983 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42591
2019-09-26 20:14:59,985 [IPC Server listener on 42591] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42591
2019-09-26 20:14:59,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:14:59,985 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 20:14:59,986 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 20:14:59,986 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43296
2019-09-26 20:14:59,988 [IPC Server listener on 43296] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43296
2019-09-26 20:14:59,988 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 20:14:59,988 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:14:59,989 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5398edd0{/,null,UNAVAILABLE}{/scm}
2019-09-26 20:14:59,990 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:14:59,990 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 20:14:59,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:14:59,992 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 20:14:59,992 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 20:14:59,992 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 20:14:59,993 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 20:15:00,001 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-26 20:15:00,009 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 20:15:00,009 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
