2019-09-26 20:31:06,934 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:07,049 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:07,053 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:07,072 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @923ms
2019-09-26 20:31:07,173 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 20:31:07,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 20:31:07,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 20:31:07,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 20:31:07,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 20:31:07,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 20:31:07,190 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 20:31:07,190 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 20:31:07,191 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 20:31:07,424 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@a1153bc
2019-09-26 20:31:07,426 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 20:31:07,499 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 20:31:07,574 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 20:31:07,589 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:07,654 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 20:31:07,658 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:07,758 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 20:31:08,117 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:31:08,145 [Socket Reader #1 for port 33972] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33972
2019-09-26 20:31:08,295 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:31:08,296 [Socket Reader #1 for port 43021] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43021
2019-09-26 20:31:08,308 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:31:08,309 [Socket Reader #1 for port 36026] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36026
2019-09-26 20:31:08,336 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 20:31:08,507 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:31:08,516 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:31:08,524 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:31:08,527 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 20:31:08,527 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:31:08,527 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:31:08,559 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36026
2019-09-26 20:31:08,631 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 20:31:08,647 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 20:31:08,647 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 20:31:08,882 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:36026
2019-09-26 20:31:08,883 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:31:08,883 [IPC Server listener on 36026] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36026: starting
2019-09-26 20:31:08,886 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:43021
2019-09-26 20:31:08,887 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:43021
2019-09-26 20:31:08,887 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:31:08,888 [IPC Server listener on 43021] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43021: starting
2019-09-26 20:31:08,890 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33972
2019-09-26 20:31:08,890 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:33972
2019-09-26 20:31:08,890 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:31:08,890 [IPC Server listener on 33972] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33972: starting
2019-09-26 20:31:08,894 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45475
2019-09-26 20:31:08,896 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:31:08,935 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@732f29af{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:31:08,936 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6622fc65{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 20:31:08,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7555b920{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-26 20:31:08,976 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6db66836{HTTP/1.1,[http/1.1]}{0.0.0.0:45475}
2019-09-26 20:31:08,976 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2828ms
2019-09-26 20:31:08,978 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 20:31:08,978 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 20:31:08,980 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:45475
2019-09-26 20:31:08,985 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78461bc4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:31:08,987 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:09,109 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(194)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-26 20:31:09,109 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(224)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 20:31:09,111 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:09,112 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:09,817 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 20:31:09,827 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 20:31:09,827 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 20:31:09,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 20:31:09,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 20:31:09,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 20:31:09,828 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 20:31:09,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 20:31:09,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 20:31:09,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 20:31:09,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 20:31:09,829 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 20:31:09,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 20:31:09,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 20:31:09,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 20:31:09,830 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 20:31:09,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 20:31:09,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 20:31:09,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 20:31:09,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 20:31:09,831 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 20:31:09,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 20:31:09,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 20:31:09,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 20:31:09,832 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 20:31:09,833 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 20:31:10,423 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 20:31:10,424 [Socket Reader #1 for port 40783] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40783
2019-09-26 20:31:10,454 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40783
2019-09-26 20:31:10,454 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 20:31:10,456 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 20:31:10,456 [IPC Server listener on 40783] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40783: starting
2019-09-26 20:31:10,462 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 20:31:10,465 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:31:10,466 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:31:10,472 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:31:10,474 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 20:31:10,474 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:31:10,475 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:31:10,479 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40395
2019-09-26 20:31:10,479 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:31:10,482 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67dba613{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:31:10,483 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cf8edcf{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-26 20:31:10,492 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22d1886d{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-26 20:31:10,493 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7df60067{HTTP/1.1,[http/1.1]}{0.0.0.0:40395}
2019-09-26 20:31:10,494 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4346ms
2019-09-26 20:31:10,494 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:31:10,495 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:40395
2019-09-26 20:31:10,822 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:31:10,878 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:31:10,912 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:31:10,914 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 20:31:10,917 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5136207f
2019-09-26 20:31:10,936 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5136207f
2019-09-26 20:31:11,059 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:31:11,141 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:31:11,146 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:31:11,147 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:31:11,148 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:11,149 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:31:11,150 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:31:11,305 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis] (custom)
2019-09-26 20:31:11,358 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:31:11,361 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:31:11,362 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:31:11,364 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:31:11,365 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:31:11,366 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:31:11,366 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:31:11,367 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41609
2019-09-26 20:31:11,368 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:31:11,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6069dd38{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:31:11,372 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@558756be{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:31:11,407 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43e9089{/,file:///tmp/jetty-0.0.0.0-41609-hddsDatanode-_-any-8122073876943414284.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:31:11,408 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c5dbdf8{HTTP/1.1,[http/1.1]}{0.0.0.0:41609}
2019-09-26 20:31:11,409 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5261ms
2019-09-26 20:31:11,410 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:31:11,410 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41609
2019-09-26 20:31:11,411 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:31:11,414 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:31:11,417 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78f49be6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:31:11,423 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:31:11,423 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 20:31:11,424 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@68a4dcc6
2019-09-26 20:31:11,426 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@68a4dcc6
2019-09-26 20:31:11,455 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:31:11,455 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:31:11,455 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:31:11,456 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:31:11,456 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:11,456 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:31:11,457 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:31:11,457 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis] (custom)
2019-09-26 20:31:11,460 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:31:11,461 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:31:11,462 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:31:11,464 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:31:11,465 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:31:11,465 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:31:11,466 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:31:11,467 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43164
2019-09-26 20:31:11,467 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:31:11,471 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18d910b3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:31:11,471 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@625d9132{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:31:11,505 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@455c1d8c{/,file:///tmp/jetty-0.0.0.0-43164-hddsDatanode-_-any-3884280963287423433.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:31:11,506 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a451491{HTTP/1.1,[http/1.1]}{0.0.0.0:43164}
2019-09-26 20:31:11,507 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5359ms
2019-09-26 20:31:11,508 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:31:11,508 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43164
2019-09-26 20:31:11,509 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 20:31:11,512 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5735899] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:31:11,512 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-kpcbn-4093309294 ip:192.168.151.109
2019-09-26 20:31:11,520 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 20:31:11,521 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 20:31:11,521 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cff61fc
2019-09-26 20:31:11,521 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cff61fc
2019-09-26 20:31:11,534 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 20:31:11,535 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 20:31:11,535 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 20:31:11,535 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 20:31:11,535 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:11,536 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 20:31:11,536 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:31:11,536 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis] (custom)
2019-09-26 20:31:11,538 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 20:31:11,540 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 20:31:11,540 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 20:31:11,542 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 20:31:11,543 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 20:31:11,543 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 20:31:11,543 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 20:31:11,544 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44420
2019-09-26 20:31:11,544 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 20:31:11,546 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44536de4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-26 20:31:11,546 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d95a72e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 20:31:11,548 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/meta/datanode.id
2019-09-26 20:31:11,551 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/meta/datanode.id
2019-09-26 20:31:11,581 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@fc807c1{/,file:///tmp/jetty-0.0.0.0-44420-hddsDatanode-_-any-9164702216854838266.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 20:31:11,583 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@296e281a{HTTP/1.1,[http/1.1]}{0.0.0.0:44420}
2019-09-26 20:31:11,585 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5436ms
2019-09-26 20:31:11,585 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 20:31:11,586 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44420
2019-09-26 20:31:11,589 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:31:11,589 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3c019e61] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 20:31:11,594 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/meta/datanode.id
2019-09-26 20:31:12,589 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:31:13,475 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:31:13,479 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:31:13,479 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 2894c3b8-bd5b-4f7b-a9c0-101386a80bce at port 0
2019-09-26 20:31:13,507 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: start RPC server
2019-09-26 20:31:13,529 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:31:13,535 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:31:13,535 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 87f6a0d6-7e67-4a18-be15-155a5b3297c9 at port 0
2019-09-26 20:31:13,543 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start RPC server
2019-09-26 20:31:13,590 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:31:13,605 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 20:31:13,606 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 20:31:13,607 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis f078820d-9001-472d-9d0b-47ab86a814e0 at port 0
2019-09-26 20:31:13,616 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - f078820d-9001-472d-9d0b-47ab86a814e0: start RPC server
2019-09-26 20:31:13,685 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - f078820d-9001-472d-9d0b-47ab86a814e0: GrpcService started, listening on 0.0.0.0/0.0.0.0:40976
2019-09-26 20:31:13,685 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: GrpcService started, listening on 0.0.0.0/0.0.0.0:41005
2019-09-26 20:31:13,685 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: GrpcService started, listening on 0.0.0.0/0.0.0.0:39043
2019-09-26 20:31:13,686 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 2894c3b8-bd5b-4f7b-a9c0-101386a80bce is started using port 41005
2019-09-26 20:31:13,686 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis f078820d-9001-472d-9d0b-47ab86a814e0 is started using port 40976
2019-09-26 20:31:13,686 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 87f6a0d6-7e67-4a18-be15-155a5b3297c9 is started using port 39043
2019-09-26 20:31:13,692 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 2894c3b8-bd5b-4f7b-a9c0-101386a80bce is started using port 42932
2019-09-26 20:31:13,692 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 87f6a0d6-7e67-4a18-be15-155a5b3297c9 is started using port 35034
2019-09-26 20:31:13,692 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc f078820d-9001-472d-9d0b-47ab86a814e0 is started using port 32960
2019-09-26 20:31:14,590 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-26 20:31:15,457 [IPC Server handler 0 on 33972] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/2894c3b8-bd5b-4f7b-a9c0-101386a80bce
2019-09-26 20:31:15,458 [IPC Server handler 0 on 33972] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:31:15,462 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 20:31:15,462 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 20:31:15,463 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 20:31:15,514 [IPC Server handler 1 on 33972] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:31:15,514 [IPC Server handler 1 on 33972] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:31:15,591 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-26 20:31:15,591 [IPC Server handler 3 on 33972] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f078820d-9001-472d-9d0b-47ab86a814e0
2019-09-26 20:31:15,591 [IPC Server handler 3 on 33972] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}
2019-09-26 20:31:15,944 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: addNew group-FA87758E3C6B:[2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] returns group-FA87758E3C6B:java.util.concurrent.CompletableFuture@500784e4[Not completed]
2019-09-26 20:31:15,963 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: new RaftServerImpl for group-FA87758E3C6B:[2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] with ContainerStateMachine:uninitialized
2019-09-26 20:31:15,966 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:31:15,967 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:31:15,967 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:31:15,969 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:31:15,970 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:15,979 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: ConfigurationManager, init=-1: [2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null, confs=<EMPTY_MAP>
2019-09-26 20:31:15,979 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis] (custom)
2019-09-26 20:31:15,988 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/255ee0d6-81b9-4872-882a-fa87758e3c6b does not exist. Creating ...
2019-09-26 20:31:16,006 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/255ee0d6-81b9-4872-882a-fa87758e3c6b/in_use.lock acquired by nodename 2259@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:31:16,022 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/255ee0d6-81b9-4872-882a-fa87758e3c6b has been successfully formatted.
2019-09-26 20:31:16,025 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FA87758E3C6B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:31:16,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:31:16,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:31:16,039 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:31:16,039 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:16,042 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,048 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:31:16,055 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/255ee0d6-81b9-4872-882a-fa87758e3c6b
2019-09-26 20:31:16,057 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 20:31:16,066 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 20:31:16,098 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:31:16,099 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:31:16,102 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:31:16,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:31:16,104 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:31:16,105 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:31:16,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:31:16,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:31:16,116 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:31:16,120 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:31:16,124 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:31:16,125 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:31:16,125 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:31:16,126 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:31:16,159 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: start as a follower, conf=-1: [2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:16,160 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:31:16,162 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: start FollowerState
2019-09-26 20:31:16,164 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FA87758E3C6B,id=2894c3b8-bd5b-4f7b-a9c0-101386a80bce
2019-09-26 20:31:16,226 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 255ee0d6-81b9-4872-882a-fa87758e3c6b, Nodes: 2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:31:16,246 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f078820d-9001-472d-9d0b-47ab86a814e0: addNew group-716ABF015E55:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976] returns group-716ABF015E55:java.util.concurrent.CompletableFuture@587d38b8[Not completed]
2019-09-26 20:31:16,281 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f078820d-9001-472d-9d0b-47ab86a814e0: new RaftServerImpl for group-716ABF015E55:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976] with ContainerStateMachine:uninitialized
2019-09-26 20:31:16,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:31:16,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:31:16,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:31:16,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:31:16,283 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:16,284 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: ConfigurationManager, init=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976], old=null, confs=<EMPTY_MAP>
2019-09-26 20:31:16,284 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis] (custom)
2019-09-26 20:31:16,284 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/f812fd18-b7c7-42ed-9356-716abf015e55 does not exist. Creating ...
2019-09-26 20:31:16,298 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/f812fd18-b7c7-42ed-9356-716abf015e55/in_use.lock acquired by nodename 2259@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:31:16,311 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/f812fd18-b7c7-42ed-9356-716abf015e55 has been successfully formatted.
2019-09-26 20:31:16,312 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-716ABF015E55: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:31:16,313 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:31:16,314 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:31:16,314 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:31:16,314 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:16,314 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,314 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:31:16,314 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/f812fd18-b7c7-42ed-9356-716abf015e55
2019-09-26 20:31:16,321 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:31:16,321 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:31:16,322 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,322 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:31:16,322 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:31:16,322 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:31:16,323 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:31:16,323 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:31:16,323 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:31:16,323 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:31:16,324 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:31:16,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:31:16,324 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:31:16,325 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:31:16,325 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:31:16,329 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: start as a follower, conf=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976], old=null
2019-09-26 20:31:16,329 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:31:16,329 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f078820d-9001-472d-9d0b-47ab86a814e0: start FollowerState
2019-09-26 20:31:16,330 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-716ABF015E55,id=f078820d-9001-472d-9d0b-47ab86a814e0
2019-09-26 20:31:16,342 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f812fd18-b7c7-42ed-9356-716abf015e55, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:31:16,360 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: addNew group-3070E41CE99D:[87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043] returns group-3070E41CE99D:java.util.concurrent.CompletableFuture@93e4170[Not completed]
2019-09-26 20:31:16,377 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: new RaftServerImpl for group-3070E41CE99D:[87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043] with ContainerStateMachine:uninitialized
2019-09-26 20:31:16,377 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:31:16,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:31:16,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:31:16,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:31:16,379 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:16,379 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: ConfigurationManager, init=-1: [87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043], old=null, confs=<EMPTY_MAP>
2019-09-26 20:31:16,379 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis] (custom)
2019-09-26 20:31:16,380 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/b4190716-8fab-4bd9-8bdb-3070e41ce99d does not exist. Creating ...
2019-09-26 20:31:16,393 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/b4190716-8fab-4bd9-8bdb-3070e41ce99d/in_use.lock acquired by nodename 2259@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:31:16,407 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/b4190716-8fab-4bd9-8bdb-3070e41ce99d has been successfully formatted.
2019-09-26 20:31:16,407 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-3070E41CE99D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:31:16,408 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:31:16,408 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:31:16,408 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:31:16,409 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:16,409 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,409 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:31:16,410 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/b4190716-8fab-4bd9-8bdb-3070e41ce99d
2019-09-26 20:31:16,436 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:31:16,437 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:31:16,437 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,437 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:31:16,437 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:31:16,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:31:16,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:31:16,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:31:16,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:31:16,439 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:31:16,439 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:31:16,440 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:31:16,440 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:31:16,440 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:31:16,440 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:31:16,446 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: start as a follower, conf=-1: [87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043], old=null
2019-09-26 20:31:16,446 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:31:16,447 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start FollowerState
2019-09-26 20:31:16,447 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3070E41CE99D,id=87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:31:16,457 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b4190716-8fab-4bd9-8bdb-3070e41ce99d, Nodes: 87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:31:16,489 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: addNew group-1386DCB71338:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] returns group-1386DCB71338:java.util.concurrent.CompletableFuture@43bf7c90[Not completed]
2019-09-26 20:31:16,491 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f078820d-9001-472d-9d0b-47ab86a814e0: addNew group-1386DCB71338:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] returns group-1386DCB71338:java.util.concurrent.CompletableFuture@28276ab[Not completed]
2019-09-26 20:31:16,493 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: new RaftServerImpl for group-1386DCB71338:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] with ContainerStateMachine:uninitialized
2019-09-26 20:31:16,494 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:31:16,494 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:31:16,494 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:31:16,495 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:31:16,495 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:16,495 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - f078820d-9001-472d-9d0b-47ab86a814e0: new RaftServerImpl for group-1386DCB71338:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] with ContainerStateMachine:uninitialized
2019-09-26 20:31:16,496 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: ConfigurationManager, init=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null, confs=<EMPTY_MAP>
2019-09-26 20:31:16,496 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:31:16,496 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: addNew group-1386DCB71338:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] returns group-1386DCB71338:java.util.concurrent.CompletableFuture@b293757[Not completed]
2019-09-26 20:31:16,496 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:31:16,496 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis] (custom)
2019-09-26 20:31:16,496 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:31:16,497 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:31:16,497 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:16,497 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338 does not exist. Creating ...
2019-09-26 20:31:16,497 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: ConfigurationManager, init=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null, confs=<EMPTY_MAP>
2019-09-26 20:31:16,497 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis] (custom)
2019-09-26 20:31:16,498 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: new RaftServerImpl for group-1386DCB71338:[f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005] with ContainerStateMachine:uninitialized
2019-09-26 20:31:16,498 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338 does not exist. Creating ...
2019-09-26 20:31:16,498 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 20:31:16,498 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 20:31:16,498 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 20:31:16,499 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 20:31:16,499 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:16,499 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: ConfigurationManager, init=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null, confs=<EMPTY_MAP>
2019-09-26 20:31:16,499 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis] (custom)
2019-09-26 20:31:16,499 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338 does not exist. Creating ...
2019-09-26 20:31:16,511 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338/in_use.lock acquired by nodename 2259@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:31:16,511 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338/in_use.lock acquired by nodename 2259@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:31:16,511 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338/in_use.lock acquired by nodename 2259@pr-hdds-2162-kpcbn-4093309294
2019-09-26 20:31:16,524 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338 has been successfully formatted.
2019-09-26 20:31:16,524 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338 has been successfully formatted.
2019-09-26 20:31:16,524 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338 has been successfully formatted.
2019-09-26 20:31:16,525 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1386DCB71338: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:31:16,525 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1386DCB71338: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:31:16,525 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:31:16,525 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1386DCB71338: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 20:31:16,525 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:31:16,525 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:31:16,526 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:31:16,525 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 20:31:16,526 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:16,526 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:31:16,526 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,526 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 20:31:16,526 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:31:16,526 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:31:16,527 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338
2019-09-26 20:31:16,527 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 20:31:16,527 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:31:16,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:16,527 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:31:16,527 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:16,528 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,527 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,528 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:31:16,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,528 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:31:16,528 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:31:16,529 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:31:16,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 20:31:16,529 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:31:16,529 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338
2019-09-26 20:31:16,529 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:31:16,529 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338
2019-09-26 20:31:16,530 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:31:16,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:31:16,530 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:31:16,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 20:31:16,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:31:16,530 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:31:16,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 20:31:16,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:31:16,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 20:31:16,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:31:16,531 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:31:16,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:31:16,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 20:31:16,532 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:31:16,531 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:31:16,532 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 20:31:16,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:31:16,532 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 20:31:16,532 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:31:16,532 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 20:31:16,533 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:31:16,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 20:31:16,533 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:31:16,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 20:31:16,533 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:31:16,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 20:31:16,534 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:31:16,534 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 20:31:16,534 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:31:16,534 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:31:16,534 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 20:31:16,534 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:31:16,534 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 20:31:16,535 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:31:16,535 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 20:31:16,535 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 20:31:16,536 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: start as a follower, conf=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:16,536 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:31:16,537 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start FollowerState
2019-09-26 20:31:16,537 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1386DCB71338,id=87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:31:16,546 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: start as a follower, conf=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:16,546 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:31:16,546 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f078820d-9001-472d-9d0b-47ab86a814e0: start FollowerState
2019-09-26 20:31:16,546 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: start as a follower, conf=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:16,546 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 20:31:16,546 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1386DCB71338,id=f078820d-9001-472d-9d0b-47ab86a814e0
2019-09-26 20:31:16,547 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: start FollowerState
2019-09-26 20:31:16,548 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1386DCB71338,id=2894c3b8-bd5b-4f7b-a9c0-101386a80bce
2019-09-26 20:31:16,562 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d85534f9-01cd-463f-9fd7-1386dcb71338, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-26 20:31:16,591 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-26 20:31:17,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:18,469 [Thread-178] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-26 20:31:18,472 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-26 20:31:18,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:19,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:20,780 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:21,261 [Thread-180] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:group-FA87758E3C6B changes to CANDIDATE, lastRpcTime:5100, electionTimeout:5099ms
2019-09-26 20:31:21,264 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown FollowerState
2019-09-26 20:31:21,264 [Thread-180] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:31:21,270 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: start LeaderElection
2019-09-26 20:31:21,288 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1: begin an election at term 1 for -1: [2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:21,290 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown LeaderElection
2019-09-26 20:31:21,291 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:31:21,291 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: change Leader from null to 2894c3b8-bd5b-4f7b-a9c0-101386a80bce at term 1 for becomeLeader, leader elected after 5265ms
2019-09-26 20:31:21,298 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:31:21,298 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:31:21,302 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:31:21,305 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:31:21,305 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:31:21,306 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:31:21,321 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: start LeaderState
2019-09-26 20:31:21,344 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:31:21,353 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: set configuration 0: [2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null at 0
2019-09-26 20:31:21,474 [Thread-183] INFO  impl.FollowerState (FollowerState.java:run(106)) - f078820d-9001-472d-9d0b-47ab86a814e0:group-716ABF015E55 changes to CANDIDATE, lastRpcTime:5145, electionTimeout:5144ms
2019-09-26 20:31:21,476 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown FollowerState
2019-09-26 20:31:21,476 [Thread-183] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:31:21,476 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f078820d-9001-472d-9d0b-47ab86a814e0: start LeaderElection
2019-09-26 20:31:21,492 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2: begin an election at term 1 for -1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976], old=null
2019-09-26 20:31:21,493 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown LeaderElection
2019-09-26 20:31:21,493 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:31:21,493 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: change Leader from null to f078820d-9001-472d-9d0b-47ab86a814e0 at term 1 for becomeLeader, leader elected after 5179ms
2019-09-26 20:31:21,493 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:31:21,493 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:31:21,494 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:31:21,494 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:31:21,494 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:31:21,494 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:31:21,497 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f078820d-9001-472d-9d0b-47ab86a814e0: start LeaderState
2019-09-26 20:31:21,497 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:31:21,497 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: set configuration 0: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976], old=null at 0
2019-09-26 20:31:21,544 [Thread-191] INFO  impl.FollowerState (FollowerState.java:run(106)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9:group-1386DCB71338 changes to CANDIDATE, lastRpcTime:5003, electionTimeout:5003ms
2019-09-26 20:31:21,544 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown FollowerState
2019-09-26 20:31:21,544 [Thread-191] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:31:21,544 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start LeaderElection
2019-09-26 20:31:21,561 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/f812fd18-b7c7-42ed-9356-716abf015e55/current/log_inprogress_0
2019-09-26 20:31:21,561 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3: begin an election at term 1 for -1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:21,561 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/255ee0d6-81b9-4872-882a-fa87758e3c6b/current/log_inprogress_0
2019-09-26 20:31:21,595 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:31:21,595 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:31:21,595 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown FollowerState
2019-09-26 20:31:21,596 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown FollowerState
2019-09-26 20:31:21,596 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f078820d-9001-472d-9d0b-47ab86a814e0: start FollowerState
2019-09-26 20:31:21,596 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(115)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:31:21,596 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: start FollowerState
2019-09-26 20:31:21,596 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(115)) - f078820d-9001-472d-9d0b-47ab86a814e0: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:31:21,630 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3: Election PASSED; received 1 response(s) [87f6a0d6-7e67-4a18-be15-155a5b3297c9<-f078820d-9001-472d-9d0b-47ab86a814e0#0:OK-t1] and 0 exception(s); 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:t1, leader=null, voted=87f6a0d6-7e67-4a18-be15-155a5b3297c9, raftlog=87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null
2019-09-26 20:31:21,631 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown LeaderElection
2019-09-26 20:31:21,631 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: change Leader from null to 87f6a0d6-7e67-4a18-be15-155a5b3297c9 at term 1 for becomeLeader, leader elected after 5106ms
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:31:21,632 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:31:21,637 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 20:31:21,637 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:21,637 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 20:31:21,640 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 20:31:21,643 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:31:21,644 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:21,644 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-26 20:31:21,645 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 20:31:21,645 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-26 20:31:21,645 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-26 20:31:21,645 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 20:31:21,645 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 20:31:21,647 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9:group-3070E41CE99D changes to CANDIDATE, lastRpcTime:5200, electionTimeout:5200ms
2019-09-26 20:31:21,649 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown FollowerState
2019-09-26 20:31:21,649 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 20:31:21,649 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start LeaderElection
2019-09-26 20:31:21,649 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start LeaderState
2019-09-26 20:31:21,649 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:31:21,652 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: set configuration 0: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null at 0
2019-09-26 20:31:21,694 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338/current/log_inprogress_0
2019-09-26 20:31:21,694 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4: begin an election at term 1 for -1: [87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043], old=null
2019-09-26 20:31:21,694 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown LeaderElection
2019-09-26 20:31:21,695 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 20:31:21,695 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: change Leader from null to 87f6a0d6-7e67-4a18-be15-155a5b3297c9 at term 1 for becomeLeader, leader elected after 5286ms
2019-09-26 20:31:21,695 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 20:31:21,696 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 20:31:21,696 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 20:31:21,697 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 20:31:21,697 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 20:31:21,697 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 20:31:21,699 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: change Leader from null to 87f6a0d6-7e67-4a18-be15-155a5b3297c9 at term 1 for appendEntries, leader elected after 5173ms
2019-09-26 20:31:21,700 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: change Leader from null to 87f6a0d6-7e67-4a18-be15-155a5b3297c9 at term 1 for appendEntries, leader elected after 5174ms
2019-09-26 20:31:21,706 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: start LeaderState
2019-09-26 20:31:21,706 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:31:21,707 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: set configuration 0: [87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043], old=null at 0
2019-09-26 20:31:21,755 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/ratis/b4190716-8fab-4bd9-8bdb-3070e41ce99d/current/log_inprogress_0
2019-09-26 20:31:21,762 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: set configuration 0: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null at 0
2019-09-26 20:31:21,762 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: set configuration 0: [f078820d-9001-472d-9d0b-47ab86a814e0:192.168.151.109:40976, 87f6a0d6-7e67-4a18-be15-155a5b3297c9:192.168.151.109:39043, 2894c3b8-bd5b-4f7b-a9c0-101386a80bce:192.168.151.109:41005], old=null at 0
2019-09-26 20:31:21,762 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:31:21,763 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 20:31:21,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:21,801 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338/current/log_inprogress_0
2019-09-26 20:31:21,801 [f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/ratis/d85534f9-01cd-463f-9fd7-1386dcb71338/current/log_inprogress_0
2019-09-26 20:31:22,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:23,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:24,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:25,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:26,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:27,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:28,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:29,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:30,797 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:31,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:32,800 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:33,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:34,803 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:35,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:36,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:36,807 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-26 20:31:37,809 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:38,810 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:39,811 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:40,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:41,814 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:42,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:43,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:44,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:45,820 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:46,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:46,823 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-26 20:31:47,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:48,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:49,826 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:50,827 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:51,828 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:52,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:53,831 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:54,832 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:55,833 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:56,835 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:56,836 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-26 20:31:57,837 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:58,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:31:59,840 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:00,841 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:01,842 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:02,844 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:03,845 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:04,846 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:05,848 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:06,849 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:06,851 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-26 20:32:07,852 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:08,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:09,855 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:10,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:11,858 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:12,859 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:13,860 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:14,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:15,862 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:16,864 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:16,865 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-26 20:32:17,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:18,868 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:19,869 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:20,870 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:21,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:22,873 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:23,874 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:24,875 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:25,876 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:26,878 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:26,879 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-26 20:32:27,880 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:28,881 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:29,882 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:30,883 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:31,884 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:32,885 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:33,887 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:34,888 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:35,889 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:36,890 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:36,892 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-26 20:32:37,893 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:38,894 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:39,895 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:40,896 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:41,898 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:42,899 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:43,900 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:44,901 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:45,903 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:46,904 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:46,905 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-26 20:32:47,906 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:48,908 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:49,909 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:50,911 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:51,912 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:52,913 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:53,914 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:54,915 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:55,917 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:56,918 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:56,920 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-26 20:32:57,921 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:58,922 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:32:59,923 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:00,924 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:01,925 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:02,927 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:03,928 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:04,929 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:05,930 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:06,932 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-26 20:33:06,933 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-26 20:33:06,937 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestKeyInputStream.init(TestKeyInputStream.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-26 20:33:06,941 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 20:33:06,942 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 20:33:06,942 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 20:33:06,942 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40783
2019-09-26 20:33:06,956 [IPC Server listener on 40783] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40783
2019-09-26 20:33:06,959 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 20:33:06,967 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:33:06,968 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 20:33:06,970 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 20:33:06,974 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22d1886d{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 20:33:06,981 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7df60067{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:33:06,982 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cf8edcf{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 20:33:06,982 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67dba613{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:33:06,987 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 20:33:07,432 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:33:07,528 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:33:09,447 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=d85534f9-01cd-463f-9fd7-1386dcb71338, PipelineID=255ee0d6-81b9-4872-882a-fa87758e3c6b]
2019-09-26 20:33:09,447 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: d85534f9-01cd-463f-9fd7-1386dcb71338, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-26 20:33:09,448 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: d85534f9-01cd-463f-9fd7-1386dcb71338, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-09-26 20:33:09,450 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 255ee0d6-81b9-4872-882a-fa87758e3c6b, Nodes: 2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:33:09,450 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 255ee0d6-81b9-4872-882a-fa87758e3c6b, Nodes: 2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-26 20:33:09,547 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=d85534f9-01cd-463f-9fd7-1386dcb71338, PipelineID=b4190716-8fab-4bd9-8bdb-3070e41ce99d]
2019-09-26 20:33:09,547 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: d85534f9-01cd-463f-9fd7-1386dcb71338, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-26 20:33:09,547 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: b4190716-8fab-4bd9-8bdb-3070e41ce99d, Nodes: 87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:33:09,550 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: b4190716-8fab-4bd9-8bdb-3070e41ce99d, Nodes: 87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-26 20:33:11,990 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:33:11,990 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:33:11,993 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: close
2019-09-26 20:33:11,993 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: close
2019-09-26 20:33:11,996 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: shutdown
2019-09-26 20:33:11,996 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: shutdown
2019-09-26 20:33:11,997 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1386DCB71338,id=2894c3b8-bd5b-4f7b-a9c0-101386a80bce
2019-09-26 20:33:11,997 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1386DCB71338,id=87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:33:11,997 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown FollowerState
2019-09-26 20:33:11,998 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown LeaderState
2019-09-26 20:33:11,998 [Thread-207] INFO  impl.FollowerState (FollowerState.java:run(115)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:33:11,998 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:33:12,002 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$395/256325580@7aceb6c9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338->f078820d-9001-472d-9d0b-47ab86a814e0-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 20:33:12,004 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338: closes. applyIndex: 0
2019-09-26 20:33:12,002 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$395/256325580@17d42384] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338->2894c3b8-bd5b-4f7b-a9c0-101386a80bce-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-26 20:33:12,004 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9-PendingRequests: sendNotLeaderResponses
2019-09-26 20:33:12,009 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:33:12,010 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:33:12,010 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - f078820d-9001-472d-9d0b-47ab86a814e0: Completed APPEND_ENTRIES, lastRequest: 87f6a0d6-7e67-4a18-be15-155a5b3297c9->f078820d-9001-472d-9d0b-47ab86a814e0#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 20:33:12,010 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: Completed APPEND_ENTRIES, lastRequest: 87f6a0d6-7e67-4a18-be15-155a5b3297c9->2894c3b8-bd5b-4f7b-a9c0-101386a80bce#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-26 20:33:12,013 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338: closes. applyIndex: 0
2019-09-26 20:33:12,015 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-1386DCB71338-SegmentedRaftLogWorker close()
2019-09-26 20:33:12,015 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:33:12,019 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338->f078820d-9001-472d-9d0b-47ab86a814e0-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 20:33:12,019 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: shutdown
2019-09-26 20:33:12,019 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338->2894c3b8-bd5b-4f7b-a9c0-101386a80bce-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-26 20:33:12,019 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338-SegmentedRaftLogWorker close()
2019-09-26 20:33:12,021 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FA87758E3C6B,id=2894c3b8-bd5b-4f7b-a9c0-101386a80bce
2019-09-26 20:33:12,025 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: shutdown
2019-09-26 20:33:12,026 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown LeaderState
2019-09-26 20:33:12,027 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338->2894c3b8-bd5b-4f7b-a9c0-101386a80bce: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 20:33:12,028 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce-PendingRequests: sendNotLeaderResponses
2019-09-26 20:33:12,027 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-1386DCB71338->f078820d-9001-472d-9d0b-47ab86a814e0: nextIndex: updateUnconditionally 1 -> 0
2019-09-26 20:33:12,027 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3070E41CE99D,id=87f6a0d6-7e67-4a18-be15-155a5b3297c9
2019-09-26 20:33:12,030 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:33:12,030 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown LeaderState
2019-09-26 20:33:12,031 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B: closes. applyIndex: 0
2019-09-26 20:33:12,032 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9-PendingRequests: sendNotLeaderResponses
2019-09-26 20:33:12,032 [2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:33:12,032 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:33:12,033 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce@group-FA87758E3C6B-SegmentedRaftLogWorker close()
2019-09-26 20:33:12,034 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D: closes. applyIndex: 0
2019-09-26 20:33:12,037 [87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:33:12,037 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown server with port 41005 now
2019-09-26 20:33:12,038 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9@group-3070E41CE99D-SegmentedRaftLogWorker close()
2019-09-26 20:33:12,041 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown server with port 39043 now
2019-09-26 20:33:12,043 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 2894c3b8-bd5b-4f7b-a9c0-101386a80bce: shutdown server with port 41005 successfully
2019-09-26 20:33:12,043 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 87f6a0d6-7e67-4a18-be15-155a5b3297c9: shutdown server with port 39043 successfully
2019-09-26 20:33:12,045 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:33:12,045 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:33:12,068 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:33:12,072 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:33:12,073 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@455c1d8c{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:33:12,074 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a451491{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:33:12,074 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@625d9132{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:33:12,075 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18d910b3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:33:12,075 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:33:12,078 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:33:12,081 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43e9089{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:33:12,081 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c5dbdf8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:33:12,082 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@558756be{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:33:12,083 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6069dd38{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:33:12,606 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 20:33:14,655 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=d85534f9-01cd-463f-9fd7-1386dcb71338, PipelineID=f812fd18-b7c7-42ed-9356-716abf015e55]
2019-09-26 20:33:14,656 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: d85534f9-01cd-463f-9fd7-1386dcb71338, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}2894c3b8-bd5b-4f7b-a9c0-101386a80bce{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}87f6a0d6-7e67-4a18-be15-155a5b3297c9{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED]
2019-09-26 20:33:14,656 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: f812fd18-b7c7-42ed-9356-716abf015e55, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 20:33:14,657 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: f812fd18-b7c7-42ed-9356-716abf015e55, Nodes: f078820d-9001-472d-9d0b-47ab86a814e0{ip: 192.168.151.109, host: pr-hdds-2162-kpcbn-4093309294, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-09-26 20:33:17,077 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 20:33:17,079 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - f078820d-9001-472d-9d0b-47ab86a814e0: close
2019-09-26 20:33:17,080 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: shutdown
2019-09-26 20:33:17,080 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: shutdown
2019-09-26 20:33:17,081 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1386DCB71338,id=f078820d-9001-472d-9d0b-47ab86a814e0
2019-09-26 20:33:17,081 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-716ABF015E55,id=f078820d-9001-472d-9d0b-47ab86a814e0
2019-09-26 20:33:17,081 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown FollowerState
2019-09-26 20:33:17,082 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown LeaderState
2019-09-26 20:33:17,082 [Thread-206] INFO  impl.FollowerState (FollowerState.java:run(115)) - f078820d-9001-472d-9d0b-47ab86a814e0: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-26 20:33:17,082 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:33:17,082 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - f078820d-9001-472d-9d0b-47ab86a814e0-PendingRequests: sendNotLeaderResponses
2019-09-26 20:33:17,084 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338: closes. applyIndex: 0
2019-09-26 20:33:17,085 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-StateMachineUpdater: set stopIndex = 0
2019-09-26 20:33:17,085 [f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:33:17,086 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55: closes. applyIndex: 0
2019-09-26 20:33:17,087 [f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 20:33:17,087 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-1386DCB71338-SegmentedRaftLogWorker close()
2019-09-26 20:33:17,088 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - f078820d-9001-472d-9d0b-47ab86a814e0@group-716ABF015E55-SegmentedRaftLogWorker close()
2019-09-26 20:33:17,091 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown server with port 40976 now
2019-09-26 20:33:17,092 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - f078820d-9001-472d-9d0b-47ab86a814e0: shutdown server with port 40976 successfully
2019-09-26 20:33:17,103 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7e4ff20b-20ac-4efc-9d5d-5863e1220587/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 20:33:17,122 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 20:33:17,125 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 20:33:17,126 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@fc807c1{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 20:33:17,127 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@296e281a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:33:17,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d95a72e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 20:33:17,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44536de4{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:33:17,129 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 20:33:17,130 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 20:33:17,130 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-26 20:33:17,130 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 20:33:17,130 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 20:33:17,130 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 20:33:17,131 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33972
2019-09-26 20:33:17,133 [IPC Server listener on 33972] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33972
2019-09-26 20:33:17,133 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:33:17,162 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 20:33:17,162 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 20:33:17,162 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 20:33:17,162 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43021
2019-09-26 20:33:17,164 [IPC Server listener on 43021] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43021
2019-09-26 20:33:17,164 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 20:33:17,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:33:17,165 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 20:33:17,165 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36026
2019-09-26 20:33:17,167 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 20:33:17,167 [IPC Server listener on 36026] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36026
2019-09-26 20:33:17,167 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 20:33:17,168 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7555b920{/,null,UNAVAILABLE}{/scm}
2019-09-26 20:33:17,168 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6db66836{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 20:33:17,169 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6622fc65{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-26 20:33:17,169 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@732f29af{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-26 20:33:17,170 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 20:33:17,170 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 20:33:17,170 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 20:33:17,171 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 20:33:17,179 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-26 20:33:17,186 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 20:33:17,186 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.
