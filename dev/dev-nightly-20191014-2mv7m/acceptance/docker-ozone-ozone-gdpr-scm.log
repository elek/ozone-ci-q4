Attaching to ozone_datanode_2, ozone_datanode_3, ozone_datanode_1, ozone_scm_1, ozone_om_1
datanode_3  | 2019-10-14 14:18:02,759 [main] INFO       - STARTUP_MSG: 
datanode_2  | 2019-10-14 14:18:00,366 [main] INFO       - STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_2  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
scm_1       | 2019-10-14 14:17:59,628 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 53c9678395ac/172.18.0.5
scm_1       | /************************************************************
datanode_2  | STARTUP_MSG:   host = 67e44db53542/172.18.0.6
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_3  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   host = d9db5b12c94a/172.18.0.3
datanode_3  | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   args = [--init]
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_1  | 2019-10-14 14:17:59,629 [main] INFO       - STARTUP_MSG: 
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | /************************************************************
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.3
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | STARTUP_MSG:   java = 11.0.3
datanode_2  | ************************************************************/
datanode_1  | STARTUP_MSG:   host = 7ea411c4428c/172.18.0.4
scm_1       | STARTUP_MSG:   java = 11.0.3
datanode_3  | ************************************************************/
datanode_1  | STARTUP_MSG:   args = []
datanode_2  | 2019-10-14 14:18:00,386 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | ************************************************************/
om_1        | 2019-10-14 14:17:59,014 [main] INFO       - STARTUP_MSG: 
datanode_1  | STARTUP_MSG:   version = 3.2.0
scm_1       | 2019-10-14 14:17:59,635 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2019-10-14 14:18:00,661 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | /************************************************************
datanode_3  | 2019-10-14 14:18:02,784 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_2  | 2019-10-14 14:18:00,814 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_3  | 2019-10-14 14:18:03,117 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | 2019-10-14 14:17:59,858 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2019-10-14 14:18:00,815 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1        | STARTUP_MSG:   host = 41dd508d0601/172.18.0.2
datanode_3  | 2019-10-14 14:18:03,302 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | STARTUP_MSG:   java = 11.0.3
datanode_2  | 2019-10-14 14:18:00,975 [main] INFO       - HddsDatanodeService host:67e44db53542 ip:172.18.0.6
om_1        | STARTUP_MSG:   args = [--init]
scm_1       | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-c388cba4-f7ad-45b0-a816-e58618f2e72d
datanode_1  | ************************************************************/
datanode_3  | 2019-10-14 14:18:03,302 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2019-10-14 14:18:01,011 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
om_1        | STARTUP_MSG:   version = 3.2.0
scm_1       | 2019-10-14 14:18:00,859 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_3  | 2019-10-14 14:18:03,494 [main] INFO       - HddsDatanodeService host:53c9678395ac ip:172.18.0.5
datanode_1  | 2019-10-14 14:17:59,644 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2019-10-14 14:18:01,013 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
scm_1       | /************************************************************
datanode_3  | 2019-10-14 14:18:03,540 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_2  | 2019-10-14 14:18:01,021 [main] INFO       - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1199fe66
datanode_1  | 2019-10-14 14:17:59,951 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at d9db5b12c94a/172.18.0.3
datanode_3  | 2019-10-14 14:18:03,542 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2019-10-14 14:18:00,108 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | STARTUP_MSG:   java = 11.0.3
scm_1       | ************************************************************/
datanode_2  | 2019-10-14 14:18:01,041 [main] INFO       - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1199fe66
datanode_3  | 2019-10-14 14:18:03,550 [main] INFO       - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1199fe66
datanode_1  | 2019-10-14 14:18:00,109 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1        | ************************************************************/
scm_1       | 2019-10-14 14:18:03,404 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_2  | 2019-10-14 14:18:02,998 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2019-10-14 14:18:03,583 [main] INFO       - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1199fe66
om_1        | 2019-10-14 14:17:59,023 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | /************************************************************
datanode_1  | 2019-10-14 14:18:00,483 [main] INFO       - HddsDatanodeService host:7ea411c4428c ip:172.18.0.4
datanode_2  | 2019-10-14 14:18:03,031 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2019-10-14 14:18:04,492 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  | 2019-10-14 14:18:00,526 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_2  | 2019-10-14 14:18:03,210 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2019-10-14 14:18:04,521 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om_1        | 2019-10-14 14:18:00,391 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.2:9862
scm_1       | STARTUP_MSG:   host = d9db5b12c94a/172.18.0.3
datanode_1  | 2019-10-14 14:18:00,529 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2019-10-14 14:18:03,212 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_3  | 2019-10-14 14:18:04,659 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
scm_1       | STARTUP_MSG:   args = []
om_1        | 2019-10-14 14:18:00,392 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_1  | 2019-10-14 14:18:00,537 [main] INFO       - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1199fe66
datanode_2  | 2019-10-14 14:18:03,214 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-14 14:18:04,660 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
scm_1       | STARTUP_MSG:   version = 3.2.0
om_1        | 2019-10-14 14:18:00,399 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-14 14:18:00,561 [main] INFO       - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1199fe66
datanode_2  | 2019-10-14 14:18:03,215 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_3  | 2019-10-14 14:18:04,662 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
om_1        | 2019-10-14 14:18:01,609 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:02,610 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2019-10-14 14:18:03,215 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_3  | 2019-10-14 14:18:04,663 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2019-10-14 14:18:02,613 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:02,642 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2019-10-14 14:18:03,384 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-14 14:18:04,663 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | 2019-10-14 14:18:03,614 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:02,794 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2019-10-14 14:18:03,574 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2019-10-14 14:18:04,804 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2019-10-14 14:18:04,615 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | STARTUP_MSG:   java = 11.0.3
datanode_1  | 2019-10-14 14:18:02,795 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_2  | 2019-10-14 14:18:03,607 INFO util.log: Logging initialized @4096ms
datanode_3  | 2019-10-14 14:18:04,968 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | ************************************************************/
datanode_1  | 2019-10-14 14:18:02,797 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-14 14:18:04,990 INFO util.log: Logging initialized @3981ms
datanode_2  | 2019-10-14 14:18:03,721 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2019-10-14 14:18:05,617 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:02,798 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2019-10-14 14:18:03,414 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2019-10-14 14:18:05,068 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-14 14:18:03,724 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1        | 2019-10-14 14:18:06,618 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:02,799 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-14 14:18:03,653 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2019-10-14 14:18:03,732 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2019-10-14 14:18:05,071 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1        | 2019-10-14 14:18:07,619 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:02,972 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-14 14:18:03,667 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2019-10-14 14:18:03,733 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2019-10-14 14:18:05,079 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2019-10-14 14:18:03,116 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | 2019-10-14 14:18:03,698 INFO util.log: Logging initialized @1171ms
datanode_2  | 2019-10-14 14:18:03,733 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2019-10-14 14:18:05,081 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2019-10-14 14:18:03,144 INFO util.log: Logging initialized @4483ms
om_1        | 2019-10-14 14:18:08,620 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,807 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
datanode_2  | 2019-10-14 14:18:03,734 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2019-10-14 14:18:05,081 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2019-10-14 14:18:03,289 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2019-10-14 14:18:09,621 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,808 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
datanode_2  | 2019-10-14 14:18:03,751 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3  | 2019-10-14 14:18:05,081 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2019-10-14 14:18:03,293 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1        | 2019-10-14 14:18:10,622 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,808 INFO db.DBStoreBuilder: using custom profile for table: validCerts
datanode_2  | 2019-10-14 14:18:03,757 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2019-10-14 14:18:05,101 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1  | 2019-10-14 14:18:03,303 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
om_1        | 2019-10-14 14:18:10,627 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
scm_1       | 2019-10-14 14:18:03,808 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
datanode_2  | 2019-10-14 14:18:03,759 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3  | 2019-10-14 14:18:05,108 INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2019-10-14 14:18:03,306 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
om_1        | 2019-10-14 14:18:16,632 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,809 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
datanode_3  | 2019-10-14 14:18:05,109 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1  | 2019-10-14 14:18:03,306 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2019-10-14 14:18:17,633 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,809 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
datanode_3  | 2019-10-14 14:18:05,134 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@50fb33a{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-10-14 14:18:03,783 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@60c8a093{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2019-10-14 14:18:03,306 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2019-10-14 14:18:18,634 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,824 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_3  | 2019-10-14 14:18:05,135 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20b9d5d5{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2019-10-14 14:18:03,784 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@75d982d3{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2019-10-14 14:18:03,332 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1        | 2019-10-14 14:18:19,635 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,825 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_3  | 2019-10-14 14:18:05,213 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@9b9a327{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-2644194515315833593.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_2  | 2019-10-14 14:18:03,862 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@a96d56c{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-8018072861776756128.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1        | 2019-10-14 14:18:20,636 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:03,827 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_3  | 2019-10-14 14:18:05,221 INFO server.AbstractConnector: Started ServerConnector@f52007c{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2019-10-14 14:18:03,871 INFO server.AbstractConnector: Started ServerConnector@16671607{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
om_1        | 2019-10-14 14:18:21,637 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:31,564 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@51c693d
datanode_1  | 2019-10-14 14:18:03,342 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2019-10-14 14:18:05,221 INFO server.Server: Started @4212ms
om_1        | 2019-10-14 14:18:22,638 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:03,872 INFO server.Server: Started @4360ms
scm_1       | 2019-10-14 14:18:31,567 INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_1  | 2019-10-14 14:18:03,344 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3  | 2019-10-14 14:18:05,223 INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2019-10-14 14:18:23,639 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:31,665 INFO node.SCMNodeManager: Entering startup safe mode.
datanode_1  | 2019-10-14 14:18:03,383 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@60c8a093{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2019-10-14 14:18:05,224 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2019-10-14 14:18:03,876 INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2019-10-14 14:18:31,779 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om_1        | 2019-10-14 14:18:24,640 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,386 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@75d982d3{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2019-10-14 14:18:05,226 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
scm_1       | 2019-10-14 14:18:31,790 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2019-10-14 14:18:25,641 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:03,876 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2019-10-14 14:18:03,477 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@a96d56c{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-1350265628750905825.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_3  | 2019-10-14 14:18:05,236 INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2019-10-14 14:18:40,423 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
om_1        | 2019-10-14 14:18:25,643 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
datanode_2  | 2019-10-14 14:18:03,878 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_1  | 2019-10-14 14:18:03,486 INFO server.AbstractConnector: Started ServerConnector@54db056b{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2019-10-14 14:18:05,368 [Datanode State Machine Thread - 0] INFO       - DatanodeDetails is persisted to /data/datanode.id
scm_1       | 2019-10-14 14:18:40,426 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2019-10-14 14:18:31,646 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:03,889 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2019-10-14 14:18:08,306 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:50,581 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
om_1        | 2019-10-14 14:18:32,647 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:04,044 [Datanode State Machine Thread - 0] INFO       - DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2019-10-14 14:18:09,307 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,487 INFO server.Server: Started @4826ms
scm_1       | 2019-10-14 14:18:53,526 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2019-10-14 14:18:33,648 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:06,949 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,490 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2019-10-14 14:18:10,308 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,554 INFO ipc.Server: Starting Socket Reader #1 for port 9861
om_1        | 2019-10-14 14:18:34,649 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:07,951 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,490 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2019-10-14 14:18:11,309 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,599 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2019-10-14 14:18:35,650 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:08,952 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:12,310 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,600 INFO ipc.Server: Starting Socket Reader #1 for port 9863
om_1        | 2019-10-14 14:18:36,652 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:09,953 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,492 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
scm_1       | 2019-10-14 14:18:53,617 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2019-10-14 14:18:13,312 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:37,653 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:10,954 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,506 INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2019-10-14 14:18:53,618 INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_3  | 2019-10-14 14:18:14,313 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:38,654 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:11,955 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:03,659 [Datanode State Machine Thread - 0] INFO       - DatanodeDetails is persisted to /data/datanode.id
scm_1       | 2019-10-14 14:18:53,701 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_3  | 2019-10-14 14:18:15,314 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:39,655 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:12,955 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:06,583 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,822 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-10-14 14:18:16,315 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:13,956 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:40,656 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:07,584 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,839 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
datanode_3  | 2019-10-14 14:18:17,316 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:14,957 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:40,658 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
datanode_1  | 2019-10-14 14:18:08,585 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,847 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2019-10-14 14:18:18,317 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:15,958 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:09,585 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:46,660 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,849 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
datanode_3  | 2019-10-14 14:18:19,318 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:16,959 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:10,586 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:47,661 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,849 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2019-10-14 14:18:20,319 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:17,960 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:11,587 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:48,662 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,849 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2019-10-14 14:18:21,320 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:18,961 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:12,589 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,870 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1        | 2019-10-14 14:18:49,663 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:13,590 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:22,321 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,877 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_2  | 2019-10-14 14:18:19,962 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:50,665 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:14,591 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:23,322 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,941 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2019-10-14 14:18:20,963 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:15,592 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:51,666 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,992 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2019-10-14 14:18:21,964 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:24,323 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:16,593 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:52,667 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:53,992 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_2  | 2019-10-14 14:18:22,965 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:25,324 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:17,594 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:53,668 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,217 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_2  | 2019-10-14 14:18:23,966 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:18,595 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:26,325 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c388cba4-f7ad-45b0-a816-e58618f2e72d
scm_1       | 2019-10-14 14:18:54,217 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-10-14 14:18:24,966 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:27,326 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:56,377 [shutdown-hook-0] INFO       - SHUTDOWN_MSG: 
datanode_1  | 2019-10-14 14:18:19,596 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:25,968 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,217 INFO ipc.Server: IPC Server listener on 9860: starting
datanode_3  | 2019-10-14 14:18:28,327 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | /************************************************************
datanode_2  | 2019-10-14 14:18:26,969 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,220 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_1  | 2019-10-14 14:18:20,597 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at 41dd508d0601/172.18.0.2
datanode_2  | 2019-10-14 14:18:27,970 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:21,598 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,220 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_3  | 2019-10-14 14:18:29,328 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | ************************************************************/
datanode_2  | 2019-10-14 14:18:28,971 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:22,599 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,221 INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2019-10-14 14:18:30,329 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:57,534 [main] INFO       - STARTUP_MSG: 
datanode_2  | 2019-10-14 14:18:29,972 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:23,600 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,221 INFO ipc.Server: IPC Server listener on 9863: starting
datanode_3  | 2019-10-14 14:18:31,330 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | /************************************************************
datanode_2  | 2019-10-14 14:18:30,973 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:24,602 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,223 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_3  | 2019-10-14 14:18:32,331 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_2  | 2019-10-14 14:18:31,975 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:25,603 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,223 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_3  | 2019-10-14 14:18:33,332 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | STARTUP_MSG:   host = 41dd508d0601/172.18.0.2
datanode_2  | 2019-10-14 14:18:32,976 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:26,604 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:34,333 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,224 INFO ipc.Server: IPC Server Responder: starting
om_1        | STARTUP_MSG:   args = []
datanode_2  | 2019-10-14 14:18:33,977 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:27,605 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:35,334 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,224 INFO ipc.Server: IPC Server listener on 9861: starting
datanode_2  | 2019-10-14 14:18:34,978 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2019-10-14 14:18:28,606 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:36,336 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,229 INFO http.HttpServer2: Jetty bound to port 9876
datanode_2  | 2019-10-14 14:18:35,979 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-201fc85-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_1  | 2019-10-14 14:18:29,608 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:37,337 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,231 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-14 14:18:36,980 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | 2019-10-14 14:18:30,609 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:38,338 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,276 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6ae7deac{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-10-14 14:18:37,983 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 31 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | STARTUP_MSG:   java = 11.0.3
datanode_1  | 2019-10-14 14:18:31,610 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:39,339 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 31 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,277 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@21fdfefc{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2019-10-14 14:18:38,984 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 32 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | ************************************************************/
datanode_1  | 2019-10-14 14:18:32,611 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:40,341 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 32 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:54,839 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@35d5ac51{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-2859337191568028313.dir/webapp/,AVAILABLE}{/scm}
datanode_2  | 2019-10-14 14:18:39,985 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 33 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:57,543 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2019-10-14 14:18:33,612 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:41,342 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 33 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:42,343 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 34 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:40,986 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 34 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:58,485 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.2:9862
datanode_1  | 2019-10-14 14:18:34,614 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:43,344 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 35 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:41,987 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 35 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:55,324 WARN ipc.Server: IPC Server handler 0 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.4:56380: output error
om_1        | 2019-10-14 14:18:58,486 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_1  | 2019-10-14 14:18:35,615 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:44,345 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 36 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:42,988 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 36 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:55,326 INFO server.AbstractConnector: Started ServerConnector@5d21202d{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
om_1        | 2019-10-14 14:18:58,491 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-14 14:18:36,616 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:43,989 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 37 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:45,345 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 37 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:55,327 INFO server.Server: Started @52799ms
om_1        | 2019-10-14 14:18:58,501 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-14 14:18:37,617 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 31 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:44,990 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 38 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:46,346 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 38 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-10-14 14:18:55,328 INFO ipc.Server: IPC Server handler 0 on 9861 caught an exception
om_1        | 2019-10-14 14:18:59,285 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-14 14:18:38,618 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 32 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:45,991 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 39 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:47,348 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 39 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,308 INFO util.log: Logging initialized @2588ms
datanode_2  | 2019-10-14 14:18:46,992 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 40 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:48,348 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 40 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,400 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_1  | 2019-10-14 14:18:39,620 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 33 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | java.nio.channels.AsynchronousCloseException
datanode_2  | 2019-10-14 14:18:47,993 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 41 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:49,350 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 41 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,401 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_1  | 2019-10-14 14:18:40,621 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 34 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:48,994 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 42 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_3  | 2019-10-14 14:18:50,351 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 42 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,401 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_1  | 2019-10-14 14:18:41,622 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 35 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:49,995 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 43 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
datanode_3  | 2019-10-14 14:18:51,352 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 43 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:42,623 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 36 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,401 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
datanode_2  | 2019-10-14 14:18:50,996 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 44 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
datanode_3  | 2019-10-14 14:18:52,353 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 44 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:43,624 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 37 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,402 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_2  | 2019-10-14 14:18:51,997 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 45 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
datanode_3  | 2019-10-14 14:18:53,354 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 45 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:44,625 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 38 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,402 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
datanode_2  | 2019-10-14 14:18:52,998 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 46 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
datanode_3  | 2019-10-14 14:18:54,355 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 46 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-14 14:18:45,626 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 39 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,402 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_2  | 2019-10-14 14:18:53,999 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 47 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
datanode_3  | 2019-10-14 14:18:56,373 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
datanode_1  | 2019-10-14 14:18:46,627 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 40 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,402 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
datanode_2  | 2019-10-14 14:18:56,374 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
datanode_3  | 2019-10-14 14:18:56,375 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_1  | 2019-10-14 14:18:47,628 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 41 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-14 14:18:59,403 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
datanode_3  | 2019-10-14 14:18:56,376 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 0e742648-ed9c-42ab-b1c0-9d96dc7964bb at port 9858
datanode_2  | 2019-10-14 14:18:56,376 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
om_1        | 2019-10-14 14:18:59,404 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_1  | 2019-10-14 14:18:48,630 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 42 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
datanode_3  | 2019-10-14 14:18:56,399 INFO impl.RaftServerProxy: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start RPC server
om_1        | 2019-10-14 14:18:59,404 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
datanode_1  | 2019-10-14 14:18:49,631 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 43 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-10-14 14:18:56,377 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 8bcb0729-02d2-4799-b948-e7e95afde7be at port 9858
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
om_1        | 2019-10-14 14:18:59,404 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
datanode_1  | 2019-10-14 14:18:50,632 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 44 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-14 14:18:56,497 INFO server.GrpcService: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 2019-10-14 14:18:59,404 INFO db.DBStoreBuilder: using custom profile for table: s3Table
datanode_1  | 2019-10-14 14:18:51,633 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 45 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | WARNING: An illegal reflective access operation has occurred
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 2019-10-14 14:18:56,405 INFO impl.RaftServerProxy: 8bcb0729-02d2-4799-b948-e7e95afde7be: start RPC server
om_1        | 2019-10-14 14:18:59,404 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
datanode_1  | 2019-10-14 14:18:52,634 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 46 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 2019-10-14 14:18:56,529 INFO server.GrpcService: 8bcb0729-02d2-4799-b948-e7e95afde7be: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
om_1        | 2019-10-14 14:18:59,405 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
datanode_1  | 2019-10-14 14:18:53,635 INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 47 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2  | WARNING: An illegal reflective access operation has occurred
om_1        | 2019-10-14 14:18:59,405 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1  | 2019-10-14 14:18:54,651 [Datanode State Machine Thread - 0] ERROR      - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_2  | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
om_1        | 2019-10-14 14:18:59,405 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
datanode_3  | WARNING: All illegal access operations will be denied in a future release
scm_1       | 2019-10-14 14:18:55,332 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | java.net.SocketTimeoutException: Call From 7ea411c4428c/172.18.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:56380 remote=scm/172.18.0.3:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
om_1        | 2019-10-14 14:18:59,405 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
datanode_3  | 2019-10-14 14:18:59,438 INFO impl.RaftServerProxy: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: addNew group-50B6D54616C0:[0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858] returns group-50B6D54616C0:java.util.concurrent.CompletableFuture@5ac0ab57[Not completed]
scm_1       | 2019-10-14 14:18:55,332 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | 2019-10-14 14:18:59,405 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
datanode_3  | 2019-10-14 14:18:59,453 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: new RaftServerImpl for group-50B6D54616C0:[0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858] with ContainerStateMachine:uninitialized
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm_1       | 2019-10-14 14:18:55,335 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
datanode_2  | WARNING: All illegal access operations will be denied in a future release
om_1        | 2019-10-14 14:18:59,406 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
datanode_3  | 2019-10-14 14:18:59,454 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm_1       | 2019-10-14 14:18:55,342 INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2019-10-14 14:18:59,406 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
datanode_2  | 2019-10-14 14:18:58,897 INFO impl.RaftServerProxy: 8bcb0729-02d2-4799-b948-e7e95afde7be: addNew group-5381537FE24E:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858] returns group-5381537FE24E:java.util.concurrent.CompletableFuture@68b295ac[Not completed]
datanode_3  | 2019-10-14 14:18:59,455 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm_1       | 2019-10-14 14:18:57,238 INFO net.NetworkTopology: Added a new node: /default-rack/3d9b4a76-0eed-49bb-8f19-814727d1fbec
om_1        | 2019-10-14 14:18:59,406 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
datanode_2  | 2019-10-14 14:18:58,914 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be: new RaftServerImpl for group-5381537FE24E:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2019-10-14 14:18:59,455 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm_1       | 2019-10-14 14:18:57,239 INFO node.SCMNodeManager: Registered Data node : 3d9b4a76-0eed-49bb-8f19-814727d1fbec{ip: 172.18.0.4, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 2019-10-14 14:18:59,417 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_2  | 2019-10-14 14:18:58,915 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2019-10-14 14:18:59,455 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1       | 2019-10-14 14:18:57,241 INFO net.NetworkTopology: Added a new node: /default-rack/0e742648-ed9c-42ab-b1c0-9d96dc7964bb
om_1        | 2019-10-14 14:18:59,417 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_2  | 2019-10-14 14:18:58,915 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2019-10-14 14:18:59,456 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2019-10-14 14:18:57,242 INFO node.SCMNodeManager: Registered Data node : 0e742648-ed9c-42ab-b1c0-9d96dc7964bb{ip: 172.18.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 2019-10-14 14:18:59,418 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_2  | 2019-10-14 14:18:58,915 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-10-14 14:18:59,462 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: ConfigurationManager, init=-1: [0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 2019-10-14 14:18:57,245 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
om_1        | 2019-10-14 14:18:59,741 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_2  | 2019-10-14 14:18:58,916 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2019-10-14 14:18:59,463 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-14 14:18:57,246 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-14 14:18:59,749 INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_2  | 2019-10-14 14:18:58,916 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-14 14:18:59,468 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2019-10-14 14:18:57,246 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-14 14:18:59,784 [main] INFO       - OzoneManager RPC server is listening at om/172.18.0.2:9862
datanode_2  | 2019-10-14 14:18:58,923 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: ConfigurationManager, init=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-14 14:18:59,469 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2ba88d09-f357-4aec-ba42-50b6d54616c0 does not exist. Creating ...
scm_1       | 2019-10-14 14:18:57,282 INFO net.NetworkTopology: Added a new node: /default-rack/8bcb0729-02d2-4799-b948-e7e95afde7be
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-14 14:18:59,860 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2019-10-14 14:18:58,923 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-14 14:18:59,477 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2ba88d09-f357-4aec-ba42-50b6d54616c0/in_use.lock acquired by nodename 7@53c9678395ac
scm_1       | 2019-10-14 14:18:57,282 INFO node.SCMNodeManager: Registered Data node : 8bcb0729-02d2-4799-b948-e7e95afde7be{ip: 172.18.0.6, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-14 14:18:59,900 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2019-10-14 14:18:58,928 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2019-10-14 14:18:59,492 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2ba88d09-f357-4aec-ba42-50b6d54616c0 has been successfully formatted.
scm_1       | WARNING: An illegal reflective access operation has occurred
datanode_1  | 	at com.sun.proxy.$Proxy35.submitRequest(Unknown Source)
om_1        | 2019-10-14 14:18:59,900 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode_2  | 2019-10-14 14:18:58,929 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/5a871f72-ae9e-4597-af96-5381537fe24e does not exist. Creating ...
datanode_3  | 2019-10-14 14:18:59,496 [pool-8-thread-1] INFO       - group-50B6D54616C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
om_1        | 2019-10-14 14:18:59,954 INFO ipc.Server: IPC Server listener on 9862: starting
datanode_2  | 2019-10-14 14:18:58,946 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5a871f72-ae9e-4597-af96-5381537fe24e/in_use.lock acquired by nodename 7@67e44db53542
datanode_3  | 2019-10-14 14:18:59,497 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
om_1        | 2019-10-14 14:18:59,954 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-10-14 14:18:58,962 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/5a871f72-ae9e-4597-af96-5381537fe24e has been successfully formatted.
datanode_3  | 2019-10-14 14:18:59,500 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | 2019-10-14 14:18:59,982 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
datanode_2  | 2019-10-14 14:18:58,966 [pool-8-thread-1] INFO       - group-5381537FE24E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_3  | 2019-10-14 14:18:59,509 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2019-10-14 14:19:00,097 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-14 14:18:58,966 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1       | 2019-10-14 14:18:58,547 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3ae447cb-a3ab-4f8c-87f9-063b96bc73a4, Nodes: 3d9b4a76-0eed-49bb-8f19-814727d1fbec{ip: 172.18.0.4, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 2019-10-14 14:18:59,509 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2019-10-14 14:19:00,099 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_2  | 2019-10-14 14:18:58,968 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2019-10-14 14:18:59,133 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 5a871f72-ae9e-4597-af96-5381537fe24e, Nodes: 8bcb0729-02d2-4799-b948-e7e95afde7be{ip: 172.18.0.6, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_3  | 2019-10-14 14:18:59,512 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 2019-10-14 14:19:00,106 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2019-10-14 14:18:58,972 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2019-10-14 14:18:59,660 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2ba88d09-f357-4aec-ba42-50b6d54616c0, Nodes: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb{ip: 172.18.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_3  | 2019-10-14 14:18:59,514 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 2019-10-14 14:19:00,108 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
scm_1       | 2019-10-14 14:18:59,762 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 4176e589-eb89-436c-9073-62623b696642, Nodes: 3d9b4a76-0eed-49bb-8f19-814727d1fbec{ip: 172.18.0.4, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}8bcb0729-02d2-4799-b948-e7e95afde7be{ip: 172.18.0.6, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}0e742648-ed9c-42ab-b1c0-9d96dc7964bb{ip: 172.18.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2019-10-14 14:18:59,519 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1        | 2019-10-14 14:19:00,108 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2019-10-14 14:18:58,973 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-14 14:19:13,364 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 26264310-633d-4ff0-bdb3-d22a591164c8, Nodes: 8bcb0729-02d2-4799-b948-e7e95afde7be{ip: 172.18.0.6, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2019-10-14 14:18:59,552 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2019-10-14 14:19:00,108 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2019-10-14 14:18:58,974 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-14 14:19:59,982 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2019-10-14 14:18:59,558 INFO segmented.SegmentedRaftLogWorker: new 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2ba88d09-f357-4aec-ba42-50b6d54616c0
om_1        | 2019-10-14 14:19:00,126 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2  | 2019-10-14 14:18:58,976 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
scm_1       | 2019-10-14 14:19:59,984 INFO block.BlockManagerImpl: Deleting blocks conID: 4 locID: 102961169911513213 bcsId: 0
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:56380 remote=scm/172.18.0.3:9861]
datanode_3  | 2019-10-14 14:18:59,558 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1        | 2019-10-14 14:19:00,128 INFO http.HttpServer2: Jetty bound to port 9874
datanode_2  | 2019-10-14 14:18:58,980 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2019-10-14 14:19:59,998 INFO block.BlockManagerImpl: Deleting blocks conID: 5 locID: 102961170725142654 bcsId: 0
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 2019-10-14 14:18:59,558 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1        | 2019-10-14 14:19:00,129 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-14 14:18:59,014 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 2019-10-14 14:18:59,559 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 2019-10-14 14:19:00,163 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44b21f9f{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-10-14 14:18:59,019 INFO segmented.SegmentedRaftLogWorker: new 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/5a871f72-ae9e-4597-af96-5381537fe24e
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
om_1        | 2019-10-14 14:19:00,164 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c601d50{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2019-10-14 14:18:59,560 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 2019-10-14 14:18:59,019 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-10-14 14:18:59,560 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
om_1        | 2019-10-14 14:19:00,238 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@28f4f300{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-15366409867461523179.dir/webapp/,AVAILABLE}{/ozoneManager}
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 2019-10-14 14:18:59,020 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2019-10-14 14:18:59,560 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2019-10-14 14:19:00,244 INFO server.AbstractConnector: Started ServerConnector@24aaa639{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 2019-10-14 14:18:59,021 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-14 14:18:59,561 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2019-10-14 14:19:00,244 INFO server.Server: Started @3524ms
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 2019-10-14 14:18:59,021 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2019-10-14 14:18:59,561 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2019-10-14 14:19:00,247 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 2019-10-14 14:18:59,022 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
om_1        | 2019-10-14 14:19:00,247 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2019-10-14 14:18:59,562 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_2  | 2019-10-14 14:18:59,022 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2019-10-14 14:19:00,249 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_3  | 2019-10-14 14:18:59,570 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 2019-10-14 14:18:59,023 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2019-10-14 14:19:13,050 [IPC Server handler 1 on 9862] INFO       - created volume:vol-0-21234 for user:hadoop
datanode_3  | 2019-10-14 14:18:59,574 INFO segmented.SegmentedRaftLogWorker: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_2  | 2019-10-14 14:18:59,023 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2019-10-14 14:19:13,082 [IPC Server handler 2 on 9862] INFO       - created volume:vol-1-76818 for user:hadoop
datanode_3  | 2019-10-14 14:18:59,578 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_2  | 2019-10-14 14:18:59,023 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-10-14 14:18:59,578 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-10-14 14:19:13,090 [IPC Server handler 4 on 9862] INFO       - created volume:vol-2-77983 for user:hadoop
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_2  | 2019-10-14 14:18:59,032 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-14 14:18:59,579 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-10-14 14:18:56,373 [Datanode State Machine Thread - 1] INFO       - Attempting to start container services.
datanode_2  | 2019-10-14 14:18:59,037 INFO segmented.SegmentedRaftLogWorker: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2019-10-14 14:19:13,097 [IPC Server handler 7 on 9862] INFO       - created volume:vol-3-91374 for user:hadoop
datanode_3  | 2019-10-14 14:18:59,579 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2019-10-14 14:18:56,376 [Datanode State Machine Thread - 1] INFO       - Background container scanner has been disabled.
datanode_2  | 2019-10-14 14:18:59,041 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2019-10-14 14:18:59,600 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: start as a follower, conf=-1: [0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858], old=null
om_1        | 2019-10-14 14:19:13,105 [IPC Server handler 8 on 9862] INFO       - created volume:vol-4-92915 for user:hadoop
datanode_1  | 2019-10-14 14:18:56,376 [Datanode State Machine Thread - 1] INFO       - Starting XceiverServerRatis 3d9b4a76-0eed-49bb-8f19-814727d1fbec at port 9858
datanode_2  | 2019-10-14 14:18:59,042 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2019-10-14 14:18:59,601 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-14 14:19:27,000 [IPC Server handler 3 on 9862] INFO       - created volume:bxmfo for user:hadoop
datanode_1  | 2019-10-14 14:18:56,408 INFO impl.RaftServerProxy: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start RPC server
datanode_2  | 2019-10-14 14:18:59,042 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2019-10-14 14:18:59,602 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start FollowerState
datanode_1  | 2019-10-14 14:18:56,521 INFO server.GrpcService: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2019-10-14 14:18:59,043 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2019-10-14 14:18:59,605 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-50B6D54616C0,id=0e742648-ed9c-42ab-b1c0-9d96dc7964bb
datanode_1  | WARNING: An illegal reflective access operation has occurred
datanode_2  | 2019-10-14 14:18:59,068 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: start as a follower, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858], old=null
datanode_3  | 2019-10-14 14:18:59,712 INFO impl.RaftServerProxy: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: addNew group-62623B696642:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] returns group-62623B696642:java.util.concurrent.CompletableFuture@6b5cd57e[Not completed]
datanode_1  | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_2  | 2019-10-14 14:18:59,069 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2019-10-14 14:18:59,715 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: new RaftServerImpl for group-62623B696642:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
datanode_2  | 2019-10-14 14:18:59,070 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start FollowerState
datanode_3  | 2019-10-14 14:18:59,716 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | 2019-10-14 14:18:59,074 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5381537FE24E,id=8bcb0729-02d2-4799-b948-e7e95afde7be
datanode_3  | 2019-10-14 14:18:59,716 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-10-14 14:18:59,701 INFO impl.RaftServerProxy: 8bcb0729-02d2-4799-b948-e7e95afde7be: addNew group-62623B696642:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] returns group-62623B696642:java.util.concurrent.CompletableFuture@6641486e[Not completed]
datanode_3  | 2019-10-14 14:18:59,716 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-10-14 14:18:58,148 INFO impl.RaftServerProxy: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: addNew group-063B96BC73A4:[3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] returns group-063B96BC73A4:java.util.concurrent.CompletableFuture@11d47fbd[Not completed]
datanode_2  | 2019-10-14 14:18:59,703 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be: new RaftServerImpl for group-62623B696642:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2019-10-14 14:18:59,716 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2019-10-14 14:18:58,166 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: new RaftServerImpl for group-063B96BC73A4:[3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2019-10-14 14:18:59,716 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-14 14:18:58,168 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-10-14 14:18:59,703 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2019-10-14 14:18:59,717 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: ConfigurationManager, init=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2019-10-14 14:18:58,168 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2019-10-14 14:18:59,717 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2019-10-14 14:18:59,703 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2019-10-14 14:18:58,168 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-10-14 14:18:59,717 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2019-10-14 14:18:58,169 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2019-10-14 14:18:59,717 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642 does not exist. Creating ...
datanode_1  | 2019-10-14 14:18:58,169 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-14 14:18:59,733 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642/in_use.lock acquired by nodename 7@53c9678395ac
datanode_2  | 2019-10-14 14:18:59,703 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-10-14 14:18:58,175 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: ConfigurationManager, init=-1: [3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-14 14:18:59,737 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642 has been successfully formatted.
datanode_2  | 2019-10-14 14:18:59,704 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2019-10-14 14:18:58,175 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-14 14:18:59,738 [pool-8-thread-1] INFO       - group-62623B696642: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2019-10-14 14:18:59,704 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-14 14:18:59,738 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-10-14 14:18:58,179 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-10-14 14:18:59,704 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: ConfigurationManager, init=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2019-10-14 14:18:58,181 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3ae447cb-a3ab-4f8c-87f9-063b96bc73a4 does not exist. Creating ...
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2019-10-14 14:18:59,705 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2019-10-14 14:18:58,268 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3ae447cb-a3ab-4f8c-87f9-063b96bc73a4/in_use.lock acquired by nodename 7@7ea411c4428c
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2019-10-14 14:18:59,706 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2019-10-14 14:18:58,305 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3ae447cb-a3ab-4f8c-87f9-063b96bc73a4 has been successfully formatted.
datanode_2  | 2019-10-14 14:18:59,706 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642 does not exist. Creating ...
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-14 14:18:58,311 [pool-8-thread-1] INFO       - group-063B96BC73A4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2019-10-14 14:18:59,720 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642/in_use.lock acquired by nodename 7@67e44db53542
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2019-10-14 14:18:58,311 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-10-14 14:18:59,733 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642 has been successfully formatted.
datanode_1  | 2019-10-14 14:18:58,314 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2019-10-14 14:18:59,734 [pool-8-thread-1] INFO       - group-62623B696642: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-14 14:18:58,322 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2019-10-14 14:18:59,739 INFO segmented.SegmentedRaftLogWorker: new 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642
datanode_2  | 2019-10-14 14:18:59,734 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-10-14 14:18:58,322 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-14 14:18:59,734 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2019-10-14 14:18:58,325 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-14 14:18:59,734 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-14 14:18:59,739 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2019-10-14 14:18:58,327 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-14 14:18:59,740 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2019-10-14 14:18:58,335 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2019-10-14 14:18:59,740 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2019-10-14 14:18:59,735 INFO segmented.SegmentedRaftLogWorker: new 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642
datanode_3  | 2019-10-14 14:18:59,740 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2019-10-14 14:18:58,382 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-10-14 14:18:59,740 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-10-14 14:18:58,388 INFO segmented.SegmentedRaftLogWorker: new 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3ae447cb-a3ab-4f8c-87f9-063b96bc73a4
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2019-10-14 14:18:59,740 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2019-10-14 14:18:58,388 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-14 14:18:59,740 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2019-10-14 14:18:58,389 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2019-10-14 14:18:59,740 INFO segmented.SegmentedRaftLogWorker: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2019-10-14 14:18:58,390 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-14 14:18:59,735 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2019-10-14 14:18:58,390 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2019-10-14 14:18:58,391 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-10-14 14:18:59,736 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2019-10-14 14:18:58,391 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-10-14 14:18:58,393 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-10-14 14:18:59,736 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2019-10-14 14:18:58,393 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-10-14 14:18:59,748 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: start as a follower, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_2  | 2019-10-14 14:18:59,736 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-10-14 14:18:58,393 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-10-14 14:18:59,748 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-10-14 14:18:59,736 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2019-10-14 14:18:58,404 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-14 14:18:59,748 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start FollowerState
datanode_1  | 2019-10-14 14:18:58,409 INFO segmented.SegmentedRaftLogWorker: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2019-10-14 14:18:59,736 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-14 14:18:59,748 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-62623B696642,id=0e742648-ed9c-42ab-b1c0-9d96dc7964bb
datanode_1  | 2019-10-14 14:18:58,413 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2019-10-14 14:18:59,736 INFO segmented.SegmentedRaftLogWorker: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2019-10-14 14:19:04,699 INFO impl.FollowerState: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0-FollowerState: change to CANDIDATE, lastRpcTime:5097ms, electionTimeout:5097ms
datanode_1  | 2019-10-14 14:18:58,413 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-10-14 14:18:59,737 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2019-10-14 14:19:04,702 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: shutdown FollowerState
datanode_1  | 2019-10-14 14:18:58,414 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2019-10-14 14:18:59,737 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2019-10-14 14:19:04,703 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2019-10-14 14:18:58,414 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-10-14 14:18:59,737 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2019-10-14 14:19:04,707 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start LeaderElection
datanode_1  | 2019-10-14 14:18:58,434 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: start as a follower, conf=-1: [3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_2  | 2019-10-14 14:18:59,737 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2019-10-14 14:19:04,722 INFO impl.LeaderElection: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0-LeaderElection1: begin an election at term 1 for -1: [0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858], old=null
datanode_1  | 2019-10-14 14:18:58,435 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-10-14 14:18:59,743 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: start as a follower, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_3  | 2019-10-14 14:19:04,724 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: shutdown LeaderElection
datanode_1  | 2019-10-14 14:18:58,436 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start FollowerState
datanode_2  | 2019-10-14 14:18:59,744 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2019-10-14 14:19:04,725 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2019-10-14 14:18:58,440 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-063B96BC73A4,id=3d9b4a76-0eed-49bb-8f19-814727d1fbec
datanode_2  | 2019-10-14 14:18:59,744 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start FollowerState
datanode_3  | 2019-10-14 14:19:04,725 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: change Leader from null to 0e742648-ed9c-42ab-b1c0-9d96dc7964bb at term 1 for becomeLeader, leader elected after 5228ms
datanode_1  | 2019-10-14 14:18:59,714 INFO impl.RaftServerProxy: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: addNew group-62623B696642:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] returns group-62623B696642:java.util.concurrent.CompletableFuture@4417c02d[Not completed]
datanode_2  | 2019-10-14 14:18:59,744 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-62623B696642,id=8bcb0729-02d2-4799-b948-e7e95afde7be
datanode_3  | 2019-10-14 14:19:04,731 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2019-10-14 14:18:59,719 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: new RaftServerImpl for group-62623B696642:[8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2019-10-14 14:19:04,101 INFO impl.FollowerState: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E-FollowerState: change to CANDIDATE, lastRpcTime:5030ms, electionTimeout:5030ms
datanode_3  | 2019-10-14 14:19:04,731 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2019-10-14 14:18:59,719 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-10-14 14:19:04,103 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: shutdown FollowerState
datanode_3  | 2019-10-14 14:19:04,736 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2019-10-14 14:18:59,720 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2019-10-14 14:19:04,103 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2019-10-14 14:19:04,740 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1  | 2019-10-14 14:18:59,720 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_2  | 2019-10-14 14:19:04,106 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start LeaderElection
datanode_3  | 2019-10-14 14:19:04,740 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2019-10-14 14:18:59,720 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2019-10-14 14:19:04,121 INFO impl.LeaderElection: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E-LeaderElection1: begin an election at term 1 for -1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858], old=null
datanode_3  | 2019-10-14 14:19:04,741 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-10-14 14:18:59,720 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2019-10-14 14:19:04,122 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: shutdown LeaderElection
datanode_3  | 2019-10-14 14:19:04,756 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start LeaderState
datanode_1  | 2019-10-14 14:18:59,720 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: ConfigurationManager, init=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2019-10-14 14:19:04,123 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2019-10-14 14:19:04,777 INFO segmented.SegmentedRaftLogWorker: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-10-14 14:18:59,721 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2019-10-14 14:19:04,123 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: change Leader from null to 8bcb0729-02d2-4799-b948-e7e95afde7be at term 1 for becomeLeader, leader elected after 5157ms
datanode_3  | 2019-10-14 14:19:04,787 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0: set configuration 0: [0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858], old=null at 0
datanode_1  | 2019-10-14 14:18:59,721 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-10-14 14:19:04,128 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2019-10-14 14:19:04,817 INFO impl.FollowerState: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-FollowerState: change to CANDIDATE, lastRpcTime:5068ms, electionTimeout:5068ms
datanode_1  | 2019-10-14 14:18:59,721 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642 does not exist. Creating ...
datanode_2  | 2019-10-14 14:19:04,128 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2019-10-14 14:19:04,817 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: shutdown FollowerState
datanode_1  | 2019-10-14 14:18:59,735 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642/in_use.lock acquired by nodename 7@7ea411c4428c
datanode_2  | 2019-10-14 14:19:04,132 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2019-10-14 14:18:59,740 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642 has been successfully formatted.
datanode_3  | 2019-10-14 14:19:04,817 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2019-10-14 14:19:04,135 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1  | 2019-10-14 14:18:59,740 [pool-8-thread-1] INFO       - group-62623B696642: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2019-10-14 14:19:04,136 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2019-10-14 14:19:04,817 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start LeaderElection
datanode_1  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_2  | 2019-10-14 14:19:04,136 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2019-10-14 14:19:04,839 INFO impl.LeaderElection: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-LeaderElection2: begin an election at term 1 for -1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2019-10-14 14:19:04,147 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start LeaderState
datanode_3  | 2019-10-14 14:19:04,885 INFO segmented.SegmentedRaftLogWorker: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-50B6D54616C0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2ba88d09-f357-4aec-ba42-50b6d54616c0/current/log_inprogress_0
datanode_1  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2019-10-14 14:19:04,168 INFO segmented.SegmentedRaftLogWorker: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2019-10-14 14:19:05,051 INFO impl.LeaderElection: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-LeaderElection2: Election REJECTED; received 2 response(s) [0e742648-ed9c-42ab-b1c0-9d96dc7964bb<-8bcb0729-02d2-4799-b948-e7e95afde7be#0:FAIL-t1, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb<-3d9b4a76-0eed-49bb-8f19-814727d1fbec#0:FAIL-t1] and 0 exception(s); 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642:t1, leader=null, voted=0e742648-ed9c-42ab-b1c0-9d96dc7964bb, raftlog=0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2019-10-14 14:19:04,176 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E: set configuration 0: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858], old=null at 0
datanode_3  | 2019-10-14 14:19:05,053 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1  | 2019-10-14 14:18:59,741 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-14 14:19:04,275 INFO segmented.SegmentedRaftLogWorker: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-5381537FE24E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5a871f72-ae9e-4597-af96-5381537fe24e/current/log_inprogress_0
datanode_3  | 2019-10-14 14:19:05,053 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: shutdown LeaderElection
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-10-14 14:19:04,869 INFO impl.FollowerState: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-FollowerState: change to CANDIDATE, lastRpcTime:5125ms, electionTimeout:5125ms
datanode_3  | 2019-10-14 14:19:05,054 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start FollowerState
datanode_1  | 2019-10-14 14:18:59,742 INFO segmented.SegmentedRaftLogWorker: new 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642
datanode_2  | 2019-10-14 14:19:04,870 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: shutdown FollowerState
datanode_3  | 2019-10-14 14:19:10,169 INFO impl.FollowerState: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-FollowerState: change to CANDIDATE, lastRpcTime:5114ms, electionTimeout:5114ms
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-14 14:19:04,870 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2019-10-14 14:19:10,169 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: shutdown FollowerState
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-14 14:19:04,870 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start LeaderElection
datanode_3  | 2019-10-14 14:19:10,169 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-14 14:19:04,885 INFO impl.LeaderElection: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-LeaderElection2: begin an election at term 1 for -1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_3  | 2019-10-14 14:19:10,169 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start LeaderElection
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-10-14 14:19:05,052 INFO impl.LeaderElection: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-LeaderElection2: Election REJECTED; received 2 response(s) [8bcb0729-02d2-4799-b948-e7e95afde7be<-0e742648-ed9c-42ab-b1c0-9d96dc7964bb#0:FAIL-t1, 8bcb0729-02d2-4799-b948-e7e95afde7be<-3d9b4a76-0eed-49bb-8f19-814727d1fbec#0:FAIL-t1] and 0 exception(s); 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642:t1, leader=null, voted=8bcb0729-02d2-4799-b948-e7e95afde7be, raftlog=8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_3  | 2019-10-14 14:19:10,183 INFO impl.LeaderElection: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-LeaderElection3: begin an election at term 2 for -1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3  | 2019-10-14 14:19:10,220 INFO impl.LeaderElection: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-LeaderElection3: Election REJECTED; received 2 response(s) [0e742648-ed9c-42ab-b1c0-9d96dc7964bb<-8bcb0729-02d2-4799-b948-e7e95afde7be#0:FAIL-t2, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb<-3d9b4a76-0eed-49bb-8f19-814727d1fbec#0:FAIL-t2] and 0 exception(s); 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642:t2, leader=null, voted=0e742648-ed9c-42ab-b1c0-9d96dc7964bb, raftlog=0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_2  | 2019-10-14 14:19:05,054 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1  | 2019-10-14 14:18:59,742 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2019-10-14 14:19:10,221 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
datanode_2  | 2019-10-14 14:19:05,054 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: shutdown LeaderElection
datanode_1  | 2019-10-14 14:18:59,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2019-10-14 14:19:10,221 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: shutdown LeaderElection
datanode_2  | 2019-10-14 14:19:05,054 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start FollowerState
datanode_1  | 2019-10-14 14:18:59,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-10-14 14:19:10,221 INFO impl.RoleInfo: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb: start FollowerState
datanode_2  | 2019-10-14 14:19:10,184 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:3d9b4a76-0eed-49bb-8f19-814727d1fbec
datanode_1  | 2019-10-14 14:18:59,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-10-14 14:19:10,274 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: change Leader from null to 3d9b4a76-0eed-49bb-8f19-814727d1fbec at term 2 for appendEntries, leader elected after 10535ms
datanode_2  | 2019-10-14 14:19:10,185 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: shutdown FollowerState
datanode_1  | 2019-10-14 14:18:59,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-14 14:19:10,296 INFO impl.RaftServerImpl: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642: set configuration 0: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null at 0
datanode_2  | 2019-10-14 14:19:10,185 INFO impl.RoleInfo: 8bcb0729-02d2-4799-b948-e7e95afde7be: start FollowerState
datanode_3  | 2019-10-14 14:19:10,296 INFO segmented.SegmentedRaftLogWorker: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2019-10-14 14:19:10,185 INFO impl.FollowerState: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2019-10-14 14:19:10,333 INFO segmented.SegmentedRaftLogWorker: 0e742648-ed9c-42ab-b1c0-9d96dc7964bb@group-62623B696642-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642/current/log_inprogress_0
datanode_2  | 2019-10-14 14:19:10,278 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: change Leader from null to 3d9b4a76-0eed-49bb-8f19-814727d1fbec at term 2 for appendEntries, leader elected after 10544ms
datanode_1  | 2019-10-14 14:18:59,743 INFO segmented.SegmentedRaftLogWorker: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2019-10-14 14:19:35,683 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_2  | 2019-10-14 14:19:10,296 INFO impl.RaftServerImpl: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642: set configuration 0: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null at 0
datanode_1  | 2019-10-14 14:18:59,744 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2019-10-14 14:19:10,296 INFO segmented.SegmentedRaftLogWorker: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-10-14 14:18:59,744 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-10-14 14:19:10,333 INFO segmented.SegmentedRaftLogWorker: 8bcb0729-02d2-4799-b948-e7e95afde7be@group-62623B696642-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642/current/log_inprogress_0
datanode_1  | 2019-10-14 14:18:59,744 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2019-10-14 14:19:47,774 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-10-14 14:18:59,744 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2019-10-14 14:18:59,751 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: start as a follower, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:18:59,751 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2019-10-14 14:18:59,751 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start FollowerState
datanode_1  | 2019-10-14 14:18:59,751 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-62623B696642,id=3d9b4a76-0eed-49bb-8f19-814727d1fbec
datanode_1  | 2019-10-14 14:19:03,636 INFO impl.FollowerState: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4-FollowerState: change to CANDIDATE, lastRpcTime:5199ms, electionTimeout:5199ms
datanode_1  | 2019-10-14 14:19:03,638 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: shutdown FollowerState
datanode_1  | 2019-10-14 14:19:03,638 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2019-10-14 14:19:03,642 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start LeaderElection
datanode_1  | 2019-10-14 14:19:03,658 INFO impl.LeaderElection: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4-LeaderElection1: begin an election at term 1 for -1: [3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:19:03,660 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: shutdown LeaderElection
datanode_1  | 2019-10-14 14:19:03,660 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2019-10-14 14:19:03,661 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: change Leader from null to 3d9b4a76-0eed-49bb-8f19-814727d1fbec at term 1 for becomeLeader, leader elected after 5349ms
datanode_1  | 2019-10-14 14:19:03,665 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2019-10-14 14:19:03,666 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2019-10-14 14:19:03,670 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2019-10-14 14:19:03,674 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1  | 2019-10-14 14:19:03,674 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2019-10-14 14:19:03,675 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-10-14 14:19:03,688 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start LeaderState
datanode_1  | 2019-10-14 14:19:03,710 INFO segmented.SegmentedRaftLogWorker: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-10-14 14:19:03,722 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4: set configuration 0: [3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null at 0
datanode_1  | 2019-10-14 14:19:03,833 INFO segmented.SegmentedRaftLogWorker: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-063B96BC73A4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3ae447cb-a3ab-4f8c-87f9-063b96bc73a4/current/log_inprogress_0
datanode_1  | 2019-10-14 14:19:04,887 INFO impl.FollowerState: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-FollowerState: change to CANDIDATE, lastRpcTime:5136ms, electionTimeout:5136ms
datanode_1  | 2019-10-14 14:19:04,888 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: shutdown FollowerState
datanode_1  | 2019-10-14 14:19:04,888 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2019-10-14 14:19:04,888 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start LeaderElection
datanode_1  | 2019-10-14 14:19:04,901 INFO impl.LeaderElection: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-LeaderElection2: begin an election at term 1 for -1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:19:05,069 INFO impl.LeaderElection: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-LeaderElection2: Election REJECTED; received 2 response(s) [3d9b4a76-0eed-49bb-8f19-814727d1fbec<-8bcb0729-02d2-4799-b948-e7e95afde7be#0:FAIL-t1, 3d9b4a76-0eed-49bb-8f19-814727d1fbec<-0e742648-ed9c-42ab-b1c0-9d96dc7964bb#0:FAIL-t1] and 0 exception(s); 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642:t1, leader=null, voted=3d9b4a76-0eed-49bb-8f19-814727d1fbec, raftlog=3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:19:05,070 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1  | 2019-10-14 14:19:05,070 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: shutdown LeaderElection
datanode_1  | 2019-10-14 14:19:05,071 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start FollowerState
datanode_1  | 2019-10-14 14:19:10,147 INFO impl.FollowerState: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-FollowerState: change to CANDIDATE, lastRpcTime:5076ms, electionTimeout:5076ms
datanode_1  | 2019-10-14 14:19:10,148 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: shutdown FollowerState
datanode_1  | 2019-10-14 14:19:10,148 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1  | 2019-10-14 14:19:10,148 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start LeaderElection
datanode_1  | 2019-10-14 14:19:10,163 INFO impl.LeaderElection: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-LeaderElection3: begin an election at term 2 for -1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:19:10,205 INFO impl.LeaderElection: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-LeaderElection3: Election PASSED; received 2 response(s) [3d9b4a76-0eed-49bb-8f19-814727d1fbec<-8bcb0729-02d2-4799-b948-e7e95afde7be#0:OK-t2, 3d9b4a76-0eed-49bb-8f19-814727d1fbec<-0e742648-ed9c-42ab-b1c0-9d96dc7964bb#0:FAIL-t2] and 0 exception(s); 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642:t2, leader=null, voted=3d9b4a76-0eed-49bb-8f19-814727d1fbec, raftlog=3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null
datanode_1  | 2019-10-14 14:19:10,205 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: shutdown LeaderElection
datanode_1  | 2019-10-14 14:19:10,206 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_1  | 2019-10-14 14:19:10,206 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: change Leader from null to 3d9b4a76-0eed-49bb-8f19-814727d1fbec at term 2 for becomeLeader, leader elected after 10465ms
datanode_1  | 2019-10-14 14:19:10,206 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2019-10-14 14:19:10,207 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2019-10-14 14:19:10,207 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2019-10-14 14:19:10,207 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1  | 2019-10-14 14:19:10,207 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2019-10-14 14:19:10,207 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-10-14 14:19:10,213 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2019-10-14 14:19:10,213 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-14 14:19:10,214 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2019-10-14 14:19:10,216 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2019-10-14 14:19:10,217 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-10-14 14:19:10,217 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-14 14:19:10,218 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2019-10-14 14:19:10,218 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-14 14:19:10,218 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2019-10-14 14:19:10,218 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2019-10-14 14:19:10,218 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-10-14 14:19:10,218 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-14 14:19:10,220 INFO impl.RoleInfo: 3d9b4a76-0eed-49bb-8f19-814727d1fbec: start LeaderState
datanode_1  | 2019-10-14 14:19:10,220 INFO segmented.SegmentedRaftLogWorker: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-10-14 14:19:10,221 INFO impl.RaftServerImpl: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642: set configuration 0: [8bcb0729-02d2-4799-b948-e7e95afde7be:172.18.0.6:9858, 0e742648-ed9c-42ab-b1c0-9d96dc7964bb:172.18.0.5:9858, 3d9b4a76-0eed-49bb-8f19-814727d1fbec:172.18.0.4:9858], old=null at 0
datanode_1  | 2019-10-14 14:19:10,267 INFO segmented.SegmentedRaftLogWorker: 3d9b4a76-0eed-49bb-8f19-814727d1fbec@group-62623B696642-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4176e589-eb89-436c-9073-62623b696642/current/log_inprogress_0
datanode_1  | 2019-10-14 14:20:00,141 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-10-14 14:20:12,807 WARN client.GrpcClientProtocolService: 1-OrderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
